{"meta":{"title":"Kayleh","subtitle":"","description":"Kayleh","author":"Kayleh","url":"https://kayleh.top","root":"/"},"pages":[],"posts":[{"title":"jsdelivr的CDN加速缓存不刷新问题","slug":"关于CDN加速缓存不刷新的解决","date":"2020-08-20T06:20:58.000Z","updated":"2020-08-20T06:25:55.790Z","comments":true,"path":"2020/08/20/关于CDN加速缓存不刷新的解决/","link":"","permalink":"https://kayleh.top/2020/08/20/%E5%85%B3%E4%BA%8ECDN%E5%8A%A0%E9%80%9F%E7%BC%93%E5%AD%98%E4%B8%8D%E5%88%B7%E6%96%B0%E7%9A%84%E8%A7%A3%E5%86%B3/","excerpt":"","text":"The CDN acceleration cache of jsdelivr does not refresh访问链接即可解决 具体： 把链接中的 https://cdn.jsdelivr.net替换成 https://purge.jsdelivr.net访问即可实时刷新","categories":[],"tags":[{"name":"maintain","slug":"maintain","permalink":"https://kayleh.top/tags/maintain/"}]},{"title":"SpringCloud Alibaba","slug":"分布式的微服务架构9","date":"2020-08-19T12:25:56.000Z","updated":"2020-08-20T06:21:43.159Z","comments":true,"path":"2020/08/19/分布式的微服务架构9/","link":"","permalink":"https://kayleh.top/2020/08/19/%E5%88%86%E5%B8%83%E5%BC%8F%E7%9A%84%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%849/","excerpt":"SpringCloud Alibaba","text":"SpringCloud Alibaba Spring Cloud Netflix项目进入维护模式 SpringCloud NetFlix Projects Entering Maintenance Mode 什么是维护模式 进入维护模式意味着什么呢？ SpringCloud alibaba带来了什么？ 能干吗 去哪下？ https://github.com/alibaba/spring-cloud-alibaba/blob/master/README-zh.md 怎么用？ Sentinel：把流量作为切入点，从流量控制、熔断降级、系统负载保护等多个维度保护服务的稳定性。 Nacos：一个更易于构建云原生应用的动态服务发现、配置管理和服务管理平台。 RocketMQ：一款开源的分布式消息系统，基于高可用分布式集群技术，提供低延时的、高可靠的消息发布与订阅服务。 Dubbo：Apache Dubbo™ 是一款高性能 Java RPC 框架。 Seata：阿里巴巴开源产品，一个易于使用的高性能微服务分布式事务解决方案。 Alibaba Cloud ACM：一款在分布式架构环境中对应用配置进行集中管理和推送的应用配置中心产品。 Alibaba Cloud OSS: 阿里云对象存储服务（Object Storage Service，简称 OSS），是阿里云提供的海量、安全、低成本、高可靠的云存储服务。您可以在任何应用、任何时间、任何地点存储和访问任意类型的数据。 Alibaba Cloud SchedulerX: 阿里中间件团队开发的一款分布式任务调度产品，提供秒级、精准、高可靠、高可用的定时（基于 Cron 表达式）任务调度服务。 Alibaba Cloud SMS: 覆盖全球的短信服务，友好、高效、智能的互联化通讯能力，帮助企业迅速搭建客户触达通道。 资料获取官网 中文： https://github.com/alibaba/spring-cloud-alibaba/blob/master/README-zh.md","categories":[{"name":"分布式","slug":"分布式","permalink":"https://kayleh.top/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"}],"tags":[{"name":"DistributedMicroservices","slug":"DistributedMicroservices","permalink":"https://kayleh.top/tags/DistributedMicroservices/"}]},{"title":"维护3","slug":"maintain3","date":"2020-08-19T11:24:00.000Z","updated":"2020-08-19T11:59:22.763Z","comments":true,"path":"2020/08/19/maintain3/","link":"","permalink":"https://kayleh.top/2020/08/19/maintain3/","excerpt":"优化网站，DNS均衡负载","text":"优化网站，DNS均衡负载 ①kayleh.top Coding + Netlify + Github + Gitee 四线部署 国内： kayleh.gitee.io 国际： dqlcr5.coding-pages.com(香港服务器) ​ kayleh.netlify.app ​ kayleh.github.io ② 添加右下角看板娘功能，为程序员鼓励师。 ③ 网站实现 HTTP —&gt; HTTPS 由Netlify 实现的SSL证书，由 Let’s Encrypt 颁发。 也可以使用阿里云的Apache的SSL证书。 ④ 解决了HTTPS跨域问题 百度的分享功能失效，并且样式消失，导致加载资源时控制台报错 报错内容为：no-referrer-when-downgrade ，指的是升级https后调用低级http的API接口的问题， 解决方法为 百度分享资源 保存到网站的source目录下，调用本地资源 ⑤修改了爬虫规则robot.txt 1https:&#x2F;&#x2F;kayleh.top&#x2F;robots.txt 123456789101112# hexo robots.txtUser-agent: *Allow: &#x2F;Allow: &#x2F;archives&#x2F;Disallow: &#x2F;vendors&#x2F;Disallow: &#x2F;js&#x2F;Disallow: &#x2F;css&#x2F;Disallow: &#x2F;fonts&#x2F;Disallow: &#x2F;vendors&#x2F;Disallow: &#x2F;fancybox&#x2F;Sitemap: http:&#x2F;&#x2F;www.kayleh.top&#x2F;sitemap.xmlSitemap: http:&#x2F;&#x2F;www.kayleh.top&#x2F;baidusitemap.xml ⑥评论框架更换为，Valine+leancloud实现，免去登录才能评论的麻烦 ⑦添加daovoice实时通讯功能 ⑧CDN静态资源优化 网站加载静态资源过慢，采用CDN加速。 由jsdelivr实现，CDN访问Github仓库资源， 1https:&#x2F;&#x2F;cdn.jsdelivr.net&#x2F;gh&#x2F;kayleh&#x2F;cdn@1.0&#x2F; ⑨提交Bing收录","categories":[],"tags":[{"name":"maintain","slug":"maintain","permalink":"https://kayleh.top/tags/maintain/"}]},{"title":"SpringCloud Sleuth分布式请求链路追踪","slug":"分布式的微服务架构8","date":"2020-08-19T09:52:50.000Z","updated":"2020-08-20T06:18:50.092Z","comments":true,"path":"2020/08/19/分布式的微服务架构8/","link":"","permalink":"https://kayleh.top/2020/08/19/%E5%88%86%E5%B8%83%E5%BC%8F%E7%9A%84%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%848/","excerpt":"SpringCloud Sleuth分布式请求链路追踪","text":"SpringCloud Sleuth分布式请求链路追踪 为什么会出现这个技术？需要解决哪些问题？ Spring Cloud Sleuth提供了一套完整的服务跟踪的解决方案 在分布式系统中提供追踪解决方案并且兼容支持了zipkin 解决 zipkin下载 SpringCloud从F版起已不需要自己构建Zipkin server了，只需要调用jar包即可 https://dl.bintray.com/openzipkin/maven/io/zipkin/java/zipkin-server/ zipkin-server-2.12.9.exec.jar 运行jar java -jar zipkin-server-2.12.9-exec.jar 运行控制台 http://localhost:9411/zipkin/ 完整的调用链路 Trace:类似于树结构的Span集合，表示一条调用链路，存在唯一标识 span:表示调用链路来源，通俗的理解span就是一次请求信息 服务提供者cloud-provider-payment8001 pom 12345&lt;!--包含了sleuth+zipkin--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-zipkin&lt;/artifactId&gt; &lt;/dependency&gt; yaml 123456789101112131415161718192021222324252627282930313233server: port: 8001spring: application: name: cloud-payment-service zipkin: base-url: http://localhost:9411 sleuth: sampler: probability: 1 datasource: type: com.alibaba.druid.pool.DruidDataSource driver-class-name: org.gjt.mm.mysql.Driver url: username: root password: mybatis: mapperLocations: classpath:mapper/*.xml type-aliases-package: com.kayleh.springcloud.entitieseureka: client: register-with-eureka: true fetchRegistry: true service-url: defaultZone: http://eureka7001.com:7001/eureka,http://eureka7002.com:7002/eureka #集群版 instance: instance-id: payment8001 prefer-ip-address: true 业务类OrderController 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192package com.kayleh.springcloud.controller; import com.kayleh.springcloud.entities.CommonResult;import com.kayleh.springcloud.entities.Payment;import com.kayleh.springcloud.service.PaymentService;import lombok.extern.slf4j.Slf4j;import org.springframework.beans.factory.annotation.Value;import org.springframework.cloud.client.ServiceInstance;import org.springframework.web.bind.annotation.*;import org.springframework.cloud.client.discovery.DiscoveryClient; import javax.annotation.Resource;import java.util.List;import java.util.concurrent.TimeUnit; @RestController@Slf4jpublic class PaymentController&#123; @Resource private PaymentService paymentService; @Value(\"$&#123;server.port&#125;\") private String serverPort; @Resource private DiscoveryClient discoveryClient; @PostMapping(value = \"/payment/create\") public CommonResult create(@RequestBody Payment payment) &#123; int result = paymentService.create(payment); log.info(\"*****插入结果：\"+result); if(result &gt; 0) &#123; return new CommonResult(200,\"插入数据库成功,serverPort: \"+serverPort,result); &#125;else&#123; return new CommonResult(444,\"插入数据库失败\",null); &#125; &#125; @GetMapping(value = \"/payment/get/&#123;id&#125;\") public CommonResult&lt;Payment&gt; getPaymentById(@PathVariable(\"id\") Long id) &#123; Payment payment = paymentService.getPaymentById(id); if(payment != null) &#123; return new CommonResult(200,\"查询成功,serverPort: \"+serverPort,payment); &#125;else&#123; return new CommonResult(444,\"没有对应记录,查询ID: \"+id,null); &#125; &#125; @GetMapping(value = \"/payment/discovery\") public Object discovery() &#123; List&lt;String&gt; services = discoveryClient.getServices(); for (String element : services) &#123; log.info(\"*****element: \"+element); &#125; List&lt;ServiceInstance&gt; instances = discoveryClient.getInstances(\"CLOUD-PAYMENT-SERVICE\"); for (ServiceInstance instance : instances) &#123; log.info(instance.getServiceId()+\"\\t\"+instance.getHost()+\"\\t\"+instance.getPort()+\"\\t\"+instance.getUri()); &#125; return this.discoveryClient; &#125; @GetMapping(value = \"/payment/lb\") public String getPaymentLB() &#123; return serverPort; &#125; @GetMapping(value = \"/payment/feign/timeout\") public String paymentFeignTimeout() &#123; // 业务逻辑处理正确，但是需要耗费3秒钟 try &#123; TimeUnit.SECONDS.sleep(3); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; return serverPort; &#125; @GetMapping(\"/payment/zipkin\") public String paymentZipkin() &#123; return \"hi ,i'am paymentzipkin server fall back，welcome to kayleh，O(∩_∩)O哈哈~\"; &#125;&#125; 服务消费者（调用方）cloud-consumer-order80 POM 12345&lt;!--包含了sleuth+zipkin--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-zipkin&lt;/artifactId&gt; &lt;/dependency&gt; yml 1234567891011121314151617181920212223server: port: 80 spring: application: name: cloud-order-service zipkin: base-url: http://localhost:9411 sleuth: sampler: probability: 1 eureka: client: #表示是否将自己注册进EurekaServer默认为true。 register-with-eureka: false #是否从EurekaServer抓取已有的注册信息，默认为true。单节点无所谓，集群必须设置为true才能配合ribbon使用负载均衡 fetchRegistry: true service-url: #单机 #defaultZone: http://localhost:7001/eureka # 集群 defaultZone: http://eureka7001.com:7001/eureka,http://eureka7002.com:7002/eureka # 集群版 业务类OrderController 1234567// ====================&gt; zipkin+sleuth @GetMapping(\"/consumer/payment/zipkin\") public String paymentZipkin() &#123; String result = restTemplate.getForObject(\"http://localhost:8001\"+\"/payment/zipkin/\", String.class); return result; &#125; 依次启动eureka7001/8001/8080调用8001几次测试下 打开浏览器访问:http:localhost:9411会出现以下界面 查看 查看依赖关系 原理","categories":[{"name":"分布式","slug":"分布式","permalink":"https://kayleh.top/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"}],"tags":[{"name":"DistributedMicroservices","slug":"DistributedMicroservices","permalink":"https://kayleh.top/tags/DistributedMicroservices/"}]},{"title":"SpringCloud Stream消息驱动","slug":"分布式的微服务架构7","date":"2020-08-14T15:33:07.000Z","updated":"2020-08-20T06:18:42.831Z","comments":true,"path":"2020/08/14/分布式的微服务架构7/","link":"","permalink":"https://kayleh.top/2020/08/14/%E5%88%86%E5%B8%83%E5%BC%8F%E7%9A%84%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%847/","excerpt":"SpringCloud Stream消息驱动","text":"SpringCloud Stream消息驱动 消息驱动概述屏蔽底层消息中间件的差异，降低切换版本，统一消息的编程模型 Spring Cloud Stream中文指导手册 https://m.wang1314.com/doc/webapp/topic/20971999.html 设计思想标准MQ 为什么用Cloud Streamstream凭什么可以统一底层差异 Binder INPUT对应于消费者 OUTPUT对应于生产者 Stream中的消息通信方式遵循了发布-订阅模式Topic主题进行广播 在RabbitMQ就是Exchange 在kafka中就是Topic Spring Cloud Stream标准流程套路 Binder 很方便的连接中间件，屏蔽差异 Channel 通道，是队列Queue的一种抽象，在消息通讯系统中就是实现存储和转发的媒介，通过对Channel对队列进行配置 Source和Sink 简单的可理解为参照对象是Spring Cloud Stream自身，从Stream发布消息就是输出，接受消息就是输入 编码API和常用注解 案例说明RabbitMQ环境已经OK 工程中新建三个子模块 cloud-stream-rabbitmq-provider8801,作为生产者进行发消息模块 cloud-stream-rabbitmq-consumer8802,作为消息接收模块 cloud-stream-rabbitmq-consumer8803,作为消息接收模块 消息驱动之生产者新建Module cloud-stream-rabbitmq-provider8801 pom 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-stream-rabbit&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/org.springframework.cloud/spring-cloud-starter-eureka-server --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.kayleh.springcloud&lt;/groupId&gt; &lt;artifactId&gt;cloud-api-commons&lt;/artifactId&gt; &lt;version&gt;$&#123;project.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/org.springframework.boot/spring-boot-starter-web --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/org.springframework.boot/spring-boot-starter-web --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/org.springframework.boot/spring-boot-devtools --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/org.projectlombok/lombok --&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/org.springframework.boot/spring-boot-starter-test --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt;&lt;/dependencies&gt; yaml 123456789101112131415161718192021222324252627282930313233server: port: 8801spring: application: name: cloud-stream-provider cloud: stream: binders: # 在此处配置要绑定的rabbitmq的服务信息； defaultRabbit: # 表示定义的名称，用于于binding整合 type: rabbit # 消息组件类型 environment: # 设置rabbitmq的相关的环境配置 spring: rabbitmq: host: localhost port: 5672 username: guest password: guest bindings: # 服务的整合处理 output: # 这个名字是一个通道的名称 destination: studyExchange # 表示要使用的Exchange名称定义 content-type: application/json # 设置消息类型，本次为json，文本则设置“text/plain” binder: defaultRabbit # 设置要绑定的消息服务的具体设置eureka: client: # 客户端进行Eureka注册的配置 service-url: defaultZone: http://localhost:7001/eureka instance: lease-renewal-interval-in-seconds: 2 # 设置心跳的时间间隔（默认是30秒） lease-expiration-duration-in-seconds: 5 # 如果现在超过了5秒的间隔（默认是90秒） instance-id: send-8801.com # 在信息列表时显示主机名称 prefer-ip-address: true # 访问的路径变为IP地址 主启动类StreamMQMain8801 1234567891011package com.kayleh.springcloud;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;@SpringBootApplicationpublic class StreamMQMain8801 &#123; public static void main(String[] args) &#123; SpringApplication.run(StreamMQMain8801.class, args); &#125;&#125; 业务类发送消息接口 123456package com.kayleh.springcloud.service;public interface IMessageProvider&#123; public String send();&#125; 发送消息接口实现类 123456789101112131415161718192021222324252627package com.kayleh.springcloud.service.impl;import com.kayleh.springcloud.service.IMessageProvider;import org.springframework.cloud.stream.annotation.EnableBinding;import org.springframework.integration.support.MessageBuilderFactory;import org.springframework.messaging.MessageChannel;import org.springframework.integration.support.MessageBuilder;import javax.annotation.Resource;import org.springframework.cloud.stream.messaging.Source;import javax.annotation.Resource;import java.util.UUID;@EnableBinding(Source.class) //定义消息的推送管道public class MessageProviderImpl implements IMessageProvider&#123; @Resource private MessageChannel output; // 消息发送管道 @Override public String send() &#123; String serial = UUID.randomUUID().toString(); output.send(MessageBuilder.withPayload(serial).build()); System.out.println(\"*****serial: \"+serial); return null; &#125;&#125; Controller 1234567891011121314151617181920package com.kayleh.springcloud.controller;import com.kayleh.springcloud.service.IMessageProvider;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RestController;import javax.annotation.Resource;@RestControllerpublic class SendMessageController&#123; @Resource private IMessageProvider messageProvider; @GetMapping(value = \"/sendMessage\") public String sendMessage() &#123; return messageProvider.send(); &#125;&#125; 测试 启动7001eureka 启动rabbitmq: rabbitmq-plugins enable rabbitmq_management http://localhost:15672/ 启动8801 访问http://localhost:8801/sendMessage 消息驱动之消费者新建Module cloud-stream-rabbitmq-consumer8802 pom 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-stream-rabbit&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/org.springframework.cloud/spring-cloud-starter-eureka-server --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.atguigu.springcloud&lt;/groupId&gt; &lt;artifactId&gt;cloud-api-commons&lt;/artifactId&gt; &lt;version&gt;$&#123;project.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/org.springframework.boot/spring-boot-starter-web --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/org.springframework.boot/spring-boot-starter-web --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/org.springframework.boot/spring-boot-devtools --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/org.projectlombok/lombok --&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/org.springframework.boot/spring-boot-starter-test --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt;&lt;/dependencies&gt; yml 123456789101112131415161718192021222324252627282930313233server: port: 8802spring: application: name: cloud-stream-consumer cloud: stream: binders: # 在此处配置要绑定的rabbitmq的服务信息； defaultRabbit: # 表示定义的名称，用于于binding整合 type: rabbit # 消息组件类型 environment: # 设置rabbitmq的相关的环境配置 spring: rabbitmq: host: localhost port: 5672 username: guest password: guest bindings: # 服务的整合处理 input: # 这个名字是一个通道的名称 destination: studyExchange # 表示要使用的Exchange名称定义 content-type: application/json # 设置消息类型，本次为json，文本则设置“text/plain” binder: defaultRabbit # 设置要绑定的消息服务的具体设置eureka: client: # 客户端进行Eureka注册的配置 service-url: defaultZone: http://localhost:7001/eureka instance: lease-renewal-interval-in-seconds: 2 # 设置心跳的时间间隔（默认是30秒） lease-expiration-duration-in-seconds: 5 # 如果现在超过了5秒的间隔（默认是90秒） instance-id: receive-8802.com # 在信息列表时显示主机名称 prefer-ip-address: true # 访问的路径变为IP地址 主启动类StreamMQMain8802 123456789101112package com.atguigu.springcloud;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;@SpringBootApplicationpublic class StreamMQMain8802 &#123; public static void main(String[] args) &#123; SpringApplication.run(StreamMQMain8802.class, args); &#125;&#125; controller 1234567891011121314151617181920package com.atguigu.springcloud.controller;import org.springframework.cloud.stream.annotation.StreamListener;import org.springframework.messaging.Message;import org.springframework.beans.factory.annotation.Value;import org.springframework.cloud.stream.annotation.EnableBinding;import org.springframework.cloud.stream.messaging.Sink;import org.springframework.stereotype.Component;@Component@EnableBinding(Sink.class)public class ReceiveMessageListenerController &#123; @Value(\"$&#123;server.port&#125;\") private String serverPort; @StreamListener(Sink.INPUT) public void input(Message&lt;String&gt; message) &#123; System.out.println(\"消费者1号，接受：\"+message.getPayload()+\"\\t port:\"+serverPort); &#125;&#125; 测试8801发送8802接收消息 http://localhost:8801/sendMessage 分组消费与持久化依照8802，clone出来一份运行8803cloud-stream-rabbitmq-consumer8803 pom 1234567891011121314151617181920212223242526272829303132333435&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-stream-rabbit&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--基础配置--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; yaml 12345678910111213141516171819202122232425262728293031323334server: port: 8803spring: application: name: cloud-stream-consumer cloud: stream: binders: # 在此处配置要绑定的rabbitmq的服务信息； defaultRabbit: # 表示定义的名称，用于于binding整合 type: rabbit # 消息组件类型 environment: # 设置rabbitmq的相关的环境配置 spring: rabbitmq: host: localhost port: 5672 username: guest password: guest bindings: # 服务的整合处理 input: # 这个名字是一个通道的名称 destination: studyExchange # 表示要使用的Exchange名称定义 content-type: application/json # 设置消息类型，本次为对象json，如果是文本则设置“text/plain” binder: defaultRabbit # 设置要绑定的消息服务的具体设置 group: atguiguAeureka: client: # 客户端进行Eureka注册的配置 service-url: defaultZone: http://localhost:7001/eureka instance: lease-renewal-interval-in-seconds: 2 # 设置心跳的时间间隔（默认是30秒） lease-expiration-duration-in-seconds: 5 # 如果现在超过了5秒的间隔（默认是90秒） instance-id: receive-8803.com # 在信息列表时显示主机名称 prefer-ip-address: true # 访问的路径变为IP地址 主启动类 1234567891011121314package com.atguigu.springcloud;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;@SpringBootApplicationpublic class StreamMQMain8803&#123; public static void main(String[] args) &#123; SpringApplication.run(StreamMQMain8803.class,args); &#125;&#125; 业务类 12345678910111213141516171819202122package com.atguigu.springcloud.controller;import org.springframework.beans.factory.annotation.Value;import org.springframework.cloud.stream.annotation.EnableBinding;import org.springframework.cloud.stream.annotation.StreamListener;import org.springframework.cloud.stream.messaging.Sink;import org.springframework.messaging.Message;import org.springframework.stereotype.Component; @Component@EnableBinding(Sink.class)public class ReceiveMessageListenerController&#123; @Value(\"$&#123;server.port&#125;\") private String serverPort; @StreamListener(Sink.INPUT) public void input(Message&lt;String&gt; message) &#123; System.out.println(\"消费者2号,-----&gt;接受到的消息: \"+message.getPayload()+\"\\t port: \"+serverPort); &#125;&#125; 启动 7001服务注册 8801消息生产 8802消息消费 8803消息消费 运行后两个问题 有重复消费问题 消息持久化问题 消费 目前是8802/8803同时都收到了，存在重复消费问题 http://localhost:8801/sendMessage 如何解决? 分组和持久化属性group 重要 生产实际案例 分组 原理 微服务应用放置于同一个group中，就能够保证消息只会被其中一个应用消费一次。不同的组是可以消费的，同一个组内会发生竞争关系，只有其中一个可以消费。 8802/8803都变成不同组，group两个不同 group: atguiguA、atguiguB 8802修改YML 1group: atguiguA 8803修改YML 1group: atguiguB 我们自己配置 结论 还是重复消费 8802/8803实现了轮询分组，每次只有一个消费者 8801模块的发的消息只能被8802或8803其中一个接收到，这样避免了重复消费 8802/8803都变成相同组，group两个相同 group: atguiguA 8802修改YML 1group: atguiguA 8803修改YML 1group: atguiguA 结论 同一个组的多个微服务实例，每次只会有一个拿到 持久化通过上述，解决了重复消费问题，再看看持久化 停止8802/8803并去除掉8802的分组group:atguiguA 8803的分组group:atguiguA没有去掉 8801先发送4条信息到rabbitmq 先启动8802，无分组属性配置，后台没有打出来消息 先启动8803，有分组属性配置，后台打出来了MQ上的消息","categories":[{"name":"分布式","slug":"分布式","permalink":"https://kayleh.top/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"}],"tags":[{"name":"DistributedMicroservices","slug":"DistributedMicroservices","permalink":"https://kayleh.top/tags/DistributedMicroservices/"}]},{"title":"SpringCloud Bus消息总线","slug":"分布式的微服务架构6","date":"2020-08-14T15:29:28.000Z","updated":"2020-08-20T06:18:31.446Z","comments":true,"path":"2020/08/14/分布式的微服务架构6/","link":"","permalink":"https://kayleh.top/2020/08/14/%E5%88%86%E5%B8%83%E5%BC%8F%E7%9A%84%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%846/","excerpt":"SpringCloud Bus 消息总线","text":"SpringCloud Bus 消息总线 上一讲解的加深和扩充，一言以蔽之 分布式自动刷新配置功能 Spring Cloud Bus配合Spring Cloud Config使用可以实现配置的动态刷新 是什么？ Bus支持两种消息代理：RabbitMQ和Kafka 能干嘛？ 为何被称为总线 RabbitMQ环境配置安装Erlang，下载地址：http://erlang.org/download/otp_win64_21.3.exe 安装RabbitMQ，下载地址 https://dl.bintray.com/rabbitmq/all/rabbitmq-server/3.7.14/rabbitmq-server-3.7.14.exe 进入RabbitMQ安装目录下的sbin目录 如例我自己本机D:\\scmq\\rabbitmq_server-3.7.14\\sbin 输入以下命令启动管理功能 rabbitmq-plugins enable rabbitmq_management 可视化插件 访问地址查看是否安装成功 1http:&#x2F;&#x2F;localhost:15672&#x2F; 输入账号密码并登录: guest guest SpringCloud Bus动态刷新全局广播必须先具备良好的RabbitMQ环境先 演示广播效果，增加复杂度，再以3355为模板再制作一个3366 新建cloud-config-client-3366 pom 123456789101112131415161718192021222324252627282930313233343536373839404142&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-config&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.kayleh.springcloud&lt;/groupId&gt; &lt;artifactId&gt;cloud-api-commons&lt;/artifactId&gt; &lt;version&gt;$&#123;project.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt;&lt;/dependencies&gt; bootstrap.yml 123456789101112131415161718192021server: port: 3366spring: application: name: config-client cloud: config: label: master name: config profile: dev uri: http://localhost:3344eureka: client: service-url: defaultZone: http://eureka7001.com:7001/eurekamanagement: endpoints: web: exposure: include: \"*\" 主启动类 12345678910111213package com.kayleh.springcloud;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.netflix.eureka.EnableEurekaClient;@EnableEurekaClient@SpringBootApplicationpublic class ConfigClientMain3366 &#123; public static void main(String[] args) &#123; SpringApplication.run( ConfigClientMain3366.class,args); &#125;&#125; controller 1234567891011121314151617181920212223package com.kayleh.springcloud.controller;import org.springframework.beans.factory.annotation.Value;import org.springframework.cloud.context.config.annotation.RefreshScope;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RestController;@RestController@RefreshScopepublic class ConfigClientController &#123; @Value(\"$&#123;server.port&#125;\") private String serverPort; @Value(\"$&#123;config.info&#125;\") private String configInfo; @GetMapping(\"/configInfo\") public String getConfigInfo()&#123; return \"serverPort:\"+serverPort+\"\\t\\n\\n configInfo: \"+configInfo; &#125;&#125; 设计思想1) 利用消息总线触发一个客户端/bus/refresh,而刷新所有客户端的配置 2) 利用消息总线触发一个服务端ConfigServer的/bus/refresh端点,而刷新所有客户端的配置（更加推荐） 图二的架构显然更加合适，图一不适合的原因如下打破了微服务的职责单一性，因为微服务本身是业务模块，它本不应该承担配置刷新职责 破坏了微服务各节点的对等性 有一定的局限性。例如，微服务在迁移时，它的网络地址常常会发生变化，此时如果想要做到自动刷新，那就会增加更多的修改 给cloud-config-center-3344配置中心服务端添加消息总线支持pom 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-bus-amqp&lt;/artifactId&gt;&lt;/dependency&gt; yml 123456789101112131415161718192021222324252627282930server: port: 3344spring: application: name: cloud-config-center cloud: config: server: git: uri: https://github.com/hhf19906/springcloud-config.git #git@github.com:hhf19906/springcloud-config.git search-paths: - springcloud-config label: masterrabbitmq: host: localhost port: 5672 username: guest password: guesteureka: client: service-url: defaultZone: http://localhost:7001/eurekamanagement: endpoints: web: exposure: include: 'bus-refresh' 给cloud-config-center-3355客户端添加消息总线支持pom 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-bus-amqp&lt;/artifactId&gt;&lt;/dependency&gt; bootstrap.yml 12345678910111213141516171819202122232425262728server: port: 3355spring: application: name: config-client cloud: config: label: master name: config profile: dev uri: http://localhost:3344rabbitmq: host: localhost port: 5672 username: guest password: guesteureka: client: service-url: defaultZone: http://eureka7001.com:7001/eurekamanagement: endpoints: web: exposure: include: \"*\" 给cloud-config-center-3366客户端添加消息总线支持pom 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-bus-amqp&lt;/artifactId&gt;&lt;/dependency&gt; yml 123456789101112131415161718192021222324252627282930server: port: 3366spring: application: name: config-client cloud: config: label: master name: config profile: dev uri: http://localhost:3344 rabbitmq: host: localhost port: 5672 username: guest password: guesteureka: client: service-url: defaultZone: http://localhost:7001/eurekamanagement: endpoints: web: exposure: include: '*' 测试 运维工程师 修改Github上配置文件增加版本号 发送Post请求 1curl -X POST \"http://localhost:3344/actuator/bus-refresh\" 配置中心 1http://config-3344.com/config-dev.yml 客户端 12http://localhost:3355/configInfohttp://localhost:3366/configInfo 获取配置信息，发现都已经刷新了 一次发送，处处生效 SpringCloud Bus动态刷新定点通知不想全部通知，只想定点通知,只通知3355, 不通知3366 简单一句话. 指定具体某一个实例生效而不是全部 公式：http://localhost:配置中心的端口号/actuator/bus-refresh/{destination} /bus/refresh请求不再发送到具体的服务实例上，而是发给config server并通过destination参数类指定需要更新配置的服务或实例 我们这里以刷新运行在3355端口上的config-client为例. 只通知3355, 不通知3366 1curl -X POST \"http://localhost:3344/actuator/bus-refresh/config-client:3355\" 通知总结All","categories":[{"name":"分布式","slug":"分布式","permalink":"https://kayleh.top/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"}],"tags":[{"name":"DistributedMicroservices","slug":"DistributedMicroservices","permalink":"https://kayleh.top/tags/DistributedMicroservices/"}]},{"title":"SpringCloud config分布式配置中心","slug":"分布式的微服务架构5","date":"2020-08-14T15:26:05.000Z","updated":"2020-08-20T06:18:16.277Z","comments":true,"path":"2020/08/14/分布式的微服务架构5/","link":"","permalink":"https://kayleh.top/2020/08/14/%E5%88%86%E5%B8%83%E5%BC%8F%E7%9A%84%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%845/","excerpt":"SpringCloud config分布式配置中心","text":"SpringCloud config分布式配置中心 分布式系统面临的配置问题 能干嘛？集中管理配置文件 不同环境不同配置，动态化的配置更新，分环境部署比如dev/test/prod/beta/release 运行期间动态调整配置，不再需要在每个服务部署的机器上编写配置文件，服务会向配置中心统一拉取配置自己的信息 当配置发生变动时，服务不需要重启即可感知到配置的变化并应用新的配置 将配置信息以REST接口的形式暴露，post、curl访问刷新均可…. 与Github整合配置由于SpringCloud Config默认使用Git来存储配置文件（也有其它方式，比如支持svn和本地文件，但最推荐的还是Git，而且使用的是http/https访问的形式） Config服务端配置与测试1.用你自己的账号在Github上新建一个名为sprincloud-config的新Repository 2.由上一步获得刚新建的git地址，写你自己的仓库地址 3.本地硬盘上新建git仓库并clone， 本地地址：D:\\44\\SpringCloud2020 git命令 git clone xxx 4.此时在本地D盘符下D:\\44\\SpringCloud2020\\springcloud-config 表示多个环境的配置文件,保存格式必须为UTF-8,如果需要修改， 此处模拟运维人员操作git和github git add git commit -m “init yml” git push origin master 5.新建Module模块cloud-config-center-3344它既为Cloud的配置中心模块cloudConfig Center pom 123456789101112131415161718192021222324252627282930313233343536373839404142&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-server&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.kayleh.springcloud&lt;/groupId&gt; &lt;artifactId&gt;cloud-api-commons&lt;/artifactId&gt; &lt;version&gt;$&#123;project.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt;&lt;/dependencies&gt; yml 1234567891011121314151617181920server: port: 3344spring: application: name: cloud-config-center cloud: config: server: git:# uri: git@github.com:Kayleh/springcloud-config.git #填写你自己的github路径 uri: https://github.com/Kayleh/springcloud-config.git #填写你自己的github路径 search-paths: - springcloud-config username: Kayleh password: #密码 label: mastereureka: client: service-url: defaultZone: http://localhost:7001/eureka 主启动类: @EnableConfigServer 12345678910111213package com.kayleh.springcloud;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.config.server.EnableConfigServer;@SpringBootApplication@EnableConfigServerpublic class ConfigCenterMain3344 &#123; public static void main(String[] args) &#123; SpringApplication.run(ConfigCenterMain3344 .class,args); &#125;&#125; windows下修改hosts文件，增加映射 1127.0.0.1 config-3344.com 测试通过Config微服务是否可以从Github上获取配置内容 启动微服务3344 http://config-3344.com:3344/master/config-dev.yml 配置读取规则 /{label}/{application}-{profile}.yml（最推荐使用这种方式） master分支 http://config-3344.com:3344/master/config-dev.yml http://config-3344.com:3344/master/config-test.yml http://config-3344.com:3344/master/config-prod.yml dev分支 http://config-3344.com:3344/dev/config-dev.yml http://config-3344.com:3344/dev/config-test.yml http://config-3344.com:3344/dev/config-prod.yml /{application}-{profile}.yml http://config-3344.com:3344/config-dev.yml http://config-3344.com:3344/config-test.yml http://config-3344.com:3344/config-prod.yml http://config-3344.com:3344/config-xxxx.yml(不存在的配置) /{application}-{profile}[/{label}] http://config-3344.com:3344/config/dev/master http://config-3344.com:3344/config/test/master http://config-3344.com:3344/config/prod/master 重要配置细节总结 成功实现了用SpringCloud Config 通过GitHub获取配置信息 Config客户端配置与测试新建cloud-config-client-3355 pom 12345678910111213141516171819202122232425262728293031323334353637383940414243&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-config&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.kayleh.springcloud&lt;/groupId&gt; &lt;artifactId&gt;cloud-api-commons&lt;/artifactId&gt; &lt;version&gt;$&#123;project.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; bootstap.yml 是什么? 12345678910111213141516server: port: 3355spring: application: name: config-client cloud: config: label: master name: config profile: dev uri: http://localhost:3344eureka: client: service-url: defaultZone: http://eureka7001.com:7001/eureka 修改config-dev.yml配置并提交到GitHub中，比如加个变量age或者版本号version 主启动类: 1234567891011package com.kayleh.springcloud;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;@SpringBootApplicationpublic class ConfigClientMain3355 &#123; public static void main(String[] args) &#123; SpringApplication.run( ConfigClientMain3355.class,args); &#125;&#125; 业务类 1234567891011121314151617package com.kayleh.springcloud.Controller;import org.springframework.beans.factory.annotation.Value;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RestController;@RestControllerpublic class ConfigClientController &#123; @Value(\"$&#123;config.info&#125;\") private String configInfo; @GetMapping(\"/configInfo\") public String getConfigInfo()&#123; return configInfo; &#125;&#125; 启动Config配置中心3344微服务并自测 12http:&#x2F;&#x2F;config-3344.com:3344&#x2F;master&#x2F;config-dev.ymlhttp:&#x2F;&#x2F;config-3344.com:3344&#x2F;master&#x2F;config-test.yml 启动3355作为Client准备访问 1http:&#x2F;&#x2F;localhost:3355&#x2F;configInfo 成功实现了客户端3355访问SpringCloud Config3344通过GitHub获取配置信息 问题随时而来，分布式配置的动态刷新 Linux运维修改GitHub上的配置文件内容做调整 刷新3344，发现ConfigServer配置中心立刻响应 刷新3355，发现ConfigServer客户端没有任何响应 3355没有变化除非自己重启或者重新加载 难道每次运维修改配置文件，客户端都需要重启？？噩梦 Config客户端之动态刷新避免每次更新配置都要重启客户端微服务3355 修改3355模块 POM引入actuator监控 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt; 修改YML，暴露监控端口 12345678910111213141516171819202122server: port: 3355spring: application: name: config-client cloud: config: label: master name: config profile: dev uri: http://localhost:3344eureka: client: service-url: defaultZone: http://eureka7001.com:7001/eurekamanagement: endpoints: web: exposure: include: \"*\" @RefreshScope业务类Controller修改 12345678910111213141516171819package com.kayleh.springcloud.Controller;import org.springframework.beans.factory.annotation.Value;import org.springframework.cloud.context.config.annotation.RefreshScope;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RestController;@RefreshScope@RestControllerpublic class ConfigClientController &#123; @Value(\"$&#123;config.info&#125;\") private String configInfo; @GetMapping(\"/configInfo\") public String getConfigInfo()&#123; return configInfo; &#125;&#125; 此时修改去github 测试3344 和3355 http://config-3344.com:3344/master/config-dev.yml http://localhost:3355/configInfo 3355没有改变，(只有重启才有效果） 需要运维人员发送Post请求刷新3355,必须是Post请求 1curl -X POST &quot;http:&#x2F;&#x2F;localhost:3355&#x2F;actuator&#x2F;refresh&quot; 再次http://localhost:3355/configInfo 成功实现了客户端3355刷新到最新配置内容,避免了服务的重启 想想还有什么问题？ 假如有多个微服务客户端3355/3366/3377。。。。 每个微服务都要执行一次post请求，手动刷新？ 可否广播，一次通知，处处生效？ 我们想大范围的自动刷新，求方法","categories":[{"name":"分布式","slug":"分布式","permalink":"https://kayleh.top/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"}],"tags":[{"name":"DistributedMicroservices","slug":"DistributedMicroservices","permalink":"https://kayleh.top/tags/DistributedMicroservices/"}]},{"title":"GateWay服务限流","slug":"分布式的微服务架构4","date":"2020-08-14T15:21:47.000Z","updated":"2020-08-20T06:18:06.411Z","comments":true,"path":"2020/08/14/分布式的微服务架构4/","link":"","permalink":"https://kayleh.top/2020/08/14/%E5%88%86%E5%B8%83%E5%BC%8F%E7%9A%84%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%844/","excerpt":"GateWay服务限流","text":"GateWay服务限流 秒杀高并发等操作,严禁一窝蜂的过来拥挤,大家排队,一秒钟N个,有序进行.flowlimit GatewayGateway是在Spring生态系统之上构建的API网关服务，基于Spring 5，Spring Boot 2和 Project Reactor等技术。 Gateway旨在提供一种简单而有效的方式来对API进行路由，以及提供一些强大的过滤器功能，例如：熔断、限流、重试等。 SpringCloud Gateway 使用的是Webflux中的reactor-netty响应式编程组件，底层使用了Netty通讯框架。 Gateway： Gateway的三大核心概念Route(路由)路由是构建网关的基本模块，它由ID，目标URI，一系列的断言和过滤器组成，如果断言为true则匹配该路由。 Predicate（断言）参考的是java8的java.util.function.Predicate开发人员可以匹配HTTP请求中的所有内容（例如请求头或请求参数），如果请求与断言相匹配则进行路由 Filter(过滤)指的是Spring框架中GatewayFilter的实例，使用过滤器，可以在请求被路由前或者之后对请求进行修改。 工作流程 核心逻辑 路由转发+执行过滤器链 新建cloud-gateway-gateway9527 pom(移除了web依赖) 123456789101112131415161718192021222324252627282930313233343536&lt;dependencies&gt; &lt;!--新增gateway--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-gateway&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.kayleh.springcloud&lt;/groupId&gt; &lt;artifactId&gt;cloud-api-commons&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt;&lt;/dependencies&gt; yml 12345678910111213server: port: 9527spring: application: name: cloud-gatewayeureka: instance: hostname: cloud-gateway-service client: service-url: register-with-eureka: true fetch-registry: true defaultZone: http://eureka7001.com:7001/eureka 无业务类 主启动类 12345678package com.kayleh.springcloud;@SpringBootApplication@EnableEurekaClientpublic class GateWayMain9527 &#123; public static void main(String[] args) &#123; SpringApplication.run(GateWayMain9527.class, args); &#125;&#125; 观察cloud-provider-payment8001的controller的get/lb访问路径 目前不想暴露8001端口，希望在8001外面套一层9527 修改pom.xml 123456789101112131415161718192021222324252627server: port: 9527spring: application: name: cloud-gateway cloud: gateway: routes: - id: payment_routh #路由的ID，没有固定规则但要求唯一，建议配合服务名 uri: http://localhost:8001 #匹配后提供服务的路由地址 predicates: - Path=/payment/get/** #断言,路径相匹配的进行路由 - id: payment_routh2 uri: http://localhost:8001 predicates: - Path=/payment/lb/** #断言,路径相匹配的进行路由eureka: instance: hostname: cloud-gateway-service client: #服务提供者注册进eureka服务列表内 service-url: register-with-eureka: true fetch-registry: true defaultZone: http://eureka7001.com:7001/eureka 测试 添加网关前 1http:&#x2F;&#x2F;localhost:8001&#x2F;payment&#x2F;get&#x2F;31 添加网关后 1http:&#x2F;&#x2F;localhost:9527&#x2F;payment&#x2F;get&#x2F;31 除了使用yaml的方法配置还可以使用代码配置：9527 12345678910111213package com.kayleh.springcloud.config;@Configurationpublic class GateWayConfig &#123; @Bean public RouteLocator customRouteLocator(RouteLocatorBuilder routeLocatorBuilder) &#123; RouteLocatorBuilder.Builder routes = routeLocatorBuilder.routes(); routes.route(\"path_rote_kayleh\", r -&gt; r.path(\"/guonei\") .uri(\"http://news.baidu.com/guonei\")).build(); return routes.build(); &#125;&#125; 测试 1http:&#x2F;&#x2F;localhost:9527&#x2F;guonei 通过微服务名实现动态路由默认情况下Gateway会根据注册中心的服务列表，以注册中心上微服务名为路径创建动态路由进行转发，从而实现动态路由的功能 修改yaml 12345678910111213141516171819202122232425262728293031server: port: 9527spring: application: name: cloud-gateway cloud: gateway: discovery: locator: enabled: true #开启从注册中心动态创建路由的功能，利用微服务名进行路由 routes: - id: payment_routh #路由的ID，没有固定规则但要求唯一，建议配合服务名 #uri: http://localhost:8001 #匹配后提供服务的路由地址 uri: lb://cloud-payment-service predicates: - Path=/payment/get/** #断言,路径相匹配的进行路由 - id: payment_routh2 #uri: http://localhost:8001 #匹配后提供服务的路由地址 uri: lb://cloud-payment-service predicates: - Path=/payment/lb/** #断言,路径相匹配的进行路由eureka: instance: hostname: cloud-gateway-service client: service-url: register-with-eureka: true fetch-registry: true defaultZone: http://eureka7001.com:7001/eureka 需要注意的是uri的协议为lb，表示启用Gateway的负载均衡功能。 lb://serviceName是spring cloud gateway在微服务中自动为我们创建的负载均衡uri 测试 1http:&#x2F;&#x2F;localhost:9527&#x2F;payment&#x2F;lb 8001/8002两个端口切换 Predicate的使用 常用的Route PredicateAfter Route Predicate12- After=2020-03-08T10:59:34.102+08:00[Asia/Shanghai]# 在？？？时间后生效 时间可以这样获取： 12ZonedDateTime zbj = ZonedDateTime.now();System.out.println(zbj); Before Route Predicate12- After=2020-03-08T10:59:34.102+08:00[Asia/Shanghai]- Before=2020-03-08T10:59:34.102+08:00[Asia/Shanghai] Between Route Predicate1- Between&#x3D;2020-03-08T10:59:34.102+08:00[Asia&#x2F;Shanghai] , 2020-03-08T10:59:34.102+08:00[Asia&#x2F;Shanghai] Cookie Route Predicate 1- Cookie=username,kayleh #并且Cookie是username=kayleh才能访问 不带cookies访问 12345-&gt; cmdcurl http:&#x2F;&#x2F;localhost:9527&#x2F;payment&#x2F;lbcurl http:&#x2F;&#x2F;localhost:9527&#x2F;payment&#x2F;lb --cookie &quot;username,kayleh&quot; #返回端口号表示访问成功 带上cookies访问 加入curl返回中文乱码 https://blog.csdn.net/leedee/article/details/82685636 Header Route Predicate1- Header=X-Request-Id, \\d+ #请求头中要有X-Request-Id属性并且值为整数的正则表达式 Host Route Predicate1- Host&#x3D;**.atguigu.com Method Route Predicate1- Method&#x3D;GET Path Route PredicateQuery Route Predicate1- Query&#x3D;username, \\d+ #要有参数名称并且是正整数才能路由 测试 12curl http:&#x2F;&#x2F;localhost:9527&#x2F;payment&#x2F;lb?username&#x3D;1curl http:&#x2F;&#x2F;localhost:9527&#x2F;payment&#x2F;lb?username&#x3D;-1 ALL 1234567891011121314151617181920212223242526272829303132333435363738server: port: 9527spring: application: name: cloud-gateway cloud: gateway: discovery: locator: enabled: true #开启从注册中心动态创建路由的功能，利用微服务名进行路由 routes: - id: payment_routh #路由的ID，没有固定规则但要求唯一，建议配合服务名 #uri: http://localhost:8001 #匹配后提供服务的路由地址 uri: lb://cloud-payment-service predicates: - Path=/payment/get/** #断言,路径相匹配的进行路由 - id: payment_routh2 #uri: http://localhost:8001 #匹配后提供服务的路由地址 uri: lb://cloud-payment-service predicates: - Path=/payment/lb/** #断言,路径相匹配的进行路由 #- After=2020-03-08T10:59:34.102+08:00[Asia/Shanghai] #- Cookie=username,zhangshuai #并且Cookie是username=zhangshuai才能访问 #- Header=X-Request-Id, \\d+ #请求头中要有X-Request-Id属性并且值为整数的正则表达式 #- Host=**.atguigu.com #- Method=GET #- Query=username, \\d+ #要有参数名称并且是正整数才能路由 eureka: instance: hostname: cloud-gateway-service client: service-url: register-with-eureka: true fetch-registry: true defaultZone: http://eureka7001.com:7001/eureka 说白了，Predicate就是为了实现一组匹配规则， 让请求过来找到对应的Route进行处理 Filter是什么？ 生命周期pre 在业务逻辑之前 post 在业务逻辑之后 种类GatewayFilter 单一 GlobalFilter 全局 常用的GatewayFilterAddRequestParameter yml： 自定义过滤器自定义全局GlobalFilter两个主要接口介绍impiemerts GlobalFilter ，Ordered 能干嘛全局日志记录 统一网关鉴权 。。。 案例： 1234567891011121314151617181920212223242526272829303132333435package com.kayleh.springcloud.filter;import lombok.extern.slf4j.Slf4j;import org.springframework.cloud.gateway.filter.GatewayFilterChain;import org.springframework.cloud.gateway.filter.GlobalFilter;import org.springframework.core.Ordered;import org.springframework.http.HttpStatus;import org.springframework.stereotype.Component;import org.springframework.util.StringUtils;import org.springframework.web.server.ServerWebExchange;import reactor.core.publisher.Mono;import java.util.Date;@Component@Slf4jpublic class MyLogGateWayFilter implements GlobalFilter,Ordered &#123; @Override public Mono&lt;Void&gt; filter(ServerWebExchange exchange, GatewayFilterChain chain) &#123; log.info(\"*********come in MyLogGateWayFilter: \"+new Date()); String uname = exchange.getRequest().getQueryParams().getFirst(\"username\"); if(StringUtils.isEmpty(username))&#123; log.info(\"*****用户名为Null 非法用户,(┬＿┬)\"); exchange.getResponse().setStatusCode(HttpStatus.NOT_ACCEPTABLE);//给人家一个回应 return exchange.getResponse().setComplete(); &#125; return chain.filter(exchange); &#125; @Override public int getOrder() &#123; return 0; &#125;&#125; 启动： 测试： 12正确：http:&#x2F;&#x2F;localhost:9527&#x2F;payment&#x2F;lb?uname&#x3D;z3错误 http:&#x2F;&#x2F;localhost:9527&#x2F;payment&#x2F;lb","categories":[{"name":"分布式","slug":"分布式","permalink":"https://kayleh.top/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"}],"tags":[{"name":"DistributedMicroservices","slug":"DistributedMicroservices","permalink":"https://kayleh.top/tags/DistributedMicroservices/"}]},{"title":"Ribbon负载均衡服务调用、服务降级","slug":"分布式的微服务架构3","date":"2020-08-14T15:14:13.000Z","updated":"2020-08-20T06:17:34.922Z","comments":true,"path":"2020/08/14/分布式的微服务架构3/","link":"","permalink":"https://kayleh.top/2020/08/14/%E5%88%86%E5%B8%83%E5%BC%8F%E7%9A%84%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%843/","excerpt":"Ribbon负载均衡服务调用、服务降级","text":"Ribbon负载均衡服务调用、服务降级 LB(负载均衡) 集中式LB即在服务的消费方和提供方之间使用独立的LB设施(可以是硬件,如F5,也可以是软件,如nginx),由该设施负责把访问请求通过某种策略转发至服务的提供方. 进程内LB将逻辑集成到消费方,消费方从服务注册中心获知有哪些地址可用,然后自己再从这些地址中选择出一个合适的服务器. Ribbon就属于进程内LB,它只是一个类库,集成于消费方进程,消费方通过它来获取服务提供方的地址. 就是 负载均衡+RestTemplate调用. 负载均衡演示Ribbon其实就是一个软负载均衡的客户端组件,他可以和其他所需请求的客户端结合使用,和eureka结合只是其中的一个实例. 架构: Ribbon工作时分成两步 第一步先选择EurekaServer,它优先选择在同一区域内负载较少的server 第二步再根据用户指定的策略,在从server取到的服务注册列表中选择一个地址. 其中Ribbon提供了多种策略:比如轮询,随机和根据响应时间加权. 新版的eureka整合了Ribbon 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-ribbon&lt;/artifactId&gt;&lt;/dependency&gt; RestTemplate getForObject和getForEntity: 12345678910111213141516@GetMapping(\"/consumer/payment/get/&#123;id&#125;\") public CommonResult&lt;Payment&gt; getPayment(@PathVariable(\"id\") Long id) &#123; return restTemplate.getForObject(PAYMENT_URL + \"/payment/get/\" + id, CommonResult.class); &#125; @GetMapping(\"/consumer/payment/getForEntity/&#123;id&#125;\") public CommonResult&lt;Payment&gt; getPayment2(@PathVariable(\"id\") Long id) &#123; ResponseEntity&lt;CommonResult&gt; entity = restTemplate.getForEntity(PAYMENT_URL + \"/payment/get/\" + id, CommonResult.class); if (entity.getStatusCode().is2xxSuccessful()) &#123; log.info(entity.getStatusCode()+\"\\t\"+entity.getHeaders()); return entity.getBody(); &#125; else &#123; return new CommonResult&lt;&gt;(444,\"操作失败\"); &#125; &#125; IRule：根据特定算法中从服务列表中选取一个要访问的服务 修改cloyud-consumer-order80 @SpringBootApplication里有@ComponentScan注解,不能和主启动类放在同一包下 新建package com.kayleh.myrule 新建MySelfRule 123456789101112131415161718package com.kayleh.myrule;import com.netflix.loadbalancer.IRule;import com.netflix.loadbalancer.RandomRule;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;/** * @Author: Wizard * @Date: 2020/8/7 14:33 */@Configurationpublic class MySelfRule &#123; @Bean public IRule myRule() &#123; return new RandomRule();//定义为随机 &#125;&#125; 主启动类添加@RibbonClient 12345678@SpringBootApplication@EnableEurekaClient@RibbonClient(name = \"CLOUD-PAYMENT-SERVICE\", configuration = MySelfRule.class)public class OrderMain80 &#123; public static void main(String[] args) &#123; SpringApplication.run(OrderMain80.class, args); &#125;&#125; 测试 1http:&#x2F;&#x2F;localhost&#x2F;consumer&#x2F;payment&#x2F;get&#x2F;1 Ribbon负载均衡算法 Ribbon手写轮询算法 OpenFeignFeign是一个声明式WebService客户端。使用Feign能让编写Web Service客户端更加简单。 它的使用方法是定义一个服务接口然后在上面添加注解。Feign也支持可拔插式的编码器和解码器。Spring Cloud对Feign进行了封装，使其支持了Spring MVC标准注解和HttpMessageConverters。Feign可以与Eureka和Ribbon组合使用以支持负载均衡。 feign和OpenFeign OpenFeign服务调用接口+注解新建cloud-consumer-feign-order80 pom.xml 123456789101112131415161718192021222324252627282930313233343536373839404142434445&lt;dependencies&gt; &lt;!--openfeign--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--eureka-client--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt;&lt;!--引入自己定义的api通用包，可以使用Payment支付Entity--&gt; &lt;groupId&gt;com.kayleh.springcloud&lt;/groupId&gt; &lt;artifactId&gt;cloud-api-commons&lt;/artifactId&gt; &lt;version&gt;$&#123;project.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; yml 12345678server: port: 80eureka: client: register-with-eureka: false service-url: defaultZone: http://eureka7001.com:7001/eureka/,http://eureka7002.com:7002/eureka/ 主启动类： 12345678910111213package com.kayleh.springcloud;/** * @Author: Wizard * @Date: 2020/8/4 11:20 */@SpringBootApplication@EnableFeignClientspublic class OrderFeignMain80 &#123; public static void main(String[] args) &#123; SpringApplication.run(OrderFeignMain80.class, args); &#125;&#125; Service: 12345678910package com.kayleh.springcloud.service;@Component@FeignClient(\"CLOUD-PAYMENT-SERVICE\")public interface PaymentFeignService &#123; @GetMapping(value = \"/payment/get/&#123;id&#125;\") public CommonResult&lt;Payment&gt; getPaymentById(@PathVariable(\"id\") Long id);&#125; Controller 123456789101112131415package com.kayleh.springcloud.controller;@RestController@Slf4jpublic class OrderFeignController &#123; @Resource private PaymentFeignService paymentFeignService; @GetMapping(value = \"/consumer/payment/get/&#123;id&#125;\") public CommonResult&lt;Payment&gt; getPaymentById(@PathVariable(\"id\") Long id) &#123; return paymentFeignService.getPaymentById(id); &#125;&#125; 测试 1http:&#x2F;&#x2F;localhost&#x2F;consumer&#x2F;payment&#x2F;get&#x2F;1 OpenFeign超时控制修改cloud-provider-payment8001的controller，添加 12345678910@GetMapping(value &#x3D; &quot;&#x2F;payment&#x2F;feign&#x2F;timeout&quot;) public String getPaymentFeignTimeout() &#123; &#x2F;&#x2F;暂停几秒钟线程 try &#123; TimeUnit.SECONDS.sleep(3); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; return serverPort; &#125; cloud-consumer-feign-order80的PaymentFeignService接口： 12345678910@Component@FeignClient(\"CLOUD-PAYMENT-SERVICE\")public interface PaymentFeignService &#123; @GetMapping(value = \"/payment/get/&#123;id&#125;\") public CommonResult&lt;Payment&gt; getPaymentById(@PathVariable(\"id\") Long id); @GetMapping(value = \"/payment/feign/timeout\") public String getPaymentFeignTimeout();&#125; cloud-consumer-feign-order80的OrderFeignController，添加： 12345@GetMapping(value = \"/consumer/payment/feign/timeout\") public String getPaymentFeignTimeout() &#123; //客户端默认等待1秒钟 return paymentFeignService.getPaymentFeignTimeout(); &#125; 访问 12http://localhost:8001/payment/feign/timeouthttp://localhost/consumer/payment/feign/timeout #报错 OpenFeign默认支持Ribbon OpenFeign默认等待1秒钟，超过后报错 默认Feign客户端只等待1秒钟,但是服务端处理需要等待超过1秒钟,导致Feign客户端不想等待了,直接返回报错. 为了避免这样的情况,有时候我们需要设置Feign客户端的超时控制. yml文件中开启配置 修改cloud-consumer-feign-order80的yaml 123456789101112131415server: port: 80eureka: client: register-with-eureka: false service-url: defaultZone: http://eureka7001.com:7001/eureka/,http://eureka7002.com:7002/eureka/#设置feign客户端超时时间(OpenFeign默认支持Ribbon)ribbon: #指的是建立连接所用的时间,使用于网络状况正常的情况下,两端连接所用的时间 ReadTimeout: 5000 #指的是建立连接后从服务端读取到可用资源所用的时间 ConnectTimeout: 5000 再测试 1http:&#x2F;&#x2F;localhost&#x2F;consumer&#x2F;payment&#x2F;feign&#x2F;timeout OpenFeign日志打印功能Feign提供了日志打印功能，我们可以通过配置来调整日志级别，从而了解Feign中Http请求的细节。说白了就是对Feign接口的调用情况进行监控和输出 在cloud-consumer-feign-order80的FeignConfig中添加 12345678910111213141516171819package com.kayleh.springcloud.config;import feign.Logger;import org.springframework.cloud.client.loadbalancer.LoadBalanced;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.web.client.RestTemplate;/** * @Author: Wizard * @Date: 2020/8/4 12:54 */@Configurationpublic class FeignConfig &#123; @Bean Logger.Level feignLoggerLevel() &#123; return Logger.Level.FULL; &#125;&#125; 修改yaml文件 12345678910111213141516171819server: port: 80eureka: client: register-with-eureka: false service-url: defaultZone: http://eureka7001.com:7001/eureka/,http://eureka7002.com:7002/eureka/#设置feign客户端超时时间(OpenFeign默认支持Ribbon)ribbon: #指的是建立连接所用的时间,使用于网络状况正常的情况下,两端连接所用的时间 ReadTimeout: 5000 #指的是建立连接后从服务端读取到可用资源所用的时间 ConnectTimeout: 5000logging: level: # feign以什么级别监控哪个接口 com.kayleh.springcloud.service.PaymentFeignService: debug 即可开启日志功能。 Hystrix服务调用 案例:新建cloud-provider-hystrix-payment8001 pom.xml 123456789101112131415161718192021222324252627282930313233343536373839404142434445&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- eureka-client--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt;&lt;!--引入自己定义的api通用包，可以使用Payment支付Entity--&gt; &lt;groupId&gt;com.kayleh.springcloud&lt;/groupId&gt; &lt;artifactId&gt;cloud-api-commons&lt;/artifactId&gt; &lt;version&gt;$&#123;project.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- 热部署--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; yml 1234567891011121314server: port: 8001spring: application: name: cloud-provider-hystrix-paymenteureka: client: register-with-eureka: true fetch-registry: true service-url: # defaultZone: http://localhost:7001/eureka/ defaultZone: http://eureka7001.com:7001/eureka/,http://eureka7002.com:7002/eureka/ service 12345678910111213141516171819202122package com.kayleh.springcloud.service;import com.kayleh.springcloud.entities.Payment;import org.apache.ibatis.annotations.Param;import org.springframework.stereotype.Service;import java.util.concurrent.TimeUnit;@Servicepublic class PaymentService &#123; public String paymentInfo_OK(Integer id) &#123; return \"线程池: \" + Thread.currentThread().getName() + \" paymentInfo_OK,id: \" + id + \"\\t\" + \"O(∩_∩)O哈哈~\"; &#125; public String paymentInfo_TimeOut(Integer id) &#123; //暂停3秒钟 int timeNumber = 3; try &#123; TimeUnit.SECONDS.sleep(timeNumber); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; return \"线程池: \" + Thread.currentThread().getName() + \" paymentInfo_TimeOut,id: \" + id + \"\\t\" + \"o(╥﹏╥)o哭\" + \"耗时\" + timeNumber + \"秒钟\"; &#125;&#125; controller 123456789101112131415161718192021222324@RestController@Slf4jpublic class PaymentController &#123; @Resource private PaymentService paymentService; @Value(\"$&#123;server.port&#125;\") private String serverPort; @PostMapping(value = \"/payment/hystrix/ok/&#123;id&#125;\") public String paymentInfo_OK(@PathVariable(\"id\") Integer id) &#123; String result = paymentService.paymentInfo_OK(id); log.info(\"----------result:\" + result); return result; &#125; @GetMapping(value = \"/payment/hystrix/timeout/&#123;id&#125;\") public String paymentInfo_TimeOut(@PathVariable(\"id\") Integer id) &#123; String result = paymentService.paymentInfo_TimeOut(id); log.info(\"----------result:\" + result); return result; &#125;&#125; 测试 12localhost:8001&#x2F;payment&#x2F;hystrix&#x2F;ok&#x2F;&#123;id&#125;localhost:8001&#x2F;payment&#x2F;hystrix&#x2F;timeout&#x2F;&#123;id&#125; 以上述为根基平台，从正确 –&gt;错误 –&gt; 降级熔断 –&gt; 恢复 Jmeter压测测试开启 Jmeter，来20000个并发压死8001，20000个请求都去访问paymentInfo_TimeOut http://localhost:8001/payment/hystrix/timeout/1 这时访问 1http:&#x2F;&#x2F;localhost:8001&#x2F;payment&#x2F;hystrix&#x2F;ok&#x2F;1 访问开始变慢了 这只是服务提供者8001自己测试，假如此时外部的消费者80也来访问，那消费者只能干等，最终导致消费端80不满意，服务端8001直接被拖死。 新建cloud-consumer-feign-hystrix-order80 pom.xml 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849&lt;dependencies&gt; &lt;!--openfeign--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- eureka-client--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt;&lt;!--引入自己定义的api通用包，可以使用Payment支付Entity--&gt; &lt;groupId&gt;com.kayleh.springcloud&lt;/groupId&gt; &lt;artifactId&gt;cloud-api-commons&lt;/artifactId&gt; &lt;version&gt;$&#123;project.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; yml 123456789server: port: 80eureka: client: register-with-eureka: false service-url: # defaultZone: http://localhost:7001/eureka/ defaultZone: http://eureka7001.com:7001/eureka/,http://eureka7002.com:7002/eureka/ service接口，调用cloud-provider-hystrix-payment8001里的方法 12345678910111213141516171819202122package com.kayleh.springcloud.service;import org.springframework.cloud.openfeign.FeignClient;import org.springframework.stereotype.Component;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.PathVariable;/** * @Author: Wizard * @Date: 2020/8/7 20:54 */@Component@FeignClient(\"CLOUD-PROVIDER-HYSTRIX-PAYMENT\")public interface PaymentHystrixService &#123; @GetMapping(value = \"/payment/hystrix/ok/&#123;id&#125;\") public String paymentInfo_OK(@PathVariable(\"id\") Integer id); @GetMapping(value = \"/payment/hystrix/timeout/&#123;id&#125;\") public String paymentInfo_TimeOut(@PathVariable(\"id\") Integer id);&#125; controller 12345678910111213141516171819package com.kayleh.springcloud.controller;@RestController@Slf4jpublic class OrderHystrixController &#123; @Resource private PaymentHystrixService paymentFeignService; @GetMapping(value = \"/payment/hystrix/ok/&#123;id&#125;\") public String paymentInfo_OK(@PathVariable(\"id\") Integer id) &#123; return paymentFeignService.paymentInfo_OK(id); &#125; @GetMapping(value = \"/payment/hystrix/timeout/&#123;id&#125;\") public String paymentInfo_TimeOut(@PathVariable(\"id\") Integer id) &#123; return paymentFeignService.paymentInfo_TimeOut(id); &#125;&#125; 测试 1http:&#x2F;&#x2F;localhost&#x2F;consumer&#x2F;payment&#x2F;hystrix&#x2F;ok&#x2F;1 导致原因 解决超时导致服务器变慢（转圈） 超时不在等待 出错（宕机或程序运行出错） 出错要有兜底 方法： 对方服务（8001）超时了，调用者（80）不能一直卡死等待，必须有服务降级 对方服务（8001）宕机了，调用者（80）不能一直卡死等待，必须有服务降级 对方服务（8001）OK，调用者（80）自己出故障或有自我要求（自己的等待时间小于服务提供者），自己处理降级 服务降级 服务器忙,请稍后再试,不让客户端等待并立刻返回一个友好提示,fallback 哪些情况会触发降级 程序运行异常 超时 服务熔断触发服务降级 线程池/信号量打满也会导致服务降级 降级配置 @HystrixCommand 从Hystrix-8001找问题，设置自身调用超时时间的峰值，峰值内可以正常运行，超过了需要有兜底的方法处理，作服务降级fallback 修改8001的Service 1234567891011121314151617181920212223242526272829303132package com.kayleh.springcloud.service;@Servicepublic class PaymentService &#123; /** * 正常访问 */ public String paymentInfo_OK(Integer id) &#123; return \"线程池: \" + Thread.currentThread().getName() + \" paymentInfo_OK,id: \" + id + \"\\t\" + \"O(∩_∩)O哈哈~\"; &#125; /** * 超时访问，演示降级 */ @HystrixCommand(fallbackMethod = \"paymentInfo_TimeOutHandler\", commandProperties = &#123; @HystrixProperty(name = \"execution.isolation.thread.timeoutInMilliseconds\", value = \"3000\") &#125;) public String paymentInfo_TimeOut(Integer id) &#123; //暂停3秒钟 int timeNumber = 5; try &#123; TimeUnit.SECONDS.sleep(timeNumber); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; return \"线程池: \" + Thread.currentThread().getName() + \" paymentInfo_TimeOut,id: \" + id + \"\\t\" + \"o(╥﹏╥)o哭\" + \"耗时\" + timeNumber + \"秒钟\"; &#125; public String paymentInfo_TimeOutHandler(Integer id) &#123; return \"调用支付接口超时或异常:\\t\" + \"\\t当前线程池名字\" + Thread.currentThread().getName(); &#125;&#125; 一旦调用服务方法失败后并抛出错误信息后，会自动调用@HystrixCommand标注好的fallbackMethod调用类中指定的方法。 1@HystrixProperty(name = \"execution.isolation.thread.timeoutInMilliseconds\", value = \"3000\" 这行代码表示3秒以内都是正常的逻辑。 修改8001的主启动类,开启降级 12345678@SpringBootApplication@EnableEurekaClient@EnableCircuitBreakerpublic class PaymentHystrixMain8001 &#123; public static void main(String[] args) &#123; SpringApplication.run(PaymentHystrixMain8001.class, args); &#125;&#125; 测试： 1http://localhost:8001/payment/hystrix/timeout/1 注释超时异常,制造 10/0 的异常也会降级. 当前服务不可用了,做服务降级,兜底的方案都是paymentInfo_TimeOutHandler. 让支付模块也支持Hystrix 修改cloud-consumer-feign-hystrix-order80的yaml: 添加 123feign: hystrix: enabled: true 修改启动类 12345678@SpringBootApplication@EnableFeignClients@EnableHystrixpublic class OrderHystrixMain80 &#123; public static void main(String[] args) &#123; SpringApplication.run(OrderHystrixMain80.class, args); &#125;&#125; 修改Controller(客户端的等待是1.5秒) 1234567891011121314151617181920212223242526package com.kayleh.springcloud.controller;@RestController@Slf4jpublic class OrderHystrixController &#123; @Resource private PaymentHystrixService paymentFeignService; @GetMapping(value = \"/consumer/payment/hystrix/ok/&#123;id&#125;\") public String paymentInfo_OK(@PathVariable(\"id\") Integer id) &#123; return paymentFeignService.paymentInfo_OK(id); &#125; @GetMapping(value = \"/consumer/payment/hystrix/timeout/&#123;id&#125;\") @HystrixCommand(fallbackMethod = \"paymentInfo_TimeOutHandler\", commandProperties = &#123; @HystrixProperty(name = \"execution.isolation.thread.timeoutInMilliseconds\", value = \"1500\") &#125;) public String paymentInfo_TimeOut(@PathVariable(\"id\") Integer id) &#123; return paymentFeignService.paymentInfo_TimeOut(id); &#125; public String paymentTimeOutFallbackMethod(Integer id) &#123; return \"我是消费者80，对方支付系统繁忙请10秒钟后再试试或者自己运行出错请检查自己，o(╥﹏╥)o\"; &#125;&#125; 测试: 1http:&#x2F;&#x2F;localhost&#x2F;consumer&#x2F;payment&#x2F;hystrix&#x2F;timeout&#x2F;1 如果修改paymentInfo_TimeOut超时错误为10/0,也会进入paymentTimeOutFallbackMethod 全局服务降级目前问题: 每个业务方法对应一个兜底的方法,代码膨胀 统一和自定义的分开 解决问题:@DefaultProperties(defaultFallback = “”) 修改cloud-consumer-feign-hystrix-order80的OrderHystrixController： 添加：@DefaultProperties(defaultFallback = “payment_Global_FallbackMethod”) ​ 和方法payment_Global_FallbackMethod 123456789101112131415161718192021222324252627282930313233package com.kayleh.springcloud.controller;@RestController@Slf4j@DefaultProperties(defaultFallback = \"payment_Global_FallbackMethod\")public class OrderHystrixController &#123; @Resource private PaymentHystrixService paymentFeignService; @GetMapping(value = \"/consumer/payment/hystrix/ok/&#123;id&#125;\") public String paymentInfo_OK(@PathVariable(\"id\") Integer id) &#123; return paymentFeignService.paymentInfo_OK(id); &#125; @GetMapping(value = \"/consumer/payment/hystrix/timeout/&#123;id&#125;\")// @HystrixCommand(fallbackMethod = \"paymentTimeOutFallbackMethod\", commandProperties = &#123;// @HystrixProperty(name = \"execution.isolation.thread.timeoutInMilliseconds\", value = \"1500\")// &#125;) @HystrixCommand public String paymentInfo_TimeOut(@PathVariable(\"id\") Integer id) &#123; return paymentFeignService.paymentInfo_TimeOut(id); &#125; public String paymentTimeOutFallbackMethod(Integer id) &#123; return \"我是消费者80，对方支付系统繁忙请10秒钟后再试试或者自己运行出错请检查自己，o(╥﹏╥)o\"; &#125; //全局fallback方法 public String payment_Global_FallbackMethod() &#123; return \"Global异常处理信息,请稍后再试,(⊙o⊙)…\"; &#125;&#125; 再测试 123http:&#x2F;&#x2F;localhost&#x2F;consumer&#x2F;payment&#x2F;hystrix&#x2F;timeout&#x2F;1---------------------Global异常处理信息,请稍后再试,(⊙o⊙)… 通配服务降级FeignFallback 修改cloud-consumer-feign-hystrix-order80，根据cloud-consumer-feign-hystrix-order80已经有的PaymentHystrixService接口，重新新建一个类(PaymentFallbackService)实现该接口，统一为接口里的方法进行异常处理。 访问异常就访问实现类下的方法。 新建实现类 123456789101112131415161718package com.kayleh.springcloud.service;/** * @Author: Wizard * @Date: 2020/8/8 22:54 */@Componentpublic class PaymentFallbackService implements PaymentHystrixService &#123; @Override public String paymentInfo_OK(Integer id) &#123; return \"----------PaymentFallbackService fall back,o(╥﹏╥)o\\tpaymentInfo_OK\"; &#125; @Override public String paymentInfo_TimeOut(Integer id) &#123; return \"----------PaymentFallbackService fall back,o(╥﹏╥)o\\tpaymentInfo_TimeOut\"; &#125;&#125; yml:添加 123feign: hystrix: enabled: true 接口修改注解： @FeignClient(value = “CLOUD-PROVIDER-HYSTRIX-PAYMENT”, fallback = PaymentFallbackService.class) 12345678910111213141516package com.kayleh.springcloud.service;/** * @Author: Wizard * @Date: 2020/8/7 20:54 */@Component@FeignClient(value = \"CLOUD-PROVIDER-HYSTRIX-PAYMENT\", fallback = PaymentFallbackService.class)public interface PaymentHystrixService &#123; @GetMapping(value = \"/payment/hystrix/ok/&#123;id&#125;\") public String paymentInfo_OK(@PathVariable(\"id\") Integer id); @GetMapping(value = \"/payment/hystrix/timeout/&#123;id&#125;\") public String paymentInfo_TimeOut(@PathVariable(\"id\") Integer id);&#125; 测试： 123http:&#x2F;&#x2F;localhost&#x2F;consumer&#x2F;payment&#x2F;hystrix&#x2F;ok&#x2F;1 -正常访问关掉微服务8001再访问http:&#x2F;&#x2F;localhost&#x2F;consumer&#x2F;payment&#x2F;hystrix&#x2F;ok&#x2F;1 -fallback 此时服务端provider已经宕机，但是我们做了服务降级处理，让客户端在服务端不可用时也会获得提示信息而不会挂起耗死服务器。 服务熔断 类比保险丝达到最大服务器访问后,直接拒绝访问,拉闸限电,然后调用服务降级的方法并返回友好提示,break 保险丝. 服务降级–&gt;进而熔断–&gt;恢复调用链路 熔断机制概述熔断机制是应对雪崩效应的一种微服务链路保护机制。当扇出链路的某个微服务出错不可用或者响应时间太长时，会进行服务的降级，进而熔断该节点微服务的调用，快速返回错误的响应信息。 当检测到该节点微服务调用响应正常后，恢复调用链路。 在SpringCloud框架里，熔断机制通过hystrix实现。hystrix会监视微服务间调用的状况， 当失败的调用到一定阈值，缺省是5秒内20次调用失败，就会启动熔断机制。熔断机制的注解是@HystrixCommand. 案例：修改PaymentHystrixMain8001 修改PaymentService , 添加 1234567891011121314151617181920212223/** * 服务熔断 */ @HystrixCommand(fallbackMethod = \"paymentCircuitBreaker_fallback\", commandProperties = &#123;@HystrixProperty(name = \"circuitBreaker.enabled\", value = \"true\"),//是否开启断路器@HystrixProperty(name = \"circuitBreaker.requestVolumeThreshold\", value = \"10\"),//请求次数@HystrixProperty(name = \"circuitBreaker.sleepWindowInMilliseconds\", value=\"10000\"),//时间窗口期@HystrixProperty(name = \"circuitBreaker.errorThresholdPercentage\", value = \"60\"),//失败率达到多少后跳闸 &#125;) public String paymentCircuitBreaker(@PathVariable(\"id\") Integer id) &#123; if (id &lt; 0) &#123; throw new RuntimeException(\"******id 不能为负数\"); &#125; String serialNumber = IdUtil.simpleUUID(); return Thread.currentThread().getName() + \"\\t\" + \"调用成功,流水号:\" + serialNumber; &#125; public String paymentCircuitBreaker_fallback(@PathVariable(\"id\") Integer id) &#123; return \"id 不能负数，请稍后再试，o(╥﹏╥)o id:\" + id; &#125; PaymentController,添加 1234567// -----服务熔断 @GetMapping(\"/payment/circuit/&#123;id&#125;\") public String paymentCircuitBreaker(@PathVariable(\"id\") Integer id) &#123; String result = paymentService.paymentCircuitBreaker(id); log.info(\"****result:\" + result); return result; &#125; 测试 12http:&#x2F;&#x2F;localhost:8001&#x2F;payment&#x2F;circuit&#x2F;1http:&#x2F;&#x2F;localhost:8001&#x2F;payment&#x2F;circuit&#x2F;-1 熔断类型 熔断打开 请求不再进行调用当前服务,内部设置时钟一般为MTTR(平均故障处理时间),当打开时长达到所设时钟则进入半熔断状态. 熔断关闭 熔断关闭不会对服务进行熔断 熔断半开 部分请求根据规则调用当前服务,如果请求成功且符合规则则认为当前服务恢复正常,关闭熔断. 断路器在什么情况下开始起作用: 断路器打开或关闭的条件: 断路器打开之后: Hystrix图形化DashBoard 新建cloud-consumer-hystrix-dashboard9001 pom.xml 123456789101112131415161718192021222324252627282930313233343536373839&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-netflix-hystrix-dashboard&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt;&lt;!--引入自己定义的api通用包，可以使用Payment支付Entity--&gt; &lt;groupId&gt;com.kayleh.springcloud&lt;/groupId&gt; &lt;artifactId&gt;cloud-api-commons&lt;/artifactId&gt; &lt;version&gt;$&#123;project.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt;&lt;/dependencies&gt; yml 12server: port: 9001 主启动类 123456789101112/** * @Author: Wizard * @Date: 2020/8/3 18:10 */@SpringBootApplication@EnableHystrixDashboardpublic class HystrixDashboard9001 &#123; public static void main(String[] args) &#123; SpringApplication.run(HystrixDashboard9001.class, args); &#125;&#125; 修改cloud-provider-hystrix-payment8001的主启动类：添加 123456789101112131415161718192021222324252627/** * @Author: Wizard * @Date: 2020/8/3 18:10 */@SpringBootApplication@EnableEurekaClient@EnableCircuitBreakerpublic class PaymentHystrixMain8001 &#123; public static void main(String[] args) &#123; SpringApplication.run(PaymentHystrixMain8001.class, args); &#125; /** * 此配置是为了服务监控而配置，与服务容错本身无关，SpringCloud升级后的坑 * ServletRegistrationBean因为springboot的默认路径不是\"/hystrix.stream\" * 只要在自己的项目配置上下面的servlet就可以了 */ @Bean public ServletRegistrationBean getServlet() &#123; HystrixMetricsStreamServlet streamServlet = new HystrixMetricsStreamServlet(); ServletRegistrationBean registrationBean = new ServletRegistrationBean(streamServlet); registrationBean.setLoadOnStartup(1); registrationBean.addUrlMappings(\"/hystrix.stream\"); registrationBean.setName(\"HystrixMetricsStreamServlet\"); return registrationBean; &#125;&#125; 测试 1http:&#x2F;&#x2F;localhost:9001&#x2F;hystrix 配置9001监控8001 测试 12http:&#x2F;&#x2F;localhost:8001&#x2F;payment&#x2F;circuit&#x2F;1http:&#x2F;&#x2F;localhost:8001&#x2F;payment&#x2F;circuit&#x2F;-1 七色: 一圈: 一线: 整个图: 流程图：","categories":[{"name":"分布式","slug":"分布式","permalink":"https://kayleh.top/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"}],"tags":[{"name":"DistributedMicroservices","slug":"DistributedMicroservices","permalink":"https://kayleh.top/tags/DistributedMicroservices/"}]},{"title":"Eureka服务注册与发现","slug":"分布式的微服务架构2","date":"2020-08-14T15:03:57.000Z","updated":"2020-08-20T06:17:12.674Z","comments":true,"path":"2020/08/14/分布式的微服务架构2/","link":"","permalink":"https://kayleh.top/2020/08/14/%E5%88%86%E5%B8%83%E5%BC%8F%E7%9A%84%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%842/","excerpt":"Eureka服务注册与发现","text":"Eureka服务注册与发现 服务治理Spring Cloud封装了Netflix公司开发的Eureka模块来实现服务治理。 在传统的rpc远程调用框架中，管理每个服务与服务之间依赖关系比较复杂，管理比较复杂，所以需要使用服务治理，管理服务于服务之间的依赖关系，可以实现服务调用、负载均衡、容错等，实现服务发现与注册。 服务注册与发现Eureka采用了CS的设计架构，Eureka Server作为服务注册功能的服务器，它是服务注册的中心。而系统中其他的微服务，使用了Eureka的客户端连接到Eureka Server并维持心跳连接。这样系统的维护人员就可以通过Eureka Server来监控系统中各个微服务是否正常运行。 在服务注册与发现中，有一个注册中心。当服务器启动的时候，会把当前自己服务器的信息 比如 服务地址通讯地址等以别名方式注册到注册中心上。另一方(消费者|服务提供者)，以该别名的方式去注册中心上获取到实际的服务通讯地址，然后再实现本地RPC调用RPC远程调用框架核心设计思想：在于注册中心上，因为使用注册中心管理每个服务与服务之间的一个依赖关系(服务治理概念).在任何rpc远程框架中,都会有一个注册中心(存放服务地址相关信息(接口地址)); ​ 左边是Eureka系统架构,右边是Dubbo的架构 Eureka包含两个组件:Eureka Server和Eureka Client Eureka Server提供服务注册服务 各个微服务节点通过配置启动,会在EurekaServer中进行注册,这样EurekaServer中的服务注册表中将会存储所有可用服务节点的信息,服务节点的信息可以在界面中直观看到. EurekaClient通过注册中心进行访问 是一个Java客户端,用于简化Eureka Server的交互,客户端同时也具备一个内置的、使用轮询(round-robin)负载算法的负载均衡器.在应用启动后,将会向Eureka Server发送心跳(默认周期为30秒)。如果Eureka Server在多个心跳周期内没有接受到某个节点的心跳，EurekaServer将会从服务注册表中把这个服务节点移除(默认90秒)。 服务端安装新建model:cloud-eureka-server7001 pom.xml 12345678910111213141516171819202122232425262728293031323334353637383940&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt;&lt;!--引入自己定义的api通用包，可以使用Payment支付Entity--&gt; &lt;groupId&gt;com.kayleh.springcloud&lt;/groupId&gt; &lt;artifactId&gt;cloud-api-commons&lt;/artifactId&gt; &lt;version&gt;$&#123;project.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!--boot web actuator--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; applicaiton.yml 12345678910111213server: port: 7001eureka: instance: hostname: localhost # eureka服务端的实例名称 client: # false表示不向注册中心注册自己 register-with-eureka: false # false表示自己端就是注册中心,我的职责就是维护服务实例,并不需要去检索服务. fetch-registry: false service-url: # 设置与Eureka Server交互的地址查询服务和注册服务都需要依赖这个地址. defaultZone: http://$&#123;eureka.instance.hostname&#125;:$&#123;server.port&#125;/eureka/ 主启动类 1234567891011121314151617package com.kayleh.springcloud;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.netflix.eureka.server.EnableEurekaServer;/** * @Author: Wizard * @Date: 2020/8/4 15:57 */@SpringBootApplication@EnableEurekaServerpublic class EurekaMain7001 &#123; public static void main(String[] args) &#123; SpringApplication.run(EurekaMain7001.class, args); &#125;&#125; 访问 http://localhost:7001 支付微服务8001入驻进EurekaServer 微服务8001的pom文件:添加坐标 12345&lt;!--eureka-client--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; application.yml下添加 123456789eureka: client: # 表示是否将自己注册进eurekaServer默认为true register-with-eureka: true # 表示从eurekaServer抓取已有的注册信息，默认为true。单节点无所谓，集群必须设置为true才能配合ribbon使用负载均衡 fetch-registry: true service-url: # 设置与Eureka Server交互的地址查询服务和注册服务都需要依赖这个地址. defaultZone: http://localhost:7001/eureka 主启动类添加client注解 1234567@SpringBootApplication@EnableEurekaClientpublic class PaymentMain8001 &#123; public static void main(String[] args) &#123; SpringApplication.run(PaymentMain8001.class, args); &#125;&#125; 微服务注册名配置说明 访问Eureka出现红字原因: 自我保护机制. 配置微服务80进驻Eureka; 改pom,添加坐标 改yml 12345678910111213141516server: port: 80spring: application: name: cloud-order-serviceeureka: client: # 表示是否将自己注册进eurekaServer默认为true register-with-eureka: true # 表示从eurekaServer抓取已有的注册信息，默认为true。单节点无所谓，集群必须设置为true才能配合ribbon使用负载均衡 fetch-registry: true service-url: # 设置与Eureka Server交互的地址查询服务和注册服务都需要依赖这个地址. defaultZone: http://localhost:7001/eureka 主启动类添加client注解. 集群eureka构建eureka集群原理分析 解决办法:搭建eureka注册中心集群,实现负载均衡+故障容错 构建集群(单机走向集群)新建model:cloud-eureka-server7002 复制微服务7001的pom.xml 修改C:\\Windows\\System32\\drivers\\etc目录下的hosts文件 添加进hosts文件 12127.0.0.1 eureka7001.com127.0.0.1 eureka7002.com 修改7001和7002的application.yml (如果是三台集群的话,在service-url下继续写,用逗号分隔开) 12345678910111213141516171819202122232425262728297001:server: port: 7001 eureka: instance: hostname: eureka7001.com #eureka服务端的实例名称 client: # false表示不向注册中心注册自己 register-with-eureka: false # false表示自己端就是注册中心,我的职责就是维护服务实例,并不需要去检索服务. fetch-registry: false service-url: defaultZone: http://eureka7002.com:7002/eureka/--------------------------------------------------------7002:server: port: 7002 eureka: instance: hostname: eureka7002.com #eureka服务端的实例名称 client: # false表示不向注册中心注册自己 register-with-eureka: false # false表示自己端就是注册中心,我的职责就是维护服务实例,并不需要去检索服务. fetch-registry: false service-url: defaultZone: http://eureka7001.com:7001/eureka/ 7002启动类加注解 访问 12eureka7001.com:7001eureka7002.com:7002 将80和8001模块注册进eureka, 修改yaml文件 1defaultZone: http://eureka7001.com:7001/eureka/,http://eureka7002.com:7002/eureka/ 测试 1http:&#x2F;&#x2F;localhost&#x2F;consumer&#x2F;payment&#x2F;get&#x2F;1 支付服务提供者8001集群环境构建新建cloud-provider-payment8002 pom.xml和8001一致 copy 8001的yml文件到8002,修改端口号 12server: port: 8002 主启动类,业务类 直接cpoy8001 修改8001和8002的controller 1234567添加@Value(\"$&#123;server.port&#125;\")private String serverPort;修改打印\"插入数据库成功,serverPort\" + serverPort\"查询成功,serverPort:\" + serverPort 负载均衡修改消费者80模块的OrderController的订单服务访问地址 1public static final String PAYMENT_URL = \"http://CLOUD-PAYMENT-SERVICE\"; 修改ApplicationContextConfig 123456789@Configurationpublic class ApplicationContextConfig &#123; @Bean @LoadBalanced public RestTemplate getRestTemplate() &#123; return new RestTemplate(); &#125;&#125;添加@LoadBalanced开启RestTemplate的负载均衡 测试 1http:&#x2F;&#x2F;localhost&#x2F;consumer&#x2F;payment&#x2F;get&#x2F;1 可以看到8001端口和8002端口交替出现. Ribbon和Eureka整合后,Consumer可以直接调用服务而不用关心地址和端口号,且该服务还有负载功能. axtuator微服务信息完善当前问题 暴露主机名 修改cloud-provider-payment8001和8002 的yml 12345678910111213eureka: client: # 表示是否将自己注册进eurekaServer默认为true register-with-eureka: true # 表示从eurekaServer抓取已有的注册信息，默认为true。单节点无所 fetch-registry: true service-url: # 设置与Eureka Server交互的地址查询服务和注册服务都需要依赖这个地址. # defaultZone: http://localhost:7001/eureka/ defaultZone: http://eureka7001.com:7001/eureka/,http://eureka7002.com:7002/eureka/ instance: instance-id: payment8001添加instance配置 更改之后 点开链接,测试 1http:&#x2F;&#x2F;wizard:8002&#x2F;actuator&#x2F;health 访问地址显示ip地址 修改8001,8002的yml,添加 123instance: instance-id: payment8001 prefer-ip-address: true 服务发现Discovery对于注册进eureka里面的微服务,可以通过服务发现来获得该服务的信息. 修改8001的controller 12345678910111213141516添加@Resourceprivate DiscoveryClient discoveryClient;@GetMapping(value = \"/payment/discovery\")public Object discovery() &#123; List&lt;String&gt; services = discoveryClient.getServices(); for (String element : services) &#123; log.info(\"----------element:\" + element); &#125; List&lt;ServiceInstance&gt; instances = discoveryClient.getInstances(\"CLOUD-PAYMENT-SERVICE\"); for (ServiceInstance instance : instances) &#123; log.info(instance.getServiceId() + \"\\t\" + instance.getHost() + \"\\t\" + instance.getPort() + \"\\t\" + instance.getUri()); &#125; return this.discoveryClient; &#125; 启动类添加注解 12345678@SpringBootApplication@EnableEurekaClient@EnableDiscoveryClientpublic class PaymentMain8001 &#123; public static void main(String[] args) &#123; SpringApplication.run(PaymentMain8001.class, args); &#125;&#125; 测试 123http:&#x2F;&#x2F;localhost:8001&#x2F;payment&#x2F;discovery------------------------------------------&#123;&quot;services&quot;:[&quot;cloud-order-service&quot;,&quot;cloud-payment-service&quot;],&quot;order&quot;:0&#125; Eureka的自我保护机制故障现象: 导致原因: 某时刻某一个微服务不可用了,Eureka不会立刻清理,依旧会对该微服务的信息进行保存. 属于CAP里面的AP分支 关闭自我保护 修改7001的yaml 1234567891011121314151617添加 server: enable-self-preservation: false---------------------------------------eureka: instance: hostname: eureka7001.com client: register-with-eureka: false fetch-registry: false service-url: defaultZone: http://eureka7002.com:7002/eureka/ server: #关闭自我保护机制，保证不可用服务被及时删除 enable-self-preservation: false #时间间隔 eviction-interval-timer-in-ms: 2000 8001的yml加入 1234567instance: instance-id: payment8001 prefer-ip-address: true # eureka客户端向服务端发送心跳的时间间隔，单位为秒（默认是30秒） lease-expiration-duration-in-seconds: 1 # eureka服务端在收到最后一次心跳后等待时间上限，单位为秒（默认是90秒），超时将剔除服务 lease-renewal-interval-in-seconds: 2 Zookepper需要Linux安装Zookepper 新建工程cloud-provider-payment8004 pom.xml 123456789101112131415161718192021222324252627282930313233343536373839404142434445&lt;dependencies&gt; &lt;!-- Zookeeper客户端--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-zookeeper-discovery&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt;&lt;!--引入自己定义的api通用包，可以使用Payment支付Entity--&gt; &lt;groupId&gt;com.kayleh.springcloud&lt;/groupId&gt; &lt;artifactId&gt;cloud-api-commons&lt;/artifactId&gt; &lt;version&gt;$&#123;project.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- 热部署--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; application.yml 1234567891011server: port: 8004#服务别名spring: application: name: cloud-provider-payment cloud: zookeeper: # zookeeper的机器ip加端口号 connect-string: 192.168.111.144:2181 启动类 1234567891011121314151617package com.kayleh.springcloud;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.client.discovery.EnableDiscoveryClient;/** * @Author: Wizard * @Date: 2020/8/5 16:58 */@SpringBootApplication@EnableDiscoveryClientpublic class PaymentMain8004 &#123; public static void main(String[] args) &#123; SpringApplication.run(PaymentMain8004.class, args); &#125;&#125; PaymentController 123456789101112131415161718192021222324package com.kayleh.springcloud.controller;import lombok.extern.slf4j.Slf4j;import org.springframework.beans.factory.annotation.Value;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController;import java.util.UUID;/** * @Author: Wizard * @Date: 2020/8/5 17:00 */@RestController@Slf4jpublic class PaymentController &#123; @Value(\"$&#123;server.port&#125;\") private String serverPort; @RequestMapping(value = \"/payment/zk\") public String paymentzk() &#123; return \"Springcloud with zookeeper:\" + serverPort + \"\\t\" + UUID.randomUUID().toString(); &#125;&#125; jar包冲突 123456789101112131415161718&lt;!-- Zookeeper客户端--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-zookeeper-discovery&lt;/artifactId&gt; &lt;!-- 排除自带的zookeeper3.5.3--&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.apache.zookeeper&lt;/groupId&gt; &lt;artifactId&gt;zookeeper&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;!-- 添加zookeeper3.4.9--&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.zookeeper&lt;/groupId&gt; &lt;artifactId&gt;zookeeper&lt;/artifactId&gt; &lt;version&gt;3.4.9&lt;/version&gt; &lt;/dependency&gt; 测试 访问 1localhost:8004&#x2F;payment&#x2F;zk 是临时节点，项目停止后，连接会持续一小段时间，然后丢失。重新连接后是另一个UUID的Zookepper。 订单服务注册zookeeper 新建cloud-consumerzk-order80 复制80的pom yml 1234567891011server: port: 80#服务别名spring: application: name: cloud-consumer-order cloud: zookeeper: # zookeeper的机器ip加端口号 connect-string: 192.168.111.144:2181 启动: 123456789package com.kayleh.springcloud;@SpringBootApplication@EnableDiscoveryClientpublic class OrderZkMain80 &#123; public static void main(String[] args) &#123; SpringApplication.run(OrderZkMain80.class, args); &#125;&#125; config: 12345678910package com.kayleh.springcloud.config;@Configurationpublic class ApplicationContextConfig &#123; @Bean @LoadBalanced public RestTemplate getRestTemplate() &#123; return new RestTemplate(); &#125;&#125; controller 12345678910111213141516171819package com.kayleh.springcloud.controller;@RestController@Slf4jpublic class OrderZkController &#123; public static final String INVOKE_URL = \"http://cloud-provider-payment\"; @Resource private RestTemplate restTemplate; @GetMapping(\"/consumer/payment/create\") public CommonResult&lt;Payment&gt; create(Payment payment) &#123; return restTemplate.postForObject(INVOKE_URL + \"/payment/create\", payment, CommonResult.class); &#125; @GetMapping(\"/consumer/payment/get/&#123;id&#125;\") public CommonResult&lt;Payment&gt; getPayment(@PathVariable(\"id\") Long id) &#123; return restTemplate.getForObject(INVOKE_URL + \"/payment/get/\" + id, CommonResult.class); &#125;&#125; 服务访问地址INVOKE_URL填linux上的zookeeper名称 测试,启动 80zk 和 8004. 访问 1http:&#x2F;&#x2F;localhost&#x2F;consumer&#x2F;payment&#x2F;zk Consul https://www.consul.io/downloads.html 启动 1consul agent -dev 访问 1http:&#x2F;&#x2F;localhost:8500&#x2F;ui&#x2F; 服务提供者注册进Consul新建模块cloud-providerConsul-payment8006 pom.xml 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859&lt;dependencies&gt; &lt;!--consul--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-consul-discovery&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt;&lt;!--引入自己定义的api通用包，可以使用Payment支付Entity--&gt; &lt;groupId&gt;com.kayleh.springcloud&lt;/groupId&gt; &lt;artifactId&gt;cloud-api-commons&lt;/artifactId&gt; &lt;version&gt;$&#123;project.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.1.10&lt;/version&gt; &lt;/dependency&gt; &lt;!-- mysql--&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-jdbc&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- 热部署--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; yml 123456789101112131415server: port: 8006#服务别名spring: application: name: consul-provider-payment###consul注册中心地址 cloud: consul: host: localhost port: 8500 discovery: service-name: $&#123;spring.application.name&#125;# hostname: 127.0.0.1 主启动类 controller 1234567891011@RestController@Slf4jpublic class PaymentController &#123; @Value(\"$&#123;server.port&#125;\") private String serverPort; @RequestMapping(value = \"/payment/consul\") public String paymentConsul() &#123; return \"Springcloud with consul:\" + serverPort + \"\\t\" + UUID.randomUUID().toString(); &#125;&#125; 测试 1http:&#x2F;&#x2F;localhost:8006&#x2F;payment&#x2F;consul 服务消费者注册进Consul新建模块cloud-consumer-consul-order80 pom.xml 12345678910111213141516171819202122232425262728293031323334&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-consul-discovery&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 主启动类 复制cloud-consumerzk-order80模块的ApplicationContextConfig controller 1234567891011121314@RestController@Slf4jpublic class OrderConsulController &#123; public static final String INVOKE_URL = \"http://consul-provider-payment\"; @Resource private RestTemplate restTemplate; @GetMapping(\"/consumer/payment/consul\") public String paymentInfo() &#123; String result = restTemplate.getForObject(INVOKE_URL + \"/payment/consul\", String.class); return result; &#125;&#125; 三个注册中心的异同 C : Consistency(强一致性) A : Availability(可用性) P : Partition tolerance(分区容错性) CAP理论关注粒度是数据，而不是整体系统设计的策略 AP架构当网络分区出现后，为了保证可用性，系统B可用返回旧值，保证系统的可用性 结论：违背了一致性C的要求，只满足可用性和分区容错，即AP CP架构当网络分区出现后，为了保证一致性，就必须拒接请求，否则无法保证一致性。 结论：违背了可用性A的要求，只满足一致性和分区容错，即CP","categories":[{"name":"分布式","slug":"分布式","permalink":"https://kayleh.top/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"}],"tags":[{"name":"DistributedMicroservices","slug":"DistributedMicroservices","permalink":"https://kayleh.top/tags/DistributedMicroservices/"}]},{"title":"SpringCloud","slug":"分布式的微服务架构1","date":"2020-08-03T06:07:44.000Z","updated":"2020-08-20T06:17:01.237Z","comments":true,"path":"2020/08/03/分布式的微服务架构1/","link":"","permalink":"https://kayleh.top/2020/08/03/%E5%88%86%E5%B8%83%E5%BC%8F%E7%9A%84%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%841/","excerpt":"SpringCloud——基于分布式的微服务架构","text":"SpringCloud——基于分布式的微服务架构 服务构建 SpringCloud分布式微服务架构的一站式解决方案，是多种微服务架构落地技术的集合体，俗称微服务全家桶。 版本依赖 json转换：https://start.spring.io/actuator/info 工程构建：微服务cloud整体聚合父工程Project new 字符编码 注解生效激活 java编译8 美观，过滤文件*.idea;*.iml; pom 添加一行 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980&lt;packaging&gt;pom&lt;/packaging&gt;&lt;!--统一管理jar包版本--&gt;&lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt; &lt;junit.version&gt;4.12&lt;/junit.version&gt; &lt;lombok.version&gt;1.16.18&lt;/lombok.version&gt; &lt;log4j.version&gt;1.2.17&lt;/log4j.version&gt; &lt;mysql.version&gt;5.1.47&lt;/mysql.version&gt; &lt;druid.version&gt;1.1.16&lt;/druid.version&gt; &lt;mybatis.spring.boot.version&gt;1.3.0&lt;/mybatis.spring.boot.version&gt;&lt;/properties&gt;&lt;!--子模块继承之后，提供作用：锁定版本+子module不用谢groupId和version--&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-project-info-reports-plugin&lt;/artifactId&gt; &lt;version&gt;3.0.0&lt;/version&gt; &lt;/dependency&gt; &lt;!--spring boot 2.2.2--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-dependencies&lt;/artifactId&gt; &lt;version&gt;2.2.2.RELEASE&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;!--spring cloud Hoxton.SR1--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;Hoxton.SR1&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;!--spring cloud 阿里巴巴--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-alibaba-dependencies&lt;/artifactId&gt; &lt;version&gt;2.1.0.RELEASE&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;!--mysql--&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;$&#123;mysql.version&#125;&lt;/version&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- druid--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;version&gt;$&#123;druid.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!--mybatis--&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;$&#123;mybatis.spring.boot.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!--junit--&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;$&#123;junit.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!--log4j--&gt; &lt;dependency&gt; &lt;groupId&gt;log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j&lt;/artifactId&gt; &lt;version&gt;$&#123;log4j.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt; 子项目pom： 跳过test： Rest微服务工程构建新建模块cloud-provider-payment8001 pom.xml 12345678910111213141516171819202122232425262728293031323334353637383940414243&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.1.10&lt;/version&gt; &lt;/dependency&gt; &lt;!-- mysql--&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-jdbc&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 创建application.yml 12345678910111213141516server: port: 8001spring: application: name: cloud-payment-service datasource: type: com.alibaba.druid.pool.DruidDataSource #当前数据源操作类型 driver-class-name: org.gjt.mm.mysql.Driver #mysql驱动包 url: jdbc:mysql://localhost:3306/cloud?useUnicode=true&amp;characterEncoding=utf-8&amp;useSSL=false username: root password: adminmybatis: mapperLocations: classpath:mapper/*.xml type-aliases-package: com.kayleh.springcloud.entities #所有Entity别名类所在包 主启动类 123456789101112131415package com.kayleh.springcloud;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;/** * @Author: Wizard * @Date: 2020/8/3 18:10 */@SpringBootApplicationpublic class PaymentMain8001 &#123; public static void main(String[] args) &#123; SpringApplication.run(PaymentMain8001.class, args); &#125;&#125; 业务类建表SQL 12345CREATE TABLE &#96;payment&#96;(&#96;id&#96; BIGINT(20) NOT NULL AUTO_INCREMENT COMMENT &#39;ID&#39;,&#96;serial&#96; VARCHAR(200) DEFAULT &#39;&#39;,PRIMARY KEY(&#96;id&#96;))ENGINE&#x3D;INNODB AUTO_INCREMENT&#x3D;1 DEFAULT CHARSET&#x3D;utf8; entities 主实体类 12345678910111213141516171819package com.kayleh.springcloud.entities;import lombok.AllArgsConstructor;import lombok.Data;import lombok.NoArgsConstructor;import java.io.Serializable;/** * @Author: Wizard * @Date: 2020/8/3 21:23 */@Data@AllArgsConstructor@NoArgsConstructorpublic class Payment implements Serializable &#123; private Long id; private String serial;&#125; Json封装体 1234567891011121314151617181920212223package com.kayleh.springcloud.entities;import lombok.AllArgsConstructor;import lombok.Data;import lombok.NoArgsConstructor;/** * @Author: Wizard * @Date: 2020/8/3 21:27 */@Data@AllArgsConstructor@NoArgsConstructorpublic class CommonResult&lt;T&gt; &#123; //404 not_found private Integer code; private String message; private T data; public CommonResult(Integer code, String message) &#123; this(code, message, null); &#125;&#125; DAO 12345678910111213141516package com.kayleh.springcloud.dao;import com.kayleh.springcloud.entities.Payment;import org.apache.ibatis.annotations.Mapper;import org.apache.ibatis.annotations.Param;/** * @Author: Wizard * @Date: 2020/8/3 23:23 */@Mapperpublic interface PaymentDao &#123; public int create(Payment payment); public Payment getPaymentById(@Param(\"id\") Long id);&#125; PaymentMapper.xml(resources目录下的mapper目录) 1234567891011121314151617181920212223&lt;?xml version=\"1.0\" encoding=\"UTF-8\" ?&gt;&lt;!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTO Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\"&gt;&lt;mapper namespace=\"com.kayleh.springcloud.dao.PaymentDao\"&gt; &lt;!-- id对应接口的类名--&gt; &lt;!-- parameterType对应类的参数类型--&gt; &lt;!-- useGeneratedKeys使用生成的主键--&gt; &lt;!-- keyProperty主键是id--&gt; &lt;insert id=\"create\" parameterType=\"Payment\" useGeneratedKeys=\"true\" keyProperty=\"id\"&gt; insert into payment(serial) values (#&#123;serial&#125;); &lt;/insert&gt; &lt;resultMap id=\"BaseResultMap\" type=\"com.kayleh.springcloud.entities.Payment\"&gt; &lt;!--column 对应数据库的列名 property 对应java实体类的属性名 jdbcType 在数据库的类型--&gt; &lt;id column=\"id\" property=\"id\" jdbcType=\"BIGINT\"/&gt; &lt;id column=\"serial\" property=\"serial\" jdbcType=\"VARCHAR\"/&gt; &lt;/resultMap&gt; &lt;select id=\"getPaymentById\" parameterType=\"Long\" resultMap=\"BaseResultMap\"&gt; select * from payment where id = #&#123;id&#125;; &lt;/select&gt;&lt;/mapper&gt; PaymentService 1234567891011121314package com.kayleh.springcloud.service;import com.kayleh.springcloud.entities.Payment;import org.apache.ibatis.annotations.Param;/** * @Author: Wizard * @Date: 2020/8/3 23:58 */public interface PaymentService &#123; public int create(Payment payment); public Payment getPaymentById(@Param(\"id\") Long id);&#125; PaymentServiceImpl 12345678910111213141516171819202122232425262728293031package com.kayleh.springcloud.service.impl;import com.kayleh.springcloud.dao.PaymentDao;import com.kayleh.springcloud.entities.Payment;import com.kayleh.springcloud.service.PaymentService;import org.springframework.stereotype.Service;import javax.annotation.Resource;/** * @Author: Wizard * @Date: 2020/8/4 0:00 */@Servicepublic class PaymentServiceImpl implements PaymentService &#123; // @Resouce线程安全,是java自带的。 // @Autowired是Spring的 @Resource PaymentDao paymentDao; @Override public int create(Payment payment) &#123; return paymentDao.create(payment); &#125; @Override public Payment getPaymentById(Long id) &#123; return paymentDao.getPaymentById(id); &#125;&#125; PaymentController 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647package com.kayleh.springcloud.controller;import com.kayleh.springcloud.entities.CommonResult;import com.kayleh.springcloud.entities.Payment;import com.kayleh.springcloud.service.PaymentService;import lombok.extern.slf4j.Slf4j;import org.apache.ibatis.annotations.Param;import org.springframework.web.bind.annotation.*;import javax.annotation.Resource;/** * @Author: Wizard * @Date: 2020/8/4 0:07 */@RestController@Slf4jpublic class PaymentController &#123; @Resource private PaymentService paymentService; @PostMapping(value = \"/payment/create\") public CommonResult create(@RequestBody Payment payment) &#123; int result = paymentService.create(payment); log.info(\"-------插入结果------\" + result); if (result &gt; 0) &#123; return new CommonResult(200, \"插入数据库成功\", result); &#125; else &#123; return new CommonResult(444, \"插入数据库失败\", null); &#125; &#125; @GetMapping(value = \"/payment/get/&#123;id&#125;\") public CommonResult getPaymentById(@PathVariable(\"id\") Long id) &#123; Payment payment = paymentService.getPaymentById(id); log.info(\"-------插入结果------\" + payment); if (payment != null) &#123; return new CommonResult(200, \"查询成功\", payment); &#125; else &#123; return new CommonResult(444, \"没有对应记录,查询id:\" + id, null); &#125; &#125;&#125; 消费者订单model新建工程cloud-consumer-order80 pom.xml 12345678910111213141516171819202122232425262728293031323334353637383940414243444546&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;parent&gt; &lt;artifactId&gt;cloud&lt;/artifactId&gt; &lt;groupId&gt;com.kayleh.springcloud&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;cloud-consumer-order80&lt;/artifactId&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- 热部署--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; application.yml 12server: port: 80 拷贝payment模块的实体类entities 启动类 123456789101112131415package com.kayleh.springcloud;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;/** * @Author: Wizard * @Date: 2020/8/4 11:20 */@SpringBootApplicationpublic class OrderMain80 &#123; public static void main(String[] args) &#123; SpringApplication.run(OrderMain80.class, args); &#125;&#125; RestTemplateRestTemplate提供了多种便捷访问远程HTTP访问的方法,是一种简单便捷的访问restful服务模块类,是Spring提供的用于访问Rest服务的客户端模块工具集. (url,requestMap,ResponseBean.class)三个参数分别代表 REST请求地址、请求参数、HTTP响应转换被转换成的对象类型。 RestTemplate 123456789101112131415161718package com.kayleh.springcloud.config;import org.springframework.beans.factory.annotation.Configurable;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.web.client.RestTemplate;/** * @Author: Wizard * @Date: 2020/8/4 12:54 */@Configurationpublic class ApplicationContextConfig &#123; @Bean public RestTemplate getRestTemplate() &#123; return new RestTemplate(); &#125;&#125; OrderController 123456789101112131415161718192021222324252627282930313233343536package com.kayleh.springcloud.controller;import com.kayleh.springcloud.entities.CommonResult;import com.kayleh.springcloud.entities.Payment;import lombok.extern.slf4j.Slf4j;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.PathVariable;import org.springframework.web.bind.annotation.RequestBody;import org.springframework.web.bind.annotation.RestController;import org.springframework.web.client.RestTemplate;import javax.annotation.Resource;/** * @Author: Wizard * @Date: 2020/8/4 11:24 */@RestController@Slf4jpublic class OrderController &#123; public static final String PAYMENT_URL = \"http://localhost:8001\"; @Resource private RestTemplate restTemplate; @GetMapping(\"/consumer/payment/create\") public CommonResult&lt;Payment&gt; create(Payment payment) &#123; return restTemplate.postForObject(PAYMENT_URL + \"/payment/create\", payment, CommonResult.class); &#125; @GetMapping(\"/consumer/payment/get/&#123;id&#125;\") public CommonResult&lt;Payment&gt; getPayment(@PathVariable(\"id\") Long id) &#123; return restTemplate.getForObject(PAYMENT_URL + \"/payment/get/\" + id, CommonResult.class); &#125;&#125; 即可调用另一个微服务模块 重构, 实体类entities共用 新建工程cloud-api-commons pom.xml 123456789101112131415161718&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;cn.hutool&lt;/groupId&gt; &lt;artifactId&gt;hutool-all&lt;/artifactId&gt; &lt;version&gt;5.1.0&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 拷贝payment模块的实体类entities 选中这个模块,使用maven clean和install 然后在consumer模块引入pom坐标 12345&lt;dependency&gt;&lt;!--引入自己定义的api通用包，可以使用Payment支付Entity--&gt; &lt;groupId&gt;com.kayleh.springcloud&lt;/groupId&gt; &lt;artifactId&gt;cloud-api-commons&lt;/artifactId&gt; &lt;version&gt;$&#123;project.version&#125;&lt;/version&gt;&lt;/dependency&gt; cloud-provider-payment8001模块也是这样做.","categories":[{"name":"分布式","slug":"分布式","permalink":"https://kayleh.top/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"}],"tags":[{"name":"DistributedMicroservices","slug":"DistributedMicroservices","permalink":"https://kayleh.top/tags/DistributedMicroservices/"}]},{"title":"MYSQL","slug":"MYSQL","date":"2020-08-02T14:54:25.000Z","updated":"2020-08-03T04:00:03.186Z","comments":true,"path":"2020/08/02/MYSQL/","link":"","permalink":"https://kayleh.top/2020/08/02/MYSQL/","excerpt":"MYSQL索引","text":"MYSQL索引 MySQL索引的建立对于MySQL的高效运行是很重要的，索引可以大大提高MySQL的检索速度。 打个比方，如果合理的设计且使用索引的MySQL是一辆兰博基尼的话，那么没有设计和使用索引的MySQL就是一个人力三轮车。 拿汉语字典的目录页（索引）打比方，我们可以按拼音、笔画、偏旁部首等排序的目录（索引）快速查找到需要的字。 索引分单列索引和组合索引。单列索引，即一个索引只包含单个列，一个表可以有多个单列索引，但这不是组合索引。组合索引，即一个索引包含多个列。 创建索引时，你需要确保该索引是应用在 SQL 查询语句的条件(一般作为 WHERE 子句的条件)。 实际上，索引也是一张表，该表保存了主键与索引字段，并指向实体表的记录。 上面都在说使用索引的好处，但过多的使用索引将会造成滥用。因此索引也会有它的缺点：虽然索引大大提高了查询速度，同时却会降低更新表的速度，如对表进行INSERT、UPDATE和DELETE。因为更新表时，MySQL不仅要保存数据，还要保存一下索引文件。 建立索引会占用磁盘空间的索引文件。 普通索引创建索引这是最基本的索引，它没有任何限制。它有以下几种创建方式： 1CREATE INDEX indexName ON mytable(username(length)); 如果是CHAR，VARCHAR类型，length可以小于字段实际长度；如果是BLOB和TEXT类型，必须指定 length。 修改表结构(添加索引)1ALTER table tableName ADD INDEX indexName(columnName) 创建表的时候直接指定123456789CREATE TABLE mytable( ID INT NOT NULL, username VARCHAR(16) NOT NULL, INDEX [indexName] (username(length)) ); 删除索引的语法1DROP INDEX [indexName] ON mytable; 唯一索引它与前面的普通索引类似，不同的就是：索引列的值必须唯一，但允许有空值。如果是组合索引，则列值的组合必须唯一。它有以下几种创建方式： 创建索引1CREATE UNIQUE INDEX indexName ON mytable(username(length)) 修改表结构1ALTER table mytable ADD UNIQUE [indexName] (username(length)) 创建表的时候直接指定123456789CREATE TABLE mytable( ID INT NOT NULL, username VARCHAR(16) NOT NULL, UNIQUE [indexName] (username(length)) ); 使用ALTER 命令添加和删除索引有四种方式来添加数据表的索引： ALTER TABLE tbl_name ADD PRIMARY KEY (column_list): 该语句添加一个主键，这意味着索引值必须是唯一的，且不能为NULL。 ALTER TABLE tbl_name ADD UNIQUE index_name (column_list): 这条语句创建索引的值必须是唯一的（除了NULL外，NULL可能会出现多次）。 ALTER TABLE tbl_name ADD INDEX index_name (column_list): 添加普通索引，索引值可出现多次。 ALTER TABLE tbl_name ADD FULLTEXT index_name (column_list): 该语句指定了索引为 FULLTEXT ，用于全文索引。 以下实例为在表中添加索引。 1mysql&gt; ALTER TABLE testalter_tbl ADD INDEX (c); 你还可以在 ALTER 命令中使用 DROP 子句来删除索引。尝试以下实例删除索引: 1mysql&gt; ALTER TABLE testalter_tbl DROP INDEX c; 使用 ALTER 命令添加和删除主键主键只能作用于一个列上，添加主键索引时，你需要确保该主键默认不为空（NOT NULL）。实例如下： 12mysql&gt; ALTER TABLE testalter_tbl MODIFY i INT NOT NULL;mysql&gt; ALTER TABLE testalter_tbl ADD PRIMARY KEY (i); 你也可以使用 ALTER 命令删除主键： 1mysql&gt; ALTER TABLE testalter_tbl DROP PRIMARY KEY; 删除主键时只需指定PRIMARY KEY，但在删除索引时，你必须知道索引名。 显示索引信息你可以使用 SHOW INDEX 命令来列出表中的相关的索引信息。可以通过添加 \\G 来格式化输出信息。 尝试以下实例: 12mysql&gt; SHOW INDEX FROM table_name; \\G........ MySQL 临时表 MySQL 临时表在我们需要保存一些临时数据时是非常有用的。临时表只在当前连接可见，当关闭连接时，Mysql会自动删除表并释放所有空间。临时表在MySQL 3.23版本中添加，如果你的MySQL版本低于 3.23版本就无法使用MySQL的临时表。不过现在一般很少有再使用这么低版本的MySQL数据库服务了。 MySQL临时表只在当前连接可见，如果你使用PHP脚本来创建MySQL临时表，那每当PHP脚本执行完成后，该临时表也会自动销毁。 如果你使用了其他MySQL客户端程序连接MySQL数据库服务器来创建临时表，那么只有在关闭客户端程序时才会销毁临时表，当然你也可以手动销毁。 实例以下展示了使用MySQL 临时表的简单实例，以下的SQL代码可以适用于PHP脚本的mysql_query()函数。 1234567891011121314151617181920mysql&gt; CREATE TEMPORARY TABLE SalesSummary ( -&gt; product_name VARCHAR(50) NOT NULL -&gt; , total_sales DECIMAL(12,2) NOT NULL DEFAULT 0.00 -&gt; , avg_unit_price DECIMAL(7,2) NOT NULL DEFAULT 0.00 -&gt; , total_units_sold INT UNSIGNED NOT NULL DEFAULT 0);Query OK, 0 rows affected (0.00 sec)mysql&gt; INSERT INTO SalesSummary -&gt; (product_name, total_sales, avg_unit_price, total_units_sold) -&gt; VALUES -&gt; (&#39;cucumber&#39;, 100.25, 90, 2);mysql&gt; SELECT * FROM SalesSummary;+--------------+-------------+----------------+------------------+| product_name | total_sales | avg_unit_price | total_units_sold |+--------------+-------------+----------------+------------------+| cucumber | 100.25 | 90.00 | 2 |+--------------+-------------+----------------+------------------+1 row in set (0.00 sec) 当你使用 SHOW TABLES命令显示数据表列表时，你将无法看到 SalesSummary表。 如果你退出当前MySQL会话，再使用 SELECT命令来读取原先创建的临时表数据，那你会发现数据库中没有该表的存在，因为在你退出时该临时表已经被销毁了。 删除MySQL 临时表默认情况下，当你断开与数据库的连接后，临时表就会自动被销毁。当然你也可以在当前MySQL会话使用 DROP TABLE 命令来手动删除临时表。 以下是手动删除临时表的实例： 1234567891011121314151617181920212223mysql&gt; CREATE TEMPORARY TABLE SalesSummary ( -&gt; product_name VARCHAR(50) NOT NULL -&gt; , total_sales DECIMAL(12,2) NOT NULL DEFAULT 0.00 -&gt; , avg_unit_price DECIMAL(7,2) NOT NULL DEFAULT 0.00 -&gt; , total_units_sold INT UNSIGNED NOT NULL DEFAULT 0);Query OK, 0 rows affected (0.00 sec)mysql&gt; INSERT INTO SalesSummary -&gt; (product_name, total_sales, avg_unit_price, total_units_sold) -&gt; VALUES -&gt; (&#39;cucumber&#39;, 100.25, 90, 2);mysql&gt; SELECT * FROM SalesSummary;+--------------+-------------+----------------+------------------+| product_name | total_sales | avg_unit_price | total_units_sold |+--------------+-------------+----------------+------------------+| cucumber | 100.25 | 90.00 | 2 |+--------------+-------------+----------------+------------------+1 row in set (0.00 sec)mysql&gt; DROP TABLE SalesSummary;mysql&gt; SELECT * FROM SalesSummary;ERROR 1146: Table &#39;RUNOOB.SalesSummary&#39; doesn&#39;t exist MySQL 复制表如果我们需要完全的复制MySQL的数据表，包括表的结构，索引，默认值等。 如果仅仅使用CREATE TABLE … SELECT 命令，是无法实现的。 本章节将为大家介绍如何完整的复制MySQL数据表，步骤如下： 使用 SHOW CREATE TABLE 命令获取创建数据表(CREATE TABLE) 语句，该语句包含了原数据表的结构，索引等。 复制以下命令显示的SQL语句，修改数据表名，并执行SQL语句，通过以上命令 将完全的复制数据表结构。 如果你想复制表的内容，你就可以使用 INSERT INTO … SELECT 语句来实现。 实例尝试以下实例来复制表 runoob_tbl 。 步骤一： 获取数据表的完整结构。 123456789101112131415mysql&gt; SHOW CREATE TABLE runoob_tbl \\G;*************************** 1. row *************************** Table: runoob_tblCreate Table: CREATE TABLE &#96;runoob_tbl&#96; ( &#96;runoob_id&#96; int(11) NOT NULL auto_increment, &#96;runoob_title&#96; varchar(100) NOT NULL default &#39;&#39;, &#96;runoob_author&#96; varchar(40) NOT NULL default &#39;&#39;, &#96;submission_date&#96; date default NULL, PRIMARY KEY (&#96;runoob_id&#96;), UNIQUE KEY &#96;AUTHOR_INDEX&#96; (&#96;runoob_author&#96;)) ENGINE&#x3D;InnoDB 1 row in set (0.00 sec)ERROR:No query specified 步骤二： 修改SQL语句的数据表名，并执行SQL语句。 123456789mysql&gt; CREATE TABLE &#96;clone_tbl&#96; ( -&gt; &#96;runoob_id&#96; int(11) NOT NULL auto_increment, -&gt; &#96;runoob_title&#96; varchar(100) NOT NULL default &#39;&#39;, -&gt; &#96;runoob_author&#96; varchar(40) NOT NULL default &#39;&#39;, -&gt; &#96;submission_date&#96; date default NULL, -&gt; PRIMARY KEY (&#96;runoob_id&#96;), -&gt; UNIQUE KEY &#96;AUTHOR_INDEX&#96; (&#96;runoob_author&#96;)-&gt; ) ENGINE&#x3D;InnoDB;Query OK, 0 rows affected (1.80 sec) 步骤三： 执行完第二步骤后，你将在数据库中创建新的克隆表 clone_tbl。 如果你想拷贝数据表的数据你可以使用 INSERT INTO… SELECT 语句来实现。 123456789mysql&gt; INSERT INTO clone_tbl (runoob_id, -&gt; runoob_title, -&gt; runoob_author, -&gt; submission_date) -&gt; SELECT runoob_id,runoob_title, -&gt; runoob_author,submission_date -&gt; FROM runoob_tbl;Query OK, 3 rows affected (0.07 sec)Records: 3 Duplicates: 0 Warnings: 0 执行以上步骤后，你将完整的复制表，包括表结构及表数据。 另一种完整复制表的方法:12CREATE TABLE targetTable LIKE sourceTable;INSERT INTO targetTable SELECT * FROM sourceTable; 其他: 可以拷贝一个表中其中的一些字段: 1234CREATE TABLE newadmin AS( SELECT username, password FROM admin) 可以将新建的表的字段改名: 1234CREATE TABLE newadmin AS( SELECT id, username AS uname, password AS pass FROM admin) 可以拷贝一部分数据: 1234CREATE TABLE newadmin AS( SELECT * FROM admin WHERE LEFT(username,1) &#x3D; &#39;s&#39;) 可以在创建表的同时定义表中的字段信息: 12345678CREATE TABLE newadmin( id INTEGER NOT NULL AUTO_INCREMENT PRIMARY KEY)AS( SELECT * FROM admin) 区分下mysql复制表的两种方式。 第一、只复制表结构到新表 create table 新表 select * from 旧表 where 1=2 或者 create table 新表 like 旧表 第二、复制表结构及数据到新表 create table新表 select * from 旧表 主要配置文件二进制文件日志log-bin主从复制 错误日志log-error默认是关闭的,记录严重的警告和错误信息,每次启动和关闭的详细信息等 查询日志log默认关闭,记录查询的sql语句,如果开启会减低mysql的整体性能,因为记录日志也是需要消耗系统资源的 数据文件库默认路径: /var/lib/mysql frm文件存放表结构 MYD文件存放的是数据,DATA MYI文件存放的是查找数据的索引,INDEX 逻辑结构 存储引擎1show enigines 查看mysql当前默认的存储引擎 1show variable like &#39;%storage_engine%&#39; MyisAm和InnoDB区别 SQL执行加载顺序手写 机读 索引 MYSQL官方对索引的定义：索引(Index)是帮助MYSQL高效获取数据的数据结构.可以得到索引的本质:索引就是数据结构. “排好序的快速查找数据结构” 对排序和查找都有影响 在数据之外,数据库系统还维护着满足特定查找算法的数据结构,这些数据结构以某种方式引用(指向)数据. 这样可以在这些数据结构上实现高级查找算法.这种数据结构,就是索引.下图就是一种可能的索引方式示例: 索引的目的在于提高查找效率,可以类比字典; 一般来说索引本身也很大,不可能全部存储在内存中,因此索引往往以索引文件的形式存储的磁盘上 我们平常所说的索引,如果没有特别指明,都是指b+树(多路搜索树,并不一定是二叉的)结构组织的索引,其中聚集索引,次要索引,覆盖索引,复合索引,前缀索引,唯一索引默认都是使用B+树索引,统称索引.当然,除了B+树这种类型的索引之外,还有哈希索引(hash index)等 索引优势类似大学图书馆建书目索引,提高数据检索的效率,降低数据库的IO成本,通过索引对数据进行排序,降低数据排序的成本,降低了CPU的消耗. 劣势 索引的分类单值索引即一个索引只包含单个列，一个表可以有多个单列索引 唯一索引索引列的值必须唯一，但允许有空值 复合索引即一个索引包含多个列 索引的命名语句创建 CREATE [UNIQUE] INDEX indexName ON mytable(columnname(length)); ALTER mytable ADD [UNIQUE] INDEX [indexName] ON (columnname(name)); 删除 DROP INDEX [indexName] ON mytable; 查看 SHOW INDEX FROM table_name\\G 使用ALTER命令 索引结构BTree索引 b+树 Hash索引 full-text全文索引 R-Tree索引 哪些情况需要创建索引？ 主键自动创建索引 频繁作为查询条件的字段应该创建索引 查询中与其他表关联的字段，外键关系建立索引 频繁更新的字段不适合创建索引，因为每次更新不单单是更新了记录还会更新索引 where条件里用不到的字段不创建索引 单键/组合索引的选择问题（在高并发下倾向创建组合索引） 查询中排序的字段，排序字段若通过索引去访问将大大提高排序速度 查询中统计或者分组的字段 哪些情况不需要创建索引？ 表记录太少 经常增删改的表 提高了查询速度，同时会降低更新表的速度，如对表进行INSERT、UPDATE和DELETE。 因为在更新表时，MYSQL不仅要保存数据，还要保存一些索引文件。 数据重复且分布均匀的表字段，因此应该只为最经常查询和最经常排序的数据建立索引。 如果某个数据列包含许多重复内容，为它建立索引就没有太大的实际效果。 性能分析（查询执行计划）MYSQL QUERY Optimizer MYSQL的常见瓶颈 Explain 能干吗 表的读取顺序 数据读取操作的操作类型 哪些索引可以使用 那些索引被实际使用 表之间的引用 每张表有多少行被优化器查询 使用：Explain + SQL语句执行计划包含的信息 表的读取顺序id： select查询的序列号,包含一组数字,表示查询中执行select子句或操作表的顺序 三种情况: id相同,执行顺序由上至下 id不同,如果是子查询,id的序号会递增,id值越大优先级会越高,越先被执行. id相同不同,同时存在 derive的2指的是id为2的t3. 数据读取操作的操作类型select_type： table：显示这一行数据是关于哪张表的 type：访问类型 显示查询使用了何种类型， 从最好到最差依次是： system &gt; const &gt; eq_ref &gt; ref &gt; range &gt; index &gt;ALL system const eq_ref ref range index ALL 全表扫描 possible_keys 和 key：possible_keys： key： key_len: 4(char长度)*3(UTF-8）+1（null）=13 ref: rows: extra:包含不适合在其他列中显示但十分重要的额外信息 Using filesort 说明mysql会对数据使用一个外部的索引排序,而不是按照表内的索引顺序进行读取,MYSQL中无法利用索引完成的排序操作被称为”文件排序” Using temporary Using index 覆盖索引,在possible_keys没有出现但在key出现 覆盖索引: Using where 使用了where过滤 using join buffer 使用了连接缓存 impossiable where where子句的值总是false,不能用来获取任何元组 select tables optimized away 在没有GROUPBY子句的情况下,基于索引优化MIN/MAX操作或者对于MyISAM存储引擎优化COUNT(*)操作不必等到执行阶段再进行计算,查询执行计划生成的阶段即完成优化. distinct 优化distinct操作，在找到第一匹配的元组后即停止找同样值的动作。 单表优化 范围使索引失效 两表优化 先尝试只添加右表的索引 左表 所以左连接要加右表。左表全有，加不加索引都是全表查询。三表优化 索引优化避免索引失效建表 全值匹配 第一层索引没用上，梯子断裂，最佳左前缀原则 最佳左前缀原则 如果索引了多列，要遵守最左前缀法则。指的是查询从索引的最左前列开始并且不跳过索引中的列。 不在索引列上做任何操作 存储引擎不能使用索引中范围条件右边的列 范围后面的索引失效 尽量使用覆盖索引 使用不等于（!=或者&lt;&gt;）的时候无法使用索引会导致全表扫描 is not,is not null无法使用索引 like以通配符开头使索引失效会变成全表扫描 要使用两边都带有通配符 ‘ %XX% ‘ 的解决方法: 创建覆盖索引; 字符串不加单引号索引失效 少用or,用它来连接时索引失效 other: 范围后索引断开,使用范围的字段也部分使用了索引. 用于字段排序的索引一定要按照建立索引的字段顺序.否则会产生filesort. 排序也会使用索引并且不会断开,但不显示在ref字段上. 分组之前必排序,会有临时表产生 查询截取分析查询优化 小表驱动大表 “select 1 from”的1是什么都行,是个常量就行 in 和 exists Order by关键字排序优化 order by子句，尽量使用index方式排序，避免使用filesort方式排序； 默认是升序。要不就全部升序,要不就全部降序 尽可能在索引树上完成排序操作，遵照索引建的最佳最前缀 如果不在索引列上，filesort有两种算法: mysql就要启动双路排序和单路排序； 双路排序：MYSQL4.1之前是使用双路排序，字面意思就是两次扫描磁盘，最终得到数据，读取行指针和orderby列，对他们进行排序，然后扫描已经排序好的列表，按照列表中的值重新从列表中读取对应的数据输出。 从磁盘取排序字段，在buffer进行排序，再从磁盘取其他字段。 取一批数据，要从磁盘进行了两次扫描，众所周知，I\\O是很耗时的，所以在mysql4.1之后，出现了第二种改进的算法，就是单路排序。 单路排序：从磁盘读取查询需要的所有列，按照order by列在buffer对它们进行排序，然后扫描排序后的列表进行输出，它的效率更快一些，避免了第二次读取数据。并且把随机IO变成了顺序IO，但是它会使用更多的空间。因为它把每一行都保存在内存了。 单路是后出的，总体而言好过双路。 单路也有问题： 优化策略 增大sort_buffer_size参数的设置 增大max_length_for_sort_data参数的设置 总结: group by关键字优化 慢查询日志 查看是否开启 1SHOW VARIABLES LIKE &#39;%slow_query_log%&#39;; 默认是关闭的 开启 1set global slow_query_log&#x3D;1; 开启了慢查询日志后,什么样的SQL才会记录到慢查询日志里面呢? 设置慢的阈值时间: 123456set global long_query_time&#x3D;3;##需要重新连接或新开一个会话才能看到修改值.SHOW VARIABLES LIKE &#39;long_query_time%&#39;;##或者使用SHOW global VARIABLES LIKE &#39;long_query_time&#39;; 模拟 1select sleep(4); 查看日志 1cat &#x2F;var&#x2F;lib&#x2F;mysql&#x2F;***.log 查询当前系统中有多少条慢查询记录 配置文件 日志分析工具在生产环境中,如果要手工分析日志,查找、分析SQL,显然是个体力活,MYSQL提供了日志分析工具mysqldumpslow. 使用帮助 1mysqldumpslow --help 常用参考: 批量插入数据脚本 建数据库 12create database bigData;use bigData; 建表dept 123456789CREATE TABLE dept( id INT UNSIGNED PRIMARY KEY AUTO_INCREMENT, ##部门编号 deptno MEDIUMINT UNSIGNED NOT NULL DEFAULT 0, ##部门名称 dname VARCHAR(20) NOT NULL DEFAULT \"\", ##楼层 loc VARCHAR(13) NOT NULL DEFAULT \"\")ENGINE = INNODB DEFAULT CHARSET=GBK; 建表emp 设置参数log_bin_trust_function_creators 随机产生部门字符串 创建存储过程 创建往emp表插入数据的存储过程function:有返回值 procedure:无返回值 创建往dept表插入数据的存储过程 调用存储过程 dept emp Show Profile 是mysql提供可以用来分析当前会话中语句执行的资源消耗情况.可以用于SQl的调优的测量. 默认情况下,参数处于关闭状态,并保存最近15次的运行结果. 看看当前的mysql版本是否支持 123Show variables like &#39;profiling&#39;; 或者Show variables like &#39;profiling%&#39;;##默认是关闭的,使用前需要开启 开启功能 运行SQL 12select * from emp group by id%10 limit 150000;select * from emp group by id%20 order by 5; 查看结果 1show profiles; 诊断SQL 1show profile cpu, block io for query ID(上一步前面的问题SQL数字号码); 需要注意的: 全局查询日志永远不要在生产环境开启这个功能,仅在测试环境使用.配置开启: 编码开启: 数据库锁锁是计算机协调多个进程或线程并发访问某一资源的机制.在数据库中,除传统的计算资源(如CPU,RAM,I/O等)的争用以外,数据也是供许多用户共享的资源.如何保证数据并发访问的一致性、有效性hi所有数据库必须解决的一个问题，锁冲突也是影响数据库并发访问的一个重要因素。从这个角度来说，锁对数据库而言显得尤其重要，也更加复杂。 锁的分类从对数据操作的类型(读\\写)分 读锁(共享锁): 针对同一份数据,多个读操作可以同时进行而不会互相影响 写锁(排他锁): 当前写操作没有完成前,它会阻断其他写锁和读锁; 从对数据操作的粒度分 表锁 行锁 MYSQL锁机制三锁 ↓表锁(偏读)特点:偏向MyISAM存储引擎,开销小,加锁快;无死锁;锁定粒度大,发生锁冲突的概率最高,并发度最低 案例: 读操作时共享的,会话1和2都可以读mylock; 会话1不能更新表; 会话1只能读加读锁的mylock表,不能读其他表(book);会话2可以读其他表. 会话2如果要更新表,会形成阻塞,要等待锁的释放(unlock tables) 写锁 其他会话读被锁的表会阻塞; 结论: 简而言之,就是读锁会阻塞写,但是不会堵塞读,而写锁则会把读和写都堵塞. 看看哪些表被锁了1show open tables; 如何分析表锁定 行锁(偏写)特点：偏向InnoDB存储引擎，开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低，并发度也最高。 InnoDB与MyISAM的最大不同也有两点： 一是支持事务(TRANSACTION); 二是采用了行级锁. 事务(Transaction)及其ACID属性 并发处理事务带来的问题 更新丢失(Lost Update) 脏读(Dirty Reads) 不可重复读(Non-Repeatable Reads) 幻读(Planttom Reads) 事务隔离级别; 默认级别是Repeatable read 案例分析:建表 select * from test_innodb_lock; 在没session1和2提交commit之前,session-2读不到修改的数据. 操作不同行,不会阻塞 无索引行锁变表锁;类型转换,索引失效: (b=’4000’) 行锁变表锁,造成阻塞. 间隙锁的危害 session2会阻塞, 如何锁定一行 行锁总结 如何分析行锁定 优化建议: 页锁开销和加锁时间界于表锁和行锁之间,会出现死锁;锁定粒度界于表锁和行锁之间,并发度一般. 主从复制复制的基本原理： slave会从master读取binlog来进行数据同步 复制的基本原则： 每个slave只有一个master 每个slave只能有一个唯一的服务器ID 每个master可以有多个slave 复制的最大问题：延时 一主一从常见配置： mysql版本要一致且后台以服务运行. 网段要相通ping 主从都配置在[mysqld]结点下,都是小写. 主机(window)修改my.ini配置文件 主服务器唯一ID[必须] server-id = 1 启动二进制日志[必须] log-bin=自己本地的路径/mysqlbin log-bin=D:/devSoft/MySQLServer5.5/data/mysqlbin 启用错误日志[可选] log-err = 自己本地的路径/mysqlerr log-err = D:/devSoft/MySQLServer5.5/data/mysqlerr 根目录[可选] basedir = “自己本地路径” basedir = “D:/devSoft/MySQLServer5.5/“ 临时目录[可选] tmpdir = “自己本地路径” tmpdir = “D:/devSoft/MySQLServer5.5/“ 数据目录[可选] datadir = “自己本地路径/Data/“ datadir = “D:/devSoft/MySQLServer5.5/Data/“ read-only=0 主机, 读写都可以 设置不要复制的数据库[可选] binlog-ignore-db=mysql 设置需要复制的数据库[可选] binlog-do-db=需要复制的主数据库名字 从机(Linux)修改my.cnf配置文件 从服务器唯一ID[必须] 注释 server-id=1 下翻,取消注释server-id = 2 启动二进制日志[可选] 因修改过配置文件,请主机+从机都重启后台mysql服务 123service mysql stopservice mysql startps -ef|grep mysql 主机从机都关闭防火墙 12window 手动关闭linux从机 service iptables stop 在window主机上建立账户并授权slave mysql 1flush privileges 查看master的状态 1show master status; 记录下File和Position的值. Position在后面使用后会有变化 在linux从机上配置需要复制的主机 启动从服务器复制功能 1start slave; 1234show slave status\\G下面两个参数都是Yes,则说明主从配置成功.Slave_IO_Running:YesSlave_SQL_Running:Yes 主机建库,建表 insert记录 从机有记录 停止从机复制功能 1stop slave;","categories":[],"tags":[{"name":"sql","slug":"sql","permalink":"https://kayleh.top/tags/sql/"}]},{"title":"HTTP","slug":"HTTP","date":"2020-07-27T02:58:34.000Z","updated":"2020-07-27T02:58:34.989Z","comments":true,"path":"2020/07/27/HTTP/","link":"","permalink":"https://kayleh.top/2020/07/27/HTTP/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"TCP/IP","slug":"TCP-IP","date":"2020-07-27T02:58:27.000Z","updated":"2020-07-27T07:19:28.065Z","comments":true,"path":"2020/07/27/TCP-IP/","link":"","permalink":"https://kayleh.top/2020/07/27/TCP-IP/","excerpt":"TCP/IP协议","text":"TCP/IP协议 TCP/IP协议模型(Transmission Control Protocol/Internet Protocol),包含了一系列构成互联网基础的网络协议，是Internet的核心协议。TCP/IP协议参考模型： 分为四个层次：数据链路层 TCPIP协议 描述 应用层 HTTP FTP 传输层 TCP UDP 网络层 IP协议：负责对数据加上IP地址和其他的数据以确定传输的目标 数据链路层 为待传的数据加入一个以太网协议头，并进行CRC编码，为数据传输做准备 TCP/IP协议通信过程： 对应着数据入栈和出栈的过程。入栈：数据发送方每层不断的封装首部和尾部，添加一些传输的信息，确保能传输到目的地。出栈：数据接收方每层不断地拆除首部与尾部，得到最终传输的数据。 数据链路层原理：物理层负责0,1比特流与物理设备电压高低、光的闪灭之间的互换。详解：数据链路层负责将0,1序列划分为数据帧从一个节点传输到临近的另一个节点，这些节点是通过MAC来唯一标识的。功能： 封装成帧：把网络层数据报加头和尾，封装成帧，帧头中包括源MAC地址和目的MAC地址 透明传输：指不管所传数据是什么样的比特组合，都应当能够在链路上传送。当所传数据中的比特组合恰巧与某一个控制信息完全一样时，就必须采取适当的措施，使接收方不会将这样的数据误认为是某种控制信息。 可靠传输：采用一系列技术来保障信息在发送方和接收方准确、精确的传输。在出错率很低的链路上很少用，但是无线链路WLAN会保证可靠传输 差错检测(CRC)： 接收者检测错误，如果发现差错，丢弃该帧。 网络层IP协议：所有的TCP、UDP、IMCP、IGMP的数据都以IP数据格式传输。注意：IP是不可靠协议，即，IP协议没有提供一种数据未传达以后的处理机制，而是让上层协议TCP或UDP处理。 IP地址划分：数据链路层中是通过MAC地址识别不同节点，在IP层的地址标识是IP地址。 32位IP地址 = 网络号 + 地址位这样划分的目的：减少路由器中路由表记录的数目网络地址：可以限定拥有相同网络地址的终端在同一个范围内，路由器只需要维护一条这个网络地址的方向就可以找到其终端了。IP分类： A类IP地址： 0.0.0.0 ~ 127.255.255.255 B类IP地址： 128.0.0.0 ~ 191.255.255.255 C类IP地址： 192.0.0.0 ~ 239.255.255.255 D类IP地址： IP数据报的完整格式一个IP数据报有首部和数据两部分组成。首部前一部分是固定长度，20字节；可选字段的长度是可变的 ARP及RARP协议ARP：地址解析协议，根据IP地址获取MAC地址的一种协议主机是不知道这个ip对应的是哪个主机的哪个接口，当主机要发送一个IP包的时候，会首先查一下自己的ARP高速缓存(IP-MAC地址对应表缓存)如果查询的IP-MAC值对不存在，那么主机就向网络发送一个ARP协议广播包，这个广播包里面就有待查询的IP地址，而直接收到这份广播的包的所有主机都会查询自己的IP地址，如果收到广播包的某一个主机发现自己符合条件，那么就准备好一个包含自己的MAC地址的ARP包传送给发送ARP广播的主机。 而广播主机拿到ARP包后会更新自己的ARP缓存（就是存放IP-MAC对应表的地方）。发送广播的主机就会用新的ARP缓存数据准备好数据链路层的的数据包发送工作。 RARP协议的工作与此相反，不做赘述。 IPMP协议IP协议并不是一个可靠的协议，它不保证数据被送达，那么，自然的，保证数据送达的工作应该由其他的模块来完成。其中一个重要的模块就是ICMP(网络控制报文)协议。ICMP不是高层协议，而是IP层的协议。 当传送IP数据包发生错误。比如主机不可达，路由不可达等等，ICMP协议将会把错误信息封包，然后传送回给主机。给主机一个处理错误的机会，这 也就是为什么说建立在IP层以上的协议是可能做到安全的原因。 PINGping可以说是ICMP的最著名的应用，是TCP/IP协议的一部分。利用“ping”命令可以检查网络是否连通，可以很好地帮助我们分析和判定网络故障。 TracerouteTraceroute是用来侦测主机到目的主机之间所经路由情况的重要工具，也是最便利的工具。 Traceroute的原理是非常非常的有意思，它收到到目的主机的IP后，首先给目的主机发送一个TTL=1的UDP数据包，而经过的第一个路由器收到这个数据包以后，就自动把TTL减1，而TTL变为0以后，路由器就把这个包给抛弃了，并同时产生 一个主机不可达的ICMP数据报给主机。主机收到这个数据报以后再发一个TTL=2的UDP数据报给目的主机，然后刺激第二个路由器给主机发ICMP数据 报。如此往复直到到达目的主机。这样，traceroute就拿到了所有的路由器IP。 DNSDNS（Domain Name System，域名系统），因特网上作为域名和IP地址相互映射的一个分布式数据库，能够使用户更方便的访问互联网，而不用去记住能够被机器直接读取的IP数串。通过主机名，最终得到该主机名对应的IP地址的过程叫做域名解析（或主机名解析）。DNS协议运行在UDP协议之上，使用端口号53。 运输层协议进程之间的通信网络的边缘部分的两个主机使用网络的核心部分的功能进行端到端通信时，只有主机的协议栈才有运输层，网络核心部分中的路由器在转发分组时只用到下三层的功能端到端的通信是应用进程之间的通信。运输层的作用复用(multiplexing)：指在发送方不同的应用进程都可以使用同一个运输层协议传送数据分用(demultiplexing)：指接收方的运输层在剥去报文的首部后能够把这些数据正确交付到目的应用进程运输层和网络层区别网络层是为主机之间提供逻辑通信，而运输层为应用进程之间提供端到端的逻辑通信；运输层要对收到的报文进行差错检测 运输层两个协议主要的协议：TCP、UDP UDP协议 用户数据报协议UDP(User Datagram Protocol)主要应用：DNS/TFTP/RIP/BOOTP/DHCP/SNMP/NFS/IGMP 特点： 无连接 使用尽最大努力交付(即，不保证可靠交付) 面向报文：应用层交给UDP多长的报文，UDP就照样发送，既不合并也不拆分若报文太长，IP层传送时要进行分片。因此应用进程要选择合适大小的报文 UDP首部开销小，只有8字节，比TCP的20字节要短 UDP数据包组成：数据字段、首部字段首部字段共8字节：源端口、目的端口、长度、检验和 端口不可达如果接收方UDP发现报文中的目的端口号不正确(不存在对应于该端口号的应用进程)，就丢弃该报文并由ICMP发送端口不可达差错报文给发送方 伪首部：只有在计算检验和时，临时添加在UDP用户数据报前面的数据，由此计算检验和。伪首部既不向下传送，也不向上递交。 TCP协议 应用：SMTP/TELNET/HTTP/FTP 特点：1.面向连接的运输层协议2.每一条TCP连接只能有两个端点，每一条TCP连接只能是点对点的3.TCP提供可靠交付的服务4.提供全双工通信5.面向字节流：虽然应用程序和TCP的交互是一次一个数据块，但TCP把应用程序交下来的数据看成仅仅是一连串的无结构的字节流。 TCP根据对方给出的窗口值和当前网络拥塞程度来决定一个报文段应包含多少个字节 TCP连接的端点是套接字，即(IP地址:端口号) 停止等待协议“超时重传”：A只要超过一段时间没有收到确认，就认为刚才发送的分组丢失了，因而重传签名发送过的分组。需要设置超时计时器对于迟到的确认，B会(1)丢弃这个重复的分组M2，不向上层交付。(2)向A发送确认缺点：信道利用率太低 连续ARQ协议定义：发送方每收到一个确认，就把发送窗口向前滑行一个分组的位置。接收方一般都采用累计确认的方式。即：接收方在收到几个分组后，对按序到达的最后一个分组发送确认。表示到这个分组为止的所有分组都已经正确收到了。 TCP报文格式 三次握手TCP在传输之前会进行三次沟通，一般称为“三次握手”，传完数据断开的时候要进行四次沟通，一般称为“四次挥手”。 具体流程：1.最初状态：A和B的TCP进程都处于CLOSED状态2.B的TCP服务器进程先创建传输控制块TCB，准备接受客户进程的连接请求。然后服务器进程处于LISTEN状态，等待客户的连接请求3.A的TCP客户进程创建传输控制模块TCB，然后向B发出连接请求报文段，首部的同部位SYN=1，同时选择一个初始序号seq=x这时，TCP客户进程进入SYN-SENT(同步已发送)状态4.B收到连接请求后，如果同意建立连接，则向A发送确认。确认报文中SYN=1,ACK=1，确认号ack=x+1同时选择一个自己的初始序号seq=y，服务器进程进入SYN-RCVD(同步收到)状态。5.TCP客户端收到B的确认后，还要向B发送确认，确认报文ACK=1,确认号ack=y+1，自己的序号seq=x+1。这时，TCP连接建立，A进入ESTABLISHED状态6.B收到A的确认后，也进入ESTABLISHED状态 四次挥手 具体流程：1.初始状态：A和B都处于ESTABLISHED状态2.A先向TCP发送连接释放报文段，并停止发送数据，主动关闭TCP连接。报文段中FIN=1，序号seq=u(已传送过的数据的最后一个字节的序号加1)，这时A进入FIN-WAIT-1(终止等待1)状态，等待B确认。3.B收到释放报文后即发出确认，确认号ack=u+1,字节序号是v(B前面已传送数据最后一个字节序号+1)，B进入CLOSE-WAIT(关闭等待)状态。 这时的TCP处于半关闭状态。即：从B到A的方向的连接并未关闭。4.A收到确认后，进入FIN-WAIT-2(终止等待2)状态，等待B发出的连接释放报文段5.若B没有需要发送的数据，就通知TCP释放连接，FIN=1,选择序号w,ack=u+1,此时B进入LAST-ACK(最后确认)状态6.A收到B的连接释放报文段后，必须对此发出确认，ACK=1,ack=w+1,seq=u+1，A进入TIME-WAIT(时间等待)状态7.经过时间等待计时器(TIME-WAIT timer)设置的时间2MSL后，A进入CLOSED状态 TIME-WAIT状态为什么必须等待2MSL时间？ 为了保证A发送的最后一个ACK报文段能够到达B。（B收不到A发送的ACK时会重传关闭的报文，因此A需要等待其发送的ACK是否成功） 防止已失效的连接请求报文段出现在本连接中。 TCP流量控制 定义：让发送方的发送速率不要太快，要让接收方来得及接收。 滑动窗口实现流量控制发送方的发送窗口不能超过接收方给出的接收窗口的数值。(TCP的窗口单位是字节，不是报文段) 解决死锁：TCP为每一个连接设一个持续计时器。只要TCP连接的一方收到对方的零窗口通知，就启动持续计时器。若持续计时器设置的时间到期，就发送一个零窗口探测报文段(仅携带1字节数据)，对方就在确认这个探测报文段时给出现在的窗口值。 TCP拥塞控制 定义：计算机网络中的带宽、交换节点的缓存和处理机等都是网络资源。在某段时间，若对网络中某一资源的需求超过了该资源所能提供的可用部分，网络的性能就要变坏，这种情况叫拥塞。 简单的通过增加一些资源，比如把结点缓存的存储空间扩大，或把链路更换为更高速率的链路，或把结点处理机的运算速度提供，并不能解决网络拥塞问题。因为问题的实质是整个系统的各个部分不匹配，只有所有部分都平衡了，问题才能解决。 拥塞控制的四种算法：满开始(slow-start)、拥塞避免(congestion avoidance)、快重传(fast retransmit)、快恢复(fast recovery) 为什么要三次握手？ 为了防止已失效的连接请求报文突然又传送到了服务端，因为产生错误。具体解释： “已失效的连接请求报文段”产生情况：client 发出的第一个连接请求报文段并没有丢失，而是在某个网络节点长时间滞留，因此导致延误到连接释放以后的某个时间才到达 service。如果没有三次握手，那么此时server收到此失效的连接请求报文段，就误认为是 client再次发出的一个新的连接请求，于是向 client 发出确认报文段，同意建立连接，而此时 client 并没有发出建立连接的情况，因此并不会理会服务端的响应，而service将会一直等待client发送数据，因此就会导致这条连接线路白白浪费。如果此时变成两次挥手行不行？这个时候需要明白全双工与半双工，再进行回答。比如： 第一次握手： A给B打电话说，你可以听到我说话吗？第二次握手： B收到了A的信息，然后对A说： 我可以听得到你说话啊，你能听得到我说话吗？第三次握手： A收到了B的信息，然后说可以的，我要给你发信息啦！在三次握手之后，A和B都能确定这么一件事： 我说的话，你能听到； 你说的话，我也能听到。 这样，就可以开始正常通信了，如果是两次，那将无法确定。 为什么要四次挥手？ TCP 协议是一种面向连接，可靠，基于字节流的传输层通信协议。TCP 是全双工模式(同一时刻可以同时发送和接收)，这就意味着，当主机1发出 FIN 报文段时，只是表示主机1已结没有数据要发送了，主机1告诉主机2，它的数据已经全部发送完毕；但是，这个时候主机1还是可以接受来自主机2的数据；当主机2返回 ACK报文段时，这个时候就表示主机2也没有数据要发送了，就会告诉主机1，我也没有数据要发送了，之后彼此就会中断这次TCP连接。 TCP的三次握手与四次挥手具体过程如下： 第一次握手：建立连接。客户端发送连接请求报文段，并将syn(标记位)设置为1，Squence Number(数据包序号)(seq)为x,接下来等待服务端确认，客户端进入SYN_SENT状态(请求连接)； 第二次握手：服务端收到客户端的 SYN 报文段，对 SYN 报文段进行确认，设置 ack(确认号)为 x+1(即seq+1 ; 同时自己还要发送 SYN 请求信息，将 SYN 设置为1, seq为 y。服务端将上述所有信息放到 SYN+ACK 报文段中，一并发送给客户端，此时服务器进入 SYN_RECV状态。 SYN_RECV是指,服务端被动打开后,接收到了客户端的SYN并且发送了ACK时的状态。再进一步接收到客户端的ACK就进入ESTABLISHED状态。 第三次握手：客户端收到服务端的 SYN+ACK(确认符) 报文段；然后将 ACK 设置为 y+1,向服务端发送ACK报文段，这个报文段发送完毕后，客户端和服务端都进入ESTABLISHED(连接成功)状态，完成TCP 的三次握手。 上面的解释可能有点不好理解，用《图解HTTP》中的一副插图 帮助大家。 最后再看一下完整的过程： 如果有大量的连接，每次在连接，关闭都要经历三次握手，四次挥手，这显然会造成性能低下。因此。Http 有一种叫做 长连接（keepalive connections） 的机制。它可以在传输数据后仍保持连接，当客户端需要再次获取数据时，直接使用刚刚空闲下来的连接而无需再次握手。","categories":[],"tags":[{"name":"network","slug":"network","permalink":"https://kayleh.top/tags/network/"}]},{"title":"计算机网络概论","slug":"计算机网络-1","date":"2020-07-25T05:28:42.000Z","updated":"2020-07-27T03:43:39.105Z","comments":true,"path":"2020/07/25/计算机网络-1/","link":"","permalink":"https://kayleh.top/2020/07/25/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C-1/","excerpt":"计算机网络","text":"计算机网络 概念计算机网络是一个分散的、具有独立功能的计算机系统，通过通讯设备与线路连接起来由功能完善的软件实现资源共享和信息共享的系统。 组成1.组成部分硬件、软件、协议 2.工作方式边缘部分 用户直接使用 C/S方式 P2P方式 核心部分 为边缘部分服务 3.功能组成 通信子网 实现数据通信 资源子网 实现资源共享/数据处理 分类1.按分布范围分:广域网WAN，城域网MAN，局域网LAN，个人区域网PAN 2.按使用者分: 公用网(中国电信), 专用网(军事) 3.按交换技术分:电路交换、报文交换、分组交换 4.按拓扑结构分： 5.按传输技术来分： 广播式网络：共享公共通信信道 点对点网络：使用分组存储转发和路由选择机制 标准化工作要实现不同厂商的硬、软件之间相互连通，必须遵从统一的标准。 标准的分类法定标准 由权威机构制定的正式的、合法的标准 OSI 事实标准 某些公司的产品在竞争中占据了主流，时间长了 这些产品中的协议和技术就成了标准 TCP/IP 性能指标速率速率即数据率或称数据传输率或比特率 比特 数据传输单位 1/0 位 连接在计算机网络上的主机在数字信道上传送数据位数的速率 单位是b/s，kb/s，Mb/s，Gb/s，Tb/s 1kb/s = 10三次方b/s 存储容量 1Byte（字节）=8bit（比特） 1KB=2十次方B=1024B=1024*8b 1MB=2十次方KB=1024KB 带宽 带宽原本指某个信号具有的频带宽度，即最高频率与最低频率之差，单位是赫兹（Hz）。 计算机网络中，带宽用来表示网络的通信线路传送数据的能力，通常是指单位时间内从网络中的某一点到另一点所能通过的“最高数据率”。单位是 比特每秒 。b/s，kb/s，Mb/s，Gb/s。 网络设备所支持的最高速度。 吞吐量 表示在单位时间内通过某个网络（或信道、接口）的数据量。单位b/s，kb/s，Mb/s等。 吞吐量受网络的带宽或网络的额定速率的限制。 带宽可以理解为链路的理论传输速率上限，吞吐量是某时间内链路实际的数据量 时延指数据（报文/分组/比特流）从网络上（或链路）的一端传送到另一端所需要的时间。也叫延迟或迟延。单位是s。 时延 发送时延（传播时延）: 从发送分组的第一个比特算起，到该分组的最后一个比特发送完毕所需的时间。发生在网络设配器上。 123 数据长度发送时延： --------------- 信道带宽(发送速率) 传播时延：取决于电磁波传播速度和链路长度。发生在信道上的。 123 信道长度传播时延： ———————————————————— 电磁波在信道上的传播速率 排队时延：等待输出/入 链路可用 处理时延 处理时延（海水提取盐） 发送时延（运盐到城里）排队时延（买盐）传播时延（给你盐） 时延带宽积时延带宽积 = 传播时延 + 带宽 时延带宽积又称为以比特位单位的链路长度。 即“塞满链路时候的比特长度”。 容量 往返时延RTT从发送方发送数据开始，到发送方收到接收方的确认（接收方收到数据后立即发送确认），总共经历的时延。 RTT越大，在收到确认之前，可以发送的数据越多。 RTT包括 往返传播时延=传播时延*2 末端处理时间 利用率 信道利用率 123 有数据通过的时间&#x3D; --------------------- (有+无)数据通过的时间 网络利用率 1信道利用率加权平均值 分层为什么要分层？ 发送文件前要完成的工作： 1）发起通信的计算机必须将数据通信的通路进行激活。 2）要告诉网络如何识别目标主机 3）发起通信的计算机要查明目的主机是否开机，并且与网络连接正常。 4）发起通信的计算机要弄清楚，对方计算机中文件管理程序是否已经做好准备工作。 5）确保差错和意外可以解决 。。。。 分层的基本原则 分层结构 概念 OSI参考模型 物联网输会示用 通信过程 应用层 用户与网络的界面 所有能和用户交互产生网络流量的程序 应用层服务: 文件传输(FTP) 电子邮件(SMTP) 万维网(HTTP) 表示层 用于处理在两个通信系统中交换信息的表示方式(语法和语义) 功能一: 数据格式交换 功能二: 数据加密解密 功能三: 数据压缩和恢复 会话层 向表示层实体/用户进程提供建立连接并在连接上有序地传输数据. 这是会话,也是建立同步(SYN) 功能: 一. 建立,管理,终止会话 二. 使用校验点可使会话在通信失效时从校验点/同步点继续恢复通信,实现数据同步. 适用于传输大文件. 传输层 负责主机中两个进程的通信,即端到端的通信. 传输单位时报文段或用户数据报. 上面三层的都是主机应用交流 下面三层都是设备转发数据 功能: 一.可靠传输,不可靠传输 发的文字消息是不可靠传输，发出去后就不管了 二. 差错控制 发送的报文段丢失了, 传输层负责纠正错误. 三. 流量控制 四. 复用分用 复用:多个应用层进程可同时使用下面运输层的服务. 分用: 运输层把收到的信息分别交付给上面应用层的相应的进程. 网络层 主要任务是把分组从源端传到目的端,为分组交换网上的不同主机提供通信服务.网络层传输单位是数据报 功能: 一.路由选择. 最佳路径 二.流量控制 三.差错控制 四.拥塞控制 若所有节点都来不及接受分组,而要丢弃大量分组的话,网络就处于拥塞状态.因此要采取一定措施,缓解这种拥塞. 数据链路层 主要任务是把网络层传下来的数据报组装成帧. 数据链路层/链路层的传输单位是帧. 物理层 主要任务是在物理媒体上实现比特流的透明传输. 物理层传输单位是比特. 半双工(回合制) TCP/IP模型 相同点： 1.都分层 2.基于独立的协议栈的概念 3.可以实现异构网络互联 不同点： 5层参考模型 物理层物理层解决如何在连接各种计算机的传输媒体上传输数据比特流，而不是指具体的传输媒体。 数据通信 三种通讯方式 两种数据传输方式 码元 速率,波特,带宽 奈式准则（Nyquist） 是在理想状态下得出的结论 香农公式（Shannon）是在有噪声的信道中得出的结论 基带信号和宽带/带通信号（Base band，pass band） 计算机网络中用的基带信号是数字信号 编码 将数据转化为数字信号 数字数据(digtal data)通过 数字发送器(digit emitter) 转化为 数字信号(digtal signal) 模拟数据(analog data)通过 PCM编码器(PCM coder) 转化为 数字信号 (digtal signal) 单极性不归零编码：只使用一个电压值，高电平表示1，低电平表示0. 双极性不归零编码：用幅值相等的正负电平表示二进制数1和0. 单极性归零编码：发送码1时高电平在整个码元期间只持续一段时间，其余时间返回零电平。 双极性归零编码：正负零三个电平，信号本身携带同步信息。 曼彻斯特编码：单极性编码的缺点是没有办法区分此时是没有信号，还是有信号，但是信号是0.这种编码方式是bit中间有信号，低-高跳转表示0，高-低跳转表示1，一个时钟周期只可以表示一个bit，并且必须通过两次采样才能得到一个bit。它能携带时钟信号，而且能区分此时是没有信号还是信号为0. 差分曼彻斯特编码：抗干扰能力比曼彻斯特编码更强。bit与bit之间有信号跳变，表示下一个bit为0，bit与bit之间没有信号跳变，表示下一个bit为1。 调制：数据转化为模拟信号（了解） 常用的调制方法：调频(AM)，调频(FM)，调相(PM) 模拟数据(analog data)通过 调制器(modulaotr) 转化为 模拟信号 (analog signal) 数字数据(digtal data)通过 调制器(modulaotr) 转化为 模拟信号 (analog signal) 物理层传输介质传输介质分为导向性传输介质和非导向性传输介质 导向性传输介质 电磁波沿着固体媒介（铜线or光纤）被导向传播 非导向性传输介质 自由空间，如空气，水等等 常见的导向性传输介质双绞线 根据有无屏蔽层分为屏蔽双绞线（STP) *和 *无屏蔽双绞线（UTP） 同轴电缆（Coaxial Cable） 光纤（Optical fiber）根据入射角不同，又分为单模光纤和多模光纤 常见的非导向性传输介质包括无线电波，微波，红外线和激光等 物理层设备中继器（RP repeater）注释：5-4-3规则是为了限制中继器使用次数的，理由可见图5是指不能超过5个网段4是指在这些网段中的物理层网络设备（中继器，集线器）最多不超过4个3是指这些网段中最多只有三个网段挂有计算机 集线器（Hub）集线器是个大的冲突域，同时只能有两个设备进行通讯，只会传输信号，没有智能。 数据链路层（Data Link Layer）基本概念 封装成帧与透明传输封装成帧就是加将数据加头加尾，相当于将数据打包透明传输就是为了防止特殊的数据无法正常传输的的情况的发生，比如说在封装成帧的过程中出现数据中的某些标记符与开始/结束标记符恰巧重复等等情况) 透明传输的应用字符计数法就是在帧的首部做计数，看看数据是否错误缺点：如果在某一个帧内，标记位后面的某个字节的数据丢失，那么会影响后面的帧比如3 1 1 和 4 2 2 2，如果前面的帧丢失变成 3 1，那么后面的4就会被补到前面变成 3 1 4导致错误 字符填充法就是加头加尾分别标记开始结束，和零比特填充法（见下）对比，开始和结束的对应的字符不一样但有可能出现数据内某段比特流数据正好与标记字段重复，从而导致误判断的情况解决方法：添加转义字符 零比特填充法 违规编码法因为曼彻斯特编码不使用高-高，低-低来表示，所以如果使用高-高，低-低来表示帧起始和终止就不会与数据冲突 差错控制差错是什么，从哪来的数据链路层的差错检测的是比特的错误 为什么要在数据链路层进行差错控制？因为错误可以尽早发现，不会让一个错误的数据包发送了很长时间到达最终目的地之后才被发现，从而导致网络资源的浪费 检错编码（奇偶校验码，循环冗余码CRC）奇偶校验码缺点：只能检测出1，3，5，7…等等奇位数错误，检测成功率位50% 循环冗余码CRC就是用传输数据除以生成多项式得到冗余码 实际例子注释：1.阶数就是最高位是哪位，然后位数-1，如10011就是5-1=4,1011就是4-1=32.异或运算就是相同得0，不同得1，比如100和101做异或，结果就是0013.出书和最后的余数添加到要发送的数据后面，称为帧检验序列FCS 接收方收到数据后进行检测需要注意的地方 纠错编码（海明码）分为四步 第一步 确认校验码位数r 第二步 确定校验码和数据的位置注释：1.为什么是10为数据位？因为4位校验码+6位信息位=10位2.校验码放到2的几次方的位置，其他的地方按顺序放已知的信息位 第三步 求出校验码的值注释1.先是通过二进制位确定有几位。本题中因为最大位10的二进制是1010，所以是4为，将其标注2.然后从p1开始看，看p1的二进制位的数值和所有信息位的对应位置的数值是否相同，然后找出来这些位这里有点难理解，这里以p1为例辅助理解，这里找出来的就是P1,D1,D2,D4,D5 然后计算异或值，比如说这里D1=1,D2=0,D4=1,D5=0,就是p1要同时和0,1，0,1进行异或之后得到0，为了标识我加粗原始计算数据举例：0和1异或得1,1和0异或得1,1和1异或得0，那么p1和0异或得0，p1就是0了3.其他同理，按顺序计算出P2,P3,P4,然后填入表格 第四步 检测并纠错就是和上面一样，将所有校验位进行运算，得出的结果的值就是错误的位 数据链路层的流量控制和可靠传输流量控制与可靠传输流量控制是为了让传输过程中的发送速度和接受速度匹配，减少传输出错与资源浪费可靠传输是发送端发送什么，接收端就要受到什么 停止等待协议（Stop-and-Wait） 停止等待协议的无差错情况注释：因为一次就一个，所以用0和1标记ack就行 停止等待协议的特点1.简单2.信道利用率低。大部分时间数据都在路上，发送方很长时间闲置，资源浪费 · 后退N帧协议（GBN）因为停止等待协议太浪费时间了，所以尝试采用GBN，发送连续多个数据帧，以增大信道利用率注释：累计确认：就是收到一个确认帧，那么它和它之前的所有帧都默认已收到，反之，如果某个确认帧没收到，那么它和它之后的所有帧都默认丢失（即使收到了也丢掉），进行重传 下图是一个实例注释：此图发送2帧时丢失，所以接收方几首收到后面的帧也是直接丢弃并且发送最晚收到的有效帧1的ACK，直至2帧的超时重传机制被触发进行重传并得到ACK之后，接收方才会接受2帧以及后面的帧 网络层网络层概述 网络层主要任务：设法将源节点发出的数据包传送到目的节点，从而向传输层提供最基本的端到端的数据传送服务。概括如下：为传输层提供服务：面向连接的网络服务(虚电路服务)和无连接的网络服务(数据包服务)组包和拆包：数据传输的基本单位是数据包(分组)路由选择：(也叫路径选择)根据一定的原则和路由选择算法在多节点的通信子网中选择一条最佳路径流量控制：控制阻塞，避免死锁方法有4种：滑动窗口、预约缓冲区、许可证、分组丢弃 路由选择算法 静态路由算法（非自适应算法）(1) 最短路由选择(2) 扩散式路由选择(3) 随机路由选择(4) 集中路由选择 动态路由算法（自适应算法）(1) 分布式路由选择策略(2) 集中路由选择策略 网络层的连接设备 路由器 第三次交换机 IP地址 IP地址及分类Internet上基于TCP/IP的网络中每台设备既有IP地址(即逻辑地址)，也有MAC地址(即物理地址) IP地址结构： 网络ID + 主机ID IP地址分类 A类 0 - - - (网络号8位) B类 1 0 - - (网络号16位) C类 1 1 0 - (网络号24位) D类 1 1 1 0 -多播地址 E类 1 1 1 1 0 - 保留为今后使用 子网掩码子网掩码定义：（1）对应于IP地址的网络ID的所有位都设为”1”。1必须是连续的（2）对应于主机ID的所有位都设为0注意：IP分类的标准只有一个，即第一个8位数组是哪个范围，并不看子网掩码。例如IP为2.1.1.1的子网掩码为255.255.255.0，属于A类地址。该子网掩码仅仅是借用了主机ID的16位作为子网ID子网划分原因：为了解决IP地址资源短缺的问题，同时为了提高IP地址资源的利用率子网划分方法：网络管理员需要从原有IP地址的主机位中借出连续的若干高位作为子网络标识无分类编址CIDR(Classless Inter Domain Routing):无类别的域间路由，不受地址类别划分的约束，任何有效的IP地址一律对待，区别网络ID仅仅依赖于子网掩码。CIDR确定了3个网络地址范围保留为内部网络使用，即公网主机不能使用这3个地址范围的IP地址： A类 10.0.0.0 - 10.255.255.255 B类 172.16.0.0 - 172.31.255.255 C类 192.168.0.0 - 192.168.255.255 可变长子网掩码(VLSM)解决在一个网络系统中使用多种层次的子网化IP地址的问题 IP数据报格式TCP/IP协议 IP封装、分片与重组IP封装：一个网络帧携带一个数据报的传输方式叫做封装(Encapsulation)。IP数据报被封装到以太网的MAC数据帧。报文分片：将IP报文分段成两个或更多的报文以满足最大传输单元的要求。(不同的物理网络允许的最大帧长度MTU各不相同)IP数据报重组：在接收到所有分片的基础上，主机对分片进行重新组装的过程叫做IP数据报的重组。 网络设备路由器是一种具有多个输入端口和多个输出端口的专用计算机，任务是转发分组。路由器结构分为两大部分： 路由选择部分(控制部分)核心部件路由选择处理器，任务是根据所选定的路由选择协议构造出路由表，同时经常或定期地和相邻路由器交换信息而不断地更新和维护路由表。 分组转发部分组成：(1) 交换结构：根据路由表对分组进行处理，将某个输入端口进入的分组从一个合适的输出端口转发出去。(2) 一组输入端口：查找和转发功能的路由器的交换功能(3) 一组输出端口 总结：路由器的功能如下： 路由选择协议转换实现网络层的一些功能网络管理和安全多协议路由选择网关 又称网间连接器或协议转换器。与网桥只是简单的传达信息不同，网关对收到的信息要重新打包，以适应目的系统的需求。同时，网关提供过滤和安全功能。大多数网关运行在应用层。 路由选择协议虚拟专用网和网络地址转换虚拟专用网VPN网络地址转换NATIPv6ICMPARP和RARP应用层域名系统DNS概述 DNS(Domain Name System)域名系统 DNS可以为计算机服务器以及介入互联网或局域网中的任何资源进行分层次的名称解析功能 DNS主要功能为域名和ip地址之间的解析 DNS结构 1.命名方法：层次树状结构(类似于全球邮政系统和电话系统)域名系统分级：一般分为：主机名.三级域名.二级域名.顶级域名.2.最后一个.代表根域，根域是所有域的起点.例如：service.example.com. 顶级域名：代表国家或者组织机构，由ICANN管理- cn 中国- com 商业公司- edu 教育机构二级域名：代表组织或公司名称三级域名：代表组织或公司内部的主机四级域名：mail/www 域名查询方式 1.递归查询如果客户端准备访问百度，客户端首先会查询本地缓存中是否有之前的查询记录，如果有，直接读取结果，如果没有则向本地DNS服务器发起查询请求[递归查询]，本地DNS服务器如果有答案，就会将答案直接返回给客户端，但本地DNS服务器没有答案时，这时候就向根域服务器查询，根域服务器并不会返回www.baidu.com主机的ip地址，返回的是.com的ip地址，然后本地DNS到com服务器区查询baidu的地址，查询完成后，会将结果缓存到本地。2.迭代查询迭代查询每次由客户端发起请求，域名服务器提供需要查询的信息则返回ip地址信息，如不能则引导客户端到其他域名服务器查询 两者区别：递归查询由别人查找告诉自己答案，迭代查询由自己亲自去查。 DNS服务器分类高速缓存服务器：将每次域名查询结果缓存到本地主DNS服务器：提供权威的域名信息，可信赖辅助DNS服务器：DNS信息来源于主DNS服务器 DNS服务器搭建unboundbind DNS查询流程为什么机器在处理IP数据报时要使用IP地址而不使用域名呢？因为IP地址的长度是固定的32位，而域名的长度并不是固定的，机器处理起来比较困难理论上整个因特网可以只使用一个域名服务器，使它装入因特网上所有主机名，并回答所有对IP地址的查询。但因特网规模太大，域名服务器负荷过大，一旦域名服务器出现故障，整个因特网就会瘫痪。因此1983年因特网采用层次树状结构的命名方法，并使用分布式的域名系统DNS。 域名到IP地址的解析过程当一个应用进程需要把主机名解析为IP地址时，该应用进程就调用解析程序(resolver)，并称为DNS的一个客户，把待解析的域名放在DNS请求报文中，以UDP用户数据报方式发给本地域名服务器(UDP减小了开销).本地域名服务器在查找域名后，把对应的IP地址放在回答报文中返回。应用进程获得目的主机的IP地址后即可进行通信。若本地域名服务器不能回答该请求，则此域名服务器就暂时称为DNS中的另一个客户，并向其他域名服务器发出查询请求。直到找到能够回答该请求的域名服务器为止。 文件传输协议文件共享协议有两类： 1.复制整个文件，如基于TCP的FTP和基于UDP的TFTP特点：若要存取一个文件，就必须先获得一个本地的文件副本。如果要修改文件，只能对文件的副本进行修改，然后 再将修改后的文件副本传回到原节点。 2.联机访问(on-line access)：允许多个程序同时对一个文件进行存取。如网络文件系统NFS(Network-File-System),其可使本地计算机共享远地的资源，就像这些资源在本地一样。NFS允许应用进程打开一个远地文件，并能在该文件的某一个特定的位置上开始读写数据。网络上传送的指数少量的修改数据。 FTP的基本原理主要功能：减少或消除在不同操作系统下处理文件的不兼容性。FTP服务器进程由两部分组成： 主进程：负责接受新的请求。工作步骤：1.打开21端口，使客户进程能够连接上2.等待客户进程发出连接请求3.启动从属进程来处理客户进程发来的请求。4.回到等待状态，继续接受其他客户进程发来的请求。 若干个从属进程：负责处理单个请求 在进行文件传输时，FTP的客户和服务器之间要建立两个并行的TCP连接： 控制连接 整个会话期间一直保持打开。服务器端的控制进程在接收到FTP客户发来的文件传输请求后就创建”数据传送进程”和”数据连接”，用来连接客户端和服务器端的数据传送进程。 数据连接 由于FTP使用了一个分离的控制连接，因此FTP的控制信息是带外传送的。 简单文件传输协议TFTP使用UDP数据报，因此TFTP需要有自己的差错改正措施。端口69特点： 每次传送的数据报文中有512字节的数据，最后一次不足512字节 数据报文按序编号，从1开始 支持ASCII码或二进制传送 可对文件进行读或写 使用很简单的首部 电子邮件历史1982年，ARPANET的电子邮件问世，即简单邮件传送协议SMTP和因特网文本报文格式1993年，由于SMTP只能传送可打印的7位ASCII码邮件，于是提出了通用因特网邮件扩充MIME(Multipurpose Internet Mail Extensions)MIME在其邮件首部中说明了邮件的数据类型(如文本、声音、图像、视像等)；MIME邮件可同时传送多种类型数据。 概述 用户代理(UA)： 用户与电子邮件系统的接口，通常为运行在用户PC机的程序。又称电子邮件客户端软件。例如微软的Outlook和张小龙的Foxmail具备四个功能：撰写、显示、处理、通信邮件服务器： 发送和接收邮件，同时要向发件人报告邮件传送的结果(已交付、被拒绝、丢失)邮件服务器使用两种不同的协议(即邮件服务器同时充当客户和服务器)：1用于用户代理向邮件服务器发送邮件或在邮件服务器之间发送邮件，如SMTP协议2用于用户代理从邮件服务器读取邮件，如邮局协议POP3电子邮件： 由信封(envelope)和内容(content)两部分组成。信封最重要的是收件人的地址。TCP/IP体系的电子邮件系统规定电子邮件格式(收件人邮箱名即用户名)：收件人邮箱名@邮箱所在主机的域名 简单邮件传送协议SMTP-规定了在两个相互通信的SMTP进程之间应如何交换信息。-SMTP规定了14条命令和21种应答信息-发送方和接收方的邮件服务器之间的SMTP通信分三个阶段： 连接建立： SMTP客户每隔一定时间对邮件缓存扫描一次，发现有邮件就使用SMTP端口号(25)与接收方建立TCP连接。建立连接后接收方发出“220 Service ready”SMTP客户向SMTP服务器发送HELO命令SMTP服务器接收邮件后回复”250 OK”(表示准备好接收)；若不可以回复”421 Service not available”(服务不可用) 邮件传送： 从MAIL命令开始。SMTP服务器准备好接收邮件，返回”250 OK”,否则，返回451(处理时出错)，452(存储空间不够)，500(命令无法识别)RCPT命令：发送给一个/多个收件人 连接释放： 邮件发送完毕后，SMTP客户发送QUIT命令。服务器返回”221(服务关闭)”，邮件传送的全部过程即结束。 邮件读取协议POP3和网际报文存取协议IMAPIMAP(Internet Message Access Protocol) IMAP最大的好处就是：用户可以在不同的地方使用不同的计算机随时上网阅读和处理自己的邮件。还允许收件人只读取邮件中的某一个部分。IMAP的缺点：如果用户没有将邮件复制到自己的PC机上，则邮件一直是存放在IMAP服务器上。 基于万维网的电子邮件20世纪90年代中期，Hotmail引入基于万维网的电子邮件。 1.电子邮件从A的浏览器发送到网易邮件服务器时，不是使用SMTP协议，而是使用HTTP协议。2.电子邮件从网易邮件服务器发送到新浪的邮件服务器，使用SMTP协议，而不是HTTP协议。3.B用浏览器从新浪邮件服务器读取A发来的邮件时，使用HTTP协议，不是使用POP3或IMAP协议。流程如图 通用因特网邮件扩充MIME电子邮件协议SMTP缺点：1.SMTP不能传送可执行文件或其他的二进制对象2.SMTP限于传送7位ASCII码;其他非英语国家的文字(如中文)就无法传送。3.SMTP服务器会拒绝超过一定长度的邮件4.某些SMTP的实现没有按照SMTP的因特网标准，如回车、换行的删除和增加、超过76字符时的处理、多余空格的删除等通用因特网邮件扩充MIME： 增加了邮件主体的结构，并定义传送非ASCII码的编码规则在现有的电子邮件程序和协议下传送包含三部分内容： 1.5个新的邮件首部字段，提供主体信息MIME-Version：MIME的版本Content-Description:说明邮件是否有图像、音频或视频Content-Id:邮件的唯一标识符Content-Transfer-Encoding:内容传送编码，邮件主题是如何编码的。三种常用的是7位ASCII码、quoted-printable编码、base64编码Content-Type：内容类型，邮件主体的数据类型(7个)和子类型(15种) 定义许多邮件内容的格式 定义了传送编码(每个MIME报文包含告知收件人数据类型和使用编码的信息) MIME示例邮件如下：","categories":[],"tags":[{"name":"network","slug":"network","permalink":"https://kayleh.top/tags/network/"}]},{"title":"设计模式","slug":"设计模式","date":"2020-07-24T09:48:28.000Z","updated":"2020-07-25T10:25:55.901Z","comments":true,"path":"2020/07/24/设计模式/","link":"","permalink":"https://kayleh.top/2020/07/24/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/","excerpt":"设计模式","text":"设计模式 结构型模式如何实现动态代理？Java实现动态代理的大致步骤如下： 1.定义一个委托类和公共接口。 2.自己定义一个类（调用处理器类，即实现 InvocationHandler 接口），这个类的目的是指定运行时将生成的代理类需要完成的具体任务（包括Preprocess和Postprocess），即代理类调用任何方法都会经过这个调用处理器类（在本文最后一节对此进行解释）。 3.生成代理对象（当然也会生成代理类），需要为他指定(1)委托对象(2)实现的一系列接口(3)调用处理器类的实例。因此可以看出一个代理对象对应一个委托对象，对应一个调用处理器实例。 4.Java 实现动态代理主要涉及以下几个类： ①java.lang.reflect.Proxy: 这是生成代理类的主类，通过 Proxy 类生成的代理类都继承了 Proxy 类，即 DynamicProxyClass extends Proxy。 ②java.lang.reflect.InvocationHandler: 这里称他为”调用处理器”，他是一个接口，我们动态生成的代理类需要完成的具体内容需要自己定义一个类，而这个类必须实现 InvocationHandler 接口。 123456789public final class $Proxy1 extends Proxy implements Subject&#123; private InvocationHandler h; private $Proxy1()&#123;&#125; public $Proxy1(InvocationHandler h)&#123; this.h = h; &#125; public int request(int i)&#123; Method method = Subject.class.getMethod(\"request\", new Class[]&#123;int.class&#125;); //创建method对象 return (Integer)h.invoke(this, method, new Object[]&#123;new Integer(i)&#125;); //调用了invoke方法 &#125; &#125; java中有哪些代理模式？静态代理，动态代理，Cglib代理。 Java IO都有哪些设计模式，简单介绍一下。装饰模式和适配器模式 创建者模式请你介绍一下单例模式？再说一说 懒汉式的单例模式如何实现单例？定义：保证一个类仅有一个实例，并提供一个访问它的全局访问点。 优点：单例类只有一个实例、共享资源，全局使用节省创建时间，提高性能。可以用静态内部实现，保证是懒加载就行了，就是使用才会创建实例对象。 行为者模式 策略模式也叫政策模式，是一种行为型设计模式，是一种比较简单的设计模式。策略模式采用了面向对象的继承和多态机制。略模式适合使用在：1.多个类只有在算法或行为上稍有不同的场景。2.算法需要自由切换的场景。3.需要屏蔽算法规则的场景。 使用策略模式当然也有需要注意的地方，那么就是策略类不要太多，如果一个策略家族的具体策略数量超过4个，则需要考虑混合模式，解决策略类膨胀和对外暴露问题。在实际项目中，我们一般通过工厂方法模式来实现策略类的声明。 对于设计模式，你了解哪些？请手写一下观察者模式。 观察者模式优点： 观察者模式在被观察者和观察者之间建立一个抽象的耦合。被观察者角色所知道的只是一个具体观察者列表，每一个具体观察者都符合一个抽象观察者的接口。被观察者并不认识任何一个具体观察者，它只知道它们都有一个共同的接口。由于被观察者和观察者没有紧密地耦合在一起，因此它们可以属于不同的抽象化层次。如果被观察者和观察者都被扔到一起，那么这个对象必然跨越抽象化和具体化层次。 观察者模式缺点： 如果一个被观察者对象有很多的直接和间接的观察者的话，将所有的观察者都通知到会花费很多时间。 如果在被观察者之间有循环依赖的话，被观察者会触发它们之间进行循环调用，导致系统崩溃。在使用观察者模式是要特别注意这一点。 如果对观察者的通知是通过另外的线程进行异步投递的话，系统必须保证投递是以自恰的方式进行的。 虽然观察者模式可以随时使观察者知道所观察的对象发生了变化，但是观察者模式没有相应的机制使观察者知道所观察的对象是怎么发生变化的。 你了解的 Java设计模式。 所谓设计模式，就是一套被反复使用的代码设计经验的总结（情境中一个问题经过证实的一个解决方案）。使用设计模式是为了可重用代码、让代码更容易被他人理解、保证代码可靠性。设计模式使人们可以更加简单方便的复用成功的设计和体系结构。将已证实的技术表述成设计模式也会使新系统开发者更加容易理解其设计思路。在GoF的《Design Patterns: Elements of Reusable Object-Oriented Software》中给出了三类（创建型[对类的实例化过程的抽象化]、结构型[描述如何将类或对象结合在一起形成更大的结构]、行为型[对在不同的对象之间划分责任和算法的抽象化]）共23种设计模式，包括：Abstract Factory（抽象工厂模式），Builder（建造者模式），Factory Method（工厂方法模式），Prototype（原始模型模式），Singleton（单例模式）；Facade（门面模式），Adapter（适配器模式），Bridge（桥梁模式），Composite（合成模式），Decorator（装饰模式），Flyweight（享元模式），Proxy（代理模式）；Command（命令模式），Interpreter（解释器模式），Visitor（访问者模式），Iterator（迭代子模式），Mediator（调停者模式），Memento（备忘录模式），Observer（观察者模式），State（状态模式），Strategy（策略模式），Template Method（模板方法模式）， Chain Of Responsibility（责任链模式）。 开发中都用到了 哪些设计模式? 用在什么场合? 每个模式都描述了一个在我们的环境中不断出现的问题，然后描述了该问题的解决方案的核心。通过这种方式，你可以无数次地使用那些已有的解决方案，无需在重复相同的工作。主要用到了MVC的设计模式。用来开发JSP/Servlet或者J2EE的相关应用。简单工厂模式等。 J2EE 的常用 设计模式有哪些？再详细说说工厂模式。 Java中的23种设计模式：Factory（工厂模式）， Builder（建造模式）， Factory Method（工厂方法模式），Prototype（原始模型模式），Singleton（单例模式）， Facade（门面模式），Adapter（适配器模式）， Bridge（桥梁模式）， Composite（合成模式），Decorator（装饰模式）， Flyweight（享元模式）， Proxy（代理模式），Command（命令模式）， Interpreter（解释器模式）， Visitor（访问者模式），Iterator（迭代子模式）， Mediator（调停者模式）， Memento（备忘录模式），Observer（观察者模式）， State（状态模式）， Strategy（策略模式），Template Method（模板方法模式）， Chain Of Responsibleity（责任链模式）工厂模式：工厂模式是一种经常被使用到的模式，根据工厂模式实现的类可以根据提供的数据生成一组类中某一个类的实例，通常这一组类有一个公共的抽象父类并且实现了相同的方法，但是这些方法针对不同的数据进行了不同的操作。首先需要定义一个基类，该类的子类通过不同的方法实现了基类中的方法。然后需要定义一个工厂类，工厂类可以根据条件生成不同的子类实例。当得到子类的实例后，开发人员可以调用基类中的方法而不必考虑到底返回的是哪一个子类的实例。 说说你所熟悉 或听说过的，J2EE中的几种常用模式。再讲讲你对设计模式的一些看法 Session Facade Pattern：使用SessionBean访问EntityBean Message Facade Pattern：实现异步调用EJB Command Pattern：使用Command JavaBeans取代SessionBean，实现轻量级访问Data Transfer Object Factory：通过DTO Factory简化EntityBean数据提供特性Generic Attribute Access：通过AttibuteAccess接口简化EntityBean数据提供特性Business Interface：通过远程（本地）接口和Bean类实现相同接口规范业务逻辑一致性ＥＪＢ架构的设计好坏将直接影响系统的性能、可扩展性、可维护性、组件可重用性及开发效率。项目越复杂，项目队伍越庞大则越能体现良好设计的重要性。","categories":[],"tags":[{"name":"Interview","slug":"Interview","permalink":"https://kayleh.top/tags/Interview/"}]},{"title":"数据结构与算法","slug":"数据结构与算法","date":"2020-07-24T09:19:17.000Z","updated":"2020-07-24T09:47:53.547Z","comments":true,"path":"2020/07/24/数据结构与算法/","link":"","permalink":"https://kayleh.top/2020/07/24/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/","excerpt":"数据结构与算法","text":"数据结构与算法 哈希hashCode() 和equals() 方法的重要性体现在什么地方？ Java中的HashMap使用hashCode()和equals()方法来确定键值对的索引，当根据键获取值的时候也会用到这两个方法。如果没有正确的实现这两个方法，两个不同的键可能会有相同的hash值，因此，可能会被集合认为是相等的。而且，这两个方法也用来发现重复元素。所以这两个方法的实现对HashMap的精确性和正确性是至关重要的。 Java中的HashMap的工作原理是什么？HashMap类有一个叫做Entry的内部类。这个Entry类包含了key-value作为实例变量。 每当往hashmap里面存放key-value对的时候，都会为它们实例化一个Entry对象，这个Entry对象就会存储在前面提到的Entry数组table中。Entry具体存在table的那个位置是 根据key的hashcode()方法计算出来的hash值（来决定）。 什么是hashmap?HashMap 是一个散列表，它存储的内容是键值对(key-value)映射。HashMap 继承于AbstractMap，实现了Map、Cloneable、java.io.Serializable接口。HashMap 的实现不是同步的，这意味着它不是线程安全的。它的key、value都可以为null。此外，HashMap中的映射不是有序的。 HashMap 的实例有两个参数影响其性能：“初始容量” 和 “加载因子”。容量 是哈希表中桶的数量，初始容量 只是哈希表在创建时的容量。加载因子 是哈希表在其容量自动增加之前可以达到多满的一种尺度。当哈希表中的条目数超出了加载因子与当前容量的乘积时，则要对该哈希表进行 rehash 操作（即重建内部数据结构），从而哈希表将具有大约两倍的桶数。通常，默认加载因子是 0.75, 这是在时间和空间成本上寻求一种折衷。加载因子过高虽然减少了空间开销，但同时也增加了查询成本（在大多数 HashMap 类的操作中，包括 get 和 put 操作，都反映了这一点）。在设置初始容量时应该考虑到映射中所需的条目数及其加载因子，以便最大限度地减少 rehash 操作次数。如果初始容量大于最大条目数除以加载因子，则不会发生 rehash 操作。 hashmap共有4个构造函数： // 默认构造函数。HashMap() // 指定“容量大小”的构造函数 HashMap(int capacity) // 指定“容量大小”和“加载因子”的构造函数 HashMap(int capacity, float loadFactor) // 包含“子Map”的构造函数 HashMap(Map&lt;? extends K, ? extends V&gt; map) 如何构造一致性 哈希算法。先构造一个长度为232的整数环（这个环被称为一致性Hash环），根据节点名称的Hash值（其分布为[0, 232-1]）将服务器节点放置在这个Hash环上，然后根据数据的Key值计算得到其Hash值（其分布也为[0, 232-1]），接着在Hash环上顺时针查找距离这个Key值的Hash值最近的服务器节点，完成Key到服务器的映射查找。 这种算法解决了普通余数Hash算法伸缩性差的问题，可以保证在上线、下线服务器的情况下尽量有多的请求命中原来路由到的服务器。 Object作为HashMap的key的话，对Object有什么要求吗？ 要求Object中hashcode不能变。 hashset 存的数是有序的吗？ Hashset是无序的。 树TreeMap和TreeSet在排序时如何比较元素？Collections工具类中的sort()方法如何比较元素？TreeSet要求存放的对象所属的类必须实现Comparable接口，该接口提供了比较元素的compareTo()方法，当插入元素时会回调该方法比较元素的大小。TreeMap要求存放的键值对映射的键必须实现Comparable接口从而根据键对元素进行排序。Collections工具类的sort方法有两种重载的形式，第一种要求传入的待排序容器中存放的对象比较实现Comparable接口以实现元素的比较；第二种不强制性的要求容器中的元素必须可比较，但是要求传入第二个参数，参数是Comparator接口的子类型（需要重写compare方法实现元素的比较），相当于一个临时定义的排序规则，其实就是通过接口注入比较元素大小的算法，也是对回调模式的应用（Java中对函数式编程的支持）。 如何知道二叉树的深度？实现二叉树的深度方式有两种，递归以及非递归。 ①递归实现： 为了求树的深度，可以先求其左子树的深度和右子树的深度，可以用递归实现，递归的出口就是节点为空。返回值为0； ②非递归实现： 利用层次遍历的算法，设置变量level记录当前节点所在的层数，设置变量last指向当前层的最后一个节点，当处理完当前层的最后一个节点，让level指向+1操作。设置变量cur记录当前层已经访问的节点的个数，当cur等于last时，表示该层访问结束。 层次遍历在求树的宽度、输出某一层节点，某一层节点个数，每一层节点个数都可以采取类似的算法。 树的宽度：在树的深度算法基础上，加一个记录访问过的层节点个数最多的变量max,在访问每层前max与last比较，如果max比较大，max不变，如果max小于last，把last赋值给max; B+树和B-树？b+树的中间节点不保存数据，所以磁盘页能容纳更多节点元素，更“矮胖”； b+树查询必须查找到叶子节点，b树只要匹配到即可不用管元素位置，因此b+树查找更稳定（并不慢）； 对于范围查找来说，b+树只需遍历叶子节点链表即可，b树却需要重复地中序遍历。 遍历链表数组排序排序都有哪几种方法？请列举出来。 排序的方法有：插入排序（直接插入排序、希尔排序），交换排序（冒泡排序、快速排序），选择排序（直接选择排序、堆排序），归并排序，分配排序（箱排序、基数排序）快速排序的伪代码。/ /使用快速排序方法对a[ 0 :n- 1 ]排序从a[ 0 :n- 1 ]中选择一个元素作为m i d d l e，该元素为支点把余下的元素分割为两段left 和r i g h t，使得l e f t中的元素都小于等于支点，而right 中的元素都大于等于支点递归地使用快速排序方法对left 进行排序递归地使用快速排序方法对right 进行排序所得结果为l e f t + m i d d l e + r i g h t 归并排序的原理是什么？（1）归并排序是建立在归并操作上的一种有效的排序算法。该算法是采用分治法（Divide and Conquer）的一个非常典型的应用。 （2）首先考虑下如何将将二个有序数列合并。这个非常简单，只要从比较二个数列的第一个数，谁小就先取谁，取了后就在对应数列中删除这个数。然后再进行比较，如果有数列为空，那直接将另一个数列的数据依次取出即可。 （3）解决了上面的合并有序数列问题，再来看归并排序，其的基本思路就是将数组分成二组A，B，如果这二组组内的数据都是有序的，那么就可以很方便的将这二组数据进行排序。如何让这二组组内数据有序了？ 可以将A，B组各自再分成二组。依次类推，当分出来的小组只有一个数据时，可以认为这个小组组内已经达到了有序，然后再合并相邻的二个小组就可以了。这样通过先递归的分解数列，再合并数列就完成了归并排序。 堆排序的原理是什么？堆排序就是把最大堆堆顶的最大数取出，将剩余的堆继续调整为最大堆，再次将堆顶的最大数取出，这个过程持续到剩余数只有一个时结束。在堆中定义以下几种操作： （1）最大堆调整（Max-Heapify）：将堆的末端子节点作调整，使得子节点永远小于父节点。 （2）创建最大堆（Build-Max-Heap）：将堆所有数据重新排序，使其成为最大堆。 （3）堆排序（Heap-Sort）：移除位在第一个数据的根节点，并做最大堆调整的递归运算 如何得到一个数据流中的中位数？数据是从一个数据流中读出来的，数据的数目随着时间的变化而增加。如果用一个数据容器来保存从流中读出来的数据，当有新的数据流中读出来时，这些数据就插入到数据容器中。 数组是最简单的容器。如果数组没有排序，可以用 Partition 函数找出数组中的中位数。在没有排序的数组中插入一个数字和找出中位数的时间复杂度是 O(1)和 O(n)。 我们还可以往数组里插入新数据时让数组保持排序，这是由于可能要移动 O(n)个数，因此需要 O(n)时间才能完成插入操作。在已经排好序的数组中找出中位数是一个简单的操作，只需要 O(1)时间即可完成。 排序的链表时另外一个选择。我们需要 O(n)时间才能在链表中找到合适的位置插入新的数据。如果定义两个指针指向链表的中间结点（如果链表的结点数目是奇数，那么这两个指针指向同一个结点），那么可以在 O（1）时间得出中位数。此时时间效率与及基于排序的数组的时间效率一样。 如果能够保证数据容器左边的数据都小于右边的数据，这样即使左、右两边内部的数据没有排序，也可以根据左边最大的数及右边最小的数得到中位数。如何快速从一个容器中找出最大数？用最大堆实现这个数据容器，因为位于堆顶的就是最大的数据。同样，也可以快速从最小堆中找出最小数。 因此可以用如下思路来解决这个问题：用一个最大堆实现左边的数据容器，用最小堆实现右边的数据容器。往堆中插入一个数据的时间效率是 O(logn)。由于只需 O(1)时间就可以得到位于堆顶的数据，因此得到中位数的时间效率是 O(1)。 你知道哪些排序算法，这些算法的时间复杂度分别是多少，解释一下快排？ 快排：快速排序有两个方向，左边的i下标一直往右走（当条件a[i] &lt;= a[center_index]时），其中center_index是中枢元素的数组下标，一般取为数组第0个元素。 而右边的j下标一直往左走（当a[j] &gt; a[center_index]时）。 如果i和j都走不动了，i &lt;= j, 交换a[i]和a[j],重复上面的过程，直到i&gt;j。交换a[j]和a[center_index]，完成一趟快速排序。 堆与栈解释一下，内存中的栈(stack)、堆(heap) 和静态区(static area) 的用法。通常我们定义一个基本数据类型的变量，一个对象的引用，还有就是函数调用的现场保存都使用内存中的栈空间；而通过new关键字和构造器创建的对象放在堆空间；程序中的字面量（literal）如直接书写的100、”hello”和常量都是放在静态区中。栈空间操作起来最快但是栈很小，通常大量的对象都是放在堆空间，理论上整个内存没有被其他进程使用的空间甚至硬盘上的虚拟内存都可以被当成堆空间来使用。String str = new String(“hello”);上面的语句中变量str放在栈上，用new创建出来的字符串对象放在堆上，而”hello”这个字面量放在静态区。 heap和stack有什么区别。栈是一种线形集合，其添加和删除元素的操作应在同一段完成。栈按照后进先出的方式进行处理。堆是栈的一个组成元素。 堆与栈的不同是什么？（1）Java的堆是一个运行时数据区，类的对象从中分配空间。通过比如：new等指令建立，不需要代码显式的释放，由垃圾回收来负责。 优点：可以动态地分配内存大小，垃圾收集器会自动回收垃圾数据。 缺点：由于其优点，所以存取速度较慢。 （2）栈： 其数据项的插入和删除都只能在称为栈顶的一端完成，后进先出。栈中存放一些基本类型的 变量 和 对象句柄。 优点：读取数度比堆要快，仅次于寄存器，栈数据可以共享。 缺点：比堆缺乏灵活性，存在栈中的数据大小与生存期必须是确定的。 举例： String是一个特殊的包装类数据。可以用：String str = new String(“csdn”);String str = “csdn”; 两种的形式来创建，第一种是用new()来新建对象的，它会在存放于堆中。每调用一次就会创建一个新的对象。而第二种是先在栈中创建一个对String类的对象引用变量str，然后查找栈中有没有存放”csdn”，如果没有，则将”csdn”存放进栈，并令str指向”abc”，如果已经有”csdn” 则直接令str指向“csdn”。 队列什么是Java优先级队列(Priority Queue)？PriorityQueue是一个基于优先级堆的无界队列，它的元素是按照自然顺序(natural order)排序的。在创建的时候，我们可以给它提供一个负责给元素排序的比较器。PriorityQueue不允许null值，因为他们没有自然顺序，或者说他们没有任何的相关联的比较器。最后，PriorityQueue不是线程安全的，入队和出队的时间复杂度是O(log(n))。 高级算法LRU算法的实现原理？①LRU（Least recently used，最近最少使用）算法根据数据的历史访问记录来进行淘汰数据，其核心思想是“如果数据最近被访问过，那么将来被访问的几率也很高”，反过来说“如果数据最近这段时间一直都没有访问,那么将来被访问的概率也会很低”，两种理解是一样的；常用于页面置换算法，为虚拟页式存储管理服务。 ②达到这样一种情形的算法是最理想的：每次调换出的页面是所有内存页面中最迟将被使用的；这可以最大限度的推迟页面调换，这种算法，被称为理想页面置换算法。可惜的是，这种算法是无法实现的。为了尽量减少与理想算法的差距，产生了各种精妙的算法，最近最少使用页面置换算法便是其中一个。LRU 算法的提出，是基于这样一个事实：在前面几条指令中使用频繁的页面很可能在后面的几条指令中频繁使用。反过来说，已经很久没有使用的页面很可能在未来较长的一段时间内不会被用到 。这个，就是著名的局部性原理——比内存速度还要快的cache，也是基于同样的原理运行的。因此，我们只需要在每次调换时，找到最近最少使用的那个页面调出内存。 算法实现的关键 命中率：当存在热点数据时，LRU的效率很好，但偶发性的、周期性的批量操作会导致 LRU 命中率急剧下降，缓存污染情况比较严重。复杂度：实现起来较为简单。存储成本：几乎没有空间上浪费。代价：命中时需要遍历链表，找到命中的数据块索引，然后需要将数据移到头部。 为什么要设计 后缀表达式，有什么好处？后缀表达式又叫逆波兰表达式，逆波兰记法不需要括号来标识操作符的优先级。 设计一个算法，用来压缩一段URL？该算法主要使用MD5 算法对原始链接进行加密（这里使用的MD5 加密后的字符串长度为32 位），然后对加密后的字符串进行处理以得到短链接的地址。 谈一谈，id全局唯一且自增，如何实现？SnowFlake雪花算法 雪花ID生成的是一个64位的二进制正整数，然后转换成10进制的数。64位二进制数由如下部分组成： snowflake id生成规则 1位标识符：始终是0，由于long基本类型在Java中是带符号的，最高位是符号位，正数是0，负数是1，所以id一般是正数，最高位是0。 41位时间戳：41位时间截不是存储当前时间的时间截，而是存储时间截的差值（当前时间截 - 开始时间截 )得到的值，这里的的开始时间截，一般是我们的id生成器开始使用的时间，由我们程序来指定的。 10位机器标识码：可以部署在1024个节点，如果机器分机房（IDC）部署，这10位可以由 5位机房ID + 5位机器ID 组成。 12位序列：毫秒内的计数，12位的计数顺序号支持每个节点每毫秒(同一机器，同一时间截)产生4096个ID序号 优点 简单高效，生成速度快。 时间戳在高位，自增序列在低位，整个ID是趋势递增的，按照时间有序递增。 灵活度高，可以根据业务需求，调整bit位的划分，满足不同的需求。 缺点 依赖机器的时钟，如果服务器时钟回拨，会导致重复ID生成。 在分布式环境上，每个服务器的时钟不可能完全同步，有时会出现不是全局递增的情况。","categories":[],"tags":[{"name":"Interview","slug":"Interview","permalink":"https://kayleh.top/tags/Interview/"}]},{"title":"操作系统概论","slug":"操作系统概论","date":"2020-07-24T06:46:46.000Z","updated":"2020-07-24T07:24:17.778Z","comments":true,"path":"2020/07/24/操作系统概论/","link":"","permalink":"https://kayleh.top/2020/07/24/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E6%A6%82%E8%AE%BA/","excerpt":"操作系统概论","text":"操作系统概论 64位和32位的区别？操作系统只是硬件和应用软件中间的一个平台。32位操作系统针对的32位的CPU设计。64位操作系统针对的64位的CPU设计。 CentOS 和 Linux的关系？CentOS是Linux众多得发行版本之一，linux有三大发行版本（：Slackware、debian、redhat）,而Redhat有收费的商业版和免费的开源版,商业版的业内称之为RHEL系列，CentOS是来自于依照开放源代码规定而公布的源代码重新编译而成。可以用CentOS替代商业版的RHEL使用。两者的不同，CentOS不包含封闭源代码软件，是免费的。 进程的描述与控制LINUX下的线程，GDI类LINUX实现的就是基于核心轻量级进程的”一对一”线程模型，一个线程实体对应一个核心轻量级进程，而线程之间的管理在核外函数库中实现。 GDI类为图像设备编程接口类库。 进程和线程的区别是什么？进程是执行着的应用程序，而线程是进程内部的一个执行序列。一个进程可以有多个线程。线程又叫做轻量级进程。 系统线程数量上限是多少？Linux 系统中单个进程的最大线程数有其最大的限制 PTHREAD_THREADS_MAX。 这个限制可以在/usr/include/bits/local_lim.h中查看 ，对 linuxthreads 这个值一般是 1024，对于 nptl 则没有硬性的限制，仅仅受限于系统的资源。 这个系统的资源主要就是线程的 stack 所占用的内存，用 ulimit -s 可以查看默认的线程栈大小，一般情况下，这个值是8M=8192KB。 线程与进程的区别进程和线程的主要差别在于它们是不同的操作系统资源管理方式。进程有独立的地址空间，一个进程崩溃后，在保护模式下不会对其它进程产生影响，而线程只是一个进程中的不同执行路径。线程有自己的堆栈和局部变量，但线程之间没有单独的地址空间，一个线程死掉就等于整个进程死掉，所以多进程的程序要比多线程的程序健壮，但在进程切换时，耗费资源较大，效率要差一些。但对于一些要求同时进行并且又要共享某些变量的并发操作，只能用线程，不能用进程。 1) 简而言之,一个程序至少有一个进程,一个进程至少有一个线程. 2) 线程的划分尺度小于进程，使得多线程程序的并发性高。 3) 另外，进程在执行过程中拥有独立的内存单元，而多个线程共享内存，从而极大地提高了程序的运行效率。 4) 线程在执行过程中与进程还是有区别的。每个独立的线程有一个程序运行的入口、顺序执行序列和程序的出口。但是线程不能够独立执行，必须依存在应用程序中，由应用程序提供多个线程执行控制。 5) 从逻辑角度来看，多线程的意义在于一个应用程序中，有多个执行部分可以同时执行。但操作系统并没有将多个线程看做多个独立的应用，来实现进程的调度和管理以及资源分配。这就是进程和线程的重要区别。 如何杀死一个进程？Kill pid 输入输出系统请介绍一下，socket编程的三种通信模型，BIO，NIO，AIO阻塞，非阻塞，io多路复用，epoll支持文件符数目没有限制，fd集合只会从用户进程拷贝到内核一次，自己维护一个事件队列，不用每次遍历fd集合发现是否有就绪状态。 存储器管理怎么理解操作系统里的内存碎片，有什么解决办法？内存碎片分为：内部碎片和外部碎片。 内部碎片就是已经被分配出去（能明确指出属于哪个进程）却不能被利用的内存空间； 内部碎片是处于区域内部或页面内部的存储块。占有这些区域或页面的进程并不使用这个存储块。而在进程占有这块存储块时，系统无法利用它。直到进程释放它，或进程结束时，系统才有可能利用这个存储块。 单道连续分配只有内部碎片。多道固定连续分配既有内部碎片，又有外部碎片。 外部碎片指的是还没有被分配出去（不属于任何进程），但由于太小了无法分配给申请内存空间的新进程的内存空闲区域。 外部碎片是出于任何已分配区域或页面外部的空闲存储块。这些存储块的总和可以满足当前申请的长度要求，但是由于它们的地址不连续或其他原因，使得系统无法满足当前申请。 使用伙伴系统算法。 什么是页式存储？主存被等分成大小相等的片，称为主存块，又称为实页。 当一个用户程序装入内存时，以页面为单位进行分配。页面的大小是为2n ,通常为1KB、2KB、2n KB等 处理调度与死锁系统如何提高并发性？1、提高CPU并发计算能力 （1）多进程&amp;多线程 （2）减少进程切换，使用线程，考虑进程绑定CPU （3）减少使用不必要的锁，考虑无锁编程 （4）考虑进程优先级 （5）关注系统负载 2、改进I/O模型 (1)DMA技术 (2)异步I/O (3)改进多路I/O就绪通知策略，epoll (4)Sendfile (5)内存映射 (6)直接I/O 通常系统CPU比较高是什么原因？1、首先查看是哪些进程的CPU占用率最高（如下可以看到详细的路径） ps -aux –sort -pcpu | more # 定位有问题的线程可以用如下命令 ps -mp pid -o THREAD,tid,time | more 2、查看JAVA进程的每个线程的CPU占用率 ps -Lp 5798 cu | more # 5798是查出来进程PID 3、追踪线程，查看负载过高的原因，使用JDK下的一个工具 jstack 5798 # 5798是PID jstack -J-d64 -m 5798 # -j-d64指定64为系统 jstack 查出来的线程ID是16进制，可以把输出追加到文件，导出用记事本打开，再根据系统中的线程ID去搜索查看该ID的线程运行内容，可以和开发一起排查。 什么情况下会发生死锁？解决死锁的策略有哪些？（一）互斥条件：一个资源一次只能被一个进程访问。即某个资源在一段时间内只能由一个进程占有，不能同时被两个或两个以上的进程占 有。这种独占资源如CD-ROM驱动器，打印机等等，必须在占有该资源的进程主动释放它之后，其它进程才能占有该资源。这是由资源本身的属性所决定的。 （二）请求与保持条件：一个进程因请求资源而阻塞时，对已获得的资源保持不放。进程至少已经占有一个资源，但又申请新的资源；由于该资源已被另外进程占有，此时该进程阻塞；但是，它在等待新资源之时，仍继续占用已占有的资源。 （三）不剥夺条件：进程已经获得的资源，在未使用完之前不能强行剥夺，而只能由该资源的占有者进程自行释放。 （四）循环等待条件：若干资源形成一种头尾相接的循环等待资源关系。 解决方法：银行家算法","categories":[],"tags":[{"name":"Interview","slug":"Interview","permalink":"https://kayleh.top/tags/Interview/"}]},{"title":"计算机网络","slug":"计算机网络","date":"2020-07-24T06:30:23.000Z","updated":"2020-07-24T06:46:59.499Z","comments":true,"path":"2020/07/24/计算机网络/","link":"","permalink":"https://kayleh.top/2020/07/24/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/","excerpt":"计算机网络","text":"计算机网络 TCP协议、IP协议、HTTP协议分别在哪一层吗？运输层，网络层，应用层。 网络七层模型： 物理层，数据链路层，网络层，运输层，会话层，表现层，应用层 网络五层模型： 物理层，数据链路层，网络层，运输层，应用层 运输层TCP协议的4次握手。由于TCP连接是全双工的，因此每个方向都必须单独进行关闭。这个原则是当一方完成它的数据发送任务后就能发送一个FIN来终止这个方向的连接。收到一个 FIN只意味着这一方向上没有数据流动，一个TCP连接在收到一个FIN后仍能发送数据。首先进行关闭的一方将执行主动关闭，而另一方执行被动关闭。 TCP的连接的拆除需要发送四个包，因此称为四次挥手(four-way handshake)。客户端或服务器均可主动发起挥手动作，在socket编程中，任何一方执行close()操作即可产生挥手操作。 （1）客户端A发送一个FIN，用来关闭客户A到服务器B的数据传送。 （2）服务器B收到这个FIN，它发回一个ACK，确认序号为收到的序号加1。和SYN一样，一个FIN将占用一个序号。 （3）服务器B关闭与客户端A的连接，发送一个FIN给客户端A。 （4）客户端A发回ACK报文确认，并将确认序号设置为收到序号加1。 为什么tcp为什么要建立连接？保证可靠传输。 解释一下TCP为什么可靠一些 三次握手，超时重传，滑动窗口，拥塞控制。 说明一下哪种应用场景会使用TCP协议，使用它的意义 当对网络通讯质量有要求的时候，比如：整个数据要准确无误的传递给对方，这往往用于一些要求可靠的应用，比如HTTP、HTTPS、FTP等传输文件的协议，POP、SMTP等邮件传输的协议 简单描述一下，TCP的连接和释放过程。三次握手的过程1）主机A向主机B发送TCP连接请求数据包，其中包含主机A的初始序列号seq(A)=x。（其中报文中同步标志位SYN=1，ACK=0，表示这是一个TCP连接请求数据报文；序号seq=x，表明传输数据时的第一个数据字节的序号是x）； 2）主机B收到请求后，会发回连接确认数据包。（其中确认报文段中，标识位SYN=1，ACK=1，表示这是一个TCP连接响应数据报文，并含主机B的初始序列号seq(B)=y，以及主机B对主机A初始序列号的确认号ack(B)=seq(A)+1=x+1） 3）第三次，主机A收到主机B的确认报文后，还需作出确认，即发送一个序列号seq(A)=x+1；确认号为ack(A)=y+1的报文； 四次挥手过程假设主机A为客户端，主机B为服务器，其释放TCP连接的过程如下：1） 关闭客户端到服务器的连接：首先客户端A发送一个FIN，用来关闭客户到服务器的数据传送，然后等待服务器的确认。其中终止标志位FIN=1，序列号seq=u。2） 服务器收到这个FIN，它发回一个ACK，确认号ack为收到的序号加1。3） 关闭服务器到客户端的连接：也是发送一个FIN给客户端。 4） 客户段收到FIN后，并发回一个ACK报文确认，并将确认序号seq设置为收到序号加1。 首先进行关闭的一方将执行主动关闭，而另一方执行被动关闭。 三次握手 四次挥手 http请求中的304状态码的含义304(未修改)自从上次请求后，请求的网页未修改过。服务器返回此响应时，不会返回网页内容。如果网页自请求者上次请求后再也没有更改过，您应将服务器配置为返回此响应(称为 If-Modified-Since HTTP 标头)。服务器可以告诉 Googlebot 自从上次抓取后网页没有变更，进而节省带宽和开销。 说明一下，SSL四次握手的过程1、 客户端发出请求 首先，客户端（通常是浏览器）先向服务器发出加密通信的请求，这被叫做ClientHello请求。 2、服务器回应 服务器收到客户端请求后，向客户端发出回应，这叫做SeverHello。 3、客户端回应 客户端收到服务器回应以后，首先验证服务器证书。如果证书不是可信机构颁布、或者证书中的域名与实际域名不一致、或者证书已经过期，就会向访问者显示一个警告，由其选择是否还要继续通信。 4、服务器的最后回应 服务器收到客户端的第三个随机数pre-master key之后，计算生成本次会话所用的”会话密钥”。然后，向客户端最后发送下面信息。 （1）编码改变通知，表示随后的信息都将用双方商定的加密方法和密钥发送。 （2）服务器握手结束通知，表示服务器的握手阶段已经结束。这一项同时也是前面发送的所有内容的hash值，用来供客户端校验。 至此，整个握手阶段全部结束。接下来，客户端与服务器进入加密通信，就完全是使用普通的HTTP协议，只不过用”会话密钥”加密内容。 请你讲讲http1.1和1.0的区别主要区别主要体现在： 缓存处理，在HTTP1.0中主要使用header里的If-Modified-Since,Expires来做为缓存判断的标准，HTTP1.1则引入了更多的缓存控制策略例如Entity tag，If-Unmodified-Since, If-Match, If-None-Match等更多可供选择的缓存头来控制缓存策略。 带宽优化及网络连接的使用，HTTP1.0中，存在一些浪费带宽的现象，例如客户端只是需要某个对象的一部分，而服务器却将整个对象送过来了，并且不支持断点续传功能，HTTP1.1则在请求头引入了range头域，它允许只请求资源的某个部分，即返回码是206（Partial Content），这样就方便了开发者自由的选择以便于充分利用带宽和连接。 错误通知的管理，在HTTP1.1中新增了24个错误状态响应码，如409（Conflict）表示请求的资源与资源的当前状态发生冲突；410（Gone）表示服务器上的某个资源被永久性的删除。 Host头处理，在HTTP1.0中认为每台服务器都绑定一个唯一的IP地址，因此，请求消息中的URL并没有传递主机名（hostname）。但随着虚拟主机技术的发展，在一台物理服务器上可以存在多个虚拟主机（Multi-homed Web Servers），并且它们共享一个IP地址。HTTP1.1的请求消息和响应消息都应支持Host头域，且请求消息中如果没有Host头域会报告一个错误（400 Bad Request）。 长连接，HTTP 1.1支持长连接（PersistentConnection）和请求的流水线（Pipelining）处理，在一个TCP连接上可以传送多个HTTP请求和响应，减少了建立和关闭连接的消耗和延迟，在HTTP1.1中默认开启Connection： keep-alive，一定程度上弥补了HTTP1.0每次请求都要创建连接的缺点。 请谈一下，你知道的http请求，并说明应答码502和504的区别OPTIONS：返回服务器针对特定资源所支持的HTTP请求方法。也可以利用向Web服务器发送’*’的请求来测试服务器的功能性。 HEAD：向服务器索要与GET请求相一致的响应，只不过响应体将不会被返回。这一方法可以在不必传输整个响应内容的情况下，就可以获取包含在响应消息头中的元信息。 GET：向特定的资源发出请求。 POST：向指定资源提交数据进行处理请求（例如提交表单或者上传文件）。数据被包含在请求体中。POST请求可能会导致新的资源的创建和/或已有资源的修改。 PUT：向指定资源位置上传其最新内容。 DELETE：请求服务器删除Request-URI所标识的资源。 TRACE：回显服务器收到的请求，主要用于测试或诊断。 CONNECT：HTTP/1.1协议中预留给能够将连接改为管道方式的代理服务器。 虽然HTTP的请求方式有8种，但是我们在实际应用中常用的也就是get和post，其他请求方式也都可以通过这两种方式间接的来实现。 502：作为网关或者代理工作的服务器尝试执行请求时，从上游服务器接收到无效的响应。 504：作为网关或者代理工作的服务器尝试执行请求时，未能及时从上游服务器（URI标识出的服务器，例如HTTP、FTP、LDAP）或者辅助服务器（例如DNS）收到响应。 http和https的区别 https协议要申请证书到ca，需要一定经济成本；2） http是明文传输，https是加密的安全传输；3） 连接的端口不一样，http是80，https是443；4）http连接很简单，没有状态；https是ssl加密的传输，身份认证的网络协议，相对http传输比较安全。 请讲一下浏览器从接收到一个URL，到最后展示出页面，经历了哪些过程。1.DNS解析 2.TCP连接 3.发送HTTP请求 4.服务器处理请求并返回HTTP报文 5.浏览器解析渲染页面 网络层请简单解释一下，arp协议和arp攻击。地址解析协议。ARP攻击的第一步就是ARP欺骗。由上述“ARP协议的工作过程”我们知道，ARP协议基本没有对网络的安全性做任何思考，当时人们考虑的重点是如何保证网络通信能够正确和快速的完成——ARP协议工作的前提是默认了其所在的网络是一个善良的网络，每台主机在向网络中发送应答信号时都是使用的真实身份。不过后来，人们发现ARP应答中的IP地址和MAC地址中的信息是可以伪造的，并不一定是自己的真实IP地址和MAC地址，由此，ARP欺骗就产生了。 什么是icmp协议，它的作用是什么？它是TCP/IP协议族的一个子协议，用于在IP主机、路由器之间传递控制消息。控制消息是指网络通不通、主机是否可达、路由是否可用等网络本身的消息。这些控制消息虽然并不传输用户数据，但是对于用户数据的传递起着重要的作用。 请你讲一下路由器和交换机的区别？交换机用于同一网络内部数据的快速传输转发决策通过查看二层头部完成转发不需要修改数据帧工作在 TCP/IP 协议的二层 —— 数据链路层工作简单，直接使用硬件处理路由器用于不同网络间数据的跨网络传输转发决策通过查看三层头部完成转发需要修改 TTL ，IP 头部校验和需要重新计算，数据帧需要重新封装工作在 TCP/IP 协议的三层 —— 网络层工作复杂，使用软件处理。 请你谈谈DNS的寻址过程。1、在浏览器中输入www.qq.com域名，操作系统会先检查自己本地的hosts文件是否有这个网址映射关系，如果有，就先调用这个IP地址映射，完成域名解析。 2、如果hosts里没有这个域名的映射，则查找本地DNS解析器缓存，是否有这个网址映射关系，如果有，直接返回，完成域名解析。 3、如果hosts与本地DNS解析器缓存都没有相应的网址映射关系，首先会找TCP/ip参数中设置的首选DNS服务器，在此我们叫它本地DNS服务器，此服务器收到查询时，如果要查询的域名，包含在本地配置区域资源中，则返回解析结果给客户机，完成域名解析，此解析具有权威性。 4、如果要查询的域名，不由本地DNS服务器区域解析，但该服务器已缓存了此网址映射关系，则调用这个IP地址映射，完成域名解析，此解析不具有权威性。 5、如果本地DNS服务器本地区域文件与缓存解析都失效，则根据本地DNS服务器的设置（是否设置转发器）进行查询，如果未用转发模式，本地DNS就把请求发至13台根DNS，根DNS服务器收到请求后会判断这个域名(.com)是谁来授权管理，并会返回一个负责该顶级域名服务器的一个IP。本地DNS服务器收到IP信息后，将会联系负责.com域的这台服务器。这台负责.com域的服务器收到请求后，如果自己无法解析，它就会找一个管理.com域的下一级DNS服务器地址(qq.com)给本地DNS服务器。当本地DNS服务器收到这个地址后，就会找qq.com域服务器，重复上面的动作，进行查询，直至找到www.qq.com主机。 6、如果用的是转发模式，此DNS服务器就会把请求转发至上一级DNS服务器，由上一级服务器进行解析，上一级服务器如果不能解析，或找根DNS或把转请求转至上上级，以此循环。不管是本地DNS服务器用是是转发，还是根提示，最后都是把结果返回给本地DNS服务器，由此DNS服务器再返回给客户机。 从客户端到本地DNS服务器是属于递归查询，而DNS服务器之间就是的交互查询就是迭代查询。 请你简单讲解一下，负载均衡 反向代理模式的优点、缺点（1）反向代理（Reverse Proxy）方式是指以代理服务器来接受internet上的连接请求，然后将请求转发给内部网络上的服务器，并将从服务器上得到的结果返回给internet上请求连接的客户端，此时代理服务器对外就表现为一个服务器。 （2）反向代理负载均衡技术是把将来自internet上的连接请求以反向代理的方式动态地转发给内部网络上的多台服务器进行处理，从而达到负载均衡的目的。 （3）反向代理负载均衡能以软件方式来实现，如apache mod_proxy、netscape proxy等，也可以在高速缓存器、负载均衡器等硬件设备上实现。反向代理负载均衡可以将优化的负载均衡策略和代理服务器的高速缓存技术结合在一起，提升静态网页的访问速度，提供有益的性能；由于网络外部用户不能直接访问真实的服务器，具备额外的安全性（同理，NAT负载均衡技术也有此优点）。 （4）其缺点主要表现在以下两个方面 反向代理是处于OSI参考模型第七层应用的，所以就必须为每一种应用服务专门开发一个反向代理服务器，这样就限制了反向代理负载均衡技术的应用范围，现在一般都用于对web服务器的负载均衡。 针对每一次代理，代理服务器就必须打开两个连接，一个对外，一个对内，因此在并发连接请求数量非常大的时候，代理服务器的负载也就非常大了，在最后代理服务器本身会成为服务的瓶颈。 一般来讲，可以用它来对连接数量不是特别大，但每次连接都需要消耗大量处理资源的站点进行负载均衡，如search等。","categories":[],"tags":[{"name":"Interview","slug":"Interview","permalink":"https://kayleh.top/tags/Interview/"}]},{"title":"XML","slug":"XML","date":"2020-07-24T06:24:49.000Z","updated":"2020-07-24T06:30:09.571Z","comments":true,"path":"2020/07/24/XML/","link":"","permalink":"https://kayleh.top/2020/07/24/XML/","excerpt":"XML","text":"XML 请介绍一下，XML文档定义的几种形式，它们之间有何本质区别？再说说，解析XML文档又有哪几种方式？a: 两种形式 dtd schemab: 本质区别:schema本身是xml的，可以被XML解析器解析(这也是从DTD上发展schema的根本目的)c:有DOM,SAX,STAX等DOM:处理大型文件时其性能下降的非常厉害。这个问题是由DOM的树结构所造成的，这种结构占用的内存较多，而且DOM必须在解析文件之前把整个文档装入内存,适合对XML的随机访问SAX:不现于DOM,SAX是事件驱动型的XML解析方式。它顺序读取XML文件，不需要一次全部装载整个文件。当遇到像文件开头，文档结束，或者标签开头与标签结束时，它会触发一个事件，用户通过在其回调事件中写入处理代码来处理XML文件，适合对XML的顺序访问STAX:Streaming API for XML (StAX)xml文档有两种定义方法：dtd：数据类型定义（data type definition），用以描述XML文档的文档结构，是早期的XML文档定义形式。schema：其本身是基于XML语言编写的，在类型和语法上的限定能力比dtd强，处理也比较方便，因为此正逐渐代替dtd成为新的模式定义语言。 谈一谈，Java规范中和 与Web Service相关的 规范有哪些？Java规范中和Web Service相关的有三个：- JAX-WS(JSR 224)：这个规范是早期的基于SOAP的Web Service规范JAX-RPC的替代版本，它并不提供向下兼容性，因为RPC样式的WSDL以及相关的API已经在Java EE5中被移除了。WS-MetaData是JAX-WS的依赖规范，提供了基于注解配置Web Service和SOAP消息的相关API。- JAXM(JSR 67)：定义了发送和接收消息所需的API,相当于Web Service的服务器端。- JAX-RS(JSR 311 &amp; JSR 339 &amp; JSR 370)：是Java针对REST（Representation State Transfer）架构风格制定的一套Web Service规范。REST是一种软件架构模式，是一种风格，它不像SOAP那样本身承载着一种消息协议， (两种风格的Web Service均采用了HTTP做传输协议，因为HTTP协议能穿越防火墙，Java的远程方法调用（RMI）等是重量级协议，通常不能穿越防火墙），因此可以将REST视为基于HTTP协议的软件架构。REST中最重要的两个概念是资源定位和资源操作，而HTTP协议恰好完整的提供了这两个点。HTTP协议中的URI可以完成资源定位，而GET、POST、OPTION、DELETE方法可以完成资源操作。因此REST完全依赖HTTP协议就可以完成Web Service，而不像SOAP协议那样只利用了HTTP的传输特性，定位和操作都是由SOAP协议自身完成的，也正是由于SOAP消息的存在使得基于SOAP的Web Service显得笨重而逐渐被淘汰。 请你谈谈对SOAP、WSDL、UDDI的了解。- SOAP：简单对象访问协议（Simple Object Access Protocol），是Web Service中交换数据的一种协议规范。- WSDL：Web服务描述语言（Web Service Description Language），它描述了Web服务的公共接口。这是一个基于XML的关于如何与Web服务通讯和使用的服务描述；也就是描述与目录中列出的Web服务进行交互时需要绑定的协议和信息格式。通常采用抽象语言描述该服务支持的操作和信息，使用的时候再将实际的网络协议和信息格式绑定给该服务。- UDDI：统一描述、发现和集成（Universal Description, Discovery and Integration），它是一个基于XML的跨平台的描述规范，可以使世界范围内的企业在互联网上发布自己所提供的服务。简单的说，UDDI是访问各种WSDL的一个门面（可以参考设计模式中的门面模式）。 WEB SERVICE名词解释，JSWDL开发包的介绍，JAXP、JAXM的解释。SOAP、UDDI,WSDL解释。Web ServiceWeb Service是基于网络的、分布式的模块化组件，它执行特定的任务，遵守具体的技术规范，这些规范使得WebService能与其他兼容的组件进行互操作。JAXP(Java API for XML Parsing) 定义了在Java中使用DOM, SAX, XSLT的通用的接口。这样在你的程序中你只要使用这些通用的接口，当你需要改变具体的实现时候也不需要修改代码。JAXM(Java API for XML Messaging) 是为SOAP通信提供访问方法和传输机制的API。WSDL是一种 XML 格式，用于将网络服务描述为一组端点，这些端点对包含面向文档信息或面向过程信息的消息进行操作。这种格式首先对操作和消息进行抽象描述，然后将其绑定到具体的网络协议和消息格式上以定义端点。相关的具体端点即组合成为抽象端点（服务）。SOAP即简单对象访问协议(Simple Object Access Protocol)，它是用于交换XML编码信息的轻量级协议。UDDI 的目的是为电子商务建立标准；UDDI是一套基于Web的、分布式的、为Web Service提供的、信息注册中心的实现标准规范，同时也包含一组使企业能将自身提供的Web Service注册，以使别的企业能够发现的访问协议的实现标准。soap是web service最关键的技术，是web service中数据和方法调传输的介质。WSDL（web service definition language）描述了web service的接口和功能。","categories":[],"tags":[{"name":"Interview","slug":"Interview","permalink":"https://kayleh.top/tags/Interview/"}]},{"title":"JDBC","slug":"JDBC","date":"2020-07-16T07:06:43.000Z","updated":"2020-07-16T07:39:48.302Z","comments":true,"path":"2020/07/16/JDBC/","link":"","permalink":"https://kayleh.top/2020/07/16/JDBC/","excerpt":"JDBC","text":"JDBC SQL现在有一个学生表，一个课程成绩表，请问，怎么找出学生课程的最高分数，谈一谈思路现在，有一个组合索引（A,B,C），可以有哪几种查询方式？1234567891011121314151617181920212223242526272829303132333435363738优: select * from test where a=10 and b&gt;50差: select * from test where b = 50优: select * from test order by a差: select * from test order by b差: select * from test order by c优: select * from test where a=10 order by a优: select * from test where a=10 order by b差: select * from test where a=10 order by c优: select * from test where a&gt;10 order by a差: select * from test where a&gt;10 order by b差: select * from test where a&gt;10 order by c优: select * from test where a=10 and b=10 order by a优: select * from test where a=10 and b=10 order by b优: select * from test where a=10 and b=10 order by c优: select * from test where a=10 and b=10 order by a优: select * from test where a=10 and b&gt;10 order by b差: select * from test where a=10 and b&gt;10 order by c 写SQL：找出每个城市的最新一条记录。 id 城市 人口 信息 创建时间1 北京 100 info1 时间戳2 北京 100 info2 时间戳3 上海 100 info3 时间戳4 上海 100 info4 时间戳 请你讲解一下数据连接池的工作机制?J2EE 服务器启动时会建立一定数量的池连接，并一直维持不少于此数目的池连接。客户端程序需要连接时，池驱动程序会返回一个未使用的池连接并将其表记为忙。如果当前没有空闲连接，池驱动程序就新建一定数量的连接，新建连接的数量由配置参数决定。当使用的池连接调用完成后，池驱动程序将此连接表记为空闲，其他调用就可以使用这个连接。 了解继承映射吗，请简单讲讲你的理解。① 每个继承结构一张表（table per class hierarchy），不管多少个子类都用一张表。② 每个子类一张表（table per subclass），公共信息放一张表，特有信息放单独的表。③ 每个具体类一张表（table per concrete class），有多少个子类就有多少张表。第一种方式属于单表策略，其优点在于查询子类对象的时候无需表连接，查询速度快，适合多态查询；缺点是可能导致表很大。后两种方式属于多表策略，其优点在于数据存储紧凑，其缺点是需要进行连接查询，不适合多态查询。 请介绍一些你了解的数据库优化方法（1）选取最适用的字段属性 MySQL可以很好的支持大数据量的存取，但是一般说来，数据库中的表越小，在它上面执行的查询也就会越快。因此，在创建表的时候，为了获得更好的性能，我们可以将表中字段的宽度设得尽可能小。 例如，在定义邮政编码这个字段时，如果将其设置为CHAR(255),显然给数据库增加了不必要的空间，甚至使用VARCHAR这种类型也是多余的，因为CHAR(6)就可以很好的完成任务了。同样的，如果可以的话，我们应该使用MEDIUMINT而不是BIGIN来定义整型字段。 另外一个提高效率的方法是在可能的情况下，应该尽量把字段设置为NOTNULL，这样在将来执行查询的时候，数据库不用去比较NULL值。对于某些文本字段，例如“省份”或者“性别”，我们可以将它们定义为ENUM类型。因为在MySQL中，ENUM类型被当作数值型数据来处理，而数值型数据被处理起来的速度要比文本类型快得多。这样，我们又可以提高数据库的性能。 （2）使用连接（JOIN）来代替子查询(Sub-Queries) MySQL从4.1开始支持SQL的子查询。这个技术可以使用SELECT语句来创建一个单列的查询结果，然后把这个结果作为过滤条件用在另一个查询中。例如，我们要将客户基本信息表中没有任何订单的客户删除掉，就可以利用子查询先从销售信息表中将所有发出订单的客户ID取出来，然后将结果传递给主查询 （3）使用联合(UNION)来代替手动创建的临时表 MySQL从4.0的版本开始支持union查询，它可以把需要使用临时表的两条或更多的select查询合并的一个查询中。在客户端的查询会话结束的时候，临时表会被自动删除，从而保证数据库整齐、高效。使用union来创建查询的时候，我们只需要用UNION作为关键字把多个select语句连接起来就可以了，要注意的是所有select语句中的字段数目要想同。下面的例子就演示了一个使用UNION的查询。 （4）事务 尽管我们可以使用子查询（Sub-Queries）、连接（JOIN）和联合（UNION）来创建各种各样的查询，但不是所有的数据库操作都可以只用一条或少数几条SQL语句就可以完成的。更多的时候是需要用到一系列的语句来完成某种工作。但是在这种情况下，当这个语句块中的某一条语句运行出错的时候，整个语句块的操作就会变得不确定起来。设想一下，要把某个数据同时插入两个相关联的表中，可能会出现这样的情况：第一个表中成功更新后，数据库突然出现意外状况，造成第二个表中的操作没有完成，这样，就会造成数据的不完整，甚至会破坏数据库中的数据。要避免这种情况，就应该使用事务，它的作用是：要么语句块中每条语句都操作成功，要么都失败。换句话说，就是可以保持数据库中数据的一致性和完整性。事物以BEGIN关键字开始，COMMIT关键字结束。在这之间的一条SQL操作失败，那么，ROLLBACK命令就可以把数据库恢复到BEGIN开始之前的状态。 说明一下 left join 和 right join 的区别？left join(左联接) 返回包括左表中的所有记录和右表中联结字段相等的记录right join(右联接) 返回包括右表中的所有记录和左表中联结字段相等的记录 比如： 表A记录如下：aID aNum1 a200501112 a200501123 a200501134 a200501145 a20050115 表B记录如下:bID bName1 20060324012 20060324023 20060324034 20060324048 2006032408 left join是以A表的记录为基础的,A可以看成左表,B可以看成右表,left join是以左表为准的.换句话说,左表(A)的记录将会全部表示出来,而右表(B)只会显示符合搜索条件的记录(例子中为: A.aID = B.bID).B表记录不足的地方均为NULL. 介绍一下 mysql的主从复制？MySQL主从复制是其最重要的功能之一。主从复制是指一台服务器充当主数据库服务器，另一台或多台服务器充当从数据库服务器，主服务器中的数据自动复制到从服务器之中。对于多级复制，数据库服务器即可充当主机，也可充当从机。MySQL主从复制的基础是主服务器对数据库修改记录二进制日志，从服务器通过主服务器的二进制日志自动执行更新。 MySQL主从复制的两种情况：同步复制和异步复制，实际复制架构中大部分为异步复制。 复制的基本过程如下： Slave上面的IO进程连接上Master，并请求从指定日志文件的指定位置（或者从最开始的日志）之后的日志内容。 Master接收到来自Slave的IO进程的请求后，负责复制的IO进程会根据请求信息读取日志指定位置之后的日志信息，返回给Slave的IO进程。返回信息中除了日志所包含的信息之外，还包括本次返回的信息已经到Master端的bin-log文件的名称以及bin-log的位置。 Slave的IO进程接收到信息后，将接收到的日志内容依次添加到Slave端的relay-log文件的最末端，并将读取到的Master端的 bin-log的文件名和位置记录到master-info文件中，以便在下一次读取的时候能够清楚的告诉Master“我需要从某个bin-log的哪个位置开始往后的日志内容，请发给我”。 Slave的Sql进程检测到relay-log中新增加了内容后，会马上解析relay-log的内容成为在Master端真实执行时候的那些可执行的内容，并在自身执行。 数据库ACID的特性。原子性是指事务是一个不可分割的工作单位，事务中的操作要么都发生，要么都不发生。 一致性指事务前后数据的完整性必须保持一致。 隔离性指多个用户并发访问数据库时，一个用户的事务不能被其他用户的事务所干扰，多个并发事务之间数据要相互隔离。 持久性是指一个事务一旦提交，它对数据库中数据的改变就是永久性的，即便数据库发生故障也不应该对其有任何影响。 请你介绍一下，数据库的三个范式？第一范式（1NF）强调的是列的原子性，即列不能够再分成其他几列。第二范式（2NF）首先是 1NF，另外包含两部分内容，一是表必须有一个主键；二是没有包含在主键中的列必须完全依赖于主键，而不能只依赖于主键的一部分。在1NF基础上，任何非主属性不依赖于其它非主属性[在2NF基础上消除传递依赖]。第三范式（3NF）第三范式（3NF）是第二范式（2NF）的一个子集，即满足第三范式（3NF）必须满足第二范式（2NF）。首先是 2NF，另外非主键列必须直接依赖于主键，不能存在传递依赖。即不能存在：非主键列 A 依赖于非主键列 B，非主键列 B 依赖于主键的情况。 请你介绍一下，数据库乐观锁和悲观锁悲观锁 悲观锁（Pessimistic Lock），顾名思义，就是很悲观，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会block直到它拿到锁。悲观锁：假定会发生并发冲突，屏蔽一切可能违反数据完整性的操作。 Java synchronized 就属于悲观锁的一种实现，每次线程要修改数据时都先获得锁，保证同一时刻只有一个线程能操作数据，其他线程则会被block。 乐观锁 乐观锁（Optimistic Lock），顾名思义，就是很乐观，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在提交更新的时候会判断一下在此期间别人有没有去更新这个数据。乐观锁适用于读多写少的应用场景，这样可以提高吞吐量。 乐观锁：假设不会发生并发冲突，只在提交操作时检查是否违反数据完整性。 乐观锁一般来说有以下2种方式： 使用数据版本（Version）记录机制实现，这是乐观锁最常用的一种实现方式。何谓数据版本？即为数据增加一个版本标识，一般是通过为数据库表增加一个数字类型的 “version” 字段来实现。当读取数据时，将version字段的值一同读出，数据每更新一次，对此version值加一。当我们提交更新的时候，判断数据库表对应记录的当前版本信息与第一次取出来的version值进行比对，如果数据库表当前版本号与第一次取出来的version值相等，则予以更新，否则认为是过期数据。 使用时间戳（timestamp）。乐观锁定的第二种实现方式和第一种差不多，同样是在需要乐观锁控制的table中增加一个字段，名称无所谓，字段类型使用时间戳（timestamp）, 和上面的version类似，也是在更新提交的时候检查当前数据库中数据的时间戳和自己更新前取到的时间戳进行对比，如果一致则OK，否则就是版本冲突。 介绍一下数据库的隔离级别 隔离级别 脏读（Dirty Read） 不可重复读（NonRepeatable Read） 幻读（Phantom Read） 未提交读（Read uncommitted） 可能 可能 可能 已提交读（Read committed） 不可能 可能 可能 可重复读（Repeatable read） 不可能 不可能 可能 可串行化（Serializable ） 不可能 不可能 不可能 未提交读(Read Uncommitted)：允许脏读，也就是可能读取到其他会话中未提交事务修改的数据。 提交读(Read Committed)：只能读取到已经提交的数据。Oracle等多数数据库默认都是该级别 (不重复读)。 可重复读(Repeated Read)：可重复读。在同一个事务内的查询都是事务开始时刻一致的，InnoDB默认级别。在SQL标准中，该隔离级别消除了不可重复读，但是还存在幻象读。 串行读(Serializable)：完全串行化的读，每次读都需要获得表级共享锁，读写相互都会阻塞。 说明一下，数据库索引底层是怎样实现的，哪些情况下索引会失效B+树实现的。 没有遵循最左匹配原则。 一些关键字会导致索引失效，例如 or， ！= ， not in，is null ,is not unll like查询是以%开头 隐式转换会导致索引失效。 对索引应用内部函数，索引字段进行了运算。 mysql数据库的两种引擎 区别InnoDB是聚集索引，支持事务，支持行级锁；MyISAM是非聚集索引，不支持事务，只支持表级锁。 请介绍一下，数据库索引，以及，什么时候用Innodb什么时候用MyISAM。索引是对数据库表中一列或多列的值进行排序的一种结构，使用索引可快速访问数据库表中的特定信息。如果想按特定职员的姓来查找他或她，则与在表中搜索所有的行相比，索引有助于更快地获取信息。索引的一个主要目的就是加快检索表中数据的方法，亦即能协助信息搜索者尽快的找到符合限制条件的记录ID的辅助数据结构。InnoDB主要面向在线事务处理（OLTP）的应用。MyISAM主要面向一些OLAP的应用。 数据库水平切分与垂直切分垂直拆分就是要把表按模块划分到不同数据库表中（当然原则还是不破坏第三范式），这种拆分在大型网站的演变过程中是很常见的。当一个网站还在很小的时候，只有小量的人来开发和维护，各模块和表都在一起，当网站不断丰富和壮大的时候，也会变成多个子系统来支撑，这时就有按模块和功能把表划分出来的需求。其实，相对于垂直切分更进一步的是服务化改造，说得简单就是要把原来强耦合的系统拆分成多个弱耦合的服务，通过服务间的调用来满足业务需求看，因此表拆出来后要通过服务的形式暴露出去，而不是直接调用不同模块的表，淘宝在架构不断演变过程，最重要的一环就是服务化改造，把用户、交易、店铺、宝贝这些核心的概念抽取成独立的服务，也非常有利于进行局部的优化和治理，保障核心模块的稳定性。 垂直拆分：单表大数据量依然存在性能瓶颈 水平拆分，上面谈到垂直切分只是把表按模块划分到不同数据库，但没有解决单表大数据量的问题，而水平切分就是要把一个表按照某种规则把数据划分到不同表或数据库里。例如像计费系统，通过按时间来划分表就比较合适，因为系统都是处理某一时间段的数据。而像SaaS应用，通过按用户维度来划分数据比较合适，因为用户与用户之间的隔离的，一般不存在处理多个用户数据的情况，简单的按user_id范围来水平切分。 通俗理解：水平拆分行，行数据拆分到不同表中， 垂直拆分列，表数据拆分到不同表中。 JDBC中如何进行事务处理？Connection提供了事务处理的方法，通过调用setAutoCommit(false)可以设置手动提交事务；当事务完成后用commit()显式提交事务；如果在事务处理过程中发生异常则通过rollback()进行事务回滚。除此之外，从JDBC 3.0中还引入了Savepoint（保存点）的概念，允许通过代码设置保存点并让事务回滚到指定的保存点。 什么是数据库中事务的ACID？- 原子性(Atomic)：事务中各项操作，要么全做要么全不做，任何一项操作的失败都会导致整个事务的失败； - 一致性(Consistent)：事务结束后系统状态是一致的；- 隔离性(Isolated)：并发执行的事务彼此无法看到对方的中间状态；- 持久性(Durable)：事务完成后所做的改动都会被持久化，即使发生灾难性的失败。通过日志和同步备份可以在故障发生后重建数据。 关于事务，在面试中被问到的概率是很高的，可以问的问题也是很多的。首先需要知道的是，只有存在并发数据访问时才需要事务。当多个事务访问同一数据时，可能会存在5类问题，包括3类数据读取问题（脏读、不可重复读和幻读）和2类数据更新问题（第1类丢失更新和第2类丢失更新）。 使用JDBC操作数据库时，经常遇到性能问题，请你说明一下如何提升读取数据的性能，以及更新数据的性能？要提升读取数据的性能，可以指定通过结果集（ResultSet）对象的setFetchSize()方法指定每次抓取的记录数（典型的空间换时间策略）；要提升更新数据的性能可以使用PreparedStatement语句构建批处理，将若干SQL语句置于一个批处理中执行。 请你讲讲 Statement 和 PreparedStatement 的区别？哪个性能更好？与Statement相比，①PreparedStatement接口代表预编译的语句，它主要的优势在于可以减少SQL的编译错误并增加SQL的安全性（减少SQL注射攻击的可能性）；②PreparedStatement中的SQL语句是可以带参数的，避免了用字符串连接拼接SQL语句的麻烦和不安全；③当批量处理SQL或频繁执行相同的查询时，PreparedStatement有明显的性能上的优势，由于数据库可以将编译优化后的SQL语句缓存起来，下次执行相同结构的语句时就会很快（不用再次编译和生成执行计划）。 为了提供对存储过程的调用，JDBC API中还提供了CallableStatement接口。存储过程（Stored Procedure）是数据库中一组为了完成特定功能的SQL语句的集合，经编译后存储在数据库中，用户通过指定存储过程的名字并给出参数（如果该存储过程带有参数）来执行它。虽然调用存储过程会在网络开销、安全性、性能上获得很多好处，但是存在如果底层数据库发生迁移时就会有很多麻烦，因为每种数据库的存储过程在书写上存在不少的差别。 请你解释一下Jdo以及它的作用JDO 是Java对象持久化的新的规范，为java data object的简称,也是一个用于存取某种数据仓库中的对象的标准化API。JDO提供了透明的对象存储，因此对开发人员来说，存储数据对象完全不需要额外的代码（如JDBC API的使用）。这些繁琐的例行工作已经转移到JDO产品提供商身上，使开发人员解脱出来，从而集中时间和精力在业务逻辑上。另外，JDO很灵活，因为它可以在任何数据底层上运行。JDBC只是面向关系数据库（RDBMS）JDO更通用，提供到任何数据底层的存储功能，比如关系数据库、文件、XML以及对象数据库（ODBMS）等等，使得应用可移植性更强。 谈谈JDBC的反射，以及它的作用？通过反射com.mysql.jdbc.Driver类，实例化该类的时候会执行该类内部的静态代码块，该代码块会在Java实现的DriverManager类中注册自己,DriverManager管理所有已经注册的驱动类，当调用DriverManager.geConnection方法时会遍历这些驱动类，并尝试去连接数据库，只要有一个能连接成功，就返回Connection对象，否则则报异常。","categories":[],"tags":[{"name":"Interview","slug":"Interview","permalink":"https://kayleh.top/tags/Interview/"}]},{"title":"about me","slug":"Contract","date":"2020-07-15T13:57:44.000Z","updated":"2020-08-20T07:19:56.215Z","comments":true,"path":"2020/07/15/Contract/","link":"","permalink":"https://kayleh.top/2020/07/15/Contract/","excerpt":"一名保安。 about","text":"一名保安。 about 我是一名保安，安全与我无关 保安？保护不了任何人 Github: https://github.com/Kayleh Facebook: https://www.facebook.com/kayleh.yao.7 Twitter: https://twitter.com/y40jinqing Weibo: https://weibo.com/5737136689/profile?rightmod=1&amp;wvr=6&amp;mod=personinfo Zhihu: https://www.zhihu.com/people/ni-hui-gan-xie-wo-de Linkedin: https://www.linkedin.com/in/jinqing-yao-97a750186/ Google: “&#107;&#97;&#121;&#108;&#101;&#104;&#105;&#115;&#100;&#105;&#101;&#100;&#64;&#103;&#109;&#97;&#105;&#108;&#46;&#99;&#111;&#109;”","categories":[],"tags":[{"name":"about","slug":"about","permalink":"https://kayleh.top/tags/about/"}]},{"title":"J2EE","slug":"J2EE","date":"2020-07-14T05:44:34.000Z","updated":"2020-07-14T07:08:07.252Z","comments":true,"path":"2020/07/14/J2EE/","link":"","permalink":"https://kayleh.top/2020/07/14/J2EE/","excerpt":"Java Web","text":"Java Web JAVA应用服务器都有那些？BEA WebLogic Server， IBM WebSphere Application Server， Oracle9i Application Server jBoss， Tomcat 在什么情况下回使用assert？assertion (断言)在软件开发中是一种常用的调试方式，很多开发语言中都支持这种机制。在实现中，assertion就是在程序中的一条语句，它对一个 boolean表达式进行检查，一个正确程序必须保证这个boolean表达式的值为true；如果该值为false，说明程序已经处于不正确的状态下，系统将给出警告或退出。一般来说，assertion用于保证程序最基本、关键的正确性。assertion检查通常在开发和测试时开启。为了提高性能，在软件发布后，assertion检查通常是关闭的。 1分钟之内只能处理1000个请求，你怎么实现，手撕代码? 限流的几种方法：计数器，滑动窗口、漏桶法、令牌桶 如何在链接里不输入项目名称的情况下启动项目？ 可在taomcat配置虚拟目录。 说明一下JSP中的静态包含和动态包含的有哪些区别？静态包含是通过JSP的include指令包含页面，动态包含是通过JSP标准动作jsp:forward包含页面。静态包含是编译时包含，如果包含的页面不存在则会产生编译错误，而且两个页面的”contentType”属性应保持一致，因为两个页面会合二为一，只产生一个class文件，因此被包含页面发生的变动再包含它的页面更新前不会得到更新。动态包含是运行时包含，可以向被包含的页面传递参数，包含页面和被包含页面是独立的，会编译出两个class文件，如果被包含的页面不存在，不会产生编译错误，也不影响页面其他部分的执行。 例如： &lt;%– 静态包含 –%&gt;&lt;%@ include file=”…” %&gt; &lt;%– 动态包含 –%&gt;&lt;jsp:include page=”…”&gt;&lt;jsp:param name=”…” value=”…” /&gt; &lt;&gt; 请说一下表达式语言（EL）的隐式对象以及该对象的作用EL的隐式对象包括：pageContext、initParam（访问上下文参数）、param（访问请求参数）、paramValues、header（访问请求头）、headerValues、cookie（访问cookie）、applicationScope（访问application作用域）、sessionScope（访问session作用域）、requestScope（访问request作用域）、pageScope（访问page作用域）。 谈一谈JSP有哪些内置对象？以及这些对象的作用分别是什么？JSP有9个内置对象：- request：封装客户端的请求，其中包含来自GET或POST请求的参数；- response：封装服务器对客户端的响应；- pageContext：通过该对象可以获取其他对象；- session：封装用户会话的对象；- application：封装服务器运行环境的对象；- out：输出服务器响应的输出流对象；- config：Web应用的配置对象；- page：JSP页面本身（相当于Java程序中的this）；- exception：封装页面抛出异常的对象。 如果用Servlet来生成网页中的动态内容无疑是非常繁琐的工作，另一方面，所有的文本和HTML标签都是硬编码，即使做出微小的修改，都需要进行重新编译。JSP解决了Servlet的这些问题，它是Servlet很好的补充，可以专门用作为用户呈现视图（View），而Servlet作为控制器（Controller）专门负责处理用户请求并转发或重定向到某个页面。基于Java的Web开发很多都同时使用了Servlet和JSP。JSP页面其实是一个Servlet，能够运行Servlet的服务器（Servlet容器）通常也是JSP容器，可以提供JSP页面的运行环境，Tomcat就是一个Servlet/JSP容器。第一次请求一个JSP页面时，Servlet/JSP容器首先将JSP页面转换成一个JSP页面的实现类，这是一个实现了JspPage接口或其子接口HttpJspPage的Java类。JspPage接口是Servlet的子接口，因此每个JSP页面都是一个Servlet。转换成功后，容器会编译Servlet类，之后容器加载和实例化Java字节码，并执行它通常对Servlet所做的生命周期操作。对同一个JSP页面的后续请求，容器会查看这个JSP页面是否被修改过，如果修改过就会重新转换并重新编译并执行。如果没有则执行内存中已经存在的Servlet实例。 说说weblogic中一个Domain的缺省目录结构?比如要将一个简单的helloWorld.jsp放入何目录下,然后在浏览器上就可打入主机？端口号//helloword.jsp就可以看到运行结果了? 又比如这其中用到了一个自己写的javaBean该如何办?Domain 目录服务器目录applications，将应用目录放在此目录下将可以作为应用访问，如果是Web应用，应用目录需要满足Web应用目录要求，jsp文件可以直接放在应用目录中，Javabean需要放在应用目录的WEB-INF目录的classes目录中，设置服务器的缺省应用将可以实现在浏览器上无需输入应用名。 请说明一下jsp有哪些动作? 这些动作的作用又分别是什么?JSP 共有以下6种基本动作 jsp:include：在页面被请求的时候引入一个文件。 jsp:useBean：寻找或者实例化一个JavaBean。jsp:setProperty：设置JavaBean的属性。 jsp:getProperty：输出某个JavaBean的属性。 jsp:forward：把请求转到一个新的页面。 jsp:plugin：根据浏览器类型为Java插件生成OBJECT或EMBED标记。 详细说明一下Request对象的主要方法是什么？ setAttribute(String name,Object)：设置名字为name的request的参数值getAttribute(String name)：返回由name指定的属性值getAttributeNames()：返回request对象所有属性的名字集合，结果是一个枚举的实例getCookies()：返回客户端的所有Cookie对象，结果是一个Cookie数组getCharacterEncoding()：返回请求中的字符编码方式getContentLength()：返回请求的Body的长度getHeader(String name)：获得HTTP协议定义的文件头信息getHeaders(String name)：返回指定名字的request Header的所有值，结果是一个枚举的实例getHeaderNames()：返回所以request Header的名字，结果是一个枚举的实例getInputStream()：返回请求的输入流，用于获得请求中的数据getMethod()：获得客户端向服务器端传送数据的方法getParameter(String name)：获得客户端传送给服务器端的有name指定的参数值getParameterNames()：获得客户端传送给服务器端的所有参数的名字，结果是一个枚举的实例getParameterValues(String name)：获得有name指定的参数的所有值getProtocol()：获取客户端向服务器端传送数据所依据的协议名称getQueryString()：获得查询字符串getRequestURI()：获取发出请求字符串的客户端地址getRemoteAddr()：获取客户端的IP地址getRemoteHost()：获取客户端的名字getSession([Boolean create])：返回和请求相关SessiongetServerName()：获取服务器的名字getServletPath()：获取客户端所请求的脚本文件的路径getServerPort()：获取服务器的端口号removeAttribute(String name)：删除请求中的一个属性 请简要说明一下四种会话跟踪技术分别是什么？会话作用域ServletsJSP 页面描述page否是代表与一个页面相关的对象和属性。一个页面由一个编译好的 Java servlet 类（可以带有任何的 include 指令，但是没有 include 动作）表示。这既包括 servlet 又包括被编译成 servlet 的 JSP 页面request是是代表与 Web 客户机发出的一个请求相关的对象和属性。一个请求可能跨越多个页面，涉及多个 Web 组件（由于forward 指令和 include 动作的关系）session是是代表与用于某个 Web 客户机的一个用户体验相关的对象和属性。一个 Web 会话可以也经常会跨越多个客户机请求application是是代表与整个 Web 应用程序相关的对象和属性。这实质上是跨越整个 Web 应用程序，包括多个页面、请求和会话的一个全局作用域。 请简要说明一下JSP和Servlet有哪些相同点和不同点？另外他们之间的联系又是什么呢？JSP 是Servlet技术的扩展，本质上是Servlet的简易方式，更强调应用的外表表达。JSP编译后是”类servlet”。Servlet和JSP最主要的不同点在于，Servlet的应用逻辑是在Java文件中，并且完全从表示层中的HTML里分离开来。而JSP的情况是Java和HTML可以组合成一个扩展名为.jsp的文件。JSP侧重于视图，Servlet主要用于控制逻辑 请说明一下JSP的内置对象以及该对象的使用方法。 request表示HttpServletRequest对象。它包含了有关浏览器请求的信息，并且提供了几个用于获取cookie, header, 和session数据的有用的方法。response表示HttpServletResponse对象，并提供了几个用于设置送回浏览器的响应的方法（如cookies,头信息等）out对象是javax.jsp.JspWriter的一个实例，并提供了几个方法使你能用于向浏览器回送输出结果。pageContext表示一个javax.servlet.jsp.PageContext对象。它是用于方便存取各种范围的名字空间、servlet相关的对象的API，并且包装了通用的servlet相关功能的方法。session表示一个请求的javax.servlet.http.HttpSession对象。Session可以存贮用户的状态信息applicaton 表示一个javax.servle.ServletContext对象。这有助于查找有关servlet引擎和servlet环境的信息config表示一个javax.servlet.ServletConfig对象。该对象用于存取servlet实例的初始化参数。page表示从该页面产生的一个servlet实例 请说明一下web.xml文件中可以配置哪些内容？ web.xml用于配置Web应用的相关信息，如：监听器（listener）、过滤器（filter）、 Servlet、相关参数、会话超时时间、安全验证方式、错误页面等，下面是一些开发中常见的配置： ①配置Spring上下文加载监听器加载Spring配置文件并创建IoC容器：contextConfigLocationclasspath:applicationContext.xml org.springframework.web.context.ContextLoaderListener ②配置Spring的OpenSessionInView过滤器来解决延迟加载和Hibernate会话关闭的矛盾： openSessionInView org.springframework.orm.hibernate3.support.OpenSessionInViewFilter openSessionInView /* ③配置会话超时时间为10分钟： 10 ④配置404和Exception的错误页面：404/error.jsp java.lang.Exception /error.jsp ⑤配置安全认证方式： ProtectedArea /admin/* GET POST admin BASIC admin 谈谈你对Javaweb开发中的监听器的理解？Java Web开发中的监听器（listener）就是application、session、request三个对象创建、销毁或者往其中添加修改删除属性时自动执行代码的功能组件，如下所示：①ServletContextListener：对Servlet上下文的创建和销毁进行监听。②ServletContextAttributeListener：监听Servlet上下文属性的添加、删除和替换。③HttpSessionListener：对Session的创建和销毁进行监听。 session的销毁有两种情况：1). session超时（可以在web.xml中通过/标签配置超时时间）；2). 通过调用session对象的invalidate()方法使session失效。④HttpSessionAttributeListener：对Session对象中属性的添加、删除和替换进行监听。⑤ServletRequestListener：对请求对象的初始化和销毁进行监听。⑥ServletRequestAttributeListener：对请求对象属性的添加、删除和替换进行监听。 请问过滤器有哪些作用？以及过滤器的用法又是什么呢?Java Web开发中的过滤器（filter）是从Servlet 2.3规范开始增加的功能，并在Servlet 2.4规范中得到增强。对Web应用来说，过滤器是一个驻留在服务器端的Web组件，它可以截取客户端和服务器之间的请求与响应信息，并对这些信息进行过滤。当Web容器接受到一个对资源的请求时，它将判断是否有过滤器与这个资源相关联。如果有，那么容器将把请求交给过滤器进行处理。在过滤器中，你可以改变请求的内容，或者重新设置请求的报头信息，然后再将请求发送给目标资源。当目标资源对请求作出响应时候，容器同样会将响应先转发给过滤器，在过滤器中你可以对响应的内容进行转换，然后再将响应发送到客户端。 常见的过滤器用途主要包括：对用户请求进行统一认证、对用户的访问请求进行记录和审核、对用户发送的数据进行过滤或替换、转换图象格式、对响应内容进行压缩以减少传输量、对请求或响应进行加解密处理、触发资源访问事件、对XML的输出应用XSLT等。和过滤器相关的接口主要有：Filter、FilterConfig和FilterChain。 请问使用Servlet如何获取用户配置的初始化参数以及服务器上下文参数？ 可以通过重写Servlet接口的init(ServletConfig)方法并通过ServletConfig对象的getInitParameter()方法来获取Servlet的初始化参数。可以通过ServletConfig对象的getServletContext()方法获取ServletContext对象，并通过该对象的getInitParameter()方法来获取服务器上下文参数。当然，ServletContext对象也在处理用户请求的方法（如doGet()方法）中通过请求对象的getServletContext()方法来获得。 请问使用Servlet如何获取用户提交的查询参数以及表单数据？可以通过请求对象（HttpServletRequest）的getParameter()方法通过参数名获得参数值。如果有包含多个值的参数（例如复选框），可以通过请求对象的getParameterValues()方法获得。当然也可以通过请求对象的getParameterMap()获得一个参数名和参数值的映射（Map）。 服务器收到用户提交的表单数据，请问调用了以下方法中的哪一个方法？第一个是Servlet中的doGet()方法，第二个Servlet中的是doPost()方法HTML的元素有一个method属性，用来指定提交表单的方式，其值可以是get或post。我们自定义的Servlet一般情况下会重写doGet()或doPost()两个方法之一或全部，如果是GET请求就调用doGet()方法，如果是POST请求就调用doPost()方法，那为什么为什么这样呢？我们自定义的Servlet通常继承自HttpServlet，HttpServlet继承自GenericServlet并重写了其中的service()方法，这个方法是Servlet接口中定义的。HttpServlet重写的service()方法会先获取用户请求的方法，然后根据请求方法调用doGet()、doPost()、doPut()、doDelete()等方法，如果在自定义Servlet中重写了这些方法，那么显然会调用重写过的（自定义的）方法，这显然是对模板方法模式的应用（如果不理解，请参考阎宏博士的《Java与模式》一书的第37章）。当然，自定义Servlet中也可以直接重写service()方法，那么不管是哪种方式的请求，都可以通过自己的代码进行处理，这对于不区分请求方法的场景比较合适。 请问如何在基于Java的Web项目中实现文件上传和下载？在Sevlet 3 以前，Servlet API中没有支持上传功能的API，因此要实现上传功能需要引入第三方工具从POST请求中获得上传的附件或者通过自行处理输入流来获得上传的文件，我们推荐使用Apache的commons-fileupload。从Servlet 3开始，文件上传变得简单许多。 123456789101112131415161718192021222324252627282930313233343536373839404142packagecom.jackfrued.servlet; import java.io.IOException; import javax.servlet.ServletException; import javax.servlet.annotation.MultipartConfig; import javax.servlet.annotation.WebServlet; import javax.servlet.http.HttpServlet; import javax.servlet.http.HttpServletRequest; import javax.servlet.http.HttpServletResponse; import javax.servlet.http.Part; @WebServlet(\"/UploadServlet\") @MultipartConfig public class UploadServlet extends HttpServlet &#123; private static final long serialVersionUID = 1L; protected void doPost(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123; // 可以用request.getPart()方法获得名为photo的上传附件 // 也可以用request.getParts()获得所有上传附件（多文件上传） // 然后通过循环分别处理每一个上传的文件 Part part = request.getPart(\"photo\"); if (part != null &amp;&amp;part.getSubmittedFileName().length() &gt; 0) &#123; // 用ServletContext对象的getRealPath()方法获得上传文件夹的绝对路径 StringsavePath = request.getServletContext().getRealPath(\"/upload\"); // Servlet3.1规范中可以用Part对象的getSubmittedFileName()方法获得上传的文件名 // 更好的做法是为上传的文件进行重命名（避免同名文件的相互覆盖） part.write(savePath + \"/\" + part.getSubmittedFileName()); request.setAttribute(\"hint\", \"Upload Successfully!\"); &#125; else &#123; request.setAttribute(\"hint\",\"Upload failed!\"); &#125; // 跳转回到上传页面 request.getRequestDispatcher(\"index.jsp\").forward(request, response); &#125; &#125; 说明一下Servlet 3中的异步处理指的是什么？在Servlet 3中引入了一项新的技术可以让Servlet异步处理请求。有人可能会质疑，既然都有多线程了，还需要异步处理请求吗？答案是肯定的，因为如果一个任务处理时间相当长，那么Servlet或Filter会一直占用着请求处理线程直到任务结束，随着并发用户的增加，容器将会遭遇线程超出的风险，这这种情况下很多的请求将会被堆积起来而后续的请求可能会遭遇拒绝服务，直到有资源可以处理请求为止。异步特性可以帮助应用节省容器中的线程，特别适合执行时间长而且用户需要得到结果的任务，如果用户不需要得到结果则直接将一个Runnable对象交给Executor并立即返回即可。 12345678910111213141516171819202122232425262728293031323334importjava.io.IOException; import javax.servlet.AsyncContext; import javax.servlet.ServletException; import javax.servlet.annotation.WebServlet; import javax.servlet.http.HttpServlet; import javax.servlet.http.HttpServletRequest; import javax.servlet.http.HttpServletResponse; @WebServlet(urlPatterns = &#123;\"/async\"&#125;, asyncSupported = true) public class AsyncServlet extends HttpServlet &#123; private static final long serialVersionUID = 1L; @Override public void doGet(HttpServletRequest req,HttpServletResponse resp) throwsServletException, IOException &#123; // 开启Tomcat异步Servlet支持 req.setAttribute(\"org.apache.catalina.ASYNC_SUPPORTED\", true); final AsyncContext ctx =req.startAsync(); // 启动异步处理的上下文 // ctx.setTimeout(30000); ctx.start(new Runnable() &#123; @Override public voidrun() &#123; // 在此处添加异步处理的代码 ctx.complete(); &#125; &#125;); &#125; &#125; 说说Servlet接口中有哪些方法？Servlet接口定义了5个方法，其中前三个方法与Servlet生命周期相关：- void init(ServletConfig config) throws ServletException- void service(ServletRequest req, ServletResponse resp) throws ServletException, java.io.IOException- void destory()- java.lang.String getServletInfo()- ServletConfig getServletConfig()Web容器加载Servlet并将其实例化后，Servlet生命周期开始，容器运行其init()方法进行Servlet的初始化；请求到达时调用Servlet的service()方法，service()方法会根据需要调用与请求对应的doGet或doPost等方法；当服务器关闭或项目被卸载时服务器会将Servlet实例销毁，此时会调用Servlet的destroy()方法。 阐述一下阐述Servlet和CGI的区别? Servlet与CGI的区别在于Servlet处于服务器进程中，它通过多线程方式运行其service()方法，一个实例可以服务于多个请求，并且其实例一般不会销毁，而CGI对每个请求都产生新的进程，服务完成后就销毁，所以效率上低于Servlet。 在Servlet执行的过程中，一般实现哪几个方法？public void init(ServletConfig config)public ServletConfig getServletConfig()public String getServletInfo()public void service(ServletRequest request,ServletResponse response) public void destroy()init ()方法在servlet的生命周期中仅执行一次，在服务器装载servlet时执行。缺省的init()方法通常是符合要求的，不过也可以根据需要进行 override，比如管理服务器端资源，一次性装入GIF图像，初始化数据库连接等，缺省的inti()方法设置了servlet的初始化参数，并用它的ServeltConfig对象参数来启动配置，所以覆盖init()方法时，应调用super.init()以确保仍然执行这些任务。service ()方法是servlet的核心，在调用service()方法之前，应确保已完成init()方法。对于HttpServlet，每当客户请求一个HttpServlet对象，该对象的service()方法就要被调用，HttpServlet缺省的service()方法的服务功能就是调用与 HTTP请求的方法相应的do功能，doPost()和doGet()，所以对于HttpServlet，一般都是重写doPost()和doGet() 方法。destroy()方法在servlet的生命周期中也仅执行一次，即在服务器停止卸载servlet时执行，把servlet作为服务器进程的一部分关闭。缺省的destroy()方法通常是符合要求的，但也可以override，比如在卸载servlet时将统计数字保存在文件中，或是关闭数据库连接getServletConfig()方法返回一个servletConfig对象，该对象用来返回初始化参servletContext。servletContext接口提供有关servlet的环境信息。getServletInfo()方法提供有关servlet的信息，如作者，版本，版权。 请说出Servlet的生命周期是什么样的？并且请分析一下Servlet和CGI的区别。 Servlet被服务器实例化后，容器运行其init方法，请求到达时运行其service方法，service方法自动派遣运行与请求对应的doXXX方法（doGet，doPost）等，当服务器决定将实例销毁的时候调用其destroy方法。与cgi的区别在于servlet处于服务器进程中，它通过多线程方式运行其service方法，一个实例可以服务于多个请求，并且其实例一般不会销毁，而CGI对每个请求都产生新的进程，服务完成后就销毁，所以效率上低于servlet。 回答一下servlet的生命周期是什么。servlet是否为单例以及原因是什么？Servlet 生命周期可被定义为从创建直到毁灭的整个过程。以下是 Servlet 遵循的过程： Servlet 通过调用 init () 方法进行初始化。 Servlet 调用 service() 方法来处理客户端的请求。 Servlet 通过调用 destroy() 方法终止（结束）。 最后，Servlet 是由 JVM 的垃圾回收器进行垃圾回收的。 Servlet单实例，减少了产生servlet的开销； 简要说明一下forward与redirect区别，并且说一下你知道的状态码都有哪些？以及redirect的状态码又是多少？1.从地址栏显示来说 forward是服务器请求资源,服务器直接访问目标地址的URL,把那个URL的响应内容读取过来,然后把这些内容再发给浏览器.浏览器根本不知道服务器发送的内容从哪里来的,所以它的地址栏还是原来的地址. redirect是服务端根据逻辑,发送一个状态码,告诉浏览器重新去请求那个地址.所以地址栏显示的是新的URL. 2.从数据共享来说 forward:转发页面和转发到的页面可以共享request里面的数据. redirect:不能共享数据. 3.从运用地方来说 forward:一般用于用户登陆的时候,根据角色转发到相应的模块. redirect:一般用于用户注销登陆时返回主页面和跳转到其它的网站等. 4.从效率来说 forward:高. redirect:低. redirect的状态码是302 请问redis的List能在什么场景下使用？ Redis 中list的数据结构实现是双向链表，所以可以非常便捷的应用于消息队列（生产者 / 消费者模型）。消息的生产者只需要通过lpush将消息放入 list，消费者便可以通过rpop取出该消息，并且可以保证消息的有序性。如果需要实现带有优先级的消息队列也可以选择sorted set。而pub/sub功能也可以用作发布者 / 订阅者模型的消息。 分别介绍一下aof和rdb都有哪些优点？以及两者有何区别？RDB 持久化可以在指定的时间间隔内生成数据集的时间点快照（point-in-time snapshot）。 AOF 持久化记录服务器执行的所有写操作命令，并在服务器启动时，通过重新执行这些命令来还原数据集。 AOF 文件中的命令全部以 Redis 协议的格式来保存，新命令会被追加到文件的末尾。 Redis 还可以在后台对 AOF 文件进行重写（rewrite），使得 AOF 文件的体积不会超出保存数据集状态所需的实际大小。Redis 还可以同时使用 AOF 持久化和 RDB 持久化。 在这种情况下， 当 Redis 重启时， 它会优先使用 AOF 文件来还原数据集， 因为 AOF 文件保存的数据集通常比 RDB 文件所保存的数据集更完整。你甚至可以关闭持久化功能，让数据只在服务器运行时存在。 RDB 的优点: RDB 是一个非常紧凑（compact）的文件，它保存了 Redis 在某个时间点上的数据集。 这种文件非常适合用于进行备份： 比如说，你可以在最近的 24 小时内，每小时备份一次 RDB 文件，并且在每个月的每一天，也备份一个 RDB 文件。 这样的话，即使遇上问题，也可以随时将数据集还原到不同的版本。RDB 非常适用于灾难恢复（disaster recovery）：它只有一个文件，并且内容都非常紧凑，可以（在加密后）将它传送到别的数据中心，或者亚马逊 S3 中。RDB 可以最大化 Redis 的性能：父进程在保存 RDB 文件时唯一要做的就是 fork 出一个子进程，然后这个子进程就会处理接下来的所有保存工作，父进程无须执行任何磁盘 I/O 操作。RDB 在恢复大数据集时的速度比 AOF 的恢复速度要快。 RDB 的缺点: 如果你需要尽量避免在服务器故障时丢失数据，那么 RDB 不适合你。 虽然 Redis 允许你设置不同的保存点（save point）来控制保存 RDB 文件的频率， 但是， 因为RDB 文件需要保存整个数据集的状态， 所以它并不是一个轻松的操作。 因此你可能会至少 5 分钟才保存一次 RDB 文件。 在这种情况下， 一旦发生故障停机， 你就可能会丢失好几分钟的数据。每次保存 RDB 的时候，Redis 都要 fork() 出一个子进程，并由子进程来进行实际的持久化工作。 在数据集比较庞大时， fork() 可能会非常耗时，造成服务器在某某毫秒内停止处理客户端； 如果数据集非常巨大，并且 CPU 时间非常紧张的话，那么这种停止时间甚至可能会长达整整一秒。 虽然 AOF 重写也需要进行 fork() ，但无论 AOF 重写的执行间隔有多长，数据的耐久性都不会有任何损失。 AOF 的优点: 使用 AOF 持久化会让 Redis 变得非常耐久（much more durable）：你可以设置不同的 fsync 策略，比如无 fsync ，每秒钟一次 fsync ，或者每次执行写入命令时 fsync 。 AOF 的默认策略为每秒钟 fsync 一次，在这种配置下，Redis 仍然可以保持良好的性能，并且就算发生故障停机，也最多只会丢失一秒钟的数据（ fsync 会在后台线程执行，所以主线程可以继续努力地处理命令请求）。AOF 文件是一个只进行追加操作的日志文件（append only log）， 因此对 AOF 文件的写入不需要进行 seek ， 即使日志因为某些原因而包含了未写入完整的命令（比如写入时磁盘已满，写入中途停机，等等）， redis-check-aof 工具也可以轻易地修复这种问题。 Redis 可以在 AOF 文件体积变得过大时，自动地在后台对 AOF 进行重写： 重写后的新 AOF 文件包含了恢复当前数据集所需的最小命令集合。 整个重写操作是绝对安全的，因为 Redis 在创建新 AOF 文件的过程中，会继续将命令追加到现有的 AOF 文件里面，即使重写过程中发生停机，现有的 AOF 文件也不会丢失。 而一旦新 AOF 文件创建完毕，Redis 就会从旧 AOF 文件切换到新 AOF 文件，并开始对新 AOF 文件进行追加操作。AOF 文件有序地保存了对数据库执行的所有写入操作， 这些写入操作以 Redis 协议的格式保存， 因此 AOF 文件的内容非常容易被人读懂， 对文件进行分析（parse）也很轻松。 导出（export） AOF 文件也非常简单： 举个例子， 如果你不小心执行了 FLUSHALL 命令， 但只要 AOF 文件未被重写， 那么只要停止服务器， 移除 AOF 文件末尾的 FLUSHALL 命令， 并重启 Redis ， 就可以将数据集恢复到 FLUSHALL 执行之前的状态。 AOF 的缺点: 对于相同的数据集来说，AOF 文件的体积通常要大于 RDB 文件的体积。根据所使用的 fsync 策略，AOF 的速度可能会慢于 RDB 。 在一般情况下， 每秒 fsync 的性能依然非常高， 而关闭 fsync 可以让 AOF 的速度和 RDB 一样快， 即使在高负荷之下也是如此。 不过在处理巨大的写入载入时，RDB 可以提供更有保证的最大延迟时间（latency）。AOF 在过去曾经发生过这样的 bug ： 因为个别命令的原因，导致 AOF 文件在重新载入时，无法将数据集恢复成保存时的原样。 （举个例子，阻塞命令 BRPOPLPUSH 就曾经引起过这样的 bug 。） 测试套件里为这种情况添加了测试： 它们会自动生成随机的、复杂的数据集， 并通过重新载入这些数据来确保一切正常。 虽然这种 bug 在 AOF 文件中并不常见， 但是对比来说， RDB 几乎是不可能出现这种 bug 的。 缓存的优点是什么？ 优点： 1、减少了对数据库的读操作，数据库的压力降低 2、加快了响应速度 redis为什么是单线程？ 因为CPU不是Redis的瓶颈。Redis的瓶颈最有可能是机器内存或者网络带宽。既然单线程容易实现，而且CPU不会成为瓶颈，那就顺理成章地采用单线程的方案了。缺点：服务器其他核闲置。 为什么 redis 读写速率快、性能好？Redis是纯内存数据库，相对于读写磁盘，读写内存的速度就不是几倍几十倍了，一般，hash查找可以达到每秒百万次的数量级。 多路复用IO，“多路”指的是多个网络连接，“复用”指的是复用同一个线程。采用多路 I/O 复用技术可以让单个线程高效的处理多个连接请求（尽量减少网络IO的时间消耗）。可以直接理解为：单线程的原子操作，避免上下文切换的时间和性能消耗；加上对内存中数据的处理速度，很自然的提高redis的吞吐量。 redis的主从复制怎么做的？第一阶段：与master建立连接 第二阶段：向master发起同步请求（SYNC） 第三阶段：接受master发来的RDB数据 第四阶段：载入RDB文件 什么是DAO模式？DAO（Data Access Object）顾名思义是一个为数据库或其他持久化机制提供了抽象接口的对象，在不暴露底层持久化方案实现细节的前提下提供了各种数据访问操作。在实际的开发中，应该将所有对数据源的访问操作进行抽象化后封装在一个公共API中。用程序设计语言来说，就是建立一个接口，接口中定义了此应用程序中将会用到的所有事务方法。在这个应用程序中，当需要和数据源进行交互的时候则使用这个接口，并且编写一个单独的类来实现这个接口，在逻辑上该类对应一个特定的数据存储。DAO模式实际上包含了两个模式，一是Data Accessor（数据访问器），二是Data Object（数据对象），前者要解决如何访问数据的问题，而后者要解决的是如何用对象封装数据。 MVC的各个部分都有那些技术来实现?如何实现?MVC 是Model－View－Controller的简写。 ”Model” 代表的是应用的业务逻辑（通过JavaBean，EJB组件实现）， “View” 是应用的表示面，用于与用户的交互（由JSP页面产生）， ”Controller” 是提供应用的处理过程控制（一般是一个Servlet），通过这种设计模型把应用逻辑，处理过程和显示逻辑分成不同的组件实现。这些组件可以进行交互和重用。model层实现系统中的业务逻辑，view层用于与用户的交互，controller层是model与view之间沟通的桥梁，可以分派用户的请求并选择恰当的视图以用于显示，同时它也可以解释用户的输入并将它们映射为模型层可执行的操作。 使用标签库有什么好处？如何自定义JSP标签？使用标签库的好处包括以下几个方面：- 分离JSP页面的内容和逻辑，简化了Web开发；- 开发者可以创建自定义标签来封装业务逻辑和显示逻辑；- 标签具有很好的可移植性、可维护性和可重用性；- 避免了对Scriptlet（小脚本）的使用（很多公司的项目开发都不允许在JSP中书写小脚本） 编写一个Java类实现实现Tag/BodyTag/IterationTag接口（开发中通常不直接实现这些接口而是继承TagSupport/BodyTagSupport/SimpleTagSupport类，这是对缺省适配模式的应用），重写doStartTag()、doEndTag()等方法，定义标签要完成的功能：- 编写扩展名为tld的标签描述文件对自定义标签进行部署，tld文件通常放在WEB-INF文件夹下或其子目录中- 在JSP页面中使用taglib指令引用该标签库 说说你做过的项目中，使用过哪些JSTL标签？项目中主要使用了JSTL的核心标签库，包括&lt;c:if&gt;、&lt;c:choose&gt;、&lt;c: when&gt;、&lt;c: otherwise&gt;、&lt;c:forEach&gt;等，主要用于构造循环和分支结构以控制显示逻辑。 虽然JSTL标签库提供了core、sql、fmt、xml等标签库，但是实际开发中建议只使用核心标签库（core），而且最好只使用分支和循环标签并辅以表达式语言（EL），这样才能真正做到数据显示和业务逻辑的分离，这才是最佳实践。 说说你对get和post请求，并且说说它们之间的区别？①get请求用来从服务器上获得资源，而post是用来向服务器提交数据；②get将表单中数据按照name=value的形式，添加到action 所指向的URL 后面，并且两者使用”?”连接，而各个变量之间使用”&amp;”连接；post是将表单中的数据放在HTTP协议的请求头或消息体中，传递到action所指向URL；③get传输的数据要受到URL长度限制（1024字节）；而post可以传输大量的数据，上传文件通常要使用post方式；④使用get时参数会显示在地址栏上，如果这些数据不是敏感数据，那么可以使用get；对于敏感数据还是应用使用post；⑤get使用MIME类型application/x-www-form-urlencoded的URL编码（也叫百分号编码）文本的格式传递参数，保证被传送的参数由遵循规范的文本组成，例如一个空格的编码是”%20”。 转发和重定向 之间的区别？forward是容器中控制权的转向，是服务器请求资源，服务器直接访问目标地址的URL，把那个URL 的响应内容读取过来，然后把这些内容再发给浏览器，浏览器根本不知道服务器发送的内容是从哪儿来的，所以它的地址栏中还是原来的地址。redirect就是服务器端根据逻辑，发送一个状态码，告诉浏览器重新去请求那个地址，因此从浏览器的地址栏中可以看到跳转后的链接地址，很明显redirect无法访问到服务器保护起来资源，但是可以从一个网站redirect到其他网站。forward更加高效，所以在满足需要时尽量使用forward（通过调用RequestDispatcher对象的forward()方法，该对象可以通过ServletRequest对象的getRequestDispatcher()方法获得），并且这样也有助于隐藏实际的链接；在有些情况下，比如需要访问一个其它服务器上的资源，则必须使用重定向（通过HttpServletResponse对象调用其sendRedirect()方法实现）。 get和post的区别？（1）在客户端， Get 方式在通过 URL 提交数据，数据 在URL中可以看到；POST方式，数据放置在HTML HEADER内提交。 （2）GET方式提交的数据最多只能有1024字节，而POST则没有此限制。 （3）安全性问题。正如在（ 1 ）中提到，使用 Get 的时候，参数会显示在地址栏上，而 Post 不会。所以，如果这些数据是中文数据而且是非敏感数据，那么使用 get ；如果用户输入的数据不是中文字符而且包含敏感数据，那么还是使用 post 为好。 安全的和幂等的。所谓安全的意味着该操作用于获取信息而非修改信息。幂等的意味着对同一 URL 的多个请求应该返回同样的结果。完整的定义并不像看起来那样严格。换句话说， GET 请求一般不应产生副作用。从根本上讲，其目标是当用户打开一个链接时，她可以确信从自身的角度来看没有改变资源。比如，新闻站点的头版不断更新。虽然第二次请求会返回不同的一批新闻，该操作仍然被认为是安全的和幂等的，因为它总是返回当前的新闻。反之亦然。 POST 请求就不那么轻松了。 POST 表示可能改变服务器上的资源的请求。仍然以新闻站点为例，读者对文章的注解应该通过 POST 请求实现，因为在注解提交之后站点已经不同了（比方说文章下面出现一条注解）。 请对以下在J2EE中常用的名词进行解释(或简单描述) web 容器：给处于其中的应用程序组件（JSP，SERVLET）提供一个环境，使JSP,SERVLET直接和容器中的环境变量接接口互，不必关注其它系统问题。主要有WEB服务器来实现。例如：TOMCAT,WEBLOGIC,WEBSPHERE等。该容器提供的接口严格遵守J2EE规范中的WEBAPPLICATION 标准。我们把遵守以上标准的WEB服务器就叫做J2EE中的WEB容器。Web container：实现J2EE体系结构中Web组件协议的容器。这个协议规定了一个Web组件运行时的环境，包括安全，一致性，生命周期管理，事务，配置和其它的服务。一个提供和JSP和J2EE平台APIs界面相同服务的容器。一个Web container 由Web服务器或者J2EE服务器提供。EJB容器：Enterprise java bean 容器。更具有行业领域特色。他提供给运行在其中的组件EJB各种管理功能。只要满足J2EE规范的EJB放入该容器，马上就会被容器进行高效率的管理。并且可以通过现成的接口来获得系统级别的服务。例如邮件服务、事务管理。一个实现了J2EE体系结构中EJB组件规范的容器。这个规范指定了一个Enterprise bean的运行时环境，包括安全，一致性，生命周期，事务，配置，和其他的服务。JNDI：（Java Naming &amp; Directory Interface）JAVA命名目录服务。主要提供的功能是：提供一个目录系统，让其它各地的应用程序在其上面留下自己的索引，从而满足快速查找和定位分布式应用程序的功能。JMS：（Java Message Service）JAVA消息服务。主要实现各个应用程序之间的通讯。包括点对点和广播。JTA：（Java Transaction API）JAVA事务服务。提供各种分布式事务服务。应用程序只需调用其提供的接口即可。JAF：（Java Action FrameWork）JAVA安全认证框架。提供一些安全控制方面的框架。让开发者通过各种部署和自定义实现自己的个性安全控制策略。RMI/IIOP: （Remote Method Invocation /internet对象请求中介协议）他们主要用于通过远程调用服务。例如，远程有一台计算机上运行一个程序，它提供股票分析服务，我们可以在本地计算机上实现对其直接调用。当然这是要通过一定的规范才能在异构的系统之间进行通信。RMI是JAVA特有的。RMI-IIOP出现以前，只有RMI和 CORBA两种选择来进行分布式程序设计。RMI-IIOP综合了RMI和CORBA的优点，克服了他们的缺点，使得程序员能更方便的编写分布式程序设计，实现分布式计算。首先，RMI-IIOP综合了RMI的简单性和CORBA的多语言性（兼容性），其次RMI-IIOP克服了RMI只能用于Java 的缺点和CORBA的复杂性。 网站在架构上应当考虑哪些问题？ - 分层：分层是处理任何复杂系统最常见的手段之一，将系统横向切分成若干个层面，每个层面只承担单一的职责，然后通过下层为上层提供的基础设施和服务以及上层对下层的调用来形成一个完整的复杂的系统。计算机网络的开放系统互联参考模型（OSI/RM）和Internet的TCP/IP模型都是分层结构，大型网站的软件系统也可以使用分层的理念将其分为持久层（提供数据存储和访问服务）、业务层（处理业务逻辑，系统中最核心的部分）和表示层（系统交互、视图展示）。需要指出的是：（1）分层是逻辑上的划分，在物理上可以位于同一设备上也可以在不同的设备上部署不同的功能模块，这样可以使用更多的计算资源来应对用户的并发访问；（2）层与层之间应当有清晰的边界，这样分层才有意义，才更利于软件的开发和维护。- 分割：分割是对软件的纵向切分。我们可以将大型网站的不同功能和服务分割开，形成高内聚低耦合的功能模块（单元）。在设计初期可以做一个粗粒度的分割，将网站分割为若干个功能模块，后期还可以进一步对每个模块进行细粒度的分割，这样一方面有助于软件的开发和维护，另一方面有助于分布式的部署，提供网站的并发处理能力和功能的扩展。- 分布式：除了上面提到的内容，网站的静态资源（JavaScript、CSS、图片等）也可以采用独立分布式部署并采用独立的域名，这样可以减轻应用服务器的负载压力，也使得浏览器对资源的加载更快。数据的存取也应该是分布式的，传统的商业级关系型数据库产品基本上都支持分布式部署，而新生的NoSQL产品几乎都是分布式的。当然，网站后台的业务处理也要使用分布式技术，例如查询索引的构建、数据分析等，这些业务计算规模庞大，可以使用Hadoop以及MapReduce分布式计算框架来处理。- 集群：集群使得有更多的服务器提供相同的服务，可以更好的提供对并发的支持。- 缓存：所谓缓存就是用空间换取时间的技术，将数据尽可能放在距离计算最近的位置。使用缓存是网站优化的第一定律。我们通常说的CDN、反向代理、热点数据都是对缓存技术的使用。- 异步：异步是实现软件实体之间解耦合的又一重要手段。异步架构是典型的生产者消费者模式，二者之间没有直接的调用关系，只要保持数据结构不变，彼此功能实现可以随意变化而不互相影响，这对网站的扩展非常有利。使用异步处理还可以提高系统可用性，加快网站的响应速度（用Ajax加载数据就是一种异步技术），同时还可以起到削峰作用（应对瞬时高并发）。&amp;quot；能推迟处理的都要推迟处理”是网站优化的第二定律，而异步是践行网站优化第二定律的重要手段。- 冗余：各种服务器都要提供相应的冗余服务器以便在某台或某些服务器宕机时还能保证网站可以正常工作，同时也提供了灾难恢复的可能性。冗余是网站高可用性的重要保证。 hibernate的 save() 和persist() 方法分别是做什么的？有什么区别？Hibernate的对象有三种状态：瞬时态（transient）、持久态（persistent）和游离态（detached），如第135题中的图所示。瞬时态的实例可以通过调用save()、persist()或者saveOrUpdate()方法变成持久态；游离态的实例可以通过调用 update()、saveOrUpdate()、lock()或者replicate()变成持久态。save()和persist()将会引发SQL的INSERT语句，而update()或merge()会引发UPDATE语句。save()和update()的区别在于一个是将瞬时态对象变成持久态，一个是将游离态对象变为持久态。merge()方法可以完成save()和update()方法的功能，它的意图是将新的状态合并到已有的持久化对象上或创建新的持久化对象。对于persist()方法，按照官方文档的说明：① persist()方法把一个瞬时态的实例持久化，但是并不保证标识符被立刻填入到持久化实例中，标识符的填入可能被推迟到flush的时间；② persist()方法保证当它在一个事务外部被调用的时候并不触发一个INSERT语句，当需要封装一个长会话流程的时候，persist()方法是很有必要的；③ save()方法不保证第②条，它要返回标识符，所以它会立即执行INSERT语句，不管是在事务内部还是外部。至于lock()方法和update()方法的区别，update()方法是把一个已经更改过的脱管状态的对象变成持久状态；lock()方法是把一个没有更改过的脱管状态的对象变成持久状态。 什么是Web Service？从表面上看，Web Service就是一个应用程序，它向外界暴露出一个能够通过Web进行调用的API。这就是说，你能够用编程的方法透明的调用这个应用程序，不需要了解它的任何细节，跟你使用的编程语言也没有关系。例如可以创建一个提供天气预报的Web Service，那么无论你用哪种编程语言开发的应用都可以通过调用它的API并传入城市信息来获得该城市的天气预报。之所以称之为Web Service，是因为它基于HTTP协议传输数据，这使得运行在不同机器上的不同应用无须借助附加的、专门的第三方软件或硬件，就可相互交换数据或集成。 SOA（Service-Oriented Architecture，面向服务的架构），SOA是一种思想，它将应用程序的不同功能单元通过中立的契约联系起来，独立于硬件平台、操作系统和编程语言，使得各种形式的功能单元能够更好的集成。显然，Web Service是SOA的一种较好的解决方案，它更多的是一种标准，而不是一种具体的技术。 如何设置请求的编码以及响应内容的类型？通过请求对象（ServletRequest）的setCharacterEncoding(String)方法可以设置请求的编码，其实要彻底解决乱码问题就应该让页面、服务器、请求和响应、Java程序都使用统一的编码，最好的选择当然是UTF-8；通过响应对象（ServletResponse）的setContentType(String)方法可以设置响应内容的类型，当然也可以通过HttpServletResponsed对象的setHeader(String, String)方法来设置。 说明 BS与CS 的联系，还有区别。C/S是Client/Server的缩写。服务器通常采用高性能的PC、工作站或小型机，并采用大型数据库系统，如Oracle、Sybase、Informix或 SQL Server。客户端需要安装专用的客户端软件。B/Ｓ是Brower/Server的缩写，客户机上只要安装一个浏览器（Browser），如Netscape Navigator或Internet Explorer，服务器安装Oracle、Sybase、Informix或 SQL Server等数据库。在这种结构下，用户界面完全通过WWW浏览器实现，一部分事务逻辑在前端实现，但是主要事务逻辑在服务器端实现。浏览器通过Ｗeb Server 同数据库进行数据交互。C/S 与 B/S 区别： 硬件环境不同:C/S 一般建立在专用的网络上, 小范围里的网络环境, 局域网之间再通过专门服务器提供连接和数据交换服务.B/S 建立在广域网之上的, 不必是专门的网络硬件环境,例与电话上网, 租用设备. 信息自己管理. 有比C/S更强的适应范围, 一般只要有操作系统和浏览器就行２．对安全要求不同C/S 一般面向相对固定的用户群, 对信息安全的控制能力很强. 一般高度机密的信息系统采用C/S 结构适宜. 可以通过B/S发布部分可公开信息.B/S 建立在广域网之上, 对安全的控制能力相对弱, 可能面向不可知的用户。３．对程序架构不同C/S 程序可以更加注重流程, 可以对权限多层次校验, 对系统运行速度可以较少考虑.B/S 对安全以及访问速度的多重的考虑, 建立在需要更加优化的基础之上. 比C/S有更高的要求 B/S结构的程序架构是发展的趋势, 从MS的.Net系列的BizTalk 2000 Exchange 2000等, 全面支持网络的构件搭建的系统. SUN 和IBM推的JavaBean 构件技术等,使B/S更加成熟.４．软件重用不同C/S 程序可以不可避免的整体性考虑, 构件的重用性不如在B/S要求下的构件的重用性好.B/S 对的多重结构,要求构件相对独立的功能. 能够相对较好的重用.就入买来的餐桌可以再利用,而不是做在墙上的石头桌子５．系统维护不同C/S 程序由于整体性, 必须整体考察, 处理出现的问题以及系统升级. 升级难. 可能是再做一个全新的系统B/S 构件组成,方面构件个别的更换,实现系统的无缝升级. 系统维护开销减到最小.用户从网上自己下载安装就可以实现升级.６．处理问题不同C/S 程序可以处理用户面固定, 并且在相同区域, 安全要求高需求, 与操作系统相关. 应该都是相同的系统B/S 建立在广域网上, 面向不同的用户群, 分散地域, 这是C/S无法作到的. 与操作系统平台关系最小.７．用户接口不同C/S 多是建立的Window平台上,表现方法有限,对程序员普遍要求较高B/S 建立在浏览器上, 有更加丰富和生动的表现方式与用户交流. 并且大部分难度减低,减低开发成本.８．信息流不同C/S 程序一般是典型的中央集权的机械式处理, 交互性相对低B/S 信息流向可变化, B-B B-C B-G等信息、流向的变化, 更像交易中心。 forward 和redirect的区别？forward是服务器请求资源，服务器直接访问目标地址的URL，把那个URL的响应内容读取过来，然后把这些内容再发给浏览器，浏览器根本不知道服务器发送的内容是从哪儿来的，所以它的地址栏中还是原来的地址。redirect就是服务端根据逻辑,发送一个状态码,告诉浏览器重新去请求那个地址，一般来说浏览器会用刚才请求的所有参数重新请求，所以session,request参数都可以获取。 cookie 和 session 的区别？1、cookie数据存放在客户的浏览器上，session数据放在服务器上。 2、cookie不是很安全，别人可以分析存放在本地的COOKIE并进行COOKIE欺骗 考虑到安全应当使用session。 3、session会在一定时间内保存在服务器上。当访问增多，会比较占用你服务器的性能，考虑到减轻服务器性能方面，应当使用COOKIE。 4、单个cookie保存的数据不能超过4K，很多浏览器都限制一个站点最多保存20个cookie。","categories":[],"tags":[{"name":"Interview","slug":"Interview","permalink":"https://kayleh.top/tags/Interview/"}]},{"title":"MVC","slug":"MVC","date":"2020-07-14T05:43:03.000Z","updated":"2020-07-14T05:44:08.737Z","comments":true,"path":"2020/07/14/MVC/","link":"","permalink":"https://kayleh.top/2020/07/14/MVC/","excerpt":"MVC","text":"MVC 请谈一下Spring MVC的工作原理是怎样的？①客户端的所有请求都交给前端控制器DispatcherServlet来处理，它会负责调用系统的其他模块来真正处理用户的请求。② DispatcherServlet收到请求后，将根据请求的信息（包括URL、HTTP协议方法、请求头、请求参数、Cookie等）以及HandlerMapping的配置找到处理该请求的Handler（任何一个对象都可以作为请求的Handler）。③在这个地方Spring会通过HandlerAdapter对该处理器进行封装。④ HandlerAdapter是一个适配器，它用统一的接口对各种Handler中的方法进行调用。⑤ Handler完成对用户请求的处理后，会返回一个ModelAndView对象给DispatcherServlet，ModelAndView顾名思义，包含了数据模型以及相应的视图的信息。⑥ ModelAndView的视图是逻辑视图，DispatcherServlet还要借助ViewResolver完成从逻辑视图到真实视图对象的解析工作。⑦ 当得到真正的视图对象后，DispatcherServlet会利用视图对象对模型数据进行渲染。⑧ 客户端得到响应，可能是一个普通的HTML页面，也可以是XML或JSON字符串，还可以是一张图片或者一个PDF文件。 简述一下SpringMVC的运行机制？以及运行机制的流程是什么？1、用户发送请求时会先从DispathcherServler的doService方法开始，在该方法中会将ApplicationContext、localeResolver、themeResolver等对象添加到request中，紧接着就是调用doDispatch方法。 2、进入该方法后首先会检查该请求是否是文件上传的请求(校验的规则是是否是post并且contenttType是否为multipart/为前缀)即调用的是checkMultipart方法；如果是的将request包装成MultipartHttpServletRequest。 3、然后调用getHandler方法来匹配每个HandlerMapping对象，如果匹配成功会返回这个Handle的处理链HandlerExecutionChain对象，在获取该对象的内部其实也获取我们自定定义的拦截器，并执行了其中的方法。 4、执行拦截器的preHandle方法，如果返回false执行afterCompletion方法并理解返回 5、通过上述获取到了HandlerExecutionChain对象，通过该对象的getHandler()方法获得一个object通过HandlerAdapter进行封装得到HandlerAdapter对象。 6、该对象调用handle方法来执行Controller中的方法，该对象如果返回一个ModelAndView给DispatcherServlet。 7、DispatcherServlet借助ViewResolver完成逻辑试图名到真实视图对象的解析，得到View后DispatcherServlet使用这个View对ModelAndView中的模型数据进行视图渲染。 说明一下springmvc和spring-boot区别是什么？总的来说，Spring 就像一个大家族，有众多衍生产品例如 Boot，Security，JPA等等。但他们的基础都是Spring 的 IOC 和 AOP，IOC提供了依赖注入的容器，而AOP解决了面向切面的编程，然后在此两者的基础上实现了其他衍生产品的高级功能；因为 Spring 的配置非常复杂，各种xml，properties处理起来比较繁琐。于是为了简化开发者的使用，Spring社区创造性地推出了Spring Boot，它遵循约定优于配置，极大降低了Spring使用门槛，但又不失Spring原本灵活强大的功能。 说明一下Spring MVC注解的优点是什么？1、XML配置起来有时候冗长，此时注解可能是更好的选择，如jpa的实体映射；注解在处理一些不变的元数据时有时候比XML方便的多，比如springmvc的数据绑定，如果用xml写的代码会多的多； 2、注解最大的好处就是简化了XML配置；其实大部分注解一定确定后很少会改变，所以在一些中小项目中使用注解反而提供了开发效率，所以没必要一头走到黑； 3、注解相对于XML的另一个好处是类型安全的，XML只能在运行期才能发现问题。 请简单介绍一下你了解的Java领域中的Web Service框架都有哪些？Java领域的Web Service框架很多，包括Axis2（Axis的升级版本）、Jersey（RESTful的Web Service框架）、CXF（XFire的延续版本）、Hessian、Turmeric、JBoss SOA等，其中绝大多数都是开源框架。 简述一下Mybatis和Hibernate的区别是什么？1、简介 Hibernate：Hibernate是当前最流行的ORM框架之一，对JDBC提供了较为完整的封装。Hibernate的O/R Mapping实现了POJO 和数据库表之间的映射，以及SQL的自动生成和执行。 Mybatis：Mybatis同样也是非常流行的ORM框架，主要着力点在于 POJO 与 SQL 之间的映射关系。然后通过映射配置文件，将SQL所需的参数，以及返回的结果字段映射到指定 POJO 。相对Hibernate“O/R”而言，Mybatis 是一种“Sql Mapping”的ORM实现。 2、缓存机制对比 相同点 Hibernate和Mybatis的二级缓存除了采用系统默认的缓存机制外，都可以通过实现你自己的缓存或为其他第三方缓存方案，创建适配器来完全覆盖缓存行为。 不同点 Hibernate的二级缓存配置在SessionFactory生成的配置文件中进行详细配置，然后再在具体的表-对象映射中配置是那种缓存。 MyBatis的二级缓存配置都是在每个具体的表-对象映射中进行详细配置，这样针对不同的表可以自定义不同的缓存机制。并且Mybatis可以在命名空间中共享相同的缓存配置和实例，通过Cache-ref来实现。 两者比较 因为Hibernate对查询对象有着良好的管理机制，用户无需关心SQL。所以在使用二级缓存时如果出现脏数据，系统会报出错误并提示。而MyBatis在这一方面，使用二级缓存时需要特别小心。如果不能完全确定数据更新操作的波及范围，避免Cache的盲目使用。否则，脏数据的出现会给系统的正常运行带来很大的隐患。 Mybatis：小巧、方便、高效、简单、直接、半自动化 Hibernate：强大、方便、高效、复杂、间接、全自动化 请问EJB需要直接实现它的业务接口或者Home接口吗？请简述一下理由。 在EJB中则至少要包括10个class:Bean类，特定App Server的Bean实现类Bean的remote接口，特定App Server的remote接口实现类，特定App Server的remote接口的实现类的stub类和skeleton类。Bean的home接口，特定App Server的home接口实现类，特定App Server的home接口的实现类的stub类和skeleton类。和RMI不同的是，EJB中这10个class真正需要用户写的只有3个，Bean类，remote接口，home接口，其它的7个究竟怎么生成，被打包在哪里，是否需要更多的类文件，否根据不同的App Server表现出较大的差异。Weblogic：home接口和remote接口的weblogic的实现类的stub类和skeleton类是在EJB被部署到weblogic的时候，由weblogic动态生成stub类和skeleton类的字节码，所以看不到这4个类文件。对于一次客户端远程调用EJB，要经过两个远程对象的多次RMI循环。首先是通过JNDI查找Home接口，获得Home接口的实现类，这个过程其实相当复杂，首先是找到Home接口的Weblogic实现类，然后创建一个Home接口的Weblogic实现类的stub类的对象实例，将它序列化传送给客户端（注意stub类的实例是在第1次RMI循环中，由服务器动态发送给客户端的，因此不需要客户端保存Home接口的Weblogic实现类的stub 类），最后客户端获得该stub类的对象实例（普通的RMI需要在客户端保存stub类，而EJB不需要，因为服务器会把stub类的对象实例发送给客户端）。客户端拿到服务器给它的Home接口的Weblogic实现类的stub类对象实例以后，调用stub类的create方法， (在代码上就是home.create()，但是后台要做很多事情),于是经过第2次RMI循环，在服务器端，Home接口的Weblogic实现类的 skeleton类收到stub类的调用信息后，由它再去调用Home接口的Weblogic实现类的create方法。在服务端， Home接口的Weblogic实现类的create方法再去调用Bean类的Weblogic实现类的ejbCreate方法，在服务端创建或者分配一个EJB实例，然后将这个EJB实例的远程接口的Weblogic实现类的stub类对象实例序列化发送给客户端。 说明一下EJB的几种类型分别是什么？会话（Session）Bean ，实体（Entity）Bean 消息驱动的（Message Driven）Bean，会话Bean又可分为有状态（Stateful）和无状态（Stateless）两种，实体Bean可分为Bean管理的持续性（BMP）和容器管理的持续性（CMP）两种。 简述一下EJB的激活机制是什么？以Stateful Session Bean 为例：其Cache大小决定了内存中可以同时存在的Bean实例的数量，根据MRU或NRU算法，实例在激活和去激活状态之间迁移，激活机制是当客户端调用某个EJB实例业务方法时，如果对应EJB Object发现自己没有绑定对应的Bean实例则从其去激活Bean存储中（通过序列化机制存储实例）回复（激活）此实例。状态变迁前会调用对应的 ejbActive和ejbPassivate方法。 说一下EJB规范中EJB禁止的操作有哪些？1.不能操作线程和线程API(线程API指非线程对象的方法如notify,wait等)， 2.不能操作awt， 3.不能实现服务器功能， 4.不能对静态属生存取， 5.不能使用IO操作直接存取文件系统， 6.不能加载本地库.， 7.不能将this作为变量和返回， 8.不能循环调用。 请简述一下EJB的角色以及对应的三个对象分别是什么？ 一个完整的基于EJB的分布式计算结构由六个角色组成，这六个角色可以由不同的开发商提供，每个角色所作的工作必须遵循Sun公司提供的EJB规范，以保证彼此之间的兼容性。这六个角色分别是EJB组件开发者（Enterprise Bean Provider） 、应用组合者（Application Assembler）、部署者（Deployer）、EJB 服务器提供者（EJB Server Provider）、EJB 容器提供者（EJB Container Provider）、系统管理员（System Administrator）三个对象是Remote（Local）接口、Home（LocalHome）接口，Bean类 EJB包括SessionBean和EntityBean，请说出他们的生命周期以及EJB是如何管理事务的？SessionBean： Stateless Session Bean 的生命周期是由容器决定的，当客户机发出请求要建立一个Bean的实例时，EJB容器不一定要创建一个新的Bean的实例供客户机调用，而是随便找一个现有的实例提供给客户机。当客户机第一次调用一个Stateful Session Bean 时，容器必须立即在服务器中创建一个新的Bean实例，并关联到客户机上，以后此客户机调用Stateful Session Bean 的方法时容器会把调用分派到与此客户机相关联的Bean实例。EntityBean：Entity Beans能存活相对较长的时间，并且状态是持续的。只要数据库中的数据存在，Entity beans就一直存活。而不是按照应用程序或者服务进程来说的。即使EJB容器崩溃了，Entity beans也是存活的。Entity Beans生命周期能够被容器或者Beans自己管理。EJB通过以下技术管理实务：对象管理组织（OMG）的对象实务服务（OTS），Sun Microsystems的Transaction Service（JTS）、Java Transaction API（JTA），开发组（X/Open）的XA接口。 EJB与JAVA BEAN的区别是什么？ Java Bean 是可复用的组件，对Java Bean并没有严格的规范，理论上讲，任何一个Java类都可以是一个Bean。但通常情况下，由于Java Bean是被容器所创建（如Tomcat）的，所以Java Bean应具有一个无参的构造器，另外，通常Java Bean还要实现Serializable接口用于实现Bean的持久性。Java Bean实际上相当于微软COM模型中的本地进程内COM组件，它是不能被跨进程访问的。EnterpriseJava Bean 相当于DCOM，即分布式组件。它是基于Java的远程方法调用（RMI）技术的，所以EJB可以被远程访问（跨进程、跨计算机）。但EJB必须被布署在诸如Webspere、WebLogic这样的容器中，EJB客户从不直接访问真正的EJB组件，而是通过其容器访问。EJB容器是EJB组件的代理， EJB组件由容器所创建和管理。客户通过容器来访问真正的EJB组件。 请问EJB是基于哪些技术实现的？并说明一下SessionBean和EntityBean的区别以及StatefulBean和StatelessBean的区别。EJB包括Session Bean、Entity Bean、Message Driven Bean，基于JNDI、RMI、JAT等技术实现。SessionBean在J2EE应用程序中被用来完成一些服务器端的业务操作，例如访问数据库、调用其他EJB组件。EntityBean被用来代表应用系统中用到的数据。对于客户机，SessionBean是一种非持久性对象，它实现某些在服务器上运行的业务逻辑。对于客户机，EntityBean是一种持久性对象，它代表一个存储在持久性存储器中的实体的对象视图，或是一个由现有企业应用程序实现的实体。Session Bean 还可以再细分为 Stateful Session Bean 与 Stateless Session Bean ，这两种的 Session Bean都可以将系统逻辑放在 method之中执行，不同的是 Stateful Session Bean 可以记录呼叫者的状态，因此通常来说，一个使用者会有一个相对应的Stateful Session Bean 的实体。Stateless Session Bean 虽然也是逻辑组件，但是他却不负责记录使用者状态，也就是说当使用者呼叫 Stateless Session Bean 的时候，EJB Container 并不会找寻特定的 Stateless Session Bean 的实体来执行这个 method。换言之，很可能数个使用者在执行某个 Stateless Session Bean 的 methods 时，会是同一个 Bean 的 Instance 在执行。从内存方面来看， Stateful Session Bean 与 Stateless Session Bean 比较， Stateful Session Bean 会消耗 J2EE Server 较多的内存，然而 Stateful Session Bean 的优势却在于他可以维持使用者的状态。","categories":[],"tags":[{"name":"Interview","slug":"Interview","permalink":"https://kayleh.top/tags/Interview/"}]},{"title":"Mybatis","slug":"Mybatis","date":"2020-07-14T05:41:49.000Z","updated":"2020-07-16T07:40:48.739Z","comments":true,"path":"2020/07/14/Mybatis/","link":"","permalink":"https://kayleh.top/2020/07/14/Mybatis/","excerpt":"MYBATIS","text":"MYBATIS 请问MyBatis中的动态SQL是什么意思？ 对于一些复杂的查询，我们可能会指定多个查询条件，但是这些条件可能存在也可能不存在，需要根据用户指定的条件动态生成SQL语句。如果不使用持久层框架我们可能需要自己拼装SQL语句，还好MyBatis提供了动态SQL的功能来解决这个问题。MyBatis中用于实现动态SQL的元素主要有：- if- choose / when / otherwise- trim- where- set- foreach 说明一下MyBatis中命名空间（namespace）的作用是什么？在大型项目中，可能存在大量的SQL语句，这时候为每个SQL语句起一个唯一的标识（ID）就变得并不容易了。为了解决这个问题，在MyBatis中，可以为每个映射文件起一个唯一的命名空间，这样定义在这个映射文件中的每个SQL语句就成了定义在这个命名空间中的一个ID。只要我们能够保证每个命名空间中这个ID是唯一的，即使在不同映射文件中的语句ID相同，也不会再产生冲突了。 1、mybatis对JDBC做了哪些封装？ 2、mybatis如何映射？ 3、Mybatis接口绑定有几种实现方式,分别是怎么实现的? 4、Mybatis中和${}的区别？ 5、myBatis 实现一对一有几种方式?具体怎么操作的？ 6、myBatis 实现一对多有几种方式?怎么操作的？ 7、myBatis 里面的动态Sql是怎么设定的?用什么语法? 8、讲下 myBatis 的缓存？ 9、mybatis的执行流程？ 10、持久层框架为什么选择mybatis？ 2😁. mapper.xml文件中的namespace(全限名)来关联和接口的关系. 3😁. .两种方式: ①通过注解绑定,在接口的方法上添加@select,@update,等注解,里面包含了sql语句.②通过xml文件里写sql绑定,这种方式要求指定xml文件里namespace的值为接口的全限定名.4😁.使用 ${}在编译期传入的参数会直接拼接成字符串,而则会生成占位符”?”,并且因为${}会直接拼接成字符串,会造成sql注入,而传入的参数会生成占位符”?” ,可以有效的防止了sql注入. 7😁.动态sql通过if节点来实现,使用OGNL语法判断.完整的动态sql要配合where,trim节点,choose,when,otherwise标签来完成,一个choose中至少有一个when,0个or1个otherwise,如果when满足就执行, 全部不满住就执行otherwise. 8😁.mybatis分一级缓存和二级缓存;一级缓存默认开启,在对象中有个hashmap用于存储缓存数据,不同的sqlsessioin之间缓存数据互不影响.二级缓存时mapper映射级别的缓存,多个SqlSession去操作同一个mapper映射的sql语句,多个SqlSession可以公用二级缓存,二级缓存是跨SqlSession的. (二级缓存需要手动开启),一级缓存和二级缓存都是用作在短时间内重复查询而做的优化. ! 我编不下去了.!🤣","categories":[],"tags":[{"name":"Interview","slug":"Interview","permalink":"https://kayleh.top/tags/Interview/"}]},{"title":"Spring","slug":"Spring","date":"2020-07-14T05:40:15.000Z","updated":"2020-07-14T05:41:29.900Z","comments":true,"path":"2020/07/14/Spring/","link":"","permalink":"https://kayleh.top/2020/07/14/Spring/","excerpt":"SPRING","text":"SPRING Spring中自动装配的方式有哪些？- no：不进行自动装配，手动设置Bean的依赖关系。- byName：根据Bean的名字进行自动装配。- byType：根据Bean的类型进行自动装配。- constructor：类似于byType，不过是应用于构造器的参数，如果正好有一个Bean与构造器的参数类型相同则可以自动装配，否则会导致错误。- autodetect：如果有默认的构造器，则通过constructor的方式进行自动装配，否则使用byType的方式进行自动装配。 自动装配没有自定义装配方式那么精确，而且不能自动装配简单属性（基本类型、字符串等），在使用时应注意。 Spring中Bean的作用域有哪些？在Spring的早期版本中，仅有两个作用域：singleton和prototype，前者表示Bean以单例的方式存在；后者表示每次从容器中调用Bean时，都会返回一个新的实例，prototype通常翻译为原型。 设计模式中的创建型模式中也有一个原型模式，原型模式也是一个常用的模式，例如做一个室内设计软件，所有的素材都在工具箱中，而每次从工具箱中取出的都是素材对象的一个原型，可以通过对象克隆来实现原型模式。Spring 2.x中针对WebApplicationContext新增了3个作用域，分别是：request（每次HTTP请求都会创建一个新的Bean）、session（同一个HttpSession共享同一个Bean，不同的HttpSession使用不同的Bean）和globalSession（同一个全局Session共享一个Bean）。 单例模式和原型模式都是重要的设计模式。一般情况下，无状态或状态不可变的类适合使用单例模式。在传统开发中，由于DAO持有Connection这个非线程安全对象因而没有使用单例模式；但在Spring环境下，所有DAO类对可以采用单例模式，因为Spring利用AOP和Java API中的ThreadLocal对非线程安全的对象进行了特殊处理。 什么是IoC和DI？并且简要说明一下DI是如何实现的？IoC叫控制反转，是Inversion of Control的缩写，DI（Dependency Injection）叫依赖注入，是对IoC更简单的诠释。控制反转是把传统上由程序代码直接操控的对象的调用权交给容器，通过容器来实现对象组件的装配和管理。所谓的”控制反转”就是对组件对象控制权的转移，从程序代码本身转移到了外部容器，由容器来创建对象并管理对象之间的依赖关系。IoC体现了好莱坞原则 - “Don’t call me, we will call you”。依赖注入的基本原则是应用组件不应该负责查找资源或者其他依赖的协作对象。配置对象的工作应该由容器负责，查找资源的逻辑应该从应用组件的代码中抽取出来，交给容器来完成。DI是对IoC更准确的描述，即组件之间的依赖关系由容器在运行期决定，形象的来说，即由容器动态的将某种依赖关系注入到组件之中。 一个类A需要用到接口B中的方法，那么就需要为类A和接口B建立关联或依赖关系，最原始的方法是在类A中创建一个接口B的实现类C的实例，但这种方法需要开发人员自行维护二者的依赖关系，也就是说当依赖关系发生变动的时候需要修改代码并重新构建整个系统。如果通过一个容器来管理这些对象以及对象的依赖关系，则只需要在类A中定义好用于关联接口B的方法（构造器或setter方法），将类A和接口B的实现类C放入容器中，通过对容器的配置来实现二者的关联。依赖注入可以通过setter方法注入（设值注入）、构造器注入和接口注入三种方式来实现，Spring支持setter注入和构造器注入，通常使用构造器注入来注入必须的依赖关系，对于可选的依赖关系，则setter注入是更好的选择，setter注入需要类提供无参构造器或者无参的静态工厂方法来创建对象。 Spring中BeanFactory和ApplicationContext的区别是什么？BeanFactory：BeanFactory是spring中比较原始，比较古老的Factory。因为比较古老，所以BeanFactory无法支持spring插件，例如：AOP、Web应用等功能。 ApplicationContextApplicationContext是BeanFactory的子类，因为古老的BeanFactory无法满足不断更新的spring的需求，于是ApplicationContext就基本上代替了BeanFactory的工作，以一种更面向框架的工作方式以及对上下文进行分层和实现继承，并在这个基础上对功能进行扩展： &lt;1&gt;MessageSource, 提供国际化的消息访问&lt;2&gt;资源访问（如URL和文件）&lt;3&gt;事件传递&lt;4&gt;Bean的自动装配&lt;5&gt;各种不同应用层的Context实现 区别： &lt;1&gt;如果使用ApplicationContext，如果配置的bean是singleton，那么不管你有没有或想不想用它，它都会被实例化。好处是可以预先加载，坏处是浪费内存。&lt;2&gt;BeanFactory，当使用BeanFactory实例化对象时，配置的bean不会马上被实例化，而是等到你使用该bean的时候（getBean）才会被实例化。好处是节约内存，坏处是速度比较慢。多用于移动设备的开发。&lt;3&gt;没有特殊要求的情况下，应该使用ApplicationContext完成。因为BeanFactory能完成的事情，ApplicationContext都能完成，并且提供了更多接近现在开发的功能。 说明一下springIOC原理是什么？如果你要实现IOC需要怎么做？请简单描述一下实现步骤？①IoC（Inversion of Control，控制倒转）。这是spring的核心，贯穿始终。所谓IoC，对于spring框架来说，就是由spring来负责控制对象的生命周期和对象间的关系。 IoC的一个重点是在系统运行中，动态的向某个对象提供它所需要的其他对象。这一点是通过DI（Dependency Injection，依赖注入）来实现的。比如对象A需要操作数据库，以前我们总是要在A中自己编写代码来获得一个Connection对象，有了 spring我们就只需要告诉spring，A中需要一个Connection，至于这个Connection怎么构造，何时构造，A不需要知道。在系统运行时，spring会在适当的时候制造一个Connection，然后像打针一样，注射到A当中，这样就完成了对各个对象之间关系的控制。A需要依赖 Connection才能正常运行，而这个Connection是由spring注入到A中的，依赖注入的名字就这么来的。那么DI是如何实现的呢？ Java 1.3之后一个重要特征是反射（reflection），它允许程序在运行的时候动态的生成对象、执行对象的方法、改变对象的属性，spring就是通过反射来实现注入的。 举个简单的例子，我们找女朋友常见的情况是，我们到处去看哪里有长得漂亮身材又好的女孩子，然后打听她们的兴趣爱好、qq号、电话号、ip号、iq号………，想办法认识她们，投其所好送其所要，这个过程是复杂深奥的，我们必须自己设计和面对每个环节。传统的程序开发也是如此，在一个对象中，如果要使用另外的对象，就必须得到它（自己new一个，或者从JNDI中查询一个），使用完之后还要将对象销毁（比如Connection等），对象始终会和其他的接口或类藕合起来。 ②实现IOC的步骤 定义用来描述bean的配置的Java类 解析bean的配置，將bean的配置信息转换为上面的BeanDefinition对象保存在内存中，spring中采用HashMap进行对象存储，其中会用到一些xml解析技术 遍历存放BeanDefinition的HashMap对象，逐条取出BeanDefinition对象，获取bean的配置信息，利用Java的反射机制实例化对象，將实例化后的对象保存在另外一个Map中即可。 简单说明一下依赖注入的方式有哪几种？以及这些方法如何使用？ 1、Set注入 2、构造器注入 3、接口注入 @Controller和@RestController的区别是什么？ @RestController注解相当于@ResponseBody ＋ @Controller合在一起的作用 谈一下autowired 和resource区别是什么？1、共同点 两者都可以写在字段和setter方法上。两者如果都写在字段上，那么就不需要再写setter方法。 2、不同点 （1）@Autowired @Autowired为Spring提供的注解，需要导入包org.springframework.beans.factory.annotation.Autowired;只按照byType注入。 @Autowired注解是按照类型（byType）装配依赖对象，默认情况下它要求依赖对象必须存在，如果允许null值，可以设置它的required属性为false。如果我们想使用按照名称（byName）来装配，可以结合@Qualifier注解一起使用。 （2）@Resource @Resource默认按照ByName自动注入，由J2EE提供，需要导入包javax.annotation.Resource。@Resource有两个重要的属性：name和type，而Spring将@Resource注解的name属性解析为bean的名字，而type属性则解析为bean的类型。所以，如果使用name属性，则使用byName的自动注入策略，而使用type属性时则使用byType自动注入策略。如果既不制定name也不制定type属性，这时将通过反射机制使用byName自动注入策略。 介绍一下bean的生命周期Spring生命周期流程图： 简要说明一下IOC和AOP是什么？依赖注入的三种方式： （1）接口注入 （2）Construct注入 （3）Setter注入 控制反转（IoC）与依赖注入（DI）是同一个概念，引入IOC的目的： （1）脱开、降低类之间的耦合； （2）倡导面向接口编程、实施依赖倒换原则； （3）提高系统可插入、可测试、可修改等特性。 具体做法： （1）将bean之间的依赖关系尽可能地抓换为关联关系； （2）将对具体类的关联尽可能地转换为对Java interface的关联，而不是与具体的服务对象相关联； （3）Bean实例具体关联相关Java interface的哪个实现类的实例，在配置信息的元数据中描述； （4）由IoC组件（或称容器）根据配置信息，实例化具体bean类、将bean之间的依赖关系注入进来。 AOP（Aspect Oriented Programming），即面向切面编程，可以说是OOP（Object Oriented Programming，面向对象编程）的补充和完善。OOP引入封装、继承、多态等概念来建立一种对象层次结构，用于模拟公共行为的一个集合。不过OOP允许开发者定义纵向的关系，但并不适合定义横向的关系，例如日志功能。日志代码往往横向地散布在所有对象层次中，而与它对应的对象的核心功能毫无关系对于其他类型的代码，如安全性、异常处理和透明的持续性也都是如此，这种散布在各处的无关的代码被称为横切（cross cutting），在OOP设计中，它导致了大量代码的重复，而不利于各个模块的重用。 AOP技术恰恰相反，它利用一种称为”横切”的技术，剖解开封装的对象内部，并将那些影响了多个类的公共行为封装到一个可重用模块，并将其命名为”Aspect”，即切面。所谓”切面”，简单说就是那些与业务无关，却为业务模块所共同调用的逻辑或责任封装起来，便于减少系统的重复代码，降低模块之间的耦合度，并有利于未来的可操作性和可维护性。 使用”横切”技术，AOP把软件系统分为两个部分：核心关注点和横切关注点。业务处理的主要流程是核心关注点，与之关系不大的部分是横切关注点。横切关注点的一个特点是，他们经常发生在核心关注点的多处，而各处基本相似，比如权限认证、日志、事物。AOP的作用在于分离系统中的各种关注点，将核心关注点和横切关注点分离开来。 Spring支持的事务管理类型有哪些？以及你在项目中会使用哪种方式？Spring支持编程式事务管理和声明式事务管理。许多Spring框架的用户选择声明式事务管理，因为这种方式和应用程序的关联较少，因此更加符合轻量级容器的概念。声明式事务管理要优于编程式事务管理，尽管在灵活性方面它弱于编程式事务管理，因为编程式事务允许你通过代码控制业务。 事务分为全局事务和局部事务。全局事务由应用服务器管理，需要底层服务器JTA支持（如WebLogic、WildFly等）。局部事务和底层采用的持久化方案有关，例如使用JDBC进行持久化时，需要使用Connetion对象来操作事务；而采用Hibernate进行持久化时，需要使用Session对象来操作事务。 这些事务的父接口都是PlatformTransactionManager。Spring的事务管理机制是一种典型的策略模式，PlatformTransactionManager代表事务管理接口，该接口定义了三个方法，该接口并不知道底层如何管理事务，但是它的实现类必须提供getTransaction()方法（开启事务）、commit()方法（提交事务）、rollback()方法（回滚事务）的多态实现，这样就可以用不同的实现类代表不同的事务管理策略。使用JTA全局事务策略时，需要底层应用服务器支持，而不同的应用服务器所提供的JTA全局事务可能存在细节上的差异，因此实际配置全局事务管理器是可能需要使用JtaTransactionManager的子类，如：WebLogicJtaTransactionManager（Oracle的WebLogic服务器提供）、UowJtaTransactionManager（IBM的WebSphere服务器提供）等。 如何理解AOP中的连接点（Joinpoint）、切点（Pointcut）、增强（Advice）、引介（Introduction）、织入（Weaving）、切面（Aspect）这些概念？a. 连接点（Joinpoint）：程序执行的某个特定位置（如：某个方法调用前、调用后，方法抛出异常后）。一个类或一段程序代码拥有一些具有边界性质的特定点，这些代码中的特定点就是连接点。Spring仅支持方法的连接点。b. 切点（Pointcut）：如果连接点相当于数据中的记录，那么切点相当于查询条件，一个切点可以匹配多个连接点。Spring AOP的规则解析引擎负责解析切点所设定的查询条件，找到对应的连接点。c. 增强（Advice）：增强是织入到目标类连接点上的一段程序代码。Spring提供的增强接口都是带方位名的，如：BeforeAdvice、AfterReturningAdvice、ThrowsAdvice等。 d. 引介（Introduction）：引介是一种特殊的增强，它为类添加一些属性和方法。这样，即使一个业务类原本没有实现某个接口，通过引介功能，可以动态的未该业务类添加接口的实现逻辑，让业务类成为这个接口的实现类。e. 织入（Weaving）：织入是将增强添加到目标类具体连接点上的过程，AOP有三种织入方式：①编译期织入：需要特殊的Java编译期（例如AspectJ的ajc）；②装载期织入：要求使用特殊的类加载器，在装载类的时候对类进行增强；③运行时织入：在运行时为目标类生成代理实现增强。Spring采用了动态代理的方式实现了运行时织入，而AspectJ采用了编译期织入和装载期织入的方式。f. 切面（Aspect）：切面是由切点和增强（引介）组成的，它包括了对横切关注功能的定义，也包括了对连接点的定义。 AOP的原理是什么？AOP（Aspect Orient Programming），指面向方面（切面）编程，作为面向对象的一种补充，用于处理系统中分布于各个模块的横切关注点，比如事务管理、日志、缓存等等。AOP实现的关键在于AOP框架自动创建的AOP代理，AOP代理主要分为静态代理和动态代理，静态代理的代表为AspectJ；而动态代理则以Spring AOP为代表。通常使用AspectJ的编译时增强实现AOP，AspectJ是静态代理的增强，所谓的静态代理就是AOP框架会在编译阶段生成AOP代理类，因此也称为编译时增强。 Spring AOP中的动态代理主要有两种方式，JDK动态代理和CGLIB动态代理。JDK动态代理通过反射来接收被代理的类，并且要求被代理的类必须实现一个接口。JDK动态代理的核心是InvocationHandler接口和Proxy类。 如果目标类没有实现接口，那么Spring AOP会选择使用CGLIB来动态代理目标类。CGLIB（Code Generation Library），是一个代码生成的类库，可以在运行时动态的生成某个类的子类，注意，CGLIB是通过继承的方式做的动态代理，因此如果某个类被标记为final，那么它是无法使用CGLIB做动态代理的。 aop的应用场景有哪些？Authentication 权限 ，Caching 缓存 ，Context passing 内容传递 ，Error handling 错误处理 ，Lazy loading 懒加载 ，Debugging 调试 ，logging, tracing, profiling and monitoring 记录跟踪 优化 校准，Performance optimization 性能优化 ，Persistence 持久化 ，Resource pooling 资源池 ，Synchronization 同步，Transactions 事务。 说明一下Spring框架为企业级开发带来的好处有哪些？- 非侵入式：支持基于POJO的编程模式，不强制性的要求实现Spring框架中的接口或继承Spring框架中的类。- IoC容器：IoC容器帮助应用程序管理对象以及对象之间的依赖关系，对象之间的依赖关系如果发生了改变只需要修改配置文件而不是修改代码，因为代码的修改可能意味着项目的重新构建和完整的回归测试。有了IoC容器，程序员再也不需要自己编写工厂、单例，这一点特别符合Spring的精神”不要重复的发明轮子”。- AOP（面向切面编程）：将所有的横切关注功能封装到切面（aspect）中，通过配置的方式将横切关注功能动态添加到目标代码上，进一步实现了业务逻辑和系统服务之间的分离。另一方面，有了AOP程序员可以省去很多自己写代理类的工作。- MVC：Spring的MVC框架为Web表示层提供了更好的解决方案。- 事务管理：Spring以宽广的胸怀接纳多种持久层技术，并且为其提供了声明式的事务管理，在不需要任何一行代码的情况下就能够完成事务管理。- 其他：选择Spring框架的原因还远不止于此，Spring为Java企业级开发提供了一站式选择，你可以在需要的时候使用它的部分和全部，更重要的是，甚至可以在感觉不到Spring存在的情况下，在你的项目中使用Spring提供的各种优秀的功能。 谈一下spring框架的优点都有哪些？Spring是一个轻量级的DI和AOP容器框架，在项目的中的使用越来越广泛，它的优点主要有以下几点： Spring是一个非侵入式框架，其目标是使应用程序代码对框架的依赖最小化，应用代码可以在没有Spring或者其他容器的情况运行。 Spring提供了一个一致的编程模型，使应用直接使用POJO开发，从而可以使运行环境隔离开来。 Spring推动应用的设计风格向面向对象及面向接口编程转变，提高了代码的重用性和可测试性。 Spring改进了结构体系的选择，虽然作为应用平台，Spring可以帮助我们选择不同的技术实现，比如从Hibernate切换到其他的ORM工具，从Struts切换到Spring MVC,尽管我们通常不会这么做，但是我们在技术方案上选择使用Spring作为应用平台，Spring至少为我们提供了这种可能性的选择，从而降低了平台锁定风险。 Struts拦截器和Spring AOP有什么区别？拦截器是AOP的一种实现，struts2 拦截器采用xwork2的interceptor！而spring的AOP基于IoC基础,其底层采用动态代理与CGLIB代理两种方式结合的实现方式。 简单介绍一下spring？Spring是一个轻量级框架，可以一站式构建你的企业级应用。 Spring的模块大概分为6个。分别是： 1、Core Container（Spring的核心）【重要】 2、AOP（面向切面变成）【重要】 3、Messaging（消息发送的支持） 4、Data Access/Integration（数据访问和集成） 5、Web（主要是SpringWeb内容，包括MVC）【重要】 6、Test（Spring测试支持，包含JUint等测试单元的支持） 7、Instrumentation（设备支持，比如Tomcat的支持） 请问持久层设计要考虑的问题有哪些？请谈一下你用过的持久层框架都有哪些？所谓”持久”就是将数据保存到可掉电式存储设备中以便今后使用，简单的说，就是将内存中的数据保存到关系型数据库、文件系统、消息队列等提供持久化支持的设备中。持久层就是系统中专注于实现数据持久化的相对独立的层面。 持久层设计的目标包括：- 数据存储逻辑的分离，提供抽象化的数据访问接口。- 数据访问底层实现的分离，可以在不修改代码的情况下切换底层实现。- 资源管理和调度的分离，在数据访问层实现统一的资源调度（如缓存机制）。- 数据抽象，提供更面向对象的数据操作。 持久层框架有：- Hibernate- MyBatis- TopLink- Guzz- jOOQ- Spring Data- ActiveJDBC","categories":[],"tags":[{"name":"Interview","slug":"Interview","permalink":"https://kayleh.top/tags/Interview/"}]},{"title":"IO","slug":"IO","date":"2020-07-14T05:39:13.000Z","updated":"2020-07-14T05:39:45.533Z","comments":true,"path":"2020/07/14/IO/","link":"","permalink":"https://kayleh.top/2020/07/14/IO/","excerpt":"IO","text":"IO 运行时异常与受检异常有什么区别？ 异常表示程序运行过程中可能出现的非正常状态，运行时异常表示虚拟机的通常操作中可能遇到的异常，是一种常见运行错误，只要程序设计得没有问题通常就不会发生。受检异常跟程序运行的上下文环境有关，即使程序设计无误，仍然可能因使用的问题而引发。Java编译器要求方法必须声明抛出可能发生的受检异常，但是并不要求必须声明抛出未被捕获的运行时异常。异常和继承一样，是面向对象程序设计中经常被滥用的东西，在Effective Java中对异常的使用给出了以下指导原则： - 不要将异常处理用于正常的控制流（设计良好的API不应该强迫它的调用者为了正常的控制流而使用异常）- 对可以恢复的情况使用受检异常，对编程错误使用运行时异常- 避免不必要的使用受检异常（可以通过一些状态检测手段来避免异常的发生）- 优先使用标准的异常- 每个方法抛出的异常都要有文档- 保持异常的原子性- 不要在catch中忽略掉捕获到的异常 什么是java序列化？以及如何实现java序列化？序列化就是一种用来处理对象流的机制，所谓对象流也就是将对象的内容进行流化。可以对流化后的对象进行读写操作，也可将流化后的对象传输于网络之间。序列化是为了解决在对对象流进行读写操作时所引发的问题。序列化的实现：将需要被序列化的类实现Serializable接口，该接口没有需要实现的方法，implements Serializable只是为了标注该对象是可被序列化的，然后使用一个输出流(如：FileOutputStream)来构造一个 ObjectOutputStream(对象流)对象，接着，使用ObjectOutputStream对象的writeObject(Object obj)方法就可以将参数为obj的对象写出(即保存其状态)，要恢复的话则用输入流。 java中有几种类型的流？JDK为每种类型的流提供了一些抽象类以供继承，请说出他们分别是哪些类？字节流，字符流。字节流继承于InputStream OutputStream，字符流继承于InputStreamReader OutputStreamWriter。在java.io包中还有许多其他的流，主要是为了提高性能和使用方便。 说明一下Java中的异常处理机制的原理以及如何应用。当JAVA 程序违反了JAVA的语义规则时，JAVA虚拟机就会将发生的错误表示为一个异常。违反语义规则包括2种情况。一种是JAVA类库内置的语义检查。例如数组下标越界,会引发IndexOutOfBoundsException;访问null的对象时会引发NullPointerException。另一种情况就是JAVA允许程序员扩展这种语义检查，程序员可以创建自己的异常，并自由选择在何时用throw关键字引发异常。所有的异常都是 java.lang.Thowable的子类。 请问你平时最常见到的runtime exception是什么？12345678910111213141516171819202122232425ArithmeticException,ArrayStoreException,BufferOverflowException,BufferUnderflowException,CannotRedoException,CannotUndoException,ClassCastException,CMMException,ConcurrentModificationException,DOMException,EmptyStackException,IllegalArgumentException,IllegalMonitorStateException,IllegalPathStateException,IllegalStateException,ImagingOpException,IndexOutOfBoundsException,MissingResourceException,NegativeArraySizeException,NoSuchElementException,NullPointerException,ProfileDataException,ProviderException,RasterFormatException, SecurityException, SystemException, UndeclaredThrowableException, UnmodifiableSetException,UnsupportedOperationException error和exception有什么区别?error 表示恢复不是不可能但很困难的情况下的一种严重问题。比如说内存溢出。不可能指望程序能处理这样的情况。exception 表示一种设计或实现问题。也就是说，它表示如果程序运行正常，从不会发生的情况。 运行时的异常与一般情况下出现的异常有什么相同点和不同点？异常表示程序运行过程中可能出现的非正常状态，运行时异常表示虚拟机的通常操作中可能遇到的异常，是一种常见运行错误。java编译器要求方法必须声明抛出可能发生的非运行时异常，但是并不要求必须声明抛出未被捕获的运行时异常。 如何打印日志？cat /var/log/*.log 如果日志在更新，如何实时查看tail -f /var/log/messages 还可以使用watch -d -n 1 cat /var/log/messages -d表示高亮不同的地方，-n表示多少秒刷新一次。","categories":[],"tags":[{"name":"Interview","slug":"Interview","permalink":"https://kayleh.top/tags/Interview/"}]},{"title":"GC","slug":"GC","date":"2020-07-14T05:38:14.000Z","updated":"2020-07-14T05:38:53.725Z","comments":true,"path":"2020/07/14/GC/","link":"","permalink":"https://kayleh.top/2020/07/14/GC/","excerpt":"GC","text":"GC 简单描述一下垃圾回收器的基本原理是什么？还有垃圾回收器可以马上回收内存吗？并且有什么办法可以主动通知虚拟机进行垃圾回收呢？ 对于GC来说，当程序员创建对象时，GC就开始监控这个对象的地址、大小以及使用情况。通常，GC采用有向图的方式记录和管理堆(heap)中的所有对象。通过这种方式确定哪些对象是”可达的”，哪些对象是”不可达的”。当GC确定一些对象为”不可达”时，GC就有责任回收这些内存空间。可以。程序员可以手动执行System.gc()，通知GC运行，但是Java语言规范并不保证GC一定会执行。 在java中会存在内存泄漏吗？请简单描述一下。Java中的确存在Java的内存泄漏, 并且事态可以变得相当严重 Java garbage collector自动释放哪些内存里面程序不在需要的对象, 以此避免大多数的其他程序上下文的内存泄漏. 但是Java应用程序依旧会有相当的内存泄漏. 查找原因会十分困难.有两类主要的Java内存泄漏:* 不再需要的对象引用* 未释放的系统资源非必要的对象引用Java代码常常保留对于不再需要的对象引用, 并且这组织了内存的垃圾收集器的工作. Java对象通常被其他对象包含引用, 为此一个单一对象可以保持整个对象树在内存中, 于是导致了如下问题:* 在向数组添加对象以后遗漏了对于他们的处理* 直到你再次使用对象的时候都不释放引用. 比如一个菜单指令可以插件一个对象实例引用并且不释放便于以后再次调用的时候使用, 但是也许永远不会发生.* 在其他引用依然需要旧有状态的时候贸然修改对象状态. 比如当你为了在一个文本文件里面保存一些属性而使用一个数组, 诸如”字符个数”等字段在不再需要的时候依然保留在内存当中.* 允许一个长久执行的线程所引用的对象. 设置引用为NULL也无济于事, 在线程退出和空闲之前, 对象不会被收集释放未释放的系统资源Java方法可以定位Java实例意外的堆内存, 诸如针对视窗和位图的内存资源. Java常常通过JNI(Java Native Interface)调用C/C++子程序定位这些资源. 说明一下垃圾回收的优点以及原理。 Java 语言中一个显著的特点就是引入了垃圾回收机制，使c++程序员最头疼的内存管理的问题迎刃而解，它使得Java程序员在编写程序的时候不再需要考虑内存管理。由于有个垃圾回收机制，Java中的对象不再有”作用域”的概念，只有对象的引用才有”作用域”。垃圾回收可以有效的防止内存泄露，有效的使用可以使用的内存。垃圾回收器通常是作为一个单独的低级别的线程运行，不可预知的情况下对内存堆中已经死亡的或者长时间没有使用的对象进行清楚和回收，程序员不能实时的调用垃圾回收器对某个对象或所有对象进行垃圾回收。回收机制有分代复制垃圾回收和标记垃圾回收，增量垃圾回收。 请问GC是什么? 还有为什么要有GC? GC是垃圾收集的意思（Gabage Collection）,内存处理是编程人员容易出现问题的地方，忘记或者错误的内存回收会导致程序或系统的不稳定甚至崩溃，Java提供的GC功能可以自动监测对象是否超过作用域从而达到自动回收内存的目的，Java语言没有提供释放已分配内存的显示操作方法。 简述一下GC算法①GC（GarbageCollection 垃圾收集），GC的对象是堆空间和永久区 ②GC算法包含：引用计数法，标记清除，标记压缩，复制算法。 ③引用计数器的实现很简单，对于一个对象A，只要有任何一个对象引用了A，则A的引用计数器就加1，当引用失效时，引用计数器就减1。只要对象A的引用计数器的值为0，则对象A就不可能再被使用。 ④标记-清除算法是现代垃圾回收算法的思想基础。标记-清除算法将垃圾回收分为两个阶段：标记阶段和清除阶段。一种可行的实现是，在标记阶段，首先通过根节点，标记所有从根节点开始的可达对象。因此，未被标记的对象就是未被引用的垃圾对象。然后，在清除阶段，清除所有未被标记的对象。与标记-清除算法相比，复制算法是一种相对高效的回收方法不适用于存活对象较多的场合如老年代将原有的内存空间分为两块，每次只使用其中一块，在垃圾回收时，将正在使用的内存中的存活对象复制到未使用的内存块中，之后，清除正在使用的内存块中的所有对象，交换两个内存的角色，完成垃圾回收。 什么原因会导致minor gc运行频繁？同样的，什么原因又会导致minor gc运行很慢？请简要说明一下 可能是堆内存太小。 请问java中内存泄漏是什么意思？什么场景下会出现内存泄漏的情况？ Java中的内存泄露，广义并通俗的说，就是：不再会被使用的对象的内存不能被回收，就是内存泄露。如果长生命周期的对象持有短生命周期的引用，就很可能会出现内存泄露。","categories":[],"tags":[{"name":"Interview","slug":"Interview","permalink":"https://kayleh.top/tags/Interview/"}]},{"title":"JVM","slug":"JVM","date":"2020-07-14T05:35:08.000Z","updated":"2020-07-14T05:37:52.878Z","comments":true,"path":"2020/07/14/JVM/","link":"","permalink":"https://kayleh.top/2020/07/14/JVM/","excerpt":"JVM","text":"JVM 简单描述一下JVM加载class文件的原理是什么?JVM中类的装载是由ClassLoader和它的子类来实现的,Java ClassLoader 是一个重要的Java运行时系统组件。它负责在运行时查找和装入类文件的类。 Java中的所有类，都需要由类加载器装载到JVM中才能运行。类加载器本身也是一个类，而它的工作就是把class文件从硬盘读取到内存中。在写程序的时候，我们几乎不需要关心类的加载，因为这些都是隐式装载的，除非我们有特殊的用法，像是反射，就需要显式的加载所需要的类。 类装载方式，有两种（1）隐式装载，程序在运行过程中当碰到通过new 等方式生成对象时，隐式调用类装载器加载对应的类到jvm中，（2）显式装载，通过class.forname()等方法，显式加载需要的类 ,隐式加载与显式加载的区别：两者本质是一样的。 Java类的加载是动态的，它并不会一次性将所有类全部加载后再运行，而是保证程序运行的基础类(像是基类)完全加载到jvm中，至于其他类，则在需要的时候才加载。这当然就是为了节省内存开销。 什么是Java虚拟机？为什么Java被称作是“平台无关的编程语言”？Java虚拟机是一个可以执行Java字节码的虚拟机进程。Java源文件被编译成能被Java虚拟机执行的字节码文件。Java被设计成允许应用程序可以运行在任意的平台，而不需要程序员为每一个平台单独重写或者是重新编译。Java虚拟机让这个变为可能，因为它知道底层硬件平台的指令长度和其他特性。 jvm最大内存限制多少？(1)堆内存分配 JVM初始分配的内存由-Xms指定，默认是物理内存的1/64；JVM最大分配的内存由-Xmx指定，默认是物理内存的1/4。默认空余堆内存小 于40%时，JVM就会增大堆直到-Xmx的最大限制；空余堆内存大于70%时，JVM会减少堆直到-Xms的最小限制。因此服务器一般设置-Xms、 -Xmx相等以避免在每次GC后调整堆的大小。 (2)非堆内存分配 JVM使用-XX:PermSize设置非堆内存初始值，默认是物理内存的1/64；由XX:MaxPermSize设置最大非堆内存的大小，默认是物理内存的1/4。 (3)VM最大内存 首先JVM内存限制于实际的最大物理内存，假设物理内存无限大的话，JVM内存的最大值跟操作系统有很大的关系。简单的说就32位处理器虽 然可控内存空间有4GB,但是具体的操作系统会给一个限制，这个限制一般是2GB-3GB（一般来说Windows系统下为1.5G-2G，Linux系 统下为2G-3G），而64bit以上的处理器就不会有限制了。 (3)下面是当前比较流行的几个不同公司不同版本JVM最大堆内存: jvm是如何实现线程的？线程是比进程更轻量级的调度执行单位。线程可以把一个进程的资源分配和执行调度分开。一个进程里可以启动多条线程，各个线程可共享该进程的资源(内存地址，文件IO等)，又可以独立调度。线程是CPU调度的基本单位。 主流OS都提供线程实现。Java语言提供对线程操作的同一API，每个已经执行start()，且还未结束的java.lang.Thread类的实例，代表了一个线程。 Thread类的关键方法，都声明为Native。这意味着这个方法无法或没有使用平台无关的手段来实现，也可能是为了执行效率。 实现线程的方式 A.使用内核线程实现内核线程(Kernel-Level Thread, KLT)就是直接由操作系统内核支持的线程。 内核来完成线程切换 内核通过调度器Scheduler调度线程，并将线程的任务映射到各个CPU上 程序使用内核线程的高级接口，轻量级进程(Light Weight Process,LWP) 用户态和内核态切换消耗内核资源 使用用户线程实现 系统内核不能感知线程存在的实现 用户线程的建立、同步、销毁和调度完全在用户态中完成 所有线程操作需要用户程序自己处理，复杂度高 用户线程加轻量级进程混合实现 轻量级进程作为用户线程和内核线程之间的桥梁 什么是JVM内存模型？Java内存模型(简称JMM)，JMM决定一个线程对共享变量的写入何时对另一个线程可见。从抽象的角度来看，JMM定义了线程和主内存之间的抽象关系：线程之间的共享变量存储在主内存（main memory）中，每个线程都有一个私有的本地内存（local memory），本地内存中存储了该线程以读/写共享变量的副本。 本地内存是JMM的一个抽象概念，并不真实存在。它涵盖了缓存，写缓冲区，寄存器以及其他的硬件和编译器优化。其关系模型图如下图所示： 在JAVA虚拟机中，哪些对象可作为ROOT对象？虚拟机栈中的引用对象 方法区中类静态属性引用的对象 方法区中常量引用对象 本地方法栈中JNI引用对象 GC中如何判断对象是否需要被回收？即使在可达性分析算法中不可达的对象,也并非是“非回收不可”的,这时候它们暂时处于“等待”阶段,要真正宣告一个对象回收,至少要经历两次标记过程:如果对象在进行可达性分析后发现没有与GC Roots相连接的引用链,那它将会被第一次标记并且进行一次筛选,筛选的条件是此对象是否有必要执行finalize()方法。当对象没有覆盖finalize()方法,或者finalize()方法已经被虚拟机调用过,虚拟机将这两种情况都视为“没有必要执行”。(即意味着直接回收) 如果这个对象被判定为有必要执行finalize()方法,那么这个对象将会放置在一个叫做F-Queue的队列之中,并在稍后由一个由虚拟机自动建立的、低优先级的Finalizer线程去执行它。这里所谓的“执行”是指虚拟机会触发这个方法,但并不承诺会等待它运行结束,这样做的原因是,如果一个对象在finalize()方法中执行缓慢,或者发生了死循环(更极端的情况),将很可能会导致F-Queue队列中其他对象永久处于等待,甚至导致整个内存回收系统崩溃。 finalize()方法是对象逃脱回收的最后一次机会,稍后GC将对F-Queue中的对象进行第二次小规模的标记,如果对象要在finalize()中跳出回收——只要重新与引用链上的任何一个对象建立关联即可,譬如把自己(this关键字)赋值给某个类变量或者对象的成员变量,那在第二次标记时它将被移除出“即将回收”的集合;如果对象这时候还没有逃脱,那基本上它就真的被回收了。 说明一下JAVA虚拟机的作用是什么?解释运行字节码程序消除平台相关性。 jvm将java字节码解释为具体平台的具体指令。一般的高级语言如要在不同的平台上运行，至少需要编译成不同的目标代码。而引入JVM后，Java语言在不同平台上运行时不需要重新编译。Java语言使用模式Java虚拟机屏蔽了与具体平台相关的信息，使得Java语言编译程序只需生成在Java虚拟机上运行的目标代码（字节码），就可以在多种平台上不加修改地运行。Java虚拟机在执行字节码时，把字节码解释成具体平台上的机器指令执行。 假设一个场景，要求stop the world时间非常短，你会怎么设计垃圾回收机制？ 绝大多数新创建的对象分配在Eden区。 在Eden区发生一次GC后，存活的对象移到其中一个Survivor区。 在Eden区发生一次GC后，对象是存放到Survivor区，这个Survivor区已经存在其他存活的对象。 一旦一个Survivor区已满，存活的对象移动到另外一个Survivor区。然后之前那个空间已满Survivor区将置为空，没有任何数据。 经过重复多次这样的步骤后依旧存活的对象将被移到老年代。 说明一下eden区和survial区的含义以及工作原理？目前主流的虚拟机实现都采用了分代收集的思想，把整个堆区划分为新生代和老年代；新生代又被划分成Eden 空间、 From Survivor 和 To Survivor 三块区域。 我们把Eden : From Survivor : To Survivor 空间大小设成 8 : 1 : 1 ，对象总是在 Eden 区出生， From Survivor 保存当前的幸存对象， To Survivor 为空。一次 gc 发生后： 1）Eden 区活着的对象 ＋ From Survivor 存储的对象被复制到 To Survivor ；2) 清空 Eden 和 From Survivor ； 3) 颠倒 From Survivor 和 To Survivor 的逻辑关系： From 变 To ， To 变 From 。可以看出，只有在 Eden 空间快满的时候才会触发 Minor GC 。而 Eden 空间占新生代的绝大部分，所以 Minor GC 的频率得以降低。当然，使用两个 Survivor 这种方式我们也付出了一定的代价，如 10% 的空间浪费、复制对象的开销等。 简单描述一下JVM分区都有哪些？ java内存通常被划分为5个区域：程序计数器（Program Count Register）、本地方法栈（Native Stack）、方法区（Methon Area）、栈（Stack）、堆（Heap）。 简单描述一下类的加载过程如下图所示，JVM类加载机制分为五个部分：加载，验证，准备，解析，初始化，下面我们就分别来看一下这五个过程。 加载 加载是类加载过程中的一个阶段，这个阶段会在内存中生成一个代表这个类的java.lang.Class对象，作为方法区这个类的各种数据的入口。注意这里不一定非得要从一个Class文件获取，这里既可以从ZIP包中读取（比如从jar包和war包中读取），也可以在运行时计算生成（动态代理），也可以由其它文件生成（比如将JSP文件转换成对应的Class类）。 验证 这一阶段的主要目的是为了确保Class文件的字节流中包含的信息是否符合当前虚拟机的要求，并且不会危害虚拟机自身的安全。 准备 准备阶段是正式为类变量分配内存并设置类变量的初始值阶段，即在方法区中分配这些变量所使用的内存空间。注意这里所说的初始值概念，比如一个类变量定义为： public static int v = 8080; 实际上变量v在准备阶段过后的初始值为0而不是8080，将v赋值为8080的putstatic指令是程序被编译后，存放于类构造器方法之中，这里我们后面会解释。 但是注意如果声明为： public static final int v = 8080; 在编译阶段会为v生成ConstantValue属性，在准备阶段虚拟机会根据ConstantValue属性将v赋值为8080。 解析 解析阶段是指虚拟机将常量池中的符号引用替换为直接引用的过程。符号引用就是class文件中的： CONSTANT_Class_info CONSTANT_Field_info CONSTANT_Method_info 等类型的常量。 下面我们解释一下符号引用和直接引用的概念： 符号引用与虚拟机实现的布局无关，引用的目标并不一定要已经加载到内存中。各种虚拟机实现的内存布局可以各不相同，但是它们能接受的符号引用必须是一致的，因为符号引用的字面量形式明确定义在Java虚拟机规范的Class文件格式中。 直接引用可以是指向目标的指针，相对偏移量或是一个能间接定位到目标的句柄。如果有了直接引用，那引用的目标必定已经在内存中存在。 初始化 初始化阶段是类加载最后一个阶段，前面的类加载阶段之后，除了在加载阶段可以自定义类加载器以外，其它操作都由JVM主导。到了初始阶段，才开始真正执行类中定义的Java程序代码。 初始化阶段是执行类构造器方法的过程。方法是由编译器自动收集类中的类变量的赋值操作和静态语句块中的语句合并而成的。虚拟机会保证方法执行之前，父类的方法已经执行完毕。p.s: 如果一个类中没有对静态变量赋值也没有静态语句块，那么编译器可以不为这个类生成()方法。 注意以下几种情况不会执行类初始化： 通过子类引用父类的静态字段，只会触发父类的初始化，而不会触发子类的初始化。 定义对象数组，不会触发该类的初始化。 常量在编译期间会存入调用类的常量池中，本质上并没有直接引用定义常量的类，不会触发定义常量所在的类。 通过类名获取Class对象，不会触发类的初始化。 通过Class.forName加载指定类时，如果指定参数initialize为false时，也不会触发类初始化，其实这个参数是告诉虚拟机，是否要对类进行初始化。 通过ClassLoader默认的loadClass方法，也不会触发初始化动作。 类加载器 虚拟机设计团队把加载动作放到JVM外部实现，以便让应用程序决定如何获取所需的类，JVM提供了3种类加载器： 启动类加载器(Bootstrap ClassLoader)：负责加载 JAVA_HOME\\lib 目录中的，或通过-Xbootclasspath参数指定路径中的，且被虚拟机认可（按文件名识别，如rt.jar）的类。 扩展类加载器(Extension ClassLoader)：负责加载 JAVA_HOME\\lib\\ext 目录中的，或通过java.ext.dirs系统变量指定路径中的类库。 应用程序类加载器(Application ClassLoader)：负责加载用户路径（classpath）上的类库。 JVM通过双亲委派模型进行类的加载，当然我们也可以通过继承java.lang.ClassLoader实现自定义的类加载器。 当一个类加载器收到类加载任务，会先交给其父类加载器去完成，因此最终加载任务都会传递到顶层的启动类加载器，只有当父类加载器无法完成加载任务时，才会尝试执行加载任务。采用双亲委派的一个好处是比如加载位于rt.jar包中的类java.lang.Object，不管是哪个加载器加载这个类，最终都是委托给顶层的启动类加载器进行加载，这样就保证了使用不同的类加载器最终得到的都是同样一个Object对象。 简单说明一下JVM的回收算法以及它的回收器是什么？还有CMS采用哪种回收算法？使用CMS怎样解决内存碎片的问题呢？垃圾回收算法 标记清除 标记-清除算法将垃圾回收分为两个阶段：标记阶段和清除阶段。在标记阶段首先通过根节点，标记所有从根节点开始的对象，未被标记的对象就是未被引用的垃圾对象。然后，在清除阶段，清除所有未被标记的对象。标记清除算法带来的一个问题是会存在大量的空间碎片，因为回收后的空间是不连续的，这样给大对象分配内存的时候可能会提前触发full gc。 复制算法 将现有的内存空间分为两快，每次只使用其中一块，在垃圾回收时将正在使用的内存中的存活对象复制到未被使用的内存块中，之后，清除正在使用的内存块中的所有对象，交换两个内存的角色，完成垃圾回收。 现在的商业虚拟机都采用这种收集算法来回收新生代，IBM研究表明新生代中的对象98%是朝夕生死的，所以并不需要按照1:1的比例划分内存空间，而是将内存分为一块较大的Eden空间和两块较小的Survivor空间，每次使用Eden和其中的一块Survivor。当回收时，将Eden和Survivor中还存活着的对象一次性地拷贝到另外一个Survivor空间上，最后清理掉Eden和刚才用过的Survivor的空间。HotSpot虚拟机默认Eden和Survivor的大小比例是8:1(可以通过-SurvivorRattio来配置)，也就是每次新生代中可用内存空间为整个新生代容量的90%，只有10%的内存会被“浪费”。当然，98%的对象可回收只是一般场景下的数据，我们没有办法保证回收都只有不多于10%的对象存活，当Survivor空间不够用时，需要依赖其他内存（这里指老年代）进行分配担保。 标记整理 复制算法的高效性是建立在存活对象少、垃圾对象多的前提下的。这种情况在新生代经常发生，但是在老年代更常见的情况是大部分对象都是存活对象。如果依然使用复制算法，由于存活的对象较多，复制的成本也将很高。 标记-压缩算法是一种老年代的回收算法，它在标记-清除算法的基础上做了一些优化。首先也需要从根节点开始对所有可达对象做一次标记，但之后，它并不简单地清理未标记的对象，而是将所有的存活对象压缩到内存的一端。之后，清理边界外所有的空间。这种方法既避免了碎片的产生，又不需要两块相同的内存空间，因此，其性价比比较高。 增量算法 增量算法的基本思想是，如果一次性将所有的垃圾进行处理，需要造成系统长时间的停顿，那么就可以让垃圾收集线程和应用程序线程交替执行。每次，垃圾收集线程只收集一小片区域的内存空间，接着切换到应用程序线程。依次反复，直到垃圾收集完成。使用这种方式，由于在垃圾回收过程中，间断性地还执行了应用程序代码，所以能减少系统的停顿时间。但是，因为线程切换和上下文转换的消耗，会使得垃圾回收的总体成本上升，造成系统吞吐量的下降。 垃圾回收器 Serial收集器 Serial收集器是最古老的收集器，它的缺点是当Serial收集器想进行垃圾回收的时候，必须暂停用户的所有进程，即stop the world。到现在为止，它依然是虚拟机运行在client模式下的默认新生代收集器，与其他收集器相比，对于限定在单个CPU的运行环境来说，Serial收集器由于没有线程交互的开销，专心做垃圾回收自然可以获得最高的单线程收集效率。 Serial Old是Serial收集器的老年代版本，它同样是一个单线程收集器，使用”标记－整理“算法。这个收集器的主要意义也是被Client模式下的虚拟机使用。在Server模式下，它主要还有两大用途：一个是在JDK1.5及以前的版本中与Parallel Scanvenge收集器搭配使用，另外一个就是作为CMS收集器的后备预案，在并发收集发生Concurrent Mode Failure的时候使用。 通过指定-UseSerialGC参数，使用Serial + Serial Old的串行收集器组合进行内存回收。 ParNew收集器 ParNew收集器是Serial收集器新生代的多线程实现，注意在进行垃圾回收的时候依然会stop the world，只是相比较Serial收集器而言它会运行多条进程进行垃圾回收。 ParNew收集器在单CPU的环境中绝对不会有比Serial收集器更好的效果，甚至由于存在线程交互的开销，该收集器在通过超线程技术实现的两个CPU的环境中都不能百分之百的保证能超越Serial收集器。当然，随着可以使用的CPU的数量增加，它对于GC时系统资源的利用还是很有好处的。它默认开启的收集线程数与CPU的数量相同，在CPU非常多（譬如32个，现在CPU动辄4核加超线程，服务器超过32个逻辑CPU的情况越来越多了）的环境下，可以使用-XX:ParallelGCThreads参数来限制垃圾收集的线程数。 -UseParNewGC: 打开此开关后，使用ParNew + Serial Old的收集器组合进行内存回收，这样新生代使用并行收集器，老年代使用串行收集器。 Parallel Scavenge收集器 Parallel是采用复制算法的多线程新生代垃圾回收器，似乎和ParNew收集器有很多的相似的地方。但是Parallel Scanvenge收集器的一个特点是它所关注的目标是吞吐量(Throughput)。所谓吞吐量就是CPU用于运行用户代码的时间与CPU总消耗时间的比值，即吞吐量=运行用户代码时间 / (运行用户代码时间 + 垃圾收集时间)。停顿时间越短就越适合需要与用户交互的程序，良好的响应速度能够提升用户的体验；而高吞吐量则可以最高效率地利用CPU时间，尽快地完成程序的运算任务，主要适合在后台运算而不需要太多交互的任务。 Parallel Old收集器是Parallel Scavenge收集器的老年代版本，采用多线程和”标记－整理”算法。这个收集器是在jdk1.6中才开始提供的，在此之前，新生代的Parallel Scavenge收集器一直处于比较尴尬的状态。原因是如果新生代Parallel Scavenge收集器，那么老年代除了Serial Old(PS MarkSweep)收集器外别无选择。由于单线程的老年代Serial Old收集器在服务端应用性能上的”拖累“，即使使用了Parallel Scavenge收集器也未必能在整体应用上获得吞吐量最大化的效果，又因为老年代收集中无法充分利用服务器多CPU的处理能力，在老年代很大而且硬件比较高级的环境中，这种组合的吞吐量甚至还不一定有ParNew加CMS的组合”给力“。直到Parallel Old收集器出现后，”吞吐量优先“收集器终于有了比较名副其实的应用祝贺，在注重吞吐量及CPU资源敏感的场合，都可以优先考虑Parallel Scavenge加Parallel Old收集器。 -UseParallelGC: 虚拟机运行在Server模式下的默认值，打开此开关后，使用Parallel Scavenge + Serial Old的收集器组合进行内存回收。-UseParallelOldGC: 打开此开关后，使用Parallel Scavenge + Parallel Old的收集器组合进行垃圾回收 CMS收集器 CMS(Concurrent Mark Swep)收集器是一个比较重要的回收器，现在应用非常广泛，我们重点来看一下，CMS一种获取最短回收停顿时间为目标的收集器，这使得它很适合用于和用户交互的业务。从名字(Mark Swep)就可以看出，CMS收集器是基于标记清除算法实现的。它的收集过程分为四个步骤： 初始标记(initial mark) 并发标记(concurrent mark) 重新标记(remark) 并发清除(concurrent sweep) 注意初始标记和重新标记还是会stop the world，但是在耗费时间更长的并发标记和并发清除两个阶段都可以和用户进程同时工作。 G1收集器 G1收集器是一款面向服务端应用的垃圾收集器。HotSpot团队赋予它的使命是在未来替换掉JDK1.5中发布的CMS收集器。与其他GC收集器相比，G1具备如下特点： 并行与并发：G1能更充分的利用CPU，多核环境下的硬件优势来缩短stop the world的停顿时间。 分代收集：和其他收集器一样，分代的概念在G1中依然存在，不过G1不需要其他的垃圾回收器的配合就可以独自管理整个GC堆。 空间整合：G1收集器有利于程序长时间运行，分配大对象时不会无法得到连续的空间而提前触发一次GC。 可预测的非停顿：这是G1相对于CMS的另一大优势，降低停顿时间是G1和CMS共同的关注点，能让使用者明确指定在一个长度为M毫秒的时间片段内，消耗在垃圾收集上的时间不得超过N毫秒。 CMS：采用标记清除算法 解决这个问题的办法就是可以让CMS在进行一定次数的Full GC（标记清除）的时候进行一次标记整理算法，CMS提供了以下参数来控制： -XX:UseCMSCompactAtFullCollection -XX:CMSFullGCBeforeCompaction=5 也就是CMS在进行5次Full GC（标记清除）之后进行一次标记整理算法，从而可以控制老年带的碎片在一定的数量以内，甚至可以配置CMS在每次Full GC的时候都进行内存的整理。","categories":[],"tags":[{"name":"Interview","slug":"Interview","permalink":"https://kayleh.top/tags/Interview/"}]},{"title":"Reflection","slug":"Reflection","date":"2020-07-14T05:33:21.000Z","updated":"2020-07-14T05:58:25.092Z","comments":true,"path":"2020/07/14/Reflection/","link":"","permalink":"https://kayleh.top/2020/07/14/Reflection/","excerpt":"Reflection","text":"Reflection 说明一下JAVA中反射的实现过程和作用分别是什么？JAVA语言编译之后会生成一个.class文件，反射就是通过字节码文件找到某一个类、类中的方法以及属性等。反射的实现主要借助以下四个类： Class：类的对象， Constructor：类的构造方法， Field：类中的属性对象， Method：类中的方法对象。 作用：反射机制指的是程序在运行时能够获取自身的信息。在JAVA中，只要给定类的名字，那么就可以通过反射机制来获取类的所有信息。","categories":[],"tags":[{"name":"Interview","slug":"Interview","permalink":"https://kayleh.top/tags/Interview/"}]},{"title":"JDK","slug":"JDK","date":"2020-07-14T05:32:29.000Z","updated":"2020-07-14T05:34:39.318Z","comments":true,"path":"2020/07/14/JDK/","link":"","permalink":"https://kayleh.top/2020/07/14/JDK/","excerpt":"JDK","text":"JDK 请问JDK和JRE的区别是什么？Java运行时环境(JRE)是将要执行Java程序的Java虚拟机。它同时也包含了执行applet需要的浏览器插件。Java开发工具包(JDK)是完整的Java软件开发包，包含了JRE，编译器和其他的工具(比如：JavaDoc，Java调试器)，可以让开发者开发、编译、执行Java应用程序。 Java中的LongAdder和AtomicLong有什么区别？JDK1.8引入了LongAdder类。CAS机制就是，在一个死循环内，不断尝试修改目标值，直到修改成功。如果竞争不激烈，那么修改成功的概率就很高，否则，修改失败的的概率就很高，在大量修改失败时，这些原子操作就会进行多次循环尝试，因此性能就会受到影响。 结合ConcurrentHashMap的实现思想，应该可以想到对一种传统AtomicInteger等原子类的改进思路。虽然CAS操作没有锁，但是像减少粒度这种分离热点的思想依然可以使用。将AtomicInteger的内部核心数据value分离成一个数组，每个线程访问时，通过哈希等算法映射到其中一个数字进行计数，而最终的计数结果，则为这个数组的求和累加。热点数据value被分离成多个单元cell，每个cell独自维护内部的值，当前对象的实际值由所有的cell累计合成，这样热点就进行了有效的分离，提高了并行度。","categories":[],"tags":[{"name":"Interview","slug":"Interview","permalink":"https://kayleh.top/tags/Interview/"}]},{"title":"Lock","slug":"Lock","date":"2020-07-14T05:31:29.000Z","updated":"2020-07-14T05:34:34.651Z","comments":true,"path":"2020/07/14/Lock/","link":"","permalink":"https://kayleh.top/2020/07/14/Lock/","excerpt":"LOCK","text":"LOCK 简述一下synchronized与java.util.concurrent.locks.Lock的相同之处和不同之处？主要相同点：Lock能完成synchronized所实现的所有功能主要不同点：Lock有比synchronized更精确的线程语义和更好的性能。synchronized会自动释放锁，而Lock一定要求程序员手工释放，并且必须在finally从句中释放。 JAVA中如何确保N个线程可以访问N个资源，但同时又不导致死锁？使用多线程的时候，一种非常简单的避免死锁的方式就是： 指定获取锁的顺序，并强制线程按照指定的顺序获取锁。因此，如果所有的线程都是以同样的顺序加锁和释放锁，就不会出现死锁了。 预防死锁，预先破坏产生死锁的四个条件。互斥不可能破坏，所以有如下三种方法： 1.破坏请求和保持条件，进程必须等所有要请求的资源都空闲时才能申请资源，这种方法会使资源浪费严重(有些资源可能仅在运行初期或结束时才使用，甚至根本不使用). 允许进程获取初期所需资源后，便开始运行，运行过程中再逐步释放自己占有的资源，比如有一个进程的任务是把数据复制到磁盘中再打印，前期只需获得磁盘资源而不需要获得打印机资源，待复制完毕后再释放掉磁盘资源。这种方法比第一种方法好，会使资源利用率上升。 2.破坏不可抢占条件，这种方法代价大，实现复杂。 3.破坏循坏等待条件，对各进程请求资源的顺序做一个规定，避免相互等待。这种方法对资源的利用率比前两种都高，但是前期要为设备指定序号，新设备加入会有一个问题，其次对用户编程也有限制。 请问什么是死锁(deadlock)?两个线程或两个以上线程都在等待对方执行完毕才能继续往下执行的时候就发生了死锁。结果就是这些线程都陷入了无限的等待中。 例如，如果线程1锁住了A，然后尝试对B进行加锁，同时线程2已经锁住了B，接着尝试对A进行加锁，这时死锁就发生了。线程1永远得不到B，线程2也永远得不到A，并且它们永远也不会知道发生了这样的事情。为了得到彼此的对象（A和B），它们将永远阻塞下去。这种情况就是一个死锁。 说明一下锁和同步的区别。用法上的不同：synchronized既可以加在方法上，也可以加载特定代码块上，而lock需要显示地指定起始位置和终止位置。synchronized是托管给JVM执行的12，lock的锁定是通过代码实现的，它有比synchronized更精确的线程语义。性能上的不同：lock接口的实现类ReentrantLock，不仅具有和synchronized相同的并发性和内存语义，还多了超时的获取锁、定时锁、等候和中断锁等。在竞争不是很激烈的情况下，synchronized的性能优于ReentrantLock，竞争激烈的情况下synchronized的性能会下降的非常快，而ReentrantLock则基本不变。锁机制不同：synchronized获取锁和释放锁的方式都是在块结构中，当获取多个锁时，必须以相反的顺序释放，并且是自动解锁。而Lock则需要开发人员手动释放，并且必须在finally中释放，否则会引起死锁。 请说明一下synchronized的可重入怎么实现。 每个锁关联一个线程持有者和一个计数器。当计数器为0时表示该锁没有被任何线程持有，那么任何线程都都可能获得该锁而调用相应方法。当一个线程请求成功后，JVM会记下持有锁的线程，并将计数器计为1。此时其他线程请求该锁，则必须等待。而该持有锁的线程如果再次请求这个锁，就可以再次拿到这个锁，同时计数器会递增。当线程退出一个synchronized方法/块时，计数器会递减，如果计数器为0则释放该锁。 请讲一下非公平锁和公平锁在reetrantlock里的实现过程是怎样的。 如果一个锁是公平的，那么锁的获取顺序就应该符合请求的绝对时间顺序，FIFO。对于非公平锁，只要CAS设置同步状态成功，则表示当前线程获取了锁，而公平锁还需要判断当前节点是否有前驱节点，如果有，则表示有线程比当前线程更早请求获取锁，因此需要等待前驱线程获取并释放锁之后才能继续获取锁。","categories":[],"tags":[{"name":"Interview","slug":"Interview","permalink":"https://kayleh.top/tags/Interview/"}]},{"title":"Thread","slug":"Thread","date":"2020-07-14T05:30:23.000Z","updated":"2020-07-14T05:50:17.142Z","comments":true,"path":"2020/07/14/Thread/","link":"","permalink":"https://kayleh.top/2020/07/14/Thread/","excerpt":"THREAD","text":"THREAD 如何保证线程安全？通过合理的时间调度，避开共享资源的存取冲突。另外，在并行任务设计上可以通过适当的策略，保证任务与任务之间不存在共享资源，设计一个规则来保证一个客户的计算工作和数据访问只会被一个线程或一台工作机完成，而不是把一个客户的计算工作分配给多个线程去完成。 简要说明一下线程的基本状态以及状态之间的关系？其中Running表示运行状态，Runnable表示就绪状态（万事俱备，只欠CPU），Blocked表示阻塞状态，阻塞状态又有多种情况，可能是因为调用wait()方法进入等待池，也可能是执行同步方法或同步代码块进入等锁池，或者是调用了sleep()方法或join()方法等待休眠或其他线程结束，或是因为发生了I/O中断。 解释一下什么是线程池（thread pool）？在面向对象编程中，创建和销毁对象是很费时间的，因为创建一个对象要获取内存资源或者其它更多资源。在Java中更是如此，虚拟机将试图跟踪每一个对象，以便能够在对象销毁后进行垃圾回收。所以提高服务程序效率的一个手段就是尽可能减少创建和销毁对象的次数，特别是一些很耗资源的对象创建和销毁，这就是”池化资源”技术产生的原因。线程池顾名思义就是事先创建若干个可执行的线程放入一个池（容器）中，需要的时候从池中获取线程不用自行创建，使用完毕不需要销毁线程而是放回池中，从而减少创建和销毁线程对象的开销。Java 5+中的Executor接口定义一个执行线程的工具。它的子类型即线程池接口是ExecutorService。要配置一个线程池是比较复杂的，尤其是对于线程池的原理不是很清楚的情况下，因此在工具类Executors面提供了一些静态工厂方法，生成一些常用的线程池，如下所示：- newSingleThreadExecutor：创建一个单线程的线程池。这个线程池只有一个线程在工作，也就是相当于单线程串行执行所有任务。如果这个唯一的线程因为异常结束，那么会有一个新的线程来替代它。此线程池保证所有任务的执行顺序按照任务的提交顺序执行。- newFixedThreadPool：创建固定大小的线程池。每次提交一个任务就创建一个线程，直到线程达到线程池的最大大小。线程池的大小一旦达到最大值就会保持不变，如果某个线程因为执行异常而结束，那么线程池会补充一个新线程。- newCachedThreadPool：创建一个可缓存的线程池。如果线程池的大小超过了处理任务所需要的线程，那么就会回收部分空闲（60秒不执行任务）的线程，当任务数增加时，此线程池又可以智能的添加新线程来处理任务。此线程池不会对线程池大小做限制，线程池大小完全依赖于操作系统（或者说JVM）能够创建的最大线程大小。- newScheduledThreadPool：创建一个大小无限的线程池。此线程池支持定时以及周期性执行任务的需求。- newSingleThreadExecutor：创建一个单线程的线程池。此线程池支持定时以及周期性执行任务的需求。 举例说明同步和异步如果系统中存在临界资源（资源数量少于竞争资源的线程数量的资源），例如正在写的数据以后可能被另一个线程读到，或者正在读的数据可能已经被另一个线程写过了，那么这些数据就必须进行同步存取（数据库操作中的排他锁就是最好的例子）。当应用程序在对象上调用了一个需要花费很长时间来执行的方法，并且不希望让程序等待方法的返回时，就应该使用异步编程，在很多情况下采用异步途径往往更有效率。事实上，所谓的同步就是指阻塞式操作，而异步就是非阻塞式操作。 介绍一下线程同步和线程调度的相关方法。 - wait()：使一个线程处于等待（阻塞）状态，并且释放所持有的对象的锁；- sleep()：使一个正在运行的线程处于睡眠状态，是一个静态方法，调用此方法要处理InterruptedException异常；- notify()：唤醒一个处于等待状态的线程，当然在调用此方法的时候，并不能确切的唤醒某一个等待状态的线程，而是由JVM确定唤醒哪个线程，而且与优先级无关；- notityAll()：唤醒所有处于等待状态的线程，该方法并不是将对象的锁给所有线程，而是让它们竞争，只有获得锁的线程才能进入就绪状态；通过Lock接口提供了显式的锁机制（explicit lock），增强了灵活性以及对线程的协调。Lock接口中定义了加锁（lock()）和解锁（unlock()）的方法，同时还提供了newCondition()方法来产生用于线程之间通信的Condition对象；此外，Java 5还提供了信号量机制（semaphore），信号量可以用来限制对某个共享资源进行访问的线程的数量。在对资源进行访问之前，线程必须得到信号量的许可（调用Semaphore对象的acquire()方法）；在完成对资源的访问后，线程必须向信号量归还许可（调用Semaphore对象的release()方法）。 请问当一个线程进入一个对象的synchronized方法A之后，其它线程是否可进入此对象的synchronized方法B？不能。其它线程只能访问该对象的非同步方法，同步方法则不能进入。因为非静态方法上的synchronized修饰符要求执行方法时要获得对象的锁，如果已经进入A方法说明对象锁已经被取走，那么试图进入B方法的线程就只能在等锁池（注意不是等待池哦）中等待对象的锁。 请简述一下线程的sleep()方法和yield()方法有什么区别？①sleep()方法给其他线程运行机会时不考虑线程的优先级，因此会给低优先级的线程以运行的机会； yield()方法只会给相同优先级或更高优先级的线程以运行的机会； ② 线程执行sleep()方法后转入阻塞（blocked）状态， 而执行yield()方法后转入就绪（ready）状态； Java中有几种方法可以实现一个线程？用什么关键字修饰同步方法? stop()和suspend()方法为何不推荐使用，请说明原因？有两种实现方法，分别是继承Thread类与实现Runnable接口，用synchronized关键字修饰同步方法， 反对使用stop()，是因为它不安全。它会解除由线程获取的所有锁定，而且如果对象处于一种不连贯状态，那么其他线程能在那种状态下检查和修改它们。结果很难检查出真正的问题所在。suspend()方法容易发生死锁。 调用suspend()的时候，目标线程会停下来，但却仍然持有在这之前获得的锁定。此时，其他任何线程都不能访问锁定的资源，除非被”挂起”的线程恢复运行。对任何线程来说，如果它们想恢复目标线程，同时又试图使用任何一个锁定的资源，就会造成死锁。所以不应该使用suspend()，而应在自己的Thread类中置入一个标志，指出线程应该活动还是挂起。若标志指出线程应该挂起，便用 wait()命其进入等待状态。若标志指出线程应当恢复，则用一个notify()重新启动线程。 多线程和同步有几种实现方法,并且这些实现方法具体内容都是什么?多线程有两种实现方法，分别是继承Thread类与实现Runnable接口同步的实现方面有两种，分别是synchronized,wait与notify。 说出你所知道的线程同步的方法wait():使一个线程处于等待状态，并且释放所持有的对象的lock。sleep():使一个正在运行的线程处于睡眠状态，是一个静态方法，调用此方法要捕捉InterruptedException异常。notify():唤醒一个处于等待状态的线程，注意的是在调用此方法的时候，并不能确切的唤醒某一个等待状态的线程，而是由JVM确定唤醒哪个线程，而且不是按优先级。Allnotity():唤醒所有处入等待状态的线程，注意并不是给所有唤醒线程一个对象的锁，而是让它们竞争。 启动一个线程是用run()还是start()?启动一个线程是调用start()方法，使线程所代表的虚拟处理机处于可运行状态，这意味着它可以由JVM调度并执行。这并不意味着线程就会立即运行。run()方法可以产生必须退出的标志来停止一个线程。 请使用内部类实现线程设计4个线程，其中两个线程每次对j增加1，另外两个线程对j每次减少1。123456789101112131415161718192021222324252627282930313233343536public class ThreadTest1&#123;private int j;public static void main(String args[])&#123;ThreadTest1 tt=new ThreadTest1();Inc inc=tt.new Inc();Dec dec=tt.new Dec();for(int i=0;i&lt;2;i++)&#123;Thread t=new Thread(inc);t.start();t=new Thread(dec);t.start();&#125;&#125;private synchronized void inc()&#123;j++;System.out.println(Thread.currentThread().getName()+\"-inc:\"+j);&#125;private synchronized void dec()&#123;j--;System.out.println(Thread.currentThread().getName()+\"-dec:\"+j);&#125;class Inc implements Runnable&#123;public void run()&#123;for(int i=0;i&lt;100;i++)&#123;inc();&#125;&#125;&#125;class Dec implements Runnable&#123;public void run()&#123;for(int i=0;i&lt;100;i++)&#123;dec();&#125;&#125;&#125;&#125; 说明一下线程中的同步和异步有何异同？并且请举例说明在什么情况下会使用到同步和异步？如果数据将在线程间共享。例如正在写的数据以后可能被另一个线程读到，或者正在读的数据可能已经被另一个线程写过了，那么这些数据就是共享数据，必须进行同步存取。当应用程序在对象上调用了一个需要花费很长时间来执行的方法，并且不希望让程序等待方法的返回时，就应该使用异步编程，在很多情况下采用异步途径往往更有效率。 明一下sleep() 和 wait() 有什么区别？sleep是线程类（Thread）的方法，导致此线程暂停执行指定时间，把执行机会给其他线程，但是监控状态依然保持，到时后会自动恢复。调用sleep不会释放对象锁。wait是Object类的方法，对此对象调用wait方法导致本线程放弃对象锁，进入等待此对象的等待锁定池，只有针对此对象发出notify方法（或notifyAll）后本线程才进入对象锁定池准备获得对象锁进入运行状态。 请你说明一下在监视器(Monitor)内部，是如何做到线程同步的？在程序又应该做哪种级别的同步呢？监视器和锁在Java虚拟机中是一块使用的。监视器监视一块同步代码块，确保一次只有一个线程执行同步代码块。每一个监视器都和一个对象引用相关联。线程在获取锁之前不允许执行同步代码。 分析一下同步方法和同步代码块的区别是什么？同步方法默认用this或者当前类class对象作为锁；同步代码块可以选择以什么来加锁，比同步方法要更细颗粒度，我们可以选择只同步会发生同步问题的部分代码而不是整个方法。 请详细描述一下线程从创建到死亡的几种状态都有哪些？ 新建( new )：新创建了一个线程对象。 可运行( runnable )：线程对象创建后，其他线程(比如 main 线程）调用了该对象 的 start ()方法。该状态的线程位于可运行线程池中，等待被线程调度选中，获 取 cpu 的使用权 。 运行( running )：可运行状态( runnable )的线程获得了 cpu 时间片（ timeslice ） ，执行程序代码。 阻塞( block )：阻塞状态是指线程因为某种原因放弃了 cpu 使用权，也即让出了 cpu timeslice ，暂时停止运行。直到线程进入可运行( runnable )状态，才有 机会再次获得 cpu timeslice 转到运行( running )状态。阻塞的情况分三种：(一). 等待阻塞：运行( running )的线程执行 o . wait ()方法， JVM 会把该线程放 入等待队列( waitting queue )中。(二). 同步阻塞：运行( running )的线程在获取对象的同步锁时，若该同步锁 被别的线程占用，则 JVM 会把该线程放入锁池( lock pool )中。(三). 其他阻塞: 运行( running )的线程执行 Thread . sleep ( long ms )或 t . join ()方法，或者发出了 I / O 请求时， JVM 会把该线程置为阻塞状态。 当 sleep ()状态超时、 join ()等待线程终止或者超时、或者 I / O 处理完毕时，线程重新转入可运行( runnable )状态。 死亡( dead )：线程 run ()、 main () 方法执行结束，或者因异常退出了 run ()方法，则该线程结束生命周期。死亡的线程不可再次复生。 创建线程有几种不同的方式？你喜欢哪一种？为什么？有三种方式可以用来创建线程：继承Thread类实现Runnable接口应用程序可以使用Executor框架来创建线程池实现Runnable接口这种方式更受欢迎，因为这不需要继承Thread类。在应用设计中已经继承了别的对象的情况下，这需要多继承（而Java不支持多继承），只能实现接口。同时，线程池也是非常高效的，很容易实现和使用。 解释一下Java多线程回调是什么意思？所谓回调，就是客户程序C调用服务程序S中的某个方法A，然后S又在某个时候反过来调用C中的某个方法B，对于C来说，这个B便叫做回调方法。 列举一下启动线程有哪几种方式，之后再说明一下线程池的种类都有哪些？①启动线程有如下三种方式： 一、继承Thread类创建线程类 （1）定义Thread类的子类，并重写该类的run方法，该run方法的方法体就代表了线程要完成的任务。因此把run()方法称为执行体。 （2）创建Thread子类的实例，即创建了线程对象。 （3）调用线程对象的start()方法来启动该线程。 代码： 12345678910111213141516171819202122232425package com.thread;public class FirstThreadTest extends Thread&#123; int i = 0; //重写run方法，run方法的方法体就是现场执行体 public void run() &#123; for(;i&lt;100;i++)&#123; System.out.println(getName()+\" \"+i); &#125; &#125; public static void main(String[] args) &#123; for(int i = 0;i&lt; 100;i++) &#123; System.out.println(Thread.currentThread().getName()+\" : \"+i); if(i==20) &#123; new FirstThreadTest().start(); new FirstThreadTest().start(); &#125; &#125; &#125; &#125; 上述代码中Thread.currentThread()方法返回当前正在执行的线程对象。GetName()方法返回调用该方法的线程的名字。 二、通过Runnable接口创建线程类 （1）定义runnable接口的实现类，并重写该接口的run()方法，该run()方法的方法体同样是该线程的线程执行体。 （2）创建 Runnable实现类的实例，并依此实例作为Thread的target来创建Thread对象，该Thread对象才是真正的线程对象。 （3）调用线程对象的start()方法来启动该线程。 代码： 1234567891011121314151617181920212223242526272829package com.thread; public class RunnableThreadTest implements Runnable&#123; private int i; public void run() &#123; for(i = 0;i &lt;100;i++) &#123; System.out.println(Thread.currentThread().getName()+\" \"+i); &#125; &#125; public static void main(String[] args) &#123; for(int i = 0;i &lt; 100;i++) &#123; System.out.println(Thread.currentThread().getName()+\" \"+i); if(i==20) &#123; RunnableThreadTest rtt = new RunnableThreadTest(); new Thread(rtt,\"新线程1\").start(); new Thread(rtt,\"新线程2\").start(); &#125; &#125; &#125; &#125; 三、通过Callable和Future创建线程 （1）创建Callable接口的实现类，并实现call()方法，该call()方法将作为线程执行体，并且有返回值。 （2）创建Callable实现类的实例，使用FutureTask类来包装Callable对象，该FutureTask对象封装了该Callable对象的call()方法的返回值。 （3）使用FutureTask对象作为Thread对象的target创建并启动新线程。 （4）调用FutureTask对象的get()方法来获得子线程执行结束后的返回值 代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445package com.thread;import java.util.concurrent.Callable;import java.util.concurrent.ExecutionException;import java.util.concurrent.FutureTask; public class CallableThreadTest implements Callable&lt;Integer&gt;&#123; public static void main(String[] args) &#123; CallableThreadTest ctt = new CallableThreadTest(); FutureTask&lt;Integer&gt; ft = new FutureTask&lt;&gt;(ctt); for(int i = 0;i &lt; 100;i++) &#123; System.out.println(Thread.currentThread().getName()+\" 的循环变量i的值\"+i); if(i==20) &#123; new Thread(ft,\"有返回值的线程\").start(); &#125; &#125; try &#123; System.out.println(\"子线程的返回值：\"+ft.get()); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; catch (ExecutionException e) &#123; e.printStackTrace(); &#125; &#125; @Override public Integer call() throws Exception &#123; int i = 0; for(;i&lt;100;i++) &#123; System.out.println(Thread.currentThread().getName()+\" \"+i); &#125; return i; &#125; &#125; ②线程池的种类有： Java通过Executors提供四种线程池，分别为： newCachedThreadPool创建一个可缓存线程池，如果线程池长度超过处理需要，可灵活回收空闲线程，若无可回收，则新建线程。newFixedThreadPool 创建一个定长线程池，可控制线程最大并发数，超出的线程会在队列中等待。newScheduledThreadPool 创建一个定长线程池，支持定时及周期性任务执行。newSingleThreadExecutor 创建一个单线程化的线程池，它只会用唯一的工作线程来执行任务，保证所有任务按照指定顺序(FIFO, LIFO, 优先级)执行。 简要说明一下JAVA中cyclicbarrier和countdownlatch的区别分别是什么？CountDownLatch和CyclicBarrier都能够实现线程之间的等待，只不过它们侧重点不同： CountDownLatch一般用于某个线程A等待若干个其他线程执行完任务之后，它才执行； 而CyclicBarrier一般用于一组线程互相等待至某个状态，然后这一组线程再同时执行； 另外，CountDownLatch是不能够重用的，而CyclicBarrier是可以重用的。 说明一下线程池有什么优势？第一：降低资源消耗。通过重复利用已创建的线程降低线程创建和销毁造成的消耗。 第二：提高响应速度。当任务到达时，任务可以不需要等到线程创建就能执行。 第三：提高线程的可管理性，线程是稀缺资源，如果无限制地创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一分配、调优和监控。 请回答一下Java中有几种线程池？并且详细描述一下线程池的实现过程 1、newFixedThreadPool创建一个指定工作线程数量的线程池。每当提交一个任务就创建一个工作线程，如果工作线程数量达到线程池初始的最大数，则将提交的任务存入到池队列中。2、newCachedThreadPool创建一个可缓存的线程池。这种类型的线程池特点是： 1).工作线程的创建数量几乎没有限制(其实也有限制的,数目为Interger. MAX_VALUE), 这样可灵活的往线程池中添加线程。2).如果长时间没有往线程池中提交任务，即如果工作线程空闲了指定的时间(默认为1分钟)，则该工作线程将自动终止。终止后，如果你又提交了新的任务，则线程池重新创建一个工作线程。3、newSingleThreadExecutor创建一个单线程化的Executor，即只创建唯一的工作者线程来执行任务，如果这个线程异常结束，会有另一个取代它，保证顺序执行(我觉得这点是它的特色)。单工作线程最大的特点是可保证顺序地执行各个任务，并且在任意给定的时间不会有多个线程是活动的 。4、newScheduleThreadPool创建一个定长的线程池，而且支持定时的以及周期性的任务执行，类似于Timer。(这种线程池原理暂还没完全了解透彻) 请说明一下Java中都有哪些方式可以启动一个线程？ 继承自Thread类 实现Runnable接口 即实现Runnable接口，也继承Thread类，并重写run方法 请列举一下创建线程的方法，并简要说明一下在这些方法中哪个方法更好，原因是什么？需要从Java.lang.Thread类派生一个新的线程类，重载它的run()方法； 实现Runnalbe接口，重载Runnalbe接口中的run()方法。 实现Runnalbe接口更好，使用实现Runnable接口的方式创建的线程可以处理同一资源，从而实现资源的共享. 简短说明一下你对AQS的理解。 AQS其实就是一个可以给我们实现锁的框架内部实现的关键是：先进先出的队列、state状态定义了内部类ConditionObject拥有两种线程模式独占模式和共享模式。在LOCK包中的相关锁(常用的有ReentrantLock、 ReadWriteLock)都是基于AQS来构建，一般我们叫AQS为同步器。 请简述一下线程池的运行流程，使用参数以及方法策略等线程池主要就是指定线程池核心线程数大小，最大线程数，存储的队列，拒绝策略，空闲线程存活时长。当需要任务大于核心线程数时候，就开始把任务往存储任务的队列里，当存储队列满了的话，就开始增加线程池创建的线程数量，如果当线程数量也达到了最大，就开始执行拒绝策略，比如说记录日志，直接丢弃，或者丢弃最老的任务。 线程，进程，然后线程创建有很大开销，怎么优化？ 可以使用线程池。 什么是生产者消费者模式？生产者消费者问题是线程模型中的经典问题：生产者和消费者在同一时间段内共用同一存储空间，生产者向空间里生产数据，而消费者取走数据。 优点：支持并发、解耦。 简述一下实现多线程同步的方法？可以使用synchronized、lock、volatile和ThreadLocal来实现同步。 如何在线程安全的情况下实现一个计数器？可以使用加锁，比如synchronized或者lock。也可以使用Concurrent包下的原子类。 多线程中的i++线程安全吗？请简述一下原因？不安全。i++不是原子性操作。i++分为读取i值，对i值加一，再赋值给i++，执行期中任何一步都是有可能被其他线程抢占的。","categories":[],"tags":[{"name":"Interview","slug":"Interview","permalink":"https://kayleh.top/tags/Interview/"}]},{"title":"Array","slug":"Array","date":"2020-07-14T05:29:08.000Z","updated":"2020-07-14T05:48:30.894Z","comments":true,"path":"2020/07/14/Array/","link":"","permalink":"https://kayleh.top/2020/07/14/Array/","excerpt":"Array","text":"Array List、Map、Set三个接口存取元素时，各有什么特点？ List以特定索引来存取元素，可以有重复元素。 Set不能存放重复元素（用对象的equals()方法来区分元素是否重复）。 Map保存键值对（key-value pair）映射，映射关系可以是一对一或多对一。 Set和Map容器都有基于哈希存储和排序树的两种实现版本，基于哈希存储的版本理论存取时间复杂度为O(1)，而基于排序树版本的实现在插入或删除元素时会按照元素或元素的键（key）构成排序树从而达到排序和去重的效果。 阐述ArrayList、Vector、LinkedList的存储性能和特性 ArrayList 和Vector都是使用数组方式存储数据，此数组元素数大于实际存储的数据以便增加和插入元素，它们都允许直接按序号索引元素，但是插入元素要涉及数组元素移动等内存操作，所以索引数据快而插入数据慢，Vector中的方法由于添加了synchronized修饰，因此Vector是线程安全的容器，但性能上较ArrayList差，因此已经是Java中的遗留容器。 LinkedList使用双向链表实现存储（将内存中零散的内存单元通过附加的引用关联起来，形成一个可以按序号索引的线性结构，这种链式存储方式与数组的连续存储方式相比，内存的利用率更高），按序号索引数据需要进行前向或后向遍历，但是插入数据时只需要记录本项的前后项即可，所以插入速度较快。Vector属于遗留容器（Java早期的版本中提供的容器，除此之外，Hashtable、Dictionary、BitSet、Stack、Properties都是遗留容器），已经不推荐使用，但是由于ArrayList和LinkedListed都是非线程安全的，如果遇到多个线程操作同一个容器的场景，则可以通过工具类Collections中的synchronizedList方法将其转换成线程安全的容器后再使用（这是对装潢模式的应用，将已有对象传入另一个类的构造器中创建新的对象来增强实现）。 判断List、Set、Map是否继承自Collection接口？ List、Set 是，Map 不是。 Map是键值对映射容器，与List和Set有明显的区别，而Set存储的零散的元素且不允许有重复元素 （数学中的集合也是如此），List是线性结构的容器，适用于按数值索引访问元素的情形。 你所知道的常用集合类以及主要方法？最常用的集合类是List 和 Map。 List 的具体实现包括 ArrayList 和 Vector，它们是可变大小的列表，比较适合构建、存储和操作任何类型对象的元素列表。List 适用于按数值索引访问元素的情形。 Map 提供了一个更通用的元素存储方法。 Map 集合类用于存储元素对（称作”键”和”值”），其中每个键映射到一个值。 说明Collection 和 Collections的区别Collection是集合类的上级接口，继承与他的接口主要有Set 和List.Collections是针对集合类的一个帮助类，他提供一系列静态方法实现对各种集合的搜索、排序、线程安全化等操作。 说明ArrayList,Vector,LinkedList的存储性能和特性是什么？ ArrayList 和Vector都是使用数组方式存储数据，此数组元素数大于实际存储的数据以便增加和插入元素，它们都允许直接按序号索引元素，但是插入元素要涉及数组元素移动等内存操作，所以索引数据快而插入数据慢，Vector由于使用了synchronized方法（线程安全），通常性能上较ArrayList差，而LinkedList使用双向链表实现存储，按序号索引数据需要进行前向或后向遍历，但是插入数据时只需要记录本项的前后项即可，所以插入速度较快。 ArrayList和LinkedList的区别？(链表和数组的优缺点) ArrayList和LinkedList都实现了List接口，他们有以下的不同点：ArrayList是基于索引的数据接口，它的底层是数组。它可以以O(1)时间复杂度对元素进行随机访问。与此对应，LinkedList是以元素列表的形式存储它的数据，每一个元素都和它的前一个和后一个元素链接在一起，在这种情况下，查找某个元素的时间复杂度是O(n)。相对于ArrayList，LinkedList的插入，添加，删除操作速度更快，因为当元素被添加到集合任意位置的时候，不需要像数组那样重新计算大小或者是更新索引。LinkedList比ArrayList更占内存，因为LinkedList为每一个节点存储了两个引用，一个指向前一个元素，一个指向下一个元素。 说明HashMap和Hashtable的区别？HashMap和Hashtable都实现了Map接口，因此很多特性非常相似。但是，他们有以下不同点：HashMap允许键和值是null，而Hashtable不允许键或者值是null。Hashtable是同步的，而HashMap不是。因此，HashMap更适合于单线程环境，而Hashtable适合于多线程环境。HashMap提供了可供应用迭代的键的集合，因此，HashMap是快速失败的。另一方面，Hashtable提供了对键的列举(Enumeration)。一般认为Hashtable是一个遗留的类。 请说说快速失败(fail-fast)和安全失败(fail-safe)的区别？Iterator的安全失败是基于对底层集合做拷贝，因此，它不受源集合上修改的影响。java.util包下面的所有的集合类都是快速失败的，而java.util.concurrent包下面的所有的类都是安全失败的。快速失败的迭代器会抛出ConcurrentModificationException异常，而安全失败的迭代器永远不会抛出这样的异常。 说说Iterator和ListIterator的区别？Iterator和ListIterator的区别是：Iterator可用来遍历Set和List集合，但是ListIterator只能用来遍历List。Iterator对集合只能是前向遍历，ListIterator既可以前向也可以后向。ListIterator实现了Iterator接口，并包含其他的功能，比如：增加元素，替换元素，获取前一个和后一个元素的索引，等等。 请简单说明一下什么是迭代器？Iterator提供了统一遍历操作集合元素的统一接口, Collection接口实现Iterable接口,每个集合都通过实现Iterable接口中iterator()方法返回Iterator接口的实例, 然后对集合的元素进行迭代操作.有一点需要注意的是：在迭代元素的时候不能通过集合的方法删除元素, 否则会抛出ConcurrentModificationException 异常. 但是可以通过Iterator接口中的remove()方法进行删除. 解释为什么集合类没有实现Cloneable和Serializable接口？克隆(cloning)或者是序列化(serialization)的语义和含义是跟具体的实现相关的。因此，应该由集合类的具体实现来决定如何被克隆或者是序列化。实现Serializable序列化的作用：将对象的状态保存在存储媒体中以便可以在以后重写创建出完全相同的副本；按值将对象从一个从一个应用程序域发向另一个应用程序域。实现 Serializable接口的作用就是可以把对象存到字节流，然后可以恢复。所以你想如果你的对象没有序列化，怎么才能进行网络传输呢？要网络传输就得转为字节流，所以在分布式应用中，你就得实现序列化。如果你不需要分布式应用，那就没必要实现实现序列化。 Java集合类框架的基本接口有哪些？集合类接口指定了一组叫做元素的对象。集合类接口的每一种具体的实现类都可以选择以它自己的方式对元素进行保存和排序。有的集合类允许重复的键，有些不允许。Java集合类提供了一套设计良好的支持对一组对象进行操作的接口和类。Java集合类里面最基本的接口有：Collection：代表一组对象，每一个对象都是它的子元素。Set：不包含重复元素的Collection。List：有顺序的collection，并且可以包含重复元素。Map：可以把键(key)映射到值(value)的对象，键不能重复。 ConcurrentHashMap的原理？ ConcurrentHashMap 类中包含两个静态内部类 HashEntry 和 Segment。 HashEntry 用来封装映射表的键 / 值对； Segment 用来充当锁的角色，每个 Segment 对象守护整个散列映射表的若干个桶。每个桶是由若干个 HashEntry 对象链接起来的链表。 一个 ConcurrentHashMap 实例中包含由若干个 Segment 对象组成的数组。HashEntry 用来封装散列映射表中的键值对。在 HashEntry 类中，key，hash 和 next 域都被声明为 final 型，value 域被声明为 volatile 型。 12345678910111213static final class HashEntry&lt;K,V&gt; &#123; final K key; // 声明 key 为 final 型 final int hash; // 声明 hash 值为 final 型 volatile V value; // 声明 value 为 volatile 型 final HashEntry&lt;K,V&gt; next; // 声明 next 为 final 型 HashEntry(K key, int hash, HashEntry&lt;K,V&gt; next, V value) &#123; this.key = key; this.hash = hash; this.next = next; this.value = value; &#125;&#125; 在ConcurrentHashMap 中，在散列时如果产生“碰撞”，将采用“分离链接法”来处理“碰撞”：把“碰撞”的 HashEntry 对象链接成一个链表。由于 HashEntry 的 next 域为 final 型，所以新节点只能在链表的表头处插入。 下图是在一个空桶中依次插入 A，B，C 三个 HashEntry 对象后的结构图： 插入三个节点后桶的结构示意图： 注意：由于只能在表头插入，所以链表中节点的顺序和插入的顺序相反。 Segment 类继承于 ReentrantLock 类，从而使得 Segment 对象能充当锁的角色。每个 Segment 对象用来守护其（成员对象 table 中）包含的若干个桶。 解释一下TreeMap?TreeMap是一个有序的key-value集合，基于红黑树（Red-Black tree）的 NavigableMap实现。该映射根据其键的自然顺序进行排序，或者根据创建映射时提供的 Comparator进行排序，具体取决于使用的构造方法。TreeMap的特性：根节点是黑色每个节点都只能是红色或者黑色每个叶节点（NIL节点，空节点）是黑色的。如果一个节点是红色的，则它两个子节点都是黑色的，也就是说在一条路径上不能出现两个红色的节点。从任一节点到其每个叶子的所有路径都包含相同数目的黑色节点。 请说明ArrayList是否会越界？ArrayList是实现了基于动态数组的数据结构，而LinkedList是基于链表的数据结构2. 对于随机访问get和set，ArrayList要优于LinkedList，因为LinkedList要移动指针；ArrayList并发add()可能出现数组下标越界异常。 说明concurrenthashmap有什么优势以及1.7和1.8区别？Concurrenthashmap线程安全的，1.7是在jdk1.7中采用Segment + HashEntry的方式进行实现的，lock加在Segment上面。1.7size计算是先采用不加锁的方式，连续计算元素的个数，最多计算3次：1、如果前后两次计算结果相同，则说明计算出来的元素个数是准确的；2、如果前后两次计算结果都不同，则给每个Segment进行加锁，再计算一次元素的个数； 1.8中放弃了Segment臃肿的设计，取而代之的是采用Node + CAS + Synchronized来保证并发安全进行实现，1.8中使用一个volatile类型的变量baseCount记录元素的个数，当插入新数据或则删除数据时，会通过addCount()方法更新baseCount，通过累加baseCount和CounterCell数组中的数量，即可得到元素的总个数； TreeMap的底层实现？TreeMap 的实现就是红黑树数据结构，也就说是一棵自平衡的排序二叉树，这样就可以保证当需要快速检索指定节点。 红黑树的插入、删除、遍历时间复杂度都为O(lgN)，所以性能上低于哈希表。但是哈希表无法提供键值对的有序输出，红黑树因为是排序插入的，可以按照键的值的大小有序输出。红黑树性质： 性质1：每个节点要么是红色，要么是黑色。 性质2：根节点永远是黑色的。 性质3：所有的叶节点都是空节点（即 null），并且是黑色的。 性质4：每个红色节点的两个子节点都是黑色。（从每个叶子到根的路径上不会有两个连续的红色节点） 性质5：从任一节点到其子树中每个叶子节点的路径都包含相同数量的黑色节点。 说明ConcurrentHashMap锁加在了哪些地方？加在每个Segment 上面。 解释HashMap的容量为什么是2的n次幂？负载因子默认是0.75， 2^n是为了让散列更加均匀，例如出现极端情况都散列在数组中的一个下标，那么hashmap会由O（1）复杂退化为O（n）的。 请你简单介绍一下ArrayList和LinkedList的区别，并说明如果一直在list的尾部添加元素，用哪种方式的效率高？ArrayList采用数组数组实现的，查找效率比LinkedList高。LinkedList采用双向链表实现的，插入和删除的效率比ArrayList要高。一直在list的尾部添加元素，LinkedList效率要高。 如果hashMap的key是一个自定义的类，怎么办？使用HashMap，如果key是自定义的类，就必须重写hashcode()和equals()。 解释一下hashMap具体如何实现的？ Hashmap基于数组实现的，通过对key的hashcode &amp; 数组的长度得到在数组中位置，如当前数组有元素，则数组当前元素next指向要插入的元素，这样来解决hash冲突的，形成了拉链式的结构。put时在多线程情况下，会形成环从而导致死循环。数组长度一般是2n，从0开始编号，所以hashcode &amp; （2n-1），（2n-1）每一位都是1，这样会让散列均匀。需要注意的是，HashMap在JDK1.8的版本中引入了红黑树结构做优化，当链表元素个数大于等于8时，链表转换成树结构；若桶中链表元素个数小于等于6时，树结构还原成链表。因为红黑树的平均查找长度是log(n)，长度为8的时候，平均查找长度为3，如果继续使用链表，平均查找长度为8/2=4，这才有转换为树的必要。链表长度如果是小于等于6，6/2=3，虽然速度也很快的，但是转化为树结构和生成树的时间并不会太短。还有选择6和8，中间有个差值7可以有效防止链表和树频繁转换。假设一下，如果设计成链表个数超过8则链表转换成树结构，链表个数小于8则树结构转换成链表，如果一个HashMap不停的插入、删除元素，链表个数在8左右徘徊，就会频繁的发生树转链表、链表转树，效率会很低。","categories":[],"tags":[{"name":"Interview","slug":"Interview","permalink":"https://kayleh.top/tags/Interview/"}]},{"title":"J2SE","slug":"J2SE","date":"2020-07-14T05:27:19.000Z","updated":"2020-07-14T05:28:49.876Z","comments":true,"path":"2020/07/14/J2SE/","link":"","permalink":"https://kayleh.top/2020/07/14/J2SE/","excerpt":"Object-oriented","text":"Object-oriented 关于Synchronized和locksynchronized是Java的关键字，当它用来修饰一个方法或者一个代码块的时候，能够保证在同一时刻最多只有一个线程执行该段代码。JDK1.5以后引入了自旋锁、锁粗化、轻量级锁，偏向锁来有优化关键字的性能。 Lock是一个接口，而synchronized是Java中的关键字，synchronized是内置的语言实现；synchronized在发生异常时，会自动释放线程占有的锁，因此不会导致死锁现象发生；而Lock在发生异常时，如果没有主动通过unLock()去释放锁，则很可能造成死锁现象，因此使用Lock时需要在finally块中释放锁；Lock可以让等待锁的线程响应中断，而synchronized却不行，使用synchronized时，等待的线程会一直等待下去，不能够响应中断；通过Lock可以知道有没有成功获取锁，而synchronized却无法办到。 volatile volatile关键字是用来保证有序性和可见性的。这跟Java内存模型有关。比如我们所写的代码，不一定是按照我们自己书写的顺序来执行的，编译器会做重排序，CPU也会做重排序的，这样的重排序是为了减少流水线的阻塞的，引起流水阻塞，比如数据相关性，提高CPU的执行效率。需要有一定的顺序和规则来保证，不然程序员自己写的代码都不知带对不对了，所以有happens-before规则，其中有条就是volatile变量规则：对一个变量的写操作先行发生于后面对这个变量的读操作；有序性实现的是通过插入内存屏障来保证的。可见性：首先Java内存模型分为，主内存，工作内存。比如线程A从主内存把变量从主内存读到了自己的工作内存中，做了加1的操作，但是此时没有将i的最新值刷新会主内存中，线程B此时读到的还是i的旧值。加了volatile关键字的代码生成的汇编代码发现，会多出一个lock前缀指令。Lock指令对Intel平台的CPU，早期是锁总线，这样代价太高了，后面提出了缓存一致性协议，MESI，来保证了多核之间数据不一致性问题。 请你介绍一下Syncronized锁，如果用这个关键字修饰一个静态方法，锁住了什么？如果修饰成员方法，锁住了什么？ synchronized修饰静态方法以及同步代码块的synchronized (类.class)用法锁的是类，线程想要执行对应同步代码，需要获得类锁。synchronized修饰成员方法，线程获取的是当前调用该方法的对象实例的对象锁。 若对一个类不重写，它的equals()方法是如何比较的？ 比较是对象的地址。 请解释hashCode()和equals()方法有什么联系？Java对象的eqauls方法和hashCode方法是这样规定的： ➀ 相等（相同）的对象必须具有相等的哈希码（或者散列码）。 ➁ 如果两个对象的hashCode相同，它们并不一定相同。 什么是构造函数？什么是构造函数重载？什么是复制构造函数？ 当新对象被创建的时候，构造函数会被调用。每一个类都有构造函数。在程序员没有给类提供构造函数的情况下，Java编译器会为这个类创建一个默认的构造函数。Java中构造函数重载和方法重载很相似。可以为一个类创建多个构造函数。每一个构造函数必须有它自己唯一的参数列表。Java不支持像C++中那样的复制构造函数，这个不同点是因为如果你不自己写构造函数的情况下，Java不会创建默认的复制构造函数。 请说明Java中的方法覆盖(Overriding)和方法重载(Overloading)是什么意思？ Java中的方法重载发生在同一个类里面两个或者是多个方法的方法名相同但是参数不同的情况。 与此相对，方法覆盖是说子类重新定义了父类的方法。方法覆盖必须有相同的方法名，参数列表和返回类型。覆盖者可能不会限制它所覆盖的方法的访问。 Query接口的list方法和iterate方法有什么区别？ ① list()方法无法利用一级缓存和二级缓存（对缓存只写不读），它只能在开启查询缓存的前提下使用查询缓存；iterate()方法可以充分利用缓存，如果目标数据只读或者读取频繁，使用iterate()方法可以减少性能开销。② list()方法不会引起N+1查询问题，而iterate()方法可能引起N+1查询问题 面向对象的”六原则一法则”。 - 单一职责原则：一个类只做它该做的事情。（单一职责原则想表达的就是”高内聚”，写代码最终极的原则只有六个字”高内聚、低耦合”，所谓的高内聚就是一个代码模块只完成一项功能，在面向对象中，如果只让一个类完成它该做的事，而不涉及与它无关的领域就是践行了高内聚的原则，这个类就只有单一职责。另一个是模块化，好的自行车是组装车，从减震叉、刹车到变速器，所有的部件都是可以拆卸和重新组装的，好的乒乓球拍也不是成品拍，一定是底板和胶皮可以拆分和自行组装的，一个好的软件系统，它里面的每个功能模块也应该是可以轻易的拿到其他系统中使用的，这样才能实现软件复用的目标。）- 开闭原则：软件实体应当对扩展开放，对修改关闭。（在理想的状态下，当我们需要为一个软件系统增加新功能时，只需要从原来的系统派生出一些新类就可以，不需要修改原来的任何一行代码。要做到开闭有两个要点：①抽象是关键，一个系统中如果没有抽象类或接口系统就没有扩展点；②封装可变性，将系统中的各种可变因素封装到一个继承结构中，如果多个可变因素混杂在一起，系统将变得复杂而换乱，如果不清楚如何封装可变性，可以参考《设计模式精解》一书中对桥梁模式的讲解的章节。）- 依赖倒转原则：面向接口编程。（该原则说得直白和具体一些就是声明方法的参数类型、方法的返回类型、变量的引用类型时，尽可能使用抽象类型而不用具体类型，因为抽象类型可以被它的任何一个子类型所替代，请参考下面的里氏替换原则。）里氏替换原则：任何时候都可以用子类型替换掉父类型。（关于里氏替换原则的描述，Barbara Liskov女士的描述比这个要复杂得多，但简单的说就是能用父类型的地方就一定能使用子类型。里氏替换原则可以检查继承关系是否合理，如果一个继承关系违背了里氏替换原则，那么这个继承关系一定是错误的，需要对代码进行重构。例如让猫继承狗，或者狗继承猫，又或者让正方形继承长方形都是错误的继承关系，因为你很容易找到违反里氏替换原则的场景。需要注意的是：子类一定是增加父类的能力而不是减少父类的能力，因为子类比父类的能力更多，把能力多的对象当成能力少的对象来用当然没有任何问题。）- 接口隔离原则：接口要小而专，绝不能大而全。（臃肿的接口是对接口的污染，既然接口表示能力，那么一个接口只应该描述一种能力，接口也应该是高度内聚的。例如，琴棋书画就应该分别设计为四个接口，而不应设计成一个接口中的四个方法，因为如果设计成一个接口中的四个方法，那么这个接口很难用，毕竟琴棋书画四样都精通的人还是少数，而如果设计成四个接口，会几项就实现几个接口，这样的话每个接口被复用的可能性是很高的。Java中的接口代表能力、代表约定、代表角色，能否正确的使用接口一定是编程水平高低的重要标识。）- 合成聚合复用原则：优先使用聚合或合成关系复用代码。（通过继承来复用代码是面向对象程序设计中被滥用得最多的东西，因为所有的教科书都无一例外的对继承进行了鼓吹从而误导了初学者，类与类之间简单的说有三种关系，Is-A关系、Has-A关系、Use-A关系，分别代表继承、关联和依赖。其中，关联关系根据其关联的强度又可以进一步划分为关联、聚合和合成，但说白了都是Has-A关系，合成聚合复用原则想表达的是优先考虑Has-A关系而不是Is-A关系复用代码，原因嘛可以自己从百度上找到一万个理由，需要说明的是，即使在Java的API中也有不少滥用继承的例子，例如Properties类继承了Hashtable类，Stack类继承了Vector类，这些继承明显就是错误的，更好的做法是在Properties类中放置一个Hashtable类型的成员并且将其键和值都设置为字符串来存储数据，而Stack类的设计也应该是在Stack类中放一个Vector对象来存储数据。记住：任何时候都不要继承工具类，工具是可以拥有并可以使用的，而不是拿来继承的。）- 迪米特法则：迪米特法则又叫最少知识原则，一个对象应当对其他对象有尽可能少的了解。再复杂的系统都可以为用户提供一个简单的门面，Java Web开发中作为前端控制器的Servlet或Filter不就是一个门面吗，浏览器对服务器的运作方式一无所知，但是通过前端控制器就能够根据你的请求得到相应的服务。调停者模式也可以举一个简单的例子来说明，例如一台计算机，CPU、内存、硬盘、显卡、声卡各种设备需要相互配合才能很好的工作，但是如果这些东西都直接连接到一起，计算机的布线将异常复杂，在这种情况下，主板作为一个调停者的身份出现，它将各个设备连接在一起而不需要每个设备之间直接交换数据，这样就减小了系统的耦合度和复杂度。 如何通过反射获取和设置对象私有字段的值？ 可以通过类对象的getDeclaredField()方法字段（Field）对象，然后再通过字段对象的setAccessible(true)将其设置为可以访问，接下来就可以通过get/set方法来获取/设置字段的值了。 下面的代码实现了一个反射的工具类，其中的两个静态方法分别用于获取和设置私有字段的值，字段可以是基本类型也可以是对象类型且支持多级对象操作，例如ReflectionUtil.get(dog, “owner.car.engine.id”);可以获得dog对象的主人的汽车的引擎的ID号。 12345678import java.lang.reflect.Method;class MethodInvokeTest &#123; public static void main(String[] args) throws Exception &#123; String str = \"hello\"; Method m = str.getClass().getMethod(\"toUpperCase\"); System.out.println(m.invoke(str)); // HELLO &#125;&#125; 请说明重载（Overload）和重写（Override）的区别。重载的方法能否根据返回类型进行区分？ 方法的重载和重写都是实现多态的方式， 区别在于前者实现的是编译时的多态性，而后者实现的是运行时的多态性。 重载发生在一个类中，同名的方法如果有不同的参数列表（参数类型不同、参数个数不同或者二者都不同）则视为重载；重写发生在子类与父类之间，重写要求子类被重写方法与父类被重写方法有相同的返回类型，比父类被重写方法更好访问，不能比父类被重写方法声明更多的异常（里氏代换原则）。重载对返回类型没有特殊的要求。 两个对象值相同(x.equals(y) == true)，但却可有不同的hash code，该说法是否正确，为什么？ 不对，如果两个对象x和y满足x.equals(y) == true，它们的哈希码（hash code）应当相同。Java对于eqauls方法和hashCode方法是这样规定的： (1)如果两个对象相同（equals方法返回true），那么它们的hashCode值一定要相同； (2)如果两个对象的hashCode相同，它们并不一定相同。 当然，你未必要按照要求去做，但是如果你违背了上述原则就会发现在使用容器时，相同的对象可以出现在Set集合中，同时增加新元素的效率会大大下降（对于使用哈希存储的系统，如果哈希码频繁的冲突将会造成存取性能急剧下降）。 请说明内部类可以引用他包含类的成员吗，如果可以，有没有什么限制吗？ 一个内部类对象可以访问创建它的外部类对象的内容，内部类如果不是static的，那么它可以访问创建它的外部类对象的所有属性.内部类如果是sattic的，即为nested class，那么它只可以访问创建它的外部类对象的所有static属性一般普通类只有public或package的访问修饰，而内部类可以实现static，protected，private等访问修饰。当从外部类继承的时候，内部类是不会被覆盖的，它们是完全独立的实体，每个都在自己的命名空间内，如果从内部类中明确地继承，就可以覆盖原来内部类的方法。 请说明JAVA语言如何进行异常处理，关键字：throws,throw,try,catch,finally分别代表什么意义？在try块中可以抛出异常吗？ Java 通过面向对象的方法进行异常处理，把各种不同的异常进行分类，并提供了良好的接口。在Java中，每个异常都是一个对象，它是Throwable类或其它子类的实例。当一个方法出现异常后便抛出一个异常对象，该对象中包含有异常信息，调用这个对象的方法可以捕获到这个异常并进行处理。 Java的异常处理是通过5个关键词来实现的：try、catch、throw、throws和finally。一般情况下是用try来执行一段程序，如果出现异常，系统会抛出（throws）一个异常，这时候你可以通过它的类型来捕捉（catch）它，或最后（finally）由缺省处理器来处理。用try来指定一块预防所有”异常”的程序。紧跟在try程序后面，应包含一个catch子句来指定你想要捕捉的”异常”的类型。throw语句用来明确地抛出一个”异常”。throws用来标明一个成员函数可能抛出的各种”异常”。Finally为确保一段代码不管发生什么”异常”都被执行一段代码。可以在一个成员函数调用的外面写一个try语句，在这个成员函数内部写另一个try语句保护其他代码。每当遇到一个try语句，”异常“的框架就放到堆栈上面，直到所有的try语句都完成。如果下一级的try语句没有对某种”异常”进行处理，堆栈就会展开，直到遇到有处理这种”异常”的try语句。 请说明Java的接口和C++的虚类的相同和不同处 由于Java不支持多继承，而有可能某个类或对象要使用分别在几个类或对象里面的方法或属性，现有的单继承机制就不能满足要求。与继承相比，接口有更高的灵活性，因为接口中没有任何实现代码。当一个类实现了接口以后，该类要实现接口里面所有的方法和属性，并且接口里面的属性在默认状态下面都是public static,所有方法默认情况下是public.一个类可以实现多个接口。 当一个对象被当作参数传递给一个方法后，此方法可改变这个对象的属性，并可返回变化后的结果，那么这里到底是值传递还是引用传递? 是值传递。Java 编程语言只有值传递参数。当一个对象实例作为一个参数被传递到方法中时，参数的值就是对该对象的引用。对象的内容可以在被调用的方法中改变，但对象的引用是永远不会改变的。 请你说说Static Nested Class 和 Inner Class的不同 Static Nested Class是被声明为静态（static）的内部类，它可以不依赖于外部类实例被实例化。而通常的内部类需要在外部类实例化后才能实例化。Static-Nested Class 的成员, 既可以定义为静态的(static), 也可以定义为动态的(instance).Nested Class的静态成员(Method)只能对Outer Class的静态成员(static memebr)进行操作(ACCESS), 而不能Access Outer Class的动态成员(instance member).而 Nested Class的动态成员(instance method) 却可以 Access Outer Class的所有成员, 这个概念很重要, 许多人对这个概念模糊. 有一个普通的原则, 因为静态方法(static method) 总是跟 CLASS 相关联(bind CLASS), 而动态方法( (instance method) 总是跟 instance object 相关联, 所以,静态方法(static method)永远不可以Access跟 object 相关的动态成员(instance member),反过来就可以, 一个CLASS的 instance object 可以 Access 这个 Class 的任何成员, 包括静态成员(static member). 请你讲讲abstract class和interface有什么区别?声明方法的存在而不去实现它的类被叫做抽象类（abstract class），它用于要创建一个体现某些基本行为的类，并为该类声明方法，但不能在该类中实现该类的情况。不能创建abstract 类的实例。然而可以创建一个变量，其类型是一个抽象类，并让它指向具体子类的一个实例。不能有抽象构造函数或抽象静态方法。Abstract 类的子类为它们父类中的所有抽象方法提供实现，否则它们也是抽象类为。取而代之，在子类中实现该方法。知道其行为的其它类可以在类中实现这些方法。 接口（interface）是抽象类的变体。在接口中，所有方法都是抽象的。多继承性可通过实现这样的接口而获得。接口中的所有方法都是抽象的，没有一个有程序体。接口只可以定义static final成员变量。接口的实现与子类相似，除了该实现类不能从接口定义中继承行为。当类实现特殊接口时，它定义（即将程序体给予）所有这种接口的方法。然后，它可以在实现了该接口的类的任何对象上调用接口的方法。由于有抽象类，它允许使用接口名作为引用变量的类型。通常的动态联编将生效。引用可以转换到接口类型或从接口类型转换，instanceof 运算符可以用来决定某对象的类是否实现了接口。 请说明Overload和Override的区别，Overloaded的方法是否可以改变返回值的类型? 方法的重写Overriding和重载Overloading是Java多态性的不同表现。重写Overriding是父类与子类之间多态性的一种表现，重载Overloading是一个类中多态性的一种表现。如果在子类中定义某方法与其父类有相同的名称和参数，我们说该方法被重写(Overriding)。子类的对象使用这个方法时，将调用子类中的定义，对它而言，父类中的定义如同被”屏蔽”了。如果在一个类中定义了多个同名的方法，它们或有不同的参数个数或有不同的参数类型，则称为方法的重载(Overloading)。Overloaded的方法是可以改变返回值的类型。 请说明一下final, finally, finalize的区别。final 用于声明属性，方法和类，分别表示属性不可变，方法不可覆盖，类不可继承。finally是异常处理语句结构的一部分，表示总是执行。finalize是Object类的一个方法，在垃圾收集器执行的时候会调用被回收对象的此方法，可以覆盖此方法提供垃圾收集时的其他资源回收，例如关闭文件等。 面向对象的特征有哪些方面抽象：抽象就是忽略一个主题中与当前目标无关的那些方面，以便更充分地注意与当前目标有关的方面。抽象并不打算了解全部问题，而只是选择其中的一部分，暂时不用部分细节。抽象包括两个方面，一是过程抽象，二是数据抽象。继承：继承是一种联结类的层次模型，并且允许和鼓励类的重用，它提供了一种明确表述共性的方法。对象的一个新类可以从现有的类中派生，这个过程称为类继承。新类继承了原始类的特性，新类称为原始类的派生类（子类），而原始类称为新类的基类（父类）。派生类可以从它的基类那里继承方法和实例变量，并且类可以修改或增加新的方法使之更适合特殊的需要。封装：封装是把过程和数据包围起来，对数据的访问只能通过已定义的界面。面向对象计算始于这个基本概念，即现实世界可以被描绘成一系列完全自治、封装的对象，这些对象通过一个受保护的接口访问其他对象。多态：多态性是指允许不同类的对象对同一消息作出响应。多态性包括参数化多态性和包含多态性。多态性语言具有灵活、抽象、行为共享、代码共享的优势，很好的解决了应用程序函数同名问题。 请说明Comparable和Comparator接口的作用以及它们的区别。 Java提供了只包含一个compareTo()方法的Comparable接口。这个方法可以个给两个对象排序。具体来说，它返回负数，0，正数来表明输入对象小于，等于，大于已经存在的对象。Java提供了包含compare()和equals()两个方法的Comparator接口。compare()方法用来给两个输入参数排序，返回负数，0，正数表明第一个参数是小于，等于，大于第二个参数。equals()方法需要一个对象作为参数，它用来决定输入参数是否和comparator相等。只有当输入参数也是一个comparator并且输入参数和当前comparator的排序结果是相同的时候，这个方法才返回true。 接口和抽象类的区别是什么？ Java提供和支持创建抽象类和接口。它们的实现有共同点，不同点在于：接口中所有的方法隐含的都是抽象的。而抽象类则可以同时包含抽象和非抽象的方法。类可以实现很多个接口，但是只能继承一个抽象类类可以不实现抽象类和接口声明的所有方法，当然，在这种情况下，类也必须得声明成是抽象的。抽象类可以在不提供接口方法实现的情况下实现接口。Java接口中声明的变量默认都是final的。抽象类可以包含非final的变量。Java接口中的成员函数默认是public的。抽象类的成员函数可以是private，protected或者是public。接口是绝对抽象的，不可以被实例化。抽象类也不可以被实例化，但是，如果它包含main方法的话是可以被调用的。也可以参考JDK8中抽象类和接口的区别 请说明Java是否支持多继承？ Java中类不支持多继承，只支持单继承（即一个类只有一个父类）。 但是java中的接口支持多继承，，即一个子接口可以有多个父接口。（接口的作用是用来扩展对象的功能，一个子接口继承多个父接口，说明子接口扩展了多个功能，当类实现接口时，类就扩展了相应的功能）。 如何通过反射创建对象？ 方法1：通过类对象调用newInstance()方法，例如：String.class.newInstance() 方法2：通过类对象的getConstructor()或getDeclaredConstructor()方法获得构造器（Constructor）对象并调用其newInstance()方法创建对象，例如：String.class.getConstructor(String.class).newInstance(“Hello”); 是否可以在static环境中访问非static变量？static变量在Java中是属于类的，它在所有的实例中的值是一样的。当类被Java虚拟机载入的时候，会对static变量进行初始化。如果你的代码尝试不用实例来访问非static的变量，编译器会报错，因为这些变量还没有被创建出来，还没有跟任何实例关联上。 extends 和super 泛型限定符（1）泛型中上界和下界的定义 上界&lt;? extend Fruit&gt; 下界&lt;? super Apple&gt; （2）上界和下界的特点 上界的list只能get，不能add（确切地说不能add出除null之外的对象，包括Object） 下界的list只能add，不能get （3）示例代码 12345678910111213141516171819202122232425import java.util.ArrayList;import java.util.List; class Fruit &#123;&#125;class Apple extends Fruit &#123;&#125;class Jonathan extends Apple &#123;&#125;class Orange extends Fruit &#123;&#125; public class CovariantArrays &#123; public static void main(String[] args) &#123; //上界 List&lt;? extends Fruit&gt; flistTop = new ArrayList&lt;Apple&gt;(); flistTop.add(null); //add Fruit对象会报错 //flist.add(new Fruit()); Fruit fruit1 = flistTop.get(0); //下界 List&lt;? super Apple&gt; flistBottem = new ArrayList&lt;Apple&gt;(); flistBottem.add(new Apple()); flistBottem.add(new Jonathan()); //get Apple对象会报错 //Apple apple = flistBottem.get(0); &#125;&#125; （4）上界&lt;? extend Fruit&gt; ，表示所有继承Fruit的子类，但是具体是哪个子类，无法确定，所以调用add的时候，要add什么类型，谁也不知道。但是get的时候，不管是什么子类，不管追溯多少辈，肯定有个父类是Fruit，所以，我都可以用最大的父类Fruit接着，也就是把所有的子类向上转型为Fruit。 下界&lt;? super Apple&gt;，表示Apple的所有父类，包括Fruit，一直可以追溯到老祖宗Object 。那么当我add的时候，我不能add Apple的父类，因为不能确定List里面存放的到底是哪个父类。但是我可以add Apple及其子类。因为不管我的子类是什么类型，它都可以向上转型为Apple及其所有的父类甚至转型为Object 。但是当我get的时候，Apple的父类这么多，我用什么接着呢，除了Object，其他的都接不住。 所以，归根结底可以用一句话表示，那就是编译器可以支持向上转型，但不支持向下转型。具体来讲，我可以把Apple对象赋值给Fruit的引用，但是如果把Fruit对象赋值给Apple的引用就必须得用cast。 什么是泛型？ 泛型，即“参数化类型”。一提到参数，最熟悉的就是定义方法时有形参，然后调用此方法时传递实参。那么参数化类型怎么理解呢？顾名思义，就是将类型由原来的具体的类型参数化，类似于方法中的变量参数，此时类型也定义成参数形式（可以称之为类型形参），然后在使用/调用时传入具体的类型（类型实参）。 123456789101112131415161718192021public class GenericTest &#123; public static void main(String[] args) &#123; /* List list = new ArrayList(); list.add(\"qqyumidi\"); list.add(\"corn\"); list.add(100); */ List&lt;String&gt; list = new ArrayList&lt;String&gt;(); list.add(\"qqyumidi\"); list.add(\"corn\"); //list.add(100); // 1 提示编译错误 for (int i = 0; i &lt; list.size(); i++) &#123; String name = list.get(i); // 2 System.out.println(\"name:\" + name); &#125; &#125; &#125; 采用泛型写法后，在//1处想加入一个Integer类型的对象时会出现编译错误，通过List，直接限定了list集合中只能含有String类型的元素，从而在//2处无须进行强制类型转换，因为此时，集合能够记住元素的类型信息，编译器已经能够确认它是String类型了。 静态变量存在什么位置方法区 解释类加载机制，双亲委派模型，好处是什么？某个特定的类加载器在接到加载类的请求时， 首先将加载任务委托给父类加载器，依次递归，如果父类加载器可以完成类加载任务，就成功返回；只有父类加载器无法完成此加载任务时，才自己去加载。 使用双亲委派模型的好处在于使用双亲委派模型的好处在于Java类随着它的类加载器一起具备了一种带有优先级的层次关系。例如类java.lang.Object，它存在在rt.jar中，无论哪一个类加载器要加载这个类，最终都是委派给处于模型最顶端的Bootstrap ClassLoader进行加载，因此Object类在程序的各种类加载器环境中都是同一个类。相反，如果没有双亲委派模型而是由各个类加载器自行加载的话，如果用户编写了一个java.lang.Object的同名类并放在ClassPath中，那系统中将会出现多个不同的Object类，程序将混乱。因此，如果开发者尝试编写一个与rt.jar类库中重名的Java类，可以正常编译，但是永远无法被加载运行。 双亲委派机制的意义主要是保护一些基本类不受影响。比如常用的 String类， 其全限定名是 java.lang.String， 只是 java.lang 这个包下的类在使用的时候，可以不用 import 而直接使用。像这种基本类 按照双亲委派机制 都应该从 rt.jar 里去获取，而不应该从自定义加载器里去获取某个开发人员自己写的 java.lang.String, 毕竟开发人员自己写的 java.lang.String 可能有很多 bug, 通过这种方式，无论如何大家使用的都是 rt.jar 里的 java.lang.String 类了。 请你谈谈StringBuffer和StringBuilder有什么区别，底层实现上呢？StringBuffer线程安全，StringBuilder线程不安全， 底层实现上的话，StringBuffer其实就是比StringBuilder多了Synchronized修饰符。 请说明String是否能能继承？ 不能，char数组用final修饰的。 说明”static”关键字是什么意思？Java中是否可以覆盖(override)一个private或者是static的方法？ “static”关键字表明一个成员变量或者是成员方法可以在没有所属的类的实例变量的情况下被访问。Java中static方法不能被覆盖，因为方法覆盖是基于运行时动态绑定的，而static方法是编译时静态绑定的。static方法跟类的任何实例都不相关，所以概念上不适用。 请说明重载和重写的区别，相同参数不同返回值能重载吗？重载(Overloading) （1） 方法重载是让类以统一的方式处理不同类型数据的一种手段。多个同名函数同时存在，具有不同的参数个数/类型。 重载Overloading是一个类中多态性的一种表现。 （2） Java的方法重载，就是在类中可以创建多个方法，它们具有相同的名字，但具有不同的参数和不同的定义。 调用方法时通过传递给它们的不同参数个数和参数类型来决定具体使用哪个方法, 这就是多态性。 （3） 重载的时候，方法名要一样，但是参数类型和个数不一样，返回值类型可以相同也可以不相同。无法以返回型别作为重载函数的区分标准。 重写（Overriding） （1） 父类与子类之间的多态性，对父类的函数进行重新定义。如果在子类中定义某方法与其父类有相同的名称和参数，我们说该方法被重写 (Overriding)。在Java中，子类可继承父类中的方法，而不需要重新编写相同的方法。 但有时子类并不想原封不动地继承父类的方法，而是想作一定的修改，这就需要采用方法的重写。 方法重写又称方法覆盖。 （2）若子类中的方法与父类中的某一方法具有相同的方法名、返回类型和参数表，则新方法将覆盖原有的方法。 如需父类中原有的方法，可使用super关键字，该关键字引用了当前类的父类。 （3）子类函数的访问修饰权限不能少于父类的。 请列举你所知道的Object类的方法并简要说明。Object()默认构造方法。 clone() 创建并返回此对象的一个副本。 equals(Object obj) 指示某个其他对象是否与此对象“相等”。 finalize()当垃圾回收器确定不存在对该对象的更多引用时，由对象的垃圾回收器调用此方法。 getClass()返回一个对象的运行时类。 hashCode()返回该对象的哈希码值。 notify()唤醒在此对象监视器上等待的单个线程。 notifyAll()唤醒在此对象监视器上等待的所有线程。 toString()返回该对象的字符串表示。 wait()导致当前的线程等待，直到其他线程调用此对象的 notify() 方法或 notifyAll() 方法。 wait(long timeout)导致当前的线程等待，直到其他线程调用此对象的 notify() 方法或 notifyAll() 方法，或者超过指定的时间量。 wait(long timeout, int nanos) 导致当前的线程等待，直到其他线程调用此对象的 notify() 方法或 notifyAll() 方法，或者其他某个线程中断当前线程，或者已超过某个实际时间量。 类和对象的区别1.类是对某一类事物的描述，是抽象的；而对象是一个实实在在的个体，是类的一个实例。 比如：“人”是一个类，而“教师”则是“人”的一个实例。 2.对象是函数、变量的集合体；而类是一组函数和变量的集合体，即类是一组具有相同属性的对象集合体。 String为什么不可变？不可变对象是指一个对象的状态在对象被创建之后就不再变化。不可改变的意思就是说：不能改变对象内的成员变量，包括基本数据类型的值不能改变，引用类型的变量不能指向其他的对象，引用类型指向的对象的状态也不能改变。 String 不可变是因为在 JDK 中 String 类被声明为一个 final 类，且类内部的 value 字节数组也是 final 的，只有当字符串是不可变时字符串池才有可能实现，字符串池的实现可以在运行时节约很多 heap 空间，因为不同的字符串变量都指向池中的同一个字符串；如果字符串是可变的则会引起很严重的安全问题，譬如数据库的用户名密码都是以字符串的形式传入来获得数据库的连接，或者在 socket 编程中主机名和端口都是以字符串的形式传入，因为字符串是不可变的，所以它的值是不可改变的，否则黑客们可以钻到空子改变字符串指向的对象的值造成安全漏洞；因为字符串是不可变的，所以是多线程安全的，同一个字符串实例可以被多个线程共享，这样便不用因为线程安全问题而使用同步，字符串自己便是线程安全的；因为字符串是不可变的所以在它创建的时候 hashcode 就被缓存了，不变性也保证了 hash 码的唯一性，不需要重新计算，这就使得字符串很适合作为 Map 的键，字符串的处理速度要快过其它的键对象，这就是 HashMap 中的键往往都使用字符串的原因。 请讲讲Java有哪些特性，并举一个和多态有关的例子。 封装、继承、多态。多态：指允许不同类的对象对同一消息做出响应。即同一消息可以根据发送对象的不同而采用多种不同的行为方式。（发送消息就是函数调用） 请你讲讲wait方法的底层原理ObjectSynchronizer::wait方法通过object的对象中找到ObjectMonitor对象调用方法 void ObjectMonitor::wait(jlong millis, bool interruptible, TRAPS) 通过ObjectMonitor::AddWaiter调用把新建立的ObjectWaiter对象放入到 _WaitSet 的队列的末尾中然后在ObjectMonitor::exit释放锁，接着 thread_ParkEvent-&gt;park 也就是wait。","categories":[],"tags":[{"name":"Interview","slug":"Interview","permalink":"https://kayleh.top/tags/Interview/"}]},{"title":"Linux","slug":"Linux","date":"2020-07-02T13:26:15.000Z","updated":"2020-07-27T08:44:52.070Z","comments":true,"path":"2020/07/02/Linux/","link":"","permalink":"https://kayleh.top/2020/07/02/Linux/","excerpt":"虚拟机","text":"虚拟机 下载中文支持 网络连接的三种形式 桥连接：Linux可以和其他系统通信，但是会造成IP冲突 NAT：网络地址转换方式，Linux可以访问外网，不会造成IP冲突 主机模式：你的Linux是一个独立的主机，不能访问外网 分区： boot分区：200M swap分区：交换分区，虚拟内存，没有挂载点，2048M 根分区/：使用全部剩余空间 安装VMTool复制到/opt下 tar -zxvf VM…… .tar.gz 解压,进去文件夹，执行 /vmware-install.pl 设置共享文件夹，在/mnt/hgfs下 Linux文件系统采用的是级层式的树状结构，最上层的是根目录“/”。 /bin 是Binary的缩写，这个目录存放着最经常使用的命令 /dev 管理设备 /etc管理配置文件 /home 存放普通用户的主目录，在Linux中每个用户都有一个自己的目录，一般该目录名是以用户的账号命名的 /lib 系统开机需要 /media dvd相关 /mnt 挂载文件夹 /opt 安装的软件 /proc 内核 /root 系统管理员，超级权限者的用户主目录 /sbin Super user系统管理员使用的系统管理程序 /selinux 安全加强 /sys 系统 /tmp 临时文件 /usr 用户，安装的程序 /var 变量，日志 远程登陆XShell 需要Linux开启一个sshd服务22 终端打开setup，打开系统服务，找到sshd，空格键打开服务。tab键退出。 该服务会监听22端口。 ubuntu方法： 先试着开启SSH服务 在使用SSH之前，可以先检查SSH服务有没有开启。使用命令：sudo ps -e | grep ssh来查看，如果返回的结果是“xxxx? 00:00:00 sshd”,代表服务开启。那个四个x代表四位数字，每台机数字不一样的，如图： 如果没有反应或者其他结果，再试着开启SSH服务。使用命令sudo /etc/init.d/ssh start来开启服务，如图： 如果是图中结果，说明没有安装SSH服务，此时需要安装 SSH服务，为了能提高安装成功率，建议先更新源：sudo apt-get update更新安装源，如图： 然后安装SSH服务，使用命令：sudo apt-get install openssh-server。如图： 等待安装结束即可。然后再次查看服务有没有启动：sudo ps -e | grep ssh： 有sshd那个东西，说明服务启动了，如果需要再次确认或者没有图中的结果，使用命令来启动:sudo /etc/init.d/ssh start: 看到服务starting了，服务成功开启。另外，还有几条命令需要记住： sudo service ssh status 查看服务状态： sudo service ssh stop 关闭服务： sudo service ssh restart 重启服务 Xshell新建会话，先查看linux的ip地址。 1ipconfig 箭头指向的是ip地址。 填写到xshell Ubuntu需要配置sshd服务 输入Linux的用户名和密码。成功连接。 如果远程使用命令： 1reboot 服务器也会重启 文件的上传下载XFTP协议选择SFTP 端口号选择22 乱码解决： 选择要传输的文件，右键传输就可以了。 Vi和Vim编辑器 正常模式在正常模式下，我们可以使用快捷键。 以 vim 打开一个档案就直接进入一般模式了(这是默认的模式)。在这个模式中， 你可以使用『上下左右』按键来移动光标，你可以使用『删除字符』或『删除整行』来处理档案内容， 也可以使用『复制、贴上』来处理你的文件数据。 插入模式/编辑模式在模式下，程序员可以输入内容。 按下 i, I 等任何一个字母之后才会进入编辑模式, 一般来说按 i 即可 命令行模式在这个模式当中， 可以提供你相关指令，完成读取、存盘、替换、离开 vim 、显示行号等的动作则是在此模式中达成的！ 各模式之间的互相转换 快捷键的使用案例1) 拷贝当前行 yy , 拷贝当前行向下的 5 行 5yy，并粘贴（p）。 2) 删除当前行 dd , 删除当前行向下的 5 行 5dd 3) 在文件中查找某个单词 [命令行下 /关键字 ， 回车 查找 , 输入 n 就是查找下一个 ],查询 hello. 4) 设置文件的行号，取消文件的行号.[命令行下 : set nu 和 :set nonu] 5) 编辑 /etc/profile 文件，使用快捷键到底文档的最末行[G]和最首行[gg],注意这些都是在正常模式下执行的。 6) 在一个文件中输入 “hello” ,然后又撤销这个动作，再正常模式下输入 u 7) 编辑 /etc/profile 文件，并将光标移动到 第 20 行 shift+g 第一步：显示行号 :set nu 第二步：输入 20 这个数 第三步: 输入 shift+g 关机&amp;重启命令基本介绍shutdown shutdown -h now : 表示立即关机 shutdown -h 1 : 表示 1 分钟后关机 shutdown -r now: 立即重启 halt 就是直接使用，效果等价于关机 reboot 就是重启系统。 sync： 把内存的数据同步到磁盘 注意细节当我们关机或者重启时，都应该先执行以下 sync 指令，把内存的数据写入磁盘，防止数据丢失。 用户登录和注销1) 登录时尽量少用 root 帐号登录，因为它是系统管理员，最大的权限，避免操作失误。可以利用普通用户登录，登录后再用”su - 用户名’命令来切换成系统管理员身份. 2) 在提示符下输入 logout 即可注销用户 使用细节1)logout 注销指令在图形运行级别无效，在 运行级别 3 下有效. 用户管理 说明 Linux 系统是一个多用户多任务的操作系统，任何一个要使用系统资源的用户，都必须首先向系统管理员申请一个账号 添加用户基本语法useradd [选项] 用户名 1) 当创建用户成功后，会自动的创建和用户同名的家目录 2) 也可以通过 useradd -d 指定目录 新的用户名，给新创建的用户指定家目录 设置密码基本语法 passwd 用户名 删除用户基本语法userdel 用户名 1) 删除用户 xm，但是要保留家目录 1userdel xm 2) 删除用户 xh 以及用户主目录 1userdel xh -r 在删除用户时，我们一般不会将家目录删除。 查询用户信息基本语法12345id 用户名uid=0(root) gid=0(root) 组=0(root) | | | V V V用户id号 所在组的id号 组名 切换用户在操作 Linux 中，如果当前用户的权限不够，可以通过 su - 指令，切换到高权限用户，比如 root 基本语法 123su – 切换用户名//高权限用户向低权限用户不需要密码exit //可以回到原来的用户 1)从权限高的用户切换到权限低的用户，不需要输入密码，反之需要。 2)当需要返回到原来用户时，使用 exit 指令 1whoami &#x2F;&#x2F;查看当前用户 用户组类似于角色，系统可以对有共性的多个用户进行统一的管理。 增加组 groupadd 组 名 删除组 groupdel 组 名 增加用户时直接加上组 useradd -g 用户组 用户名 修改用户的组 usermod -g 用户组 用户名 用户和组的相关文件/etc/passwd 文件 用户（user）的配置文件，记录用户的各种信息 每行的含义： 用户名 : 口令 : 用户标识号 : 组标识号 : 注释性描述 : 主目录 : 登录 Shell /etc/shadow 文件 口令的配置文件每行的含义： 登录名 : 加密口令 : 最后一次修改时间 : 最小时间间隔 : 最大时间间隔 : 警告时间 : 不活动时间 : 失效时间 : 标志 /etc/group 文件组(group)的配置文件，记录 Linux 包含的组的信息每行含义： 组名:口令:组标识号:组内用户列表 运行级别运行级别说明：0：关机1：单用户【找回丢失密码】2：多用户状态没有网络服务3：多用户状态有网络服务4：系统未使用保留给用户5：图形界面6：系统重启 常用运行级别是 3 和 5 ，要修改默认的运行级别可改文件 /etc/inittab 的 id:5:initdefault: 这一行中的数字 指定运行级别 init [012356] int 3 init [012356] 如何找回 root 密码进入到 单用户模式，然后修改 root 密码。因为进入单用户模式，root 不需要密码就可以登录。 开机在引导期间使用enter进入页面，按e进入选择第二行的内核kenral再按e进入，输入1告诉内核进入单用户模式，再按回车回去上一级按b启动。 启动后使用passwd root就可以重置密码了。reboot重启。 获得帮助信息manman [命令或配置文件]（功能描述：获得帮助信息） man ls help 指令help 命令 （功能描述：获得 shell 内置命令的帮助信息） help cd 文件目录类pwd 指令pwd (功能描述：显示当前工作目录的绝对路径) ls 指令ls [ 选 项] [目录或是文件] cd 指令cd .当前目录(不变) cd [参数] (功能描述：切换到指定目录) cd ~ 或者 cd ：回到自己的家目录 cd .. 回到当前目录的上一级目录 cd /root 使用绝对路径切换到 root 目录 cd ../../root 使用相对路径到/root 目录 mkdir 指令mkdir 指令用于创建目录(make directory) mkdir [选项] 要创建的目录 -p ：创建多级目录 1mkdir -p &#x2F;aaa&#x2F;bbb&#x2F;ccc rmdir 指令rmdir 指令删除空目录 rmdir [选项] 要删除的空目录 rmdir删除的是空目录，如果目录下有内容时无法删除的。提示：如果需要删除非空目录，需要使用rm -rf要删除的目录 touch 指令touch 指令创建空文件 touch 文件名称 cp 指令[*]cp 指令拷贝文件到指定目录 cp [选项] source dest -r ：递归复制整个文件夹 cp -r 源目录 目标目录 rm 指令rm 指令移除【删除】文件或目录 rm [选项] 要删除的文件或目录 -r ：递归删除整个文件夹 -f ： 强制删除不提示 mv 指令mv 移动文件与目录或重命名 mv oldNameFile newNameFile (功能描述：重命名) mv /temp/movefile /targetFolder (功能描述：移动文件) cat 指令cat 查看文件内容，是以只读的方式打开。 cat [选项] 要查看的文件 -n ：显示行号 cat 只能浏览文件，而不能修改文件，为了浏览方便，一般会带上 管道命令 | more cat 文件名 | more [分页浏览] more 指令more 指令是一个基于 VI 编辑器的文本过滤器，它以全屏幕的方式按页显示文本文件的内容 快捷键： less 指令less 指令用来分屏查看文件内容，它的功能与 more 指令类似，但是比 more 指令更加强大，支持各种显示终端。less 指令在显示文件内容时，并不是一次将整个文件加载之后才显示，而是根据显示需要加载内容，对于显示大型文件具有较高的效率。 1less 要查看的文件 &gt; 指令 和 &gt;&gt; 指令&gt; 输出重定向 : 会将原来的文件的内容覆盖 &gt;&gt; 追加： 不会覆盖原来文件的内容，而是追加到文件的尾部。 1234ls -l &gt;文件 （功能描述：列表的内容写入文件 a.txt 中（覆盖写））ls -al &gt;&gt;文件 （功能描述：列表的内容追加到文件 aa.txt 的末尾）cat 文件 1 &gt; 文件 2 （功能描述：将文件 1 的内容覆盖到文件 2）cal &gt;&gt; &#x2F;home&#x2F;mycal 将当前日历信息 追加到 &#x2F;home&#x2F;mycal 文件中 [提示 cal ] echo 指令echo 输出内容到控制台。 echo [选项] [输出内容] 1echo $PATH 使用 echo 指令输出环境变量,输出当前的环境路径。 head 指令head 用于显示文件的开头部分内容，默认情况下 head 指令显示文件的前 10 行内容 12head 文件 (功能描述：查看文件头 10 行内容)head -n 5 文件 (功能描述：查看文件头 5 行内容，5 可以是任意行数) tail 指令tail 用于输出文件中尾部的内容，默认情况下 tail 指令显示文件的后 10 行内容。 123tail 文件 （功能描述：查看文件后 10 行内容）tail -n 5 文件 （功能描述：查看文件后 5 行内容，5 可以是任意行数）tail -f 文件 （功能描述：实时追踪该文档的所有更新，工作经常使用） ln 指令软链接也叫符号链接，类似于 windows 里的快捷方式，主要存放了链接其他文件的路径 12345ln -s [原文件或目录] [软链接名] （功能描述：给原文件创建一个软链接）ln -s &#x2F;root linkToRoot 在&#x2F;home 目录下创建一个软连接 linkToRoot，连接到 &#x2F;root 目录rm -rf linkToRoot 删除软连接ln 硬链接 ##软链接可以跨文件系统，硬链接不可以；软链接可以对一个不存在的文件名（filename）进行链接（当然此时如果你vi这个软链接文件，linux会自动新建一个文件名为filename的文件），硬链接不可以（其文件必须存在，inode必须存在）；软链接可以对目录进行连接，硬链接不可以。两种链接都可以通过命令 ln 来创建。ln 默认创建的是硬链接。使用 -s 开关可以创建软链接。 当我们使用 pwd 指令查看目录时，仍然看到的是软链接所在目录。 history 指令查看已经执行过历史命令,也可以执行历史指令 123history （功能描述：查看已经执行过历史命令）history 10 显示最近使用过的 10 个指令。!10 执行编号为10的指令 时间日期类date 指令-显示当前日期123451) date （功能描述：显示当前时间）2) date +%Y （功能描述：显示当前年份）3) date +%m （功能描述：显示当前月份）4) date +%d （功能描述：显示当前是哪一天）5) date &quot;+%Y-%m-%d %H:%M:%S&quot;（功能描述：显示年月日时分秒） date 指令-设置日期1234date -s 字符串时间设置系统当前时间 ， 比如设置成 2018-10-10 11:22:22date -s &quot;2018-10-10 11:22:22&quot; 查看日历指令123cal [选项] （功能描述：不加选项，显示本月日历）calcal 2021 搜索查找类find 指令find 指令将从指定目录向下递归地遍历其各个子目录，将满足条件的文件或者目录显示在终端 find [搜索范围] [选项] 123456789101112按文件名：根据名称查找&#x2F;home 目录下的 hello.txt 文件find &#x2F;home -name hello.txt按拥有者：查找&#x2F;opt 目录下，用户名称为 nobody 的文件find &#x2F;opt -user nobody查找整个 linux 系统下大于 20m 的文件（+n 大于 -n 小于 n 等于）find &#x2F; -size +20Mfind &#x2F; -size +20480K查询 &#x2F; 目录下，所有 .txt 的文件find &#x2F; -name *.txt locate 指令locaate 指令可以快速定位文件路径。locate 指令利用事先建立的系统中所有文件名称及路径的locate 数据库实现快速定位给定的文件。Locate 指令无需遍历整个文件系统，查询速度较快。为了保证查询结果的准确度，管理员必须定期更新 locate 时刻。 12updatedb locate 搜索文件 由于 locate 指令基于数据库进行查询，所以第一次运行前，必须使用 updatedb 指令创建 locate 数据库。 grep 指令和 管道符号 |grep 过滤查找 ， 管道符，“|”，表示将前一个命令的处理结果输出传递给后面的命令处理。 1grep [选项] 查找内容 源文件 -n 显示匹配行及行号 -i 忽略字母大小写 12请在 hello.txt 文件中，查找 &quot;yes&quot; 所在行，并且显示行号cat hello.txt | grep -n yes 压缩和解压类gzip/gunzip 指令gzip 用于压缩文件， gunzip 用于解压的 gzip 文件 （功能描述：压缩文件，只能将文件压缩为*.gz 文件） gunzip 文 件.gz （功能描述：解压缩文件命令） 12345gzip 压缩， 将 &#x2F;home 下的 hello.txt 文件进行压缩gzip hello.txtgunzip 压缩， 将 &#x2F;home 下的 hello.txt.gz 文件进行解压缩gunzip hello.txt.gz 当我们使用 gzip 对文件进行压缩后，不会保留原来的文件。 zip/unzip 指令zip 用于压缩文件， unzip 用于解压的，这个在项目打包发布中很有用的 12zip [选项] XXX.zip 将要压缩的内容（功能描述：压缩文件和目录的命令）unzip [选项] XXX.zip （功能描述：解压缩文件） zip -r：递归压缩，即压缩目录 unzip -d&lt;目录&gt; ：指定解压后文件的存放目录 12345将 /home 下的 所有文件进行压缩成 mypackage.zipzip -r mypackage.zip /home/将 mypackge.zip 解压到 /opt/tmp 目录下unzip -d /opt/tmp/ mypackage.zip tar 指令tar 指令 是打包指令，最后打包后的文件是 .tar.gz 的文件。 1tar [选项] XXX.tar.gz 打包的内容 (功能描述：打包目录，压缩后的文件格式.tar.gz) 123456789101112压缩多个文件，将 /home/a1.txt 和 /home/a2.txt 压缩成 a.tar.gztar -zcvf a.tar.gz a1.txt a2.txt将/home 的文件夹 压缩成 myhome.tar.gztar -zcvf myhome.tar.gz /home/将 a.tar.gz 解压到当前目录tar -zxvf a.tar.gz将 myhome.tar.gz 解压到 /opt/ 目录下#指定解压到的那个目录，事先要存在才能成功，否则会报错。tar -zxvf myhome.tar.gz -C /opt/ 组管理和权限管理Linux 组基本介绍在 linux 中的每个用户必须属于一个组，不能独立于组外。在 linux 中每个文件有所有者、所在组、其它组的概念。 1) 所有者2) 所在组3) 其它组4) 改变用户所在的组 文件/目录 所有者一般为文件的创建者,谁创建了该文件，就自然的成为该文件的所有者。 查看文件的所有者指令：ls -ahl 创建一个组 police,再创建一个用户 tom,将 tom 放在 police 组 ,然后使用 tom 来创建一个文件 ok.txt 所有者👆 修改文件所有者指令：chown 用户名 文件名 使用 root 创建一个文件 apple.txt ，然后将其所有者修改成 tom 组的创建groupadd 组 名 创建一个组, ,monster 创建一个用户 fox ，并放入到 monster 组中 123groupadd monsteruseradd -g monster foxid fox &#x2F;&#x2F;查看 文件/目录 所在组当某个用户创建了一个文件后，默认这个文件的所在组就是该用户所在的组。 查看文件/目录所在组ls –ahl 修改文件所在的组chgrp 组名 文件名 使用 root 用户创建文件 orange.txt ,看看当前这个文件属于哪个组，然后将这个文件所在组，修改到 police 组 。 其它组除文件的所有者和所在组的用户外，系统的其它用户都是文件的其它组. 改变用户所在组在添加用户时，可以指定将该用户添加到哪个组中，同样的用 root 的管理权限可以改变某个用户所在的组。 12usermod –g 组名 用户名usermod –d 目录名 用户名 改变该用户 创建一个土匪组（bandit）将 tom 这个用户从原来所在的 police 组，修改到 bandit(土匪) 组 权限的基本介绍ls -l 中显示的内容如下： 1-rwxrw-r-- 1 root root 1213 Feb 2 09:39 abc 0-9 位说明 1)第 0 位确定文件类型(d, - , l , c , b) 2)第 1-3 位确定所有者（该文件的所有者）拥有该文件的权限。—User 3)第 4-6 位确定所属组（同用户组的）拥有该文件的权限，—Group 4)第 7-9 位确定其他用户拥有该文件的权限 —Other rwx权限详解rwx作用到文件1) [ r ]代表可读(read): 可以读取,查看 2) [ w ]代表可写(write): 可以修改,但是不代表可以删除该文件,删除一个文件的前提条件是对该文件所在的目录有写权限，才能删除该文件. 3) [ x ]代表可执行(execute):可以被执行 rwx作用到目录1) [ r ]代表可读(read): 可以读取，ls 查看目录内容 2) [ w ]代表可写(write): 可以修改,目录内创建+删除+重命名目录 3) [ x ]代表可执行(execute):可以进入该目录 文件及目录权限实际案例ls -l 中显示的内容如下： -rwxrw-r– 1 root root 1213 Feb 2 09:39 abc 10 个字符确定不同用户能对文件干什么 第一个字符代表文件类型： 文件 (-),目录(d),链接(l)其余字符每 3 个一组(rwx) 读(r) 写(w) 执行(x)第一组 rwx : 文件拥有者的权限是读、写和执行第二组 rw- : 与文件拥有者同一组的用户的权限是读、写但不能执行 第三组 r– : 不与文件拥有者同组的其他用户的权限是读不能写和执行 可用数字表示为: r=4,w=2,x=1 因此 rwx=4+2+1=7 1 文件：硬连接数或 目录：子目录数 root 用户 root 组 1213 文件大小(字节)，如果是文件夹，显示 4096 字节 Feb 2 09:39 最后修改日期 abc 文件名 ​ 修改权限-chmod通过 chmod 指令，可以修改文件或者目录的权限 第一种方式：+ 、-、= 变更权限u:所有者 g:所有组 o:其他人 a:所有人(u、g、o 的总和) 1) chmod u=rwx,g=rx,o=x 文件目录名 2) chmod o+w 文件目录名 3) chmod a-x 文件目录名 给 abc 文件 的所有者读写执行的权限，给所在组读执行权限，给其它组读执行权限。 给 abc 文件的所有者除去执行的权限，增加组写的权限 给 abc 文件的所有用户添加读的权限 第二种方式：通过数字变更权限规则：r=4 w=2 x=1,rwx=4+2+1=7 chmod u=rwx,g=rx,o=x 文件目录名 相当于 chmod 751 文件目录名 将 /home/abc.txt 文件的权限修改成 rwxr-xr-x, 使用给数字的方式实现： rwx = 4+2+1 = 7 r-x = 4+1=5 r-x = 4+1 =5 指令：chmod 755 /home/abc.txt 修改文件所有者-chownchown newowner file 改变文件的所有者 chown newowner:newgroup file 改变用户的所有者和所有组 -R 如果是目录 则使其下所有子文件或目录递归生效 请将 /home/abc .txt 文件的所有者修改成 tom 请将 /home/kkk 目录下所有的文件和目录的所有者都修改成 tom 首选我们应该使用 root 操作。 修改文件所在组-chgrpchgrp newgroup file 改变文件的所有组 1) 请将 /home/abc .txt 文件的所在组修改成 bandit (土匪) 1chgrp bandit /home/abc.txt 2) 请将 /home/kkk 目录下所有的文件和目录的所在组都修改成 bandit(土匪) 1chgrp -R bandit &#x2F;home&#x2F;kkk 最佳实践-警察和土匪游戏police警察 bandit土匪 jack, jerry: 警 察 xh, xq: 土 匪 (1) 创建组 bash&gt; groupadd police bash&gt; groupadd bandit (2) 创建用户 (3) jack 创建一个文件，自己可以读写，本组人可以读，其它组没人任何权限 (4) jack 修改该文件，让其它组人可以读, 本组人可以读写 (5) xh 投靠 警察，看看是否可以读写. 先用 root 修改 xh 的组 ： 使用 jack 给他的家目录 /home/jack 的所在组一个 rx 的权限 xh 需要重新注销在到 jack 目录就可以操作 jack 的文件 crond 任务调度原理 crontab 进行 定时任务的设置 任务调度：是指系统在某个时间执行的特定的命令或程序。 任务调度分类： 1.系统工作：有些重要的工作必须周而复始地执行。如病毒扫描等 2.个别用户工作：个别用户可能希望执行某些程序，比如对 mysql 数据库的备份。 基本语法1crontab [选项] 要求设置任务调度文件：/etc/crontab 设置个人任务调度。执行 crontab –e 命令。 接着输入任务到调度文件 如：*/1 * * * * ls –l /etc/ &gt; /tmp/to.txt 意思说每小时的每分钟执行 ls –l /etc/ &gt; /tmp/to.txt 命令 步骤如下1) cron -e 2) */ 1 * * * * ls -l /etc &gt;&gt; /tmp/to.txt 3) 当保存退出后就程序。 4) 在每一分钟都会自动的调用 ls -l /etc &gt;&gt; /tmp/to.txt 参数细节说明 案例 1：每隔 1 分钟，就将当前的日期信息，追加到 /tmp/mydate 文件中1) 先编写一个文件 /home/mytask1.sh date &gt;&gt; /tmp/mydate 2) 给 mytask1.sh 一个可以执行权限 chmod 744 /home/mytask1.sh 3) crontab -e 4) */1 * * * * /home/mytask1.sh 5) 成功 案例 2：每隔 1 分钟， 将当前日期和日历都追加到 /home/mycal 文件中1) 先编写一个文件 /home/mytask2.sh date &gt;&gt; /tmp/mycal cal &gt;&gt; /tmp/mycal 2) 给 mytask1.sh 一个可以执行权限 chmod 744 /home/mytask2.sh 3) crontab -e 4) */1 * * * * /home/mytask2.sh 5) 成功 案例 3: 每天凌晨 2:00 将 mysql 数据库 testdb ，备份到文件中mydb.bak。1) 先编写一个文件 /home/mytask3.sh /usr/local/mysql/bin/mysqldump -u root -proot testdb &gt; /tmp/mydb.bak 2) 给 mytask3.sh 一个可以执行权限 1chmod 744 &#x2F;home&#x2F;mytask3.sh 3) 1crontab -e 4) 10 2 * * * &#x2F;home&#x2F;mytask3.sh 5) 成功 crond 相关指令:1) conrtab –r：终止任务调度。 2) crontab –l：列出当前有那些任务调度 3) service crond restart [重启任务调度] Linux 磁盘分区、挂载分区基础知识windows 下的磁盘分区 分区的方式：1) mbr 分区: 1.最多支持四个主分区 2.系统只能安装在主分区 3.扩展分区要占一个主分区 4.MBR 最大只支持 2TB，但拥有最好的兼容性 2) gtp 分区: 1.支持无限多个主分区（但操作系统可能限制，比如 windows 下最多 128 个分区） 2.最大支持 18EB 的大容量（1EB=1024 PB，1PB=1024 TB ） 3.windows7 64 位以后支持 windows 下的磁盘分区 Linux 分区原理介绍1)Linux 来说无论有几个分区，分给哪一目录使用，它归根结底就只有一个根目录，一个独立且唯一的文件结构 , Linux 中每个分区都是用来组成整个文件系统的一部分。 2)Linux 采用了一种叫“载入”的处理方法，它的整个文件系统中包含了一整套的文件和目录， 且将一个分区和一个目录联系起来。这时要载入的一个分区将使它的存储空间在一个目录下获得。 硬盘说明1)Linux 硬盘分 IDE 硬盘和 SCSI 硬盘，目前基本上是 SCSI 硬盘 2)对于 IDE 硬盘，驱动器标识符为“hdx”,其中“hd”表明分区所在设备的类型，这里是指 IDE 硬盘了。“x”为盘号（a 为基本盘，b 为基本从属盘，c 为辅助主盘，d 为辅助从属盘）,“”代表分区，前四个分区用数字 1 到 4 表示，它们是主分区或扩展分区，从 5 开始就是逻辑分区。例，hda3 表示为第一个 IDE 硬盘上的第三个主分区或扩展分区,hdb2 表示为第二个 IDE 硬盘上的第二个主分区或扩展分区。 3)对于 SCSI 硬盘则标识为“sdx~”，SCSI 硬盘是用“sd”来表示分区所在设备的类型的，其余则和 IDE 硬盘的表示方法一样 . 使用 lsblk 指令查看当前系统的分区情况 挂载的经典案例需求是给我们的 Linux 系统增加一个新的硬盘，并且挂载到/home/newdisk 如何增加一块硬盘1)虚拟机添加硬盘 2)分区 fdisk /dev/sdb 3)格式化 mkfs -t ext4 /dev/sdb1 4)挂载 先创建一个 /home/newdisk , 挂 载 mount /dev/sdb1 /home/newdisk 5)设置可以自动挂载(永久挂载，当你重启系统，仍然可以挂载到 /home/newdisk) 。 vim /etc/fstab /dev/sdb1 /home/newdisk ext4 defaults 0 0 具体的操作步骤整理虚拟机增加硬盘步骤 1在【虚拟机】菜单中，选择【设置】，然后设备列表里添加硬盘，然后一路【下一步】，中间只有选择磁盘大小的地方需要修改，至到完成。然后重启系统（才能识别）！ 重启虚拟机reboot 重启后使用 lsblk -f 可以看见多了个sdb 虚拟机增加硬盘步骤 2使用分区命令 1fdisk &#x2F;dev&#x2F;sdb 开始对/sdb 分区 输入m可以看到帮助 m 显示命令列表 p 显示磁盘分区 同 fdisk –l n 新增分区 d 删除分区 w 写入并退出 12345输入n显示 e extended p primary partition(1-4)选择p 说明： 开始分区后输入 n，新增分区，然后选择 p ，分区类型为主分区。两次回车默认剩余全部空间。最后输入 w 写入分区并退出，若不保存退出输入 q。 虚拟机增加硬盘步骤 3格式化磁盘 分区命令: 1mkfs -t ext4 &#x2F;dev&#x2F;sdb1 其中 ext4 是分区类型 虚拟机增加硬盘步骤 4挂载: 将一个分区与一个目录联系起来， •mount 设备名称 挂载目录 •例如： mount /dev/sdb1 /home/newdisk •umount 设备名称 或者 挂载目录 •例如： umount /dev/sdb1 或者 umount /newdisk 虚拟机增加硬盘步骤 5vim /etc/fstab 在UUID上面一行插入 1/dev/sdb1 /home/newdisk ext4 defaults 0 0 这句话可以使开机后能自动挂载 使用命令mount -a立即生效 永久挂载通过修改实现挂载添加完成后 执行 –即刻生效 磁盘情况查询查询系统整体磁盘使用情况1df -h 查询指定目录的磁盘占用情况1du -h &#x2F;目录 查询指定目录的磁盘占用情况，默认为当前目录 123456789-s 指定目录占用大小汇总-h 带计量单位-a 含文件--max-depth&#x3D;1 子目录深度-c 列出明细的同时，增加汇总值 查询 /opt 目录的磁盘占用情况，深度为 1 磁盘情况-工作实用指令1) 统计/home 文件夹下文件的个数 1^- 表示以&quot;-&quot;打头的，表示文件 2) 统计/home 文件夹下目录的个数 3)统计计/home 文件夹下文件的个数，包括子文件夹里的 4) 统计文件夹下目录的个数，包括子文件夹里的 5)以树状显示目录结构 网络配置Linux 网络配置原理图(含虚拟机) 目前我们的网络配置采用的是 NAT。 查看网络 IP 和网关查看虚拟网络编辑器 修改 ip 地址(修改虚拟网络的 ip) 查看网关 查看 windows 环境的中 VMnet8 网络配置 (ipconfig 指令)1) 使用 ipconfig 查看 2) 界面查看 ping 测试主机之间网络连通ping 目的主机 （功能描述：测试当前服务器是否可以连接目的主机） 测试当前服务器是否可以连接百度 [root@hadoop100 桌面]# ping www.baidu.com linux 网络环境配置第一种方法(自动获取) 缺点: linux 启动后会自动获取 IP,缺点是每次自动获取的 ip 地址可能不一样。这个不适用于做服务器，因为我们的服务器的 ip 需要时固定的。 第二种方法(指定固定的 ip) 直 接 修 改 配 置 文 件 来 指 定 IP, 并 可 以 连 接 到 外 网 ( 程 序 员 推 荐 ) ， 编 辑 vi /etc/sysconfig/network-scripts/ifcfg-eth0 要求：将 ip 地址配置的静态的，ip 地址为 192.168.184.130 修改后，一定要 重启服务 1) service network restart 2) reboot 重启系统 进程管理进程的基本介绍 1)在 LINUX 中，每个执行的程序（代码）都称为一个进程。每一个进程都分配一个 ID 号。 2)每一个进程，都会对应一个父进程，而这个父进程可以复制多个子进程。例如 www 服务器。 3)每个进程都可能以两种方式存在的。前台与后台，所谓前台进程就是用户目前的屏幕上可以进行操作的。后台进程则是实际在操作，但由于屏幕上无法看到的进程，通常使用后台方式执行。 4)一般系统的服务都是以后台进程的方式存在，而且都会常驻在系统中。直到关机才才结束。 显示系统执行的进程查看进行使用的指令是 ps ,一般来说使用的参数是 ps -aux ps 指令详解1)指令：ps –aux|grep xxx ，比如我看看有没有 sshd 服务 指令说明 • System V 展示风格 • USER：用户名称 • PID：进程号 • %CPU：进程占用 CPU 的百分比 • %MEM：进程占用物理内存的百分比 • VSZ：进程占用的虚拟内存大小（单位：KB） • RSS：进程占用的物理内存大小（单位：KB） • TT：终端名称,缩写 . • STAT：进程状态，其中 S-睡眠，s-表示该进程是会话的先导进程，N-表示进程拥有比普通优先级更低的优先级，R-正在运行，D-短期等待，Z-僵死进程，T-被跟踪或者被停止等等 • STARTED：进程的启动时间 • TIME：CPU 时间，即进程使用 CPU 的总时间 • COMMAND：启动进程所用的命令和参数，如果过长会被截断显示 要求：以全格式显示当前所有的进程，查看进程的父进程。 • ps -ef 是以全格式显示当前所有的进程 • -e 显示所有进程。-f 全格式。 ​ • ps -ef|grep xxx ​ • 是 BSD 风格 ​ • UID：用户 ID ​ • PID：进程 ID ​ • PPID：父进程 ID ​ • C：CPU 用于计算执行优先级的因子。数值越大，表明进程是 CPU 密集型运算，执行优先级会降低；数值越小，表明进程是 I/O 密集型运算，执行优先级会提高 ​ • STIME：进程启动的时间 ​ • TTY：完整的终端名称 ​ • TIME：CPU 时间 ​ • CMD：启动进程所用的命令和参数 如果我们希望查看 sshd 进程的父进程号是多少，应该怎样查询 ？ 可以看到是1. 终止进程 kill 和 killall若是某个进程执行一半需要停止时，或是已消了很大的系统资源时，此时可以考虑停止该进程。使用 kill 命令来完成此项任务。 123kill [选项] 进程号（功能描述：通过进程号杀死进程）killall 进程名称（功能描述：通过进程名称杀死进程，也支持通配符，这在系统因负载过大而变得很慢时很有用） 选项: -9 :表示强迫进程立即停止 踢掉某个非法登录用户 xshell用jack登录 终止远程登录服务 sshd, 在适当时候再次重启 sshd 服务 终止多个 gedit 编辑器 【killall , 通过进程名称来终止进程】 强制杀掉一个终端 查看进程树 pstree1pstree [选项] ,可以更加直观的来看进程信息 -p :显示进程的 PID -u :显示进程的所属用户 树状的形式显示进程的 pid 树状的形式进程的用户 id pstree -u 即可。 服务(Service)管理服务(service) 本质就是进程，但是是运行在后台的，通常都会监听某个端口，等待其它程序的请求，比如(mysql , sshd 防火墙等)，因此我们又称为守护进程，是 Linux 中非常重要的知识点。 在 CentOS7.0 后 不再使用 service ,而是 systemctl service 管理指令：1service 服务名 [start | stop | restart | reload | status] 查看当前防火墙的状况，关闭防火墙和重启防火墙。 CentOS用firewalld: systemctl status firewalld 1) 关闭或者启用防火墙后，立即生效。[telnet 测试 某个端口即可] 在window下 telnet不是命令的，是因为没有telnet客户端 2)这种方式只是临时生效，当重启系统后，还是回归以前对服务的设置。 如果希望设置某个服务自启动或关闭永久生效，要使用 chkconfig 指令 查看服务名:方式 1：使用 setup -&gt; 系统服务 就可以看到。(空格选中，回车确认，tab切换) 方式 2: /etc/init.d/服务名称 服务的运行级别(runlevel):查看或者修改默认级别： 1vi &#x2F;etc&#x2F;inittab Linux 系统有 7 种运行级别(runlevel)：常用的是级别 3 和 5 • 运行级别 0：系统停机状态，系统默认运行级别不能设为 0，否则不能正常启动 • 运行级别 1：单用户工作状态，root 权限，用于系统维护，禁止远程登陆 • 运行级别 2：多用户状态(没有 NFS)，不支持网络 • 运行级别 3：完全的多用户状态(有 NFS)，登陆后进入控制台命令行模式 • 运行级别 4：系统未使用，保留 • 运行级别 5：X11 控制台，登陆后进入图形 GUI 模式 • 运行级别 6：系统正常关闭并重启，默认运行级别不能设为 6，否则不能正常启动 开机的流程说明 开机、BIOS自检、boot引导、init进程、判断运行级别、 chkconfig 指令通过 chkconfig 命令可以给每个服务的各个运行级别设置自启动/关闭 1查看服务 chkconfig --list|grep xxx chkconfig 服务名 –list chkconfig –level 5 服务名 on/off 将 sshd 服务在运行级别为 5 的情况下，不要自启动 请显示当前系统所有服务的各个运行级别的运行状态 bash&gt; chkconfig –list 查看 sshd 服务的运行状态** bash&gt; service sshd status 将 sshd 服务在运行级别 5 下设置为不自动启动，看看有什么效果？ bash&gt; chkconfig –level 5 sshd off 当运行级别为 5 时，关闭防火墙。 bash&gt; chkconfig –level 5 iptables off 在所有运行级别下，关闭防火墙 bash&gt; chkconfig iptables off 在所有运行级别下，开启防火墙 bash&gt; chkconfig iptables on 动态监控进程 top 与 ps 命令很相似。它们都用来显示正在执行的进程。Top 与 ps 最大的不同之处，在于 top 在执行一段时间可以更新正在运行的的进程。 1top [选项] 监视特定用户 top：输入此命令，按回车键，查看执行的进程。 u：然后输入“u”回车，再输入用户名，即可 终止指定的进程 top：输入此命令，按回车键，查看执行的进程。 k：然后输入“k”回车，再输入要结束的进程 ID 号 指定系统状态更新的时间(每隔 10 秒自动更新， 默认是 3 秒)： bash&gt; top -d 10 查看系统网络情况 netstat(重要)1234567netstat [选项]netstat -anp-an 按一定顺序排列输出-p 显示哪个进程在调用 查看系统所有的网络服务 查看服务名为 sshd 的服务的信息。 RPM 和 YUMrpm 包的管理 一种用于互联网下载包的打包及安装工具，它包含在某些 Linux 分发版中。它生成具有.RPM 扩展名的文件。RPM 是 RedHat Package Manager（RedHat 软件包管理工具）的缩写，类似 windows 的 setup.exe，这一文件格式名称虽然打上了 RedHat 的标志，但理念是通用的。 Linux 的分发版本都有采用（suse,redhat, centos 等等），可以算是公认的行业标准了。 rpm 包的简单查询指令查询已安装的 rpm 列表 rpm –qa|grep xx 请查询看一下，当前的 Linux 有没有安装 firefox . rpm 包名基本格式： 一个 rpm 包名：firefox-45.0.1-1.el6.centos.x86_64.rpm 名称:firefox 版本号：45.0.1-1 适用操作系统: el6.centos.x86_64 表示 centos6.x 的 64 位系统 如果是 i686i386 32 noarch rpm 包的其它查询指令： rpm -qa :查询所安装的所有 rpm 软件包 rpm -qa | more [分页显示] rpm -qa | grep X [rpm -qa | grep firefox ] rpm -q 软件包名 :查询软件包是否安装 rpm -q firefox rpm -qi 软件包名 ：查询软件包信息 rpm -qi file rpm -ql 软件包名 :查询软件包中的文件 rpm -ql firefox rpm -qf 文件全路径名 查询文件所属的软件包 rpm -qf /etc/passwd rpm -qf /root/install.log 卸载 rpm 包：1rpm -e RPM 包的名称 删除 firefox 软件包 1) 如果其它软件包依赖于您要卸载的软件包，卸载时则会产生错误信息。如： $ rpm -e foo removing these packages would break dependencies:foo is needed by bar-1.0-1 2) 如果我们就是要删除 foo 这个 rpm 包，可以增加参数 –nodeps ,就可以强制删除，但是一般不推荐这样做，因为依赖于该软件包的程序可能无法运行 如：$ rpm -e –nodeps foo 带上 –nodeps 就是强制删除。 安装 rpm 包：1rpm -ivh RPM 包全路径名称 i=install 安 装 v=verbose 提 示 h=hash 进度条 1) 演示安装 firefox 浏览器 步骤先找到 firefox 的安装 rpm 包,你需要挂载上我们安装 centos 的 iso 文件，然后到/media/下去找 rpm 找 。 1cp firefox-45.0.1-1.el6.centos.x86_64.rpm &#x2F;opt&#x2F; yum Yum 是一个 Shell 前端软件包管理器。基于 RPM 包管理，能够从指定的服务器自动下载 RPM 包并且安装，可以自动处理依赖性关系，并且一次安装所有依赖的软件包。使用 yum 的前提是可以联网。 1234查询 yum 服务器是否有需要安装的软件yum list|grep xx 软件列表安装指定的 yum 包yum install xxx 下载安装 使用 yum 的方式来安装 firefox 先查看一下 firefox rpm 在 yum 服务器有没有 1) 安装 yum install firefox 搭建 JavaEE 环境 安装 JDK0) 先将软件通过 xftp5 上传到 /opt 下 1) 解压缩到 /opt 2) 配置环境变量的配置文件 vim /etc/profile JAVA_HOME=/opt/jdk1.7.0_79 PATH=/opt/jdk1.7.0_79/bin:$PATH export JAVA_HOME PATH 3)需要注销用户，环境变量才能生效 如果是在 3 运行级别， logout 如果是在 5 运行级别， 4) 在任何目录下就可以使用 java 和 javac 测试是否安装成功 ​ 编写一个简单的 输出 Hello.java 输出”hello,world!” 安装 tomcat1) 解压缩到/opt 2)启动 tomcat ./startup.sh 先进入到 tomcat 的 bin 目录 使用 Linux 本地的浏览是可以访问到 tomcat 开放端口 8080 ,这样外网才能访问到 tomcat vim /etc/sysconfig/iptables 重启防火墙 测试是否安装成功： 在 windows、Linux 下 访问 http://linuxip:8080 Eclipse 的安装1) 解压缩到/opt 2)启动 eclipse，配置 jre 和 server 启动方法 1: 创建一个快捷方式 启动方式 2: 进入到 eclipse 解压后的文件夹，然后执行 ./eclipse 即可 3)编写 jsp 页面,并测试成功! mysql 的安装和配置12rpm -ivh MYSQL-server-***.rpmrpm -ivh MYSQL-client-***.rpm 查看是否启动 1ps -ef|grep mysql 查看是否安装成功 1mysqladmin --version 启动服务 1service mysql start 连接 1mysql 改密码 1&#x2F;usr&#x2F;bin&#x2F;mysqladmin -u root password 123456 连接 1mysql -uroot -p 设置开机自启动 1chkconfig mysql on 拷贝配置文件 1cp &#x2F;usr&#x2F;share&#x2F;mysql&#x2F;my-huge.cnf &#x2F;etc&#x2F;my.cnf 解决编码(已创建的数据库不影响)显示字符集 1show variables like &#39;%char%&#39; 修改客户端和服务器的字符集 12345678910111213vim &#x2F;etc&#x2F;my.cnf&#x2F;&#x2F;在[client]的socket的下方插入&#x2F;&#x2F;在光标的下一行插入 使用odefault-character-set&#x3D;utf-8&#x2F;&#x2F;在[mysqld]的port下插入character_set_server&#x3D;utf8character_set_client&#x3D;utf8collation-server&#x3D;utf8_general_ci&#x2F;&#x2F;在[mysql]的no-auto-rehash下插入default-character-set&#x3D;utf8 Linux中常用到的命令显示文件目录命令ls 如ls改变当前目录命令cd 如cd /home建立子目录mkdir 如mkdir xiong删除子目录命令rmdir 如rmdir /mnt/cdrom删除文件命令rm 如rm /ucdos.bat文件复制命令cp 如cp /ucdos /fox获取帮助信息命令man 如man ls显示文件的内容less 如less mwm.lx Linux文件属性有哪些？（共十位）-rw-r–r–那个是权限符号，总共是- — — —这几个位。 第一个短横处是文件类型识别符：-表示普通文件；c表示字符设备（character）；b表示块设备（block）；d表示目录（directory）；l表示链接文件（link）； 第一个三个连续的短横是用户权限位（User） 第二个三个连续短横是组权限位（Group） 第三个三个连续短横是其他权限位（Other）。每个权限位有三个权限，r（读权限），w（写权限），x（执行权限）。 如果每个权限位都有权限存在，那么满权限的情况就是：-rwxrwxrwx；权限为空的情况就是- — — —。权限的设定可以用chmod命令，其格式位：chmod ugoa+/-/=rwx filename/directory。例如：一个文件aaa具有完全空的权限- — — —。chmod u+rw aaa（给用户权限位设置（增加）读写权限，其权限表示为：- rw- — —）chmod g+r aaa（给组设置权限为可读，其权限表示为：- — r– —）chmod ugo+rw aaa（给用户、组、其它用户或组设置权限为读写，权限表示为：- rw- rw- rw-）如果aaa具有满权限- rwx rwx rwx。chmod u-x aaa（去掉用户可执行权限，权限表示为：- rw- rwx rwx）如果要给aaa赋予制定权限- rwx r-x r-x，命令为：chmod u=rwx，go=rx aaa","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://kayleh.top/tags/Linux/"}]},{"title":"C prime plus","slug":"C-prime-plus","date":"2020-06-28T09:33:01.000Z","updated":"2020-08-20T06:50:31.220Z","comments":true,"path":"2020/06/28/C-prime-plus/","link":"","permalink":"https://kayleh.top/2020/06/28/C-prime-plus/","excerpt":"指针","text":"指针 每一个变量都有一个内存位置，每一个内存位置都定义了可使用连字号（&amp;）运算符访问的地址，它表示了在内存中的一个地址。取地址&amp; 取值* 123456789#include &lt;stdio.h&gt;int main()&#123; int a; char b[10]; printf(\"a变量的内存地址：%p\\n\", &amp;a); printf(\"b变量的内存地址：%p\\n\", &amp;b); return 0;&#125; 访问数组b的地址其实就是数组第一个变量的数组 指针是一个变量，其值为另一个变量的地址，即，内存位置的直接地址。就像其他变量或常量一样，您必须在使用指针存储其他变量地址之前，对其进行声明。指针变量声明的一般形式为： 1type *var-name; 在这里，type 是指针的基类型，它必须是一个有效的 C 数据类型，var-name 是指针变量的名称。用来声明指针的星号 * 与乘法中使用的星号是相同的。但是，在这个语句中，星号是用来指定一个变量是指针。以下是有效的指针声明： 1234int *ip; /* 一个整型的指针 */double *dp; /* 一个 double 型的指针 */float *fp; /* 一个浮点型的指针 */char *ch; /* 一个字符型的指针 */ 所有实际数据类型，不管是整型、浮点型、字符型，还是其他的数据类型，对应指针的值的类型都是一样的，都是一个代表内存地址的长的十六进制数。 指针的使用 使用指针时会频繁进行以下几个操作：定义一个指针变量、把变量地址赋值给指针、访问指针变量中可用地址的值。这些是通过使用一元运算符 ***** 来返回位于操作数所指定地址的变量的值。下面的实例涉及到了这些操作： 12345678910111213141516171819#include &lt;stdio.h&gt; int main ()&#123; int var = 20; /* 实际变量的声明 */ int *ip; /* 指针变量的声明 */ ip = &amp;var; /* 在指针变量中存储 var 的地址 */ printf(\"Address of var variable: %p\\n\", &amp;var ); /* 在指针变量中存储的地址 */ printf(\"Address stored in ip variable: %p\\n\", ip ); /* 使用指针访问值 */ printf(\"Value of *ip variable: %d\\n\", *ip ); //20 return 0;&#125; C 中的 NULL 指针在变量声明的时候，如果没有确切的地址可以赋值，为指针变量赋一个 NULL 值是一个良好的编程习惯。赋为 NULL 值的指针被称为空指针。 NULL 指针是一个定义在标准库中的值为零的常量。请看下面的程序： 12345678910#include &lt;stdio.h&gt; int main ()&#123; int *ptr = NULL; printf(\"ptr 的地址是 %p\\n\", ptr ); return 0;&#125; 在大多数的操作系统上，程序不允许访问地址为 0 的内存，因为该内存是操作系统保留的。然而，内存地址 0 有特别重要的意义，它表明该指针不指向一个可访问的内存位置。但按照惯例，如果指针包含空值（零值），则假定它不指向任何东西。 如需检查一个空指针，您可以使用 if 语句，如下所示： 12if(ptr) /* 如果 p 非空，则完成 */if(!ptr) /* 如果 p 为空，则完成 */ 指针的算数运算C 指针是一个用数值表示的地址。因此，您可以对指针执行算术运算。可以对指针进行四种算术运算：++、–、+、-。 假设 ptr 是一个指向地址 1000 的整型指针，是一个 32 位的整数，让我们对该指针执行下列的算术运算： 1ptr++ 在执行完上述的运算之后，ptr 将指向位置 1004，因为 ptr 每增加一次，它都将指向下一个整数位置，即当前位置往后移 4 字节。这个运算会在不影响内存位置中实际值的情况下，移动指针到下一个内存位置。如果 ptr 指向一个地址为 1000 的字符，上面的运算会导致指针指向位置 1001，因为下一个字符位置是在 1001。 我们概括一下： 指针的每一次递增，它其实会指向下一个元素的存储单元。 指针的每一次递减，它都会指向前一个元素的存储单元。 指针在递增和递减时跳跃的字节数取决于指针所指向变量数据类型长度，比如 int 就是 4 个字节。 递增一个指针我们喜欢在程序中使用指针代替数组，因为变量指针可以递增，而数组不能递增，数组可以看成一个指针常量。下面的程序递增变量指针，以便顺序访问数组中的每一个元素： 1234567891011121314151617181920212223242526272829#include &lt;stdio.h&gt; const int MAX = 3; int main ()&#123; int var[] = &#123;10, 100, 200&#125;; int i, *ptr; /* 指针中的数组地址 */ ptr = var; for ( i = 0; i &lt; MAX; i++) &#123; printf(\"存储地址：var[%d] = %x\\n\", i, ptr ); printf(\"存储值：var[%d] = %d\\n\", i, *ptr ); /* 移动到下一个位置 */ ptr++; &#125; return 0;&#125;----存储地址：var[0] = bf882b30存储值：var[0] = 10存储地址：of var[1] = bf882b34存储值： var[1] = 100存储地址：of var[2] = bf882b38存储值：var[2] = 200 指针的比较指针可以用关系运算符进行比较，如 ==、&lt; 和 &gt;。如果 p1 和 p2 指向两个相关的变量，比如同一个数组中的不同元素，则可对 p1 和 p2 进行大小比较。 下面的程序修改了上面的实例，只要变量指针所指向的地址小于或等于数组的最后一个元素的地址 &amp;var[MAX - 1]，则把变量指针进行递增： 12345678910111213141516171819202122232425262728293031#include &lt;stdio.h&gt; const int MAX = 3; int main ()&#123; int var[] = &#123;10, 100, 200&#125;; int i, *ptr; /* 指针中第一个元素的地址 */ ptr = var; i = 0; while ( ptr &lt;= &amp;var[MAX - 1] ) &#123; printf(\"Address of var[%d] = %p\\n\", i, ptr ); printf(\"Value of var[%d] = %d\\n\", i, *ptr ); /* 指向上一个位置 */ ptr++; i++; &#125; return 0;&#125;----------------Address of var[0] = bfdbcb20Value of var[0] = 10Address of var[1] = bfdbcb24Value of var[1] = 100Address of var[2] = bfdbcb28Value of var[2] = 200 指针数组一个指向整数的指针数组的声明： 1int *ptr[MAX]; 在这里，把 ptr 声明为一个数组，由 MAX 个整数指针组成。因此，ptr 中的每个元素，都是一个指向 int 值的指针。下面的实例用到了三个整数，它们将存储在一个指针数组中，如下所示： 1234567891011121314151617181920212223#include &lt;stdio.h&gt; const int MAX = 3; int main ()&#123; int var[] = &#123;10, 100, 200&#125;; int i, *ptr[MAX]; for ( i = 0; i &lt; MAX; i++) &#123; ptr[i] = &amp;var[i]; /* 赋值为整数的地址 */ &#125; for ( i = 0; i &lt; MAX; i++) &#123; printf(\"Value of var[%d] = %d\\n\", i, *ptr[i] ); &#125; return 0;&#125;------Value of var[0] = 10Value of var[1] = 100Value of var[2] = 200 您也可以用一个指向字符的指针数组来存储一个字符串列表，如下： 12345678910111213141516171819202122232425#include &lt;stdio.h&gt; const int MAX = 4; int main ()&#123; const char *names[] = &#123; \"Zara Ali\", \"Hina Ali\", \"Nuha Ali\", \"Sara Ali\", &#125;; int i = 0; for ( i = 0; i &lt; MAX; i++) &#123; printf(\"Value of names[%d] = %s\\n\", i, names[i] ); &#125; return 0;&#125;------Value of names[0] = Zara AliValue of names[1] = Hina AliValue of names[2] = Nuha AliValue of names[3] = Sara Ali 指向指针的指针 指向指针的指针是一种多级间接寻址的形式，或者说是一个指针链。通常，一个指针包含一个变量的地址。当我们定义一个指向指针的指针时，第一个指针包含了第二个指针的地址，第二个指针指向包含实际值的位置。 1234 Pointer Pointer Variable _____________ _____________ _____________| Address | ------&gt;| Address |--------&gt;| Value ||_____________| |_____________| |_____________| 一个指向指针的指针变量必须如下声明，即在变量名前放置两个星号。例如，下面声明了一个指向 int 类型指针的指针： 1int **var; 当一个目标值被一个指针间接指向到另一个指针时，访问这个值需要使用两个星号运算符，如下面实例所示： 123456789101112131415161718192021222324252627#include &lt;stdio.h&gt; int main ()&#123; int var; int *ptr; int **pptr; var = 3000; /* 获取 var 的地址 */ ptr = &amp;var; /* 使用运算符 &amp; 获取 ptr 的地址 */ pptr = &amp;ptr; /* 使用 pptr 获取值 */ printf(\"Value of var = %d\\n\", var ); printf(\"Value available at *ptr = %d\\n\", *ptr ); printf(\"Value available at **pptr = %d\\n\", **pptr); return 0;&#125;-------------------Value of var = 3000Value available at *ptr = 3000Value available at **pptr = 3000 指针数组和数组指针12int *p1[5] ----------指针数组int (*p2)[5]---------数组指针 指针数组是一个数组，每个数组元素存放一个指针变量。 1234567891011121314151617#include &lt;stdio.h&gt;int main()&#123; //指针数组，里面存的是指针 char *p1[5] = &#123;\"wo\", \"jiao\", \"Kayleh\", \"!\"&#125;; int i; for (i = 0; i &lt; 5; i++) &#123; /* code */ // %s会取地址对应的值，char形是特列,通过字符串首地址输出字符串 printf(\"%s\\n\", p1[i]); &#125;&#125; 数组指针是一个指针，它指向的是一个数组 12345678910111213141516#include &lt;stdio.h&gt;int main()&#123; int temp[5] = &#123;1, 2, 3, 4, 5&#125;; //&amp;temp表示取出整个数组的地址 //temp表示数组的第一个元素的地址 int(*p2)[5] = &amp;temp; int i; for (i = 0; i &lt; 5; i++) &#123; /* code */ //内部的*取得是数组的，外部的取得是数组元素的 printf(\"%d\\n\", *(*p2 + i)); &#125; return 0;&#125; 二维数组数组名实际上是第一组一维数组的指针。 1234array[4][5]*(array+1) = array[1] = &amp;array[1][0]*(array+1)+3 == &amp;array[1][3] 结论 123*(array+i) == array[i]*(*(array+i)+j) == &amp;array[i][j]*(*(*(array+i)+j)+k) == &amp;array[i][j][k] 初始化二维数组 1int array[][3];&#x2F;&#x2F;前面的可不写 数组指针和二维数组 void指针 void指针称为通用指针，就是可以指向任意类型的数据。也就是说，任何类型的指针都可以赋值给void指针 1234567891011121314151617181920#include &lt;stdio.h&gt;int main()&#123; int num = 1024; int *pi = &amp;num; char *pc = \"Kayleh\"; void *pv; pv = pi; printf(\"pi:%p,pv:%p\\n\", pi, pv); printf(\"pv:%d\\n\", *(int *)pv); //强制转换 pv = pc; printf(\"pc:%p,pv:%p\\n\", pc, pv); //因为字符数组中每一个元素都相当于一个指针变量，就不需要在加*了，不用解引用 printf(\"pv:%s\\n\", pv); return 0;&#125; NULL指针1#define NULL ((void *)0) 12345678910#include &lt;stdio.h&gt;int main()&#123; int *p1; int *p2 = NULL; printf(\"%d\\n\", *p1); printf(\"%d\\n\", *p2); return 0;&#125; 函数定义 1234return_type function_name( parameter list )&#123; body of the function&#125; 返回类型：一个函数可以返回一个值。return_type 是函数返回的值的数据类型。有些函数执行所需的操作而不返回值，在这种情况下，return_type 是关键字 void。 函数名称：这是函数的实际名称。函数名和参数列表一起构成了函数签名。 参数：参数就像是占位符。当函数被调用时，您向参数传递一个值，这个值被称为实际参数。参数列表包括函数参数的类型、顺序、数量。参数是可选的，也就是说，函数可能不包含参数。 函数主体：函数主体包含一组定义函数执行任务的语句。 函数指针函数指针是指向函数的指针变量。 通常我们说的指针变量是指向一个整型、字符型或数组等变量，而函数指针是指向函数。 函数指针可以像一般函数一样，用于调用函数、传递参数。 函数指针变量的声明： 1typedef int (*fun_ptr)(int,int); // 声明一个指向同样参数、返回值的函数指针类型 1234567891011121314151617181920212223242526#include &lt;stdio.h&gt; int max(int x, int y)&#123; return x &gt; y ? x : y;&#125; int main(void)&#123; /* p 是函数指针 */ int (* p)(int, int) = &amp; max; // &amp;可以省略 int a, b, c, d; printf(\"请输入三个数字:\"); scanf(\"%d %d %d\", &amp; a, &amp; b, &amp; c); /* 与直接调用函数等价，d = max(max(a, b), c) */ d = p(p(a, b), c); printf(\"最大的数字是: %d\\n\", d); return 0;&#125;------------------请输入三个数字:1 2 3最大的数字是: 3 回调函数函数指针作为某个函数的参数函数指针变量可以作为某个函数的参数来使用的，回调函数就是一个通过函数指针调用的函数。 简单讲：回调函数是由别人的函数执行时调用你实现的函数。 以下是来自知乎作者常溪玲的解说： 你到一个商店买东西，刚好你要的东西没有货，于是你在店员那里留下了你的电话，过了几天店里有货了，店员就打了你的电话，然后你接到电话后就到店里去取了货。在这个例子里，你的电话号码就叫回调函数，你把电话留给店员就叫登记回调函数，店里后来有货了叫做触发了回调关联的事件，店员给你打电话叫做调用回调函数，你到店里去取货叫做响应回调事件。 实例实例中 populate_array 函数定义了三个参数，其中第三个参数是函数的指针，通过该函数来设置数组的值。 实例中我们定义了回调函数 getNextRandomValue，它返回一个随机值，它作为一个函数指针传递给 populate_array 函数。 populate_array 将调用 10 次回调函数，并将回调函数的返回值赋值给数组。 12345678910111213141516171819202122232425262728#include &lt;stdlib.h&gt; #include &lt;stdio.h&gt; // 回调函数void populate_array(int *array, size_t arraySize, int (*getNextValue)(void))&#123; for (size_t i=0; i&lt;arraySize; i++) array[i] = getNextValue();&#125; // 获取随机值int getNextRandomValue(void)&#123; return rand();&#125; int main(void)&#123; int myarray[10]; populate_array(myarray, 10, getNextRandomValue); for(int i = 0; i &lt; 10; i++) &#123; printf(\"%d \", myarray[i]); &#125; printf(\"\\n\"); return 0;&#125;--------------------16807 282475249 1622650073 984943658 1144108930 470211272 101027544 1457850878 1458777923 2007237709 C 传递指针给函数C 语言允许您传递指针给函数，只需要简单地声明函数参数为指针类型即可。 下面的实例中，我们传递一个无符号的 long 型指针给函数，并在函数内改变这个值： 1234567891011121314151617181920212223242526#include &lt;stdio.h&gt;#include &lt;time.h&gt; void getSeconds(unsigned long *par);int main ()&#123; unsigned long sec; getSeconds( &amp;sec ); /* 输出实际值 */ printf(\"Number of seconds: %ld\\n\", sec ); return 0;&#125;void getSeconds(unsigned long *par)&#123; /* 获取当前的秒数 */ *par = time( NULL ); return;&#125;------------------Number of seconds :1294450468 能接受指针作为参数的函数，也能接受数组作为参数，如下所示： 123456789101112131415161718192021222324252627282930313233343536#include &lt;stdio.h&gt; /* 函数声明 */double getAverage(int *arr, int size); int main ()&#123; /* 带有 5 个元素的整型数组 */ int balance[5] = &#123;1000, 2, 3, 17, 50&#125;; double avg; /* 传递一个指向数组的指针作为参数 */ avg = getAverage( balance, 5 ) ; /* 输出返回值 */ printf(\"Average value is: %f\\n\", avg ); return 0;&#125;double getAverage(int *arr, int size)&#123; int i, sum = 0; double avg; for (i = 0; i &lt; size; ++i) &#123; sum += arr[i]; &#125; avg = (double)sum / size; return avg;&#125;------------------Average value is: 214.40000 C 从函数返回指针 C 允许您从函数返回指针。为了做到这点，您必须声明一个返回指针的函数，如下所示： 123456int * myFunction()&#123;...&#125; C 语言不支持在调用函数时返回局部变量的地址，除非定义局部变量为 static 变量。 现在，让我们来看下面的函数，它会生成 10 个随机数，并使用表示指针的数组名（即第一个数组元素的地址）来返回它们，具体如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657#include &lt;stdio.h&gt;#include &lt;time.h&gt;#include &lt;stdlib.h&gt; /* 要生成和返回随机数的函数 */int * getRandom( )&#123; static int r[10]; int i; /* 设置种子 */ srand( (unsigned)time( NULL ) ); for ( i = 0; i &lt; 10; ++i) &#123; r[i] = rand(); printf(\"%d\\n\", r[i] ); &#125; return r;&#125; /* 要调用上面定义函数的主函数 */int main ()&#123; /* 一个指向整数的指针 */ int *p; int i; p = getRandom(); for ( i = 0; i &lt; 10; i++ ) &#123; printf(\"*(p + [%d]) : %d\\n\", i, *(p + i) ); &#125; return 0;&#125;-----------------------15231980531187214107110830097843049495914213012769309710841232504841069321401604461820149169022*(p + [0]) : 1523198053*(p + [1]) : 1187214107*(p + [2]) : 1108300978*(p + [3]) : 430494959*(p + [4]) : 1421301276*(p + [5]) : 930971084*(p + [6]) : 123250484*(p + [7]) : 106932140*(p + [8]) : 1604461820*(p + [9]) : 149169022 字符串 C 中有大量操作字符串的函数： 函数 目的 strcpy(s1, s2); 复制字符串 s2 到字符串 s1。 strcat(s1, s2); 连接字符串 s2 到字符串 s1 的末尾。 strlen(s1); 返回字符串 s1 的长度。 strcmp(s1, s2); 如果 s1 和 s2 是相同的，则返回 0；如果 s1&lt;s2 则返回小于 0；如果 s1&gt;s2 则返回大于 0。 strchr(s1, ch); 返回一个指针，指向字符串 s1 中字符 ch 的第一次出现的位置。 strstr(s1, s2); 返回一个指针，指向字符串 s1 中字符串 s2 的第一次出现的位置。 C 结构体C 数组允许定义可存储相同类型数据项的变量，结构是 C 编程中另一种用户自定义的可用的数据类型，它允许您存储不同类型的数据项。 结构用于表示一条记录，假设您想要跟踪图书馆中书本的动态，您可能需要跟踪每本书的下列属性： Title Author Subject Book ID 定义结构为了定义结构，您必须使用 struct 语句。struct 语句定义了一个包含多个成员的新的数据类型，struct 语句的格式如下： 123456struct tag &#123; member-list member-list member-list ...&#125; variable-list ; tag 是结构体标签。 member-list 是标准的变量定义，比如 int i; 或者 float f，或者其他有效的变量定义。 variable-list 结构变量，定义在结构的末尾，最后一个分号之前，您可以指定一个或多个结构变量。下面是声明 Book 结构的方式： 1234567struct Books&#123; char title[50]; char author[50]; char subject[100]; int book_id;&#125; book 在一般情况下，tag、member-list、variable-list 这 3 部分至少要出现 2 个。 结构体的成员可以包含其他结构体，也可以包含指向自己结构体类型的指针，而通常这种指针的应用是为了实现一些更高级的数据结构如链表和树等。 12345678910111213//此结构体的声明包含了其他的结构体struct COMPLEX&#123; char string[100]; struct SIMPLE a;&#125;; //此结构体的声明包含了指向自己类型的指针struct NODE&#123; char string[100]; struct NODE *next_node;&#125;;","categories":[],"tags":[{"name":"C","slug":"C","permalink":"https://kayleh.top/tags/C/"}]},{"title":"Redis","slug":"Redis","date":"2020-06-27T09:30:29.000Z","updated":"2020-07-04T11:07:18.316Z","comments":true,"path":"2020/06/27/Redis/","link":"","permalink":"https://kayleh.top/2020/06/27/Redis/","excerpt":"Redis","text":"Redis 在Linux下安装 https://redis.io/ 官网下载，移动到/opt 目录下. 在终端使用命令解压 1$ tar -zxvf redis-XXXXXX.tar.gz 进入解压后的目录,运行make指令(需要GCC编译器) 123$ cd redis.XXX$ make$ make install 进入默认安装的目录 1$ cd usr&#x2F;local&#x2F;bin 在根目录创建一个文件夹/myredis，把安装目录下的redis.conf复制到/myredis，复制的目的是不影响出厂的设置 1cp redis.conf &#x2F;myredis 要把myredis的权限修改,否则会出现redis无法SHUTDOWN的问题 1sudo chmod 777 &#x2F;myredis 修改复制过来的conf 1vim redis.conf 修改为为yes 1234567原来的：##########GENERAL###################XXXdaemonzie no修改为:daemonize yes 检查有没有启动Redis 1$ ps -ef|gref redis 检查端口是否启动 1lsof -i :6379 结果是没有启动的 启动方法：在/usr/local/bin下： 1$ redis-server &#x2F;myredis&#x2F;redis.conf 默认端口是6379 1$ redis-cli -p 6379 检查是否连接成功 1127.0.0.1:6379&gt; ping 1PONG 返回PONG表示成功 退出： 12127.0.0.1:6379&gt; SHUTDOWNexit KEY关键字12345678910DBSIZE &#x2F;&#x2F;当前数据库的key的数量select db &#x2F;&#x2F;切换数据库Flushdb &#x2F;&#x2F;清空当前库Flushall &#x2F;&#x2F;清空所有库key * 当前库所有的keyexists key &#x2F;&#x2F;判断key是否存在，有返回1，无则0move key db &#x2F;&#x2F;移动到目标库，当前库的移除expire key 秒钟 &#x2F;&#x2F;给key设置过期时间，过期后查询到的是nid空值ttl key &#x2F;&#x2F;查看还有多久过期，-1表示永不过期，-2表示已过期type key &#x2F;&#x2F;查看key是什么类型 redis五种数据结构String：字符串123456789101112set key valueget keydel keyappend key value &#x2F;&#x2F;在value后追加strlen &#x2F;&#x2F;String长度INCR&#x2F;DECR KEY&#x2F;&#x2F;一定要是数字，自增自减INCRBY&#x2F;DECRBY KEY 步长 &#x2F;&#x2F;多步递增递减getrange&#x2F;setrange key index index &#x2F;&#x2F;根据索引取值设置值setex key 秒钟 value &#x2F;&#x2F;设置值的时候设置过期时间setnx &#x2F;&#x2F;set if not existmset key1 value1 key2 value2 &#x2F;&#x2F; 设置多个值mget&#x2F;msetnx List：列表1234567891011LPUSH list1 1 2 3 4 5 (类似栈)LRANGE list1 0 -154321lpop list1&quot;5&quot;rpop list1&quot;1&quot; 1234567891011RPUSH list2 1 2 3 4 5LRANGE list2 0 -112345lpop list2&quot;1&quot;rpop list2&quot;5&quot; 1234567lindex &#x2F;&#x2F;按照索引下标获得元素，（从上到下）llen &#x2F;&#x2F;长度LREM KEY N Value &#x2F;&#x2F;删除key数组中的N个ValueLTRIM KEY 开始index 结束index &#x2F;&#x2F;截取指定范围的值后在赋值给keyrpoplpush 源列表 目的列表 &#x2F;&#x2F;把源列表的最底的值移动到目的列表的最上面lset key index value &#x2F;&#x2F;根据数组下标设置成valuelinsert key before&#x2F;after 值1 值2 &#x2F;&#x2F;把值2的值插入到key数组值1的前面&#x2F;后面 Set：集合1234567891011sadd key value1，value1，value2 &#x2F;&#x2F;只会进去不重复的值 smembers key value 0 -1 &#x2F;&#x2F;打印全部sismember key value &#x2F;&#x2F;判断value是否在key里scard &#x2F;&#x2F;获取集合里面的元素srem key value &#x2F;&#x2F;删除集合中元素srandmember key &#x2F;&#x2F;随机出几个数spop key &#x2F;&#x2F;随机出栈smove key1 key2 在key1里某个值 &#x2F;&#x2F;将key1里的某个值赋给key2sdiff set1 set2 &#x2F;&#x2F;差集，set1里有的，set2没有的sinter set1 set2 &#x2F;&#x2F;交集，都有的sunion set1 set2 &#x2F;&#x2F;并集 Hash ：哈希12345678910value是一个键值对hset key &lt;key1,value1&gt;hget key key1hmset KEY1 keyA valueA KEY2 keyB valueBhmgetall hdel KEY1 keyAHEXISTS KEY1 keyA &#x2F;&#x2F;判断是否存在hkeys&#x2F;kvals KEY1hincrby&#x2F;hincrbyfloat KEY1 keyA 步长&#x2F;浮点数 &#x2F;&#x2F;自增自减hsetnx Zset（sorted set）：有序集合在set基础上，加一个score值 set是 k1 v1 v2 v3 zset是 k1 score1 v1 score2 v2 12345678910111213zadd key k1 score1 v1 score2 v2zrange key 0 -1 &#x2F;&#x2F;只会打印valuezrange key 0 -1 withscores &#x2F;&#x2F;会打印v1，score，v2，scorezrangebyscore key 开始score 结束score &#x2F;&#x2F; &quot;（&quot; 表示不包含， a（ b 表示大于等于a，小于b zrangebyscore key 开始score 结束score withscorezrangebyscore key 开始score 结束score limit 开始下标步 多少步 zrem key score对应的value &#x2F;&#x2F;删除元素zacard key &#x2F;&#x2F;统计key里value的个数zcount key score区间zrank key value &#x2F;&#x2F;获取下标zrevrank key value &#x2F;&#x2F;获取反转后的下标zrevrange key 0 -1&#x2F;&#x2F;反转集合zrevrangebyscore key 结束score 开始score &#x2F;&#x2F;反转集合，index也要反转 配置文件Units1.配置大小单位，开头定义了一些基本的度量单位，只支持bytes，不支持bit 2.对大小写不敏感 INCLUDES可以通过includes包含，redis.conf可以作为总闸,包含其他 GENERALdaemonize 默认为no pidfile 进程管道id文件 port 默认端口 tcp-backlog,backlog 511是一个连接队列,在高并发环境下你需要一个高backlog值来避免慢客户端连接问题 bind 端口及网卡的绑定 timeout 0 当系统空闲一段时间后中断 Tcp-keepalive 单位为秒,设置为0则不会进行Keepalive检测 loglevel notice 日志级别 logfile 日志文件 syslog-enabled 是否把日志输出到syslog中 syslog-ident 指定syslog里的日志标志 syslog-facility 指定syslog设备,值可以是USER或LOCAL0-LOCAL7 databases 默认有16个库 SECURITY123config get requirepassconfig set requirepass &quot;123456&quot; &#x2F;&#x2F;立即生效访问任何命令前使用 auth 123456 LIMITmaxclients 10000 允许10000人连接 maxmemory maxmemory-policy noexiction 缓存过期清洁策略 ,默认永不过期 volatile-lru:使用LRU算法移除key,只对设置了过期时间的键 allkeys-lru:使用LRU算法移除key volatile-random:在过期集合中移除随机的key,只对设置了过期时间的键 allkeys-random:移除随机的key volatile-ttl:移除那些TTL值最小的key,即那些最近要过期的key noexiction :不进行移除.针对写操作,只是返回错误信息 LRU算法:最近最少使用的 Maxmemory-samples 设置样本数量,LRU算法和最小TTL算法都并非是精确的算法,而是估算值,所以你可以设置样本的大小,redis默认会检查这么多个key并选择其中LRU的那个; 常用配置 redis默认不是以守护进程的方式运行,可以通过该配置项修改,使用yes启动守护进程 1daemonize no 当Redis以守护进程方式运行时,Redis默认会把pid写入/var/run/redis.pid文件,可以通过pidfile指定 1pid &#x2F;var&#x2F;run&#x2F;redis.pid 指定redis监听端口,默认端口为6379 1port 6379 绑定的主机地址 1blind 127.0.0.1 当客户端闲置多长时间后关闭连接,如果指定为0,表示关闭该功能 1timeout 300 指定日志记录级别,Redis总共支持四个级别,debug、verbose、notice、warning，默认为verbose 1loglevel verbose 日志记录方式，默认为标准输出，如果配置Redis为守护进程方式，而这里又配置为日志记录方式为标准输出，则日志将会发送给/dev/null 1logfile stdout 设置数据库的数量，默认数据库为0，可以使用命令在连接上指定数据库id 1databases 16 指定在多长时间内，有多少次更新操作，就将数据同步到数据文件，可以多个条件配合 12345save &lt;seconds&gt; &lt;changes&gt;Redis默认配置文件中提供了三个条件:save 900 1save 300 10save 60 10000 指定存储至本地数据库时是否压缩数据，默认为yes，Redis采用LZF压缩，如果为了节省CPU时间，可以关闭该选项，但会导致数据库文件变的巨大 1rdbcompression yes 指定本地数据库文件名，默认为dump.rdb 1dbfilename dump.rdb 指定本地数据库存放目录 1dir .&#x2F; 设置当本机为slav服务时，设置master服务的IP地址及端口，在Redis启动时，它会自动从master进行数据同步 1slaveof &lt;masterip&gt; &lt;masterport&gt; 当master服务先设置了密码保护，slav服务连接master的密码 1masterauth &lt;master-password&gt; 设置Redis连接密码，如果配置了连接密码，客户端在连接Redis时需要通过AUTH 命令提供密码，默认关闭 1requirepass foobared 设置同一时间最大客户端连接数，默认无限制，Redis可以同时打开的客户端连接数为Redis进程可以打开的最大文件描述符，如果设置 maxclients 0，表示不作限制。当客户端连接数到达限制时，Redis会关闭新的连接并向客户端返回max numbers of clients reached 错误信息 1maxclients 128 指定Redis最大内存限制，Redis在启动时会把数据加载到内存中，达到最大内存后，redis会先尝试清除已到期或即将到期的Key，当此方法处理后，仍然到达最大内存设置，将无法再进行写入操作，但仍然可以进行读取操作。Redis新的vm机制，会把key存放内存，value会存放在swap区。 1maxmemory &lt;bytes&gt; 指定是否在每次更新操作后进行日志记录。Redis在默认情况下时异步的把数据写入磁盘，如果不开启，可能会在断电时导致一段时间内的数据丢失。因为redis本身同步数据文件时按save条件来同步的，所以有的数据会在一段时间内只存在内存中。默认为no 1appendonly no 指定更新日志文件名，默认为appendonly.aof 1appendfilename appendonly.aof 指定更新日志条件，共有3个可选值： 1234appendfsync everysecno: 表示等操作系统进行数据缓存同步到磁盘（快）always：表示每次更新操作后手动调用fsync()将数据写到磁盘（慢，安全）everysec：表示每秒同步一次（折中，默认值） 指定是否启用虚拟内存机制，默认为no。VM机制将数据分页存放，有Redis将访问量较少的页即冷数据swap到磁盘上，访问多的页面由磁盘换出到内存中 1vm-enabled no 虚拟内存文件路径,默认值为/tmp/redis.swap 1vm-swap-file &#x2F;tmp&#x2F;redis.swap 将所有大于vm-max-memory的数据存入虚拟内存，无论vm-max-memory设置多小，所有索引数据都是内存存储的(Redis的索引数据 就是keys)，也就是说，当vm-max-memory设置为0的时候，其实是所有value都存在于磁盘。默认为0 1vm-max-memory 0 Redis swap文件分成了很多page，一个对象可以保存在多个page上面，但一个page上不能被多个对象共享，vm-page-size是要根据存储的数据大小来设定的，作者建议如果存储很多小对象，page大小最好设置为32或者64bytes;如果存储很大的对象，则可以使用更大的page，如果不确定，就使用默认值 1vm-page-size 32 设置swap文件中的page数量，由于页表(一种表示页面空闲或使用的bitmap)是放在内存中的，在磁盘上每8个page将消耗1bytes的内存 1vm-pages 134217728 设置访问swap文件的线程数，最好不要超过机器的核数，如果设置为0，那么所有对swap文件的操作都是串行的，可能会造成比较长时间的延迟。默认值为4 1vm-max-threads 4 设置在向客户端应答时，是否把较小的包含并为一个包发送，默认为开启 1glueoutputbuf yes 指定在超过一定的数量或者最大的元素超过某一临界值时，采用一种特殊的哈希算法 12hash-max-zipmap-entries 64hash-max-zipmap-value 512 指定是否激活重置哈希，默认为开启 1activerehashing yes 指定包含其他的配置文件，可以在同一主机上多个Redis实例之间同一份配置文件，而同时各个实例又拥有自己的特定配置文件 1inclue &#x2F;path&#x2F;to.local,conf Redis持久化RDB 在指定的时间间隔内将内存中的数据集快照写入磁盘，即Snapshot快照，它恢复时是将快照文件直接读到内存里 是什么？Redis会单独创建(fork)一个子进程来进行持久化，会先将数据写入到一个临时文件中，待持久化过程都结束了，再用这个临时文件，替换上次持久化好的文件。 整个过程中，主进程是不进行任何IO操作的，这就确保了极高的性能。 如果需要进行大规模数据的恢复，且对于数据恢复的完整性不是非常敏感，那RDB方法要比AOF方式更加的高效。 RDB的缺点是最后一次持久化后的数据可能丢失。 Fork Fork的作用是复制一个与当前进程一样的进程。新进程的所有数据（变量、环境变量、程序计数器等） 数值都和原进程一致，但是是一个全新的进程，并作为原进程的子进程 RDB保存的是dump.rdb文件, 先拷贝一份rdb，删除原rdb，再重命名为dump.rdb，即可恢复 配置文件的位置##########SNAPSHOT########### save 秒钟 写操作次数 禁用 save “” 指定存储至本地数据库时是否压缩数据，默认为yes，Redis采用LZF压缩，如果为了节省CPU时间，可以关闭该选项，但会导致数据库文件变的巨大 rdbcompression yes stop-writes-on-bgsave-error yes 如果后台在save操作出现错误的时候，停止写入 如果配置为no，表示你不在乎数据不一致或者有其他的手段发现和控制 rgbchecksum yes ##是否校验rdb文件 在存储快照后，还可以让Redis使用CRC算法来进行数据校验，但是这样做会增加大约10%的性能消耗， 如果希望获取到最大的性能提升，可以关闭此功能。 触发RDB快照 命令 save 手动保存 save只管保存，其他不管，全部阻塞 bgsave Redis会在后台异步进行快照操作，快照同时还可以响应客户端请求，可以通过lastsave命令获得最后一次成功执行快照的时间 执行flushall命令，也会产生dump.rdb文件，但里面是空的，无意义。 config get dir获取目录 停止 动态所有停止RDB保存规则的方法：redis-cli config set save “” 优势1.适合大规模的数据恢复 2.对数据完整性和一致性要求不高 劣势1.在一定间隔时间做一次备份，所有如果redis意外down掉的话，就会丢失最后一次快照后的所有修改 2.fork的时候，内存中的数据被克隆了一份，大致2倍的膨胀性需要考虑 总结12345内存中的 rdbSave 磁盘中的数据对象 ----------》 RDB文件 rdbload RDB是一个非常紧凑的文件 RDB在保存文件时父进程唯一要做的就是fork出一个子进程来做，接下来的工作全部由子进程来做， 父进程不需要再做其他IO操作，所以RDB持久化方式可以最大化redis的性能 与AOF相比，在恢复大的数据集的时候，RDB方式会更快一些。 数据丢失风险大 RDB需要经常fork子进程来保存数据集到硬盘上，当数据集比较大的时候，fork的过程是非常耗时的，可能会导致Redis在一些毫秒级不能响应客户端的请求。 Redis持久化之AOF 以日志的形式来记录每个写操作，将Redis执行过的所有写指令记录下来（读操作不记录），只许追加文件但不可以改写文件，redis启动之初会读取该文件重新构建数据，换言之，redis重启的话就根据日志文件的内容将写指令从前到后执行一次以完成数据的恢复工作 AOF保存的是appendonly.aof文件 ###########appendonly########## 恢复：删除dump.rdb，vim appendonly.aof，删除末尾行的FLUSHALL，再次连接数据库即可访问。 两者可以共存，优先找aof，如果aof有修改为不能识别的字符，开启redis时会被拒绝。 这时，当前文件夹下有一个redis-check-aof，使用命令： 12redis-check-aof --fix appendonly.aofcontinue?[y&#x2F;N]:y 命令会删除不符合语法规范的字段。 rewriteAOF采用文件追加方式，文件会越来越大为避免出现此种情况，新增了重写机制，当AOF文件的大小超过所设定的阈值时，Redis就会启动AOF文件的内容压缩，只保留可以恢复数据的最小指令集.可以使用bgrewriteaof 重写原理： AOF文件持续增长而过大时，会fork出一条新进程来将文件重写（也是先写临时文件最后再rename），遍历新进程的内存中数据，每条记录有一条的set 语句。重写aof文件的操作，并没有读取旧的aof文件，而是将整个内存中的数据库内容用命令的方式重写了一个新的aof文件，这点和快照有点类似。 触发机制： Redis会记录上次重写时的AOF大小，默认配置是当AOF文件大小是上次rewrite后大小的一倍且文件大于64M时触发。 auto-aof-rewrite-percentage 100 一倍 auto-aof-rewrite-min-size 64mb 优势每秒同步：appendfsync always 同步持久化 每次发生数据变更会被立即记录到磁盘 性能较差但数据完整比较好 每修改同步：appendfsync everysec 异步操作，每秒记录 如果一秒内宕机，有数据丢失。 不同步：appendfsync no 从不同步 劣势相同数据集的数据而言aof文件要远大于rdb文件，恢复速度慢与rdb aof运行效率要慢与rdb，每秒同步策略较好，不同步效率和rdb相同 1234 AOF 网络协议格式 _________________ 命令请求 ________________ 的命令内容 ____________________| 客户端 | __________&gt; | 服务器 | __________&gt;| AOF文件 ||_________________| |________________| |___________________| aof文件时一个只进行追加的日志文件 Redis可以在AoF文件体积变得过大时，自动地在后台对AOF进行重写 对于相同的数据集来说，AOF文件的体积通常要大于RDB文件的体积 根据所使用的fsync策略，AOF的速度可能会慢于RDB 总结 RDB持久化方式能够在指定的时间间隔能对你的数据进行快照存储 AOP持久化方式记录每次对服务器写的操作，当服务器重启的时候回重新执行这些命令来回复原始的数据，AOP命令以redis协议追加保存每次写的操作到文件末尾. Redis还能对AOF文件进行后台重写，使得AOF文件的体积不至于过大 只做缓存：如果你只希望你的数据在服务器运行的时候存在，你也可以不使用任何持久化方式. 同时开启两种持久化方式.在这种情况下,当redis重启的时候会优先载入AOF文件来恢复原始的数据,因为在通常情况下AOF文件保存的数据集要比RDB文件保存的数据集要完整. RDB的数据不实时,同时使用两者时服务器重启也只会找AOF文件, 建议不要只使用AOF,因为RDB更适合于备份数据库(AOF在不断变化不好备份), 快速重启,而且不会有AOF可能存在的bug,留着作为一个万一的手段. 事务 可以一次执行多个命令，本质是一组命令的集合。一个事务中的所有命令都会序列化，按顺序地串行化执行而不会被其他命令插入，不许加塞 能做什么？一个队列中，一次性的、顺序性、排他性的执行一系列命令 常用命令 DISCARD 取消事务，放弃执行事务块内的所有命令。 EXEC 执行所有事务块内的命令。 MULTI 标记一个事务块的开始。 UNWATCH 取消 WATCH 命令对所有 key 的监视。 WATCH key [key …] 监视一个(或多个) key ，如果在事务执行之前这个(或这些) key 被其他命令所改动，那么事务将被打断。 正常执行MULTI 相当与 一个新的购物车，每输入一条命令返回QUEUED相当于加入购物车，EXEC执行命令相当于结账。 放弃事务在事务没有EXEC之前调用DISCARD 全体连坐如果有一个指令不能正常运行（编译出错），事务EXEC会报错 冤头债主运行时出错的命令不会执行，而其他命令仍然会放行。 Redis是否支持事务？ 是部分支持。 watch监控 悲观锁(Pessimistic Lock) 我对这个事情的发展很悲观，每次去拿数据的时候都认为别人会修改，为了避免出事，把整张表锁了， 表锁，并发性最差，一致性最好。 乐观锁(Optimistic Lock) 我认为这个事没有人会去干，不会上锁，乐观锁在每条记录的后面加一个version版本号字段。 乐观锁策略：提交版本必须大于记录当前版本才能执行。 在调用MULTI之前，先调用 WATCH + KEY UNWATCH取消所有key的监控 有加塞篡改，监控了key，key被修改了，事务将被打断，调用UNWATCH再执行一次 阶段开启：以MULTI开始一个事务 入队：将多个命令入队到事务中，接到这些命令并不会立即执行，而是放到等待执行的事务队列里面。 执行：由EXEC命令触发事务 总结watch指令，类似乐观锁，事务提交时，如果key的值已被别的客户端改变，比如某个list已被别的客户端push/pop过了，整个事务队列都不会执行。 通过watch命令在事务执行之前监控了多个keys，倘若在watch之后有任何key的值发生了变化，EXEC命令执行的事务都将被放弃，同时返回Nullmulti-bulk应答以通知调用者事务执行失败。 特性：单独的隔离操作：事务中的所有命令都会序列化、按顺序的执行。事务在执行的过程中，不会被其他客户端发送来的请求所打断。 没有隔离级别的概念：队列中的命令没有提交之前都不会实际的被执行，因为事务提交前任何指令都不会被实际执行，也就不存在“事务内的查询要看到事务里的更新，在事务外查询不能看到”这个问题。 不保证原子性：redis同一个事务中如果有一条命令执行失败，其后的命令仍然会被执行，没有回滚。 消息订阅发布是什么？ 进程间的一种消息通信模式：发送者(pub)发送消息，订阅者(sub)接收消息 下图展示了频道channel1，以及订阅这个频道的三个客户端—client2和client5、client1之间的关系 当有新消息通过PUBLISH命令发送给频道channel1时，这个消息就会发送给订阅它的三个客户端 下表列出了 redis 发布订阅常用命令： 命令 描述 PSUBSCRIBE pattern [pattern …] 订阅一个或多个符合给定模式的频道。 PUBSUB subcommand [argument [argument …]] 查看订阅与发布系统状态。 PUBLISH channel message 将信息发送到指定的频道。 PUNSUBSCRIBE [pattern [pattern …]] 退订所有给定模式的频道。 SUBSCRIBE channel[channel …] 订阅给定的一个或多个频道的信息。 UNSUBSCRIBE[channel [channel …]] 指退订给定的频道。 SUBSCRIBE c1 c2 PULISH c1 message PSUBSCRIBE new* PULISH new4 message 主从复制 主机数据更新后根据配置和策略，自动同步到备机的master/slave机制，Master以写为主，Slave以读为主。 在/myredis下：123cp redis.conf redis6379.confcp redis.conf redis6380.confcp redis.conf redis6381.conf 修改配置文件 12345678vim redis6379.confpidfile &#x2F;var&#x2F;run&#x2F;redis.pid -&gt; &#x2F;var&#x2F;run&#x2F;redis6379.pidport 6379logfile &quot;&quot; -&gt; logfile &quot;6379.log&quot;备份dbfilename dump.rdb -&gt; dump6379.rdb6380,6381 以此为例 分别启动 12redis-server &#x2F;myredis&#x2F;redis6379.confredis-cli -p 6379 检查是否启动 1ps -ef|gref redis 使用命令 info replication查看信息,他们的角色都是master 1role:master 在主机（6379）下往数据库设值 123set k1 v1set k2 v2set k3 v3 在从机（6380,6381）分别使用SLAVEOF命令 1SLAVEOF 127.0.0.1 6379 这时再往主机6379设值 1set k4 v4 从机可以获取值 1234get k4&quot;v4&quot;get k1&quot;v1&quot; 再次使用命令 info replication查看信息 6379主机下多了两个奴隶：6380,6381 6780、6781的角色变成了奴隶。 如果从机尝试写入数据。会出错。因为Master以写为主，Slave以读为主 如果主机SHUTDOWN死了，调用从机的 info replication 1master_link_status: 由up变成了down 从机在原地待命 如果主机重新连接回来了，并设值 1set k7 v7 从机依然可以获取k7的值 12get k7&quot;v7&quot; 如果从机退出并重新连接role角色会变成master，并且会丢失退出期间的数据, 调用SLAVEOF 127.0.0.1 6379就可以恢复连接并获取到原来丢失的值 每次与master断开之后，都需要重新连接，除非配置进redis.conf 薪火相传 去中心化 上一个Slave可以是下一个slave的Master，Slave同样可以接收其他slaves的连接和同步请求，那么该slave作为了链条中的下一个的master，可以有效减轻master的写压力。 中途变更转向：会清除之前的数据，重新建立拷贝最新的 Slaveof 新主库IP 新主库端口 例如81是80的从机，80是79的从机，那么80是79的奴隶，80还是奴隶，81是80的奴隶。 反客为主一主二仆里，主机挂了，从机使用命令： 1SLAVEOF no one 当前从机的角色就变成了主机，其他从机需要调用： 12Slaveof 新主库IP 新主库端口&#x2F;&#x2F;使当前数据库停止与其他数据库同步，转成组数据库。 才能跟随新主机。 复制原理 Slave启动成功连接到master后会发送一个sync命令 Master接到命令启动后台的存盘进程，同时收集所有接受到的用于修改数据集命令，在后台进程执行完毕之后，master将传送整个数据文件到slave，以完成一次完全同步 全量复制：而slave服务在接收到数据库文件数据后，将其存盘并加载到内存中。 增量复制：Master继续将新的所有收集到的修改命令依次传给slave，完成同步 但是只要是重新连接master，一次完全同步（全量复制）将会被自动执行。 哨兵模式 反客为主的自动版，能够后台监控主机是否故障，如果故障了根据投票数自动将从库转换为主库 启动在/myredis下面创建一个sentinel.conf文件 12touch sentinel.confvim sentinel.conf 修改为以下内容： 一组 sentinel.conf 可以监控多个Master 123sentinel monitor 被监控数据库名字(自己起名字) 127.0.0.1 6379 1//数字1 表示主机挂掉后salve投票看让谁接替成为主机，得票数多少后成为主机 启动redis： 1redis-sentinel &#x2F;myredis&#x2F;sentinel.conf 主机断开之后，哨兵监控到了，就开始投票，如果两个从机一人一票，就会重新投票， 票数高的从机替换主机，其他从机都跟随这个新主机。 断开的主机回来之后变成了从机，并跟随新主机。 复制的缺点由于所有的写操作都是先在Master上操作，然后同步更新到Slave上，所以从Master同步带Slave机器有一定的延迟，当系统很繁忙的时候，延迟问题会更加严重，Slave机器数量的增加也会使这个问题更加严重。 Jedis测试联通 先启动 在/usr/local/bin下： 1$ redis-server &#x2F;myredis&#x2F;redis.conf 1$ redis-cli -p 6379 Java： 依赖： 1234567891011121314&lt;dependencies&gt; &lt;!-- https://mvnrepository.com/artifact/org.apache.commons/commons-pool2 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.commons&lt;/groupId&gt; &lt;artifactId&gt;commons-pool2&lt;/artifactId&gt; &lt;version&gt;2.8.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;redis.clients&lt;/groupId&gt; &lt;artifactId&gt;jedis&lt;/artifactId&gt; &lt;version&gt;3.3.0&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 123456789101112/** * @Author: Wizard * @Date: 2020/6/29 18:33 */public class TestPing &#123; public static void main(String[] args) &#123; Jedis jedis = new Jedis(\"127.0.0.1\", 6379); System.out.println(jedis.ping()); &#125;&#125;------PONG API 1234567891011121314151617/** * @Author: Wizard * @Date: 2020/6/29 18:33 */public class TestAPI &#123; public static void main(String[] args) &#123; Jedis jedis = new Jedis(\"127.0.0.1\", 6379); jedis.set(\"k1\", \"v2\"); jedis.get(\"k1\"); Set&lt;String&gt; keys = jedis.keys(\"*\"); //事务 Transaction multi = jedis.multi(); multi.set(\"k2\", \"v2\");// multi.exec(); multi.discard(); &#125;&#125; 事务 1234567891011121314151617181920212223242526272829/** * @Author: Wizard * @Date: 2020/6/29 20:04 */public class TestTX &#123; public static void main(String[] args) throws InterruptedException &#123; TestTX test = new TestTX(); boolean b = test.transMethod(); System.out.println(b); &#125; public boolean transMethod() throws InterruptedException &#123; Jedis jedis = new Jedis(\"127.0.0.1\", 6379); int balance;//可用余额 int debt;//欠额 int amtToSubtract = 10;//实刷额度 jedis.watch(\"balance\"); //其他程序执行 // Thread.sleep(3000); //jedis.set(\"balance\", \"5\"); balance = Integer.parseInt(jedis.get(\"balance\")); if (balance &lt; amtToSubtract) &#123; jedis.unwatch(); System.out.println(\"modify\"); return false; &#125; return true; &#125;&#125; 主从 123456789101112131415/** * @Author: Wizard * @Date: 2020/6/29 20:04 */public class TestMS &#123; public static void main(String[] args) &#123; Jedis jedis_M = new Jedis(\"127.0.0.1\", 6379); Jedis jedis_S = new Jedis(\"127.0.0.1\", 6380); jedis_S.slaveof(\"127.0.0.1\", 6379); jedis_M.set(\"class\", \"1\"); System.out.println(jedis_S.get(\"class\")); &#125;&#125; 池 123456789101112131415161718192021222324252627/** * @Author: Wizard * @Date: 2020/6/29 20:29 */public class JedisPoolUtils &#123; private static volatile JedisPool jedisPool = null; private JedisPoolUtils() &#123; &#125; public static JedisPool getJedisPoolInstance() &#123; if (null == jedisPool) &#123; synchronized (JedisPoolUtils.class) &#123; if (null == jedisPool) &#123; JedisPoolConfig jedisPoolConfig = new JedisPoolConfig(); jedisPoolConfig.setMaxActive(); jedisPoolConfig.setMaxIdle(32); jedisPoolConfig.setMaxWaitMillis(100*1000); jedisPoolConfig.setTestOnBorrow(true); jedisPool = new JedisPool(\"127.0.0.1\", 6379); &#125; &#125; &#125; return jedisPool; &#125;&#125; JedisPoolConfig: 缓存雪崩","categories":[],"tags":[{"name":"sql","slug":"sql","permalink":"https://kayleh.top/tags/sql/"}]},{"title":"操作系统","slug":"操作系统","date":"2020-06-20T13:14:21.000Z","updated":"2020-07-25T05:44:14.191Z","comments":true,"path":"2020/06/20/操作系统/","link":"","permalink":"https://kayleh.top/2020/06/20/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/","excerpt":"OS Kernel的特征","text":"OS Kernel的特征 并发并发：指两个或多个事件在同一时间间隔内发生。这些事件宏观上是同时发生的，但微观上是交替发生的。 常考易混概念——并行：指两个或多个事件在同一时刻同时发生。 操作系统的并发性指计算机系统中“同时”运行着多个程序，这些程序宏观上看是同时运行着的，而微观 上看是交替运行的。 操作系统就是伴随着“多道程序技术”而出现的。因此，操作系统和程序并发是一起诞生的。 注意： 单核CPU同一时刻只能执行一个程序，各个程序只能并发地执行 多核CPU同一时刻可以同时执行多个程序，多个程序可以并行地执行。 计算机系统中存在多个运行的程序，需要OS管理和调度 共享共享即资源共享，是指系统中的资源可供内存中多个并发执行的进程共同使用。 同时共享 系统中的某些资源，虽然可以提供给 多个进程使用，但一个时间段内只允 许一个进程访问该资源 互斥共享 系统中的某些资源，允许一个时间段 内由多个进程“同时”对它们进行访 问 所谓的“同时”往往是宏观上的，而在微观上，这些进程可能是交替地对该资源进行访问的（即分时共享）生活实例： 互斥共享方式：使用QQ和微信视频。同一时间段内摄像头只能分配给其中一个进程。 同时共享方式：使用QQ发送文件A，同时使用微信发送文件B。宏观上看，两边都在同时读取并发送文件， 说明两个进程都在访问硬盘资源，从中读取数据。微观上看，两个进程是交替着访问硬盘的。 共享和并发的关系：并发性指计算机系统中同时存在着多个运行着的程序。 共享性是指系统中的资源可供内存中多个并发执行的进程共同使用。 通过上述例子来看并发与共享的关系： 并发性与共享性是互为存在条件。 虚拟利用多道程序设计技术，让每个用户都觉得有一个计算机专门为他服务。虚拟是指把一个物理上的实体变为若干个逻辑上的对应物。物理实体是实际存在的，而逻辑上 对应物是用户感受到的。虚拟技术中的“时分复用 技术”。微观上处理机在 各个微小的时间段内交替 着为各个进程服务 虚拟技术分为空分复用技术（如虚拟存储器技术）和时分复用技术（如虚拟处理器）。 没有并发性，就没有虚拟性 异步程序的执行不是一贯到底，而是走走停停，向前推进的速度不可预知。 但只要运行环境相同，OS需要保证程序运行的结果也要相同。 只有拥有并发性才有异步性。 操作系统的功能资源的管理者 处理机管理 处理机分配都是以进程为单位，所以处理机管理也被看做是进程管理。包括进程控制，进程同步，进程通信和进程调度 存储器管理 内存分配，内存保护，地址映射，内存扩充 文件管理 管理用户文件和系统文件，方便使用同时保证安全性。包括：磁盘存储空间管理，目录管理，文件读写管理以及文件共享和保护 设备管理 管理所有外围设备，包括完成用户的IO请求；为用户进程分配IO设备；提高IO设备利用率；提高IO速度；方便IO的使用 提供接口：程序接口（API）和用户接口（GUI） 联机命令接口实例 联机命令接口就是交互式命令接口(CMD) 用户命令一句，系统执行一句。 脱机命令接口实例 脱机命令接口实例，脱机命令接口也就是批处理命令接口 用户命令一堆，系统执行一堆。 程序接口： 可以在程序中进行系统调用(广义指令)来使用程序接口。普通用户不能直接使用程序接口，只能通过程 序代码间接使用。 BIOS关系：DISK：存放OS BIOS：基本I/O处理系统，最基本的功能是电源开启后检测外设，之后加载相应的软件来执行 Bootloader：加载OS，把OS从硬盘放到内存里，让CPU可以操作系统， 从图可以看出，计算机里面有一部分空间（硬盘）已经给BIOS占用了，但是还有很多地方是空的，BIOS需要从一个特定的地址开始执行，以X86为例，固定的地址为0xf000:fff0. CS寄存器和IP寄存器一起可以形成一个内存地址，一开始加电，BIOS就从这个地址开始执行。执行一系列的工作： POST（加电自检） 寻找显卡和执行BIOS，检查设备是否可以正常工作。初始化的检擦。 BIOS是如何把bootloader放进去的： Bootloader一般是放在硬盘的第一个主引导扇区。第一个扇区是512个字节。把bootloader放到内存里，CPU的掌控权就在bootloader； 运行机制两种指令 特权指令，如内存清零指令—-不允许用户程序使用 非特权指令，如普通的运算指令。 两种处理器状态 用户态（目态） 核心态（管态） 两种程序 内核程序 应用程序 操作系统内核与硬件关联紧密的模块 时钟管理 中断处理 原语 其他： 对系统资源进行管理的功能 操作系统的体系结构 大内核：将操作系统的主要功能模块都作为系统内核，运行在核心态 优点：高性能 缺点：内核代码庞大。结构混乱，难以维护。 微内核：只把最基本的功能保留在内核、 优点：内核功能少，结构清晰，方便维护 缺点：需要频繁的在核心态和用户态之间切换，性能低 1.特权指令只能在核心态下执行 2.内核程序只能在核心态下执行 3.核心态和用户态的切换 操作系统与设备和程序交互。系统调用、异常、中断 系统调用（来源于应用程序）sys call 应用程序主动向操作系统发出服务请求。 异常（来源于不良的应用程序） exception 非法指令或者其他坏的处理状态（如：内存出错） 中断（来源与外设）interrupt 来自不同硬件设备的计时器和网络中断。 为什么应用程序不直接使用外设而要经过操作系统？ 在计算机运行中，内核是被信任的第三方 只有内核可以执行特权指令 为了方便应用程序 产生的源头： 中断：外设 异常：应用程序意想不到的行为 系统调用：应用程序请求操作提供服务。 处理时间： 中断：异步，异步：当这个事件产生的时候，我们应用程序并不知道什么时候产生。 异常：同步，异常执行到某条特定的指令后一定会产生 系统调用：异步或同步，当系统调用发出请求的时候，返回的时间是异步的 响应： 中断：持续，对用户应用程序是透明的、 异常: 杀死或者重新执行意想不到的应用程序指令 系统调用：等待和持续 进程和线程以及它们的区别进程是对运行时程序的封装，是系统进行资源调度和分配的基本单位，实现了操作系统的并发（如：用户运行自己的程序，系统就创建一个进程，并为它分配资源，包括各种表格、内存空间、磁盘空间、I/O设备等，然后该进程被放入到进程的就绪队列，进程调度程序选中它，为它分配CPU及其他相关资源，该进程就被运行起来）； 线程是进程的子任务，是CPU调度和分派的基本单位，用于保证程序的实时性，实现进程内部的并发； 在没有实现线程的操作系统中，进程既是资源分配的基本单位，又是调度的基本单位，它是系统中并发执行的单元。而在实现了线程的操作系统中，进程是资源分配的基本单位，但是线程是调度的基本单位，是系统中并发执行的单元。 引入线程主要有以下4个方面的优点： 1）易于调度。 2）提高并发性。通过线程可以方便有效地实现并发。 3）开销小。创建线程比创建进程要快，所需要的开销也更小。 4）有利于发挥多处理器的功能。通过创建多线程，每个线程都在一个处理器上运行，从而实现应用程序的并行，使每个处理器都得到充分的运行。 尽管线程和进程很相似，但两者也存在着很大的不同，区别如下： 一个程序至少有一个进程，一个进程至少有一个线程，线程依赖于进程而存在； 进程在执行过程中拥有独立的内存单元，而多个线程共享进程的内存空间。 属于一个进程的所有线程共享该进程的所有资源，包括打开的文件，创建的Socket等。不同的进程互相独立。 线程又被称为轻量级进程。进程有进程控制块，线程有线程控制块。但线程控制块比进程控制块小得多。线程间切换代价小，进程间切换代价大。 进程是程序的一次执行，线程可以理解为程序中一段程序片段的执行。 进程间的通信的几种方式管道（pipe）及命名管道（named pipe）：管道可用于具有亲缘关系的父子进程间的通信，有名管道除了具有管道所具有的功能外，它还允许无亲缘关系进程间的通信； 信号（signal）：信号是一种比较复杂的通信方式，用于通知接收进程某个事件已经发生； 消息队列：消息队列是消息的链接表，它克服了上两种通信方式中信号量有限的缺点，具有写权限得进程可以按照一定得规则向消息队列中添加新信息；对消息队列有读权限得进程则可以从消息队列中读取信息； 共享内存：可以说这是最有用的进程间通信方式。它使得多个进程可以访问同一块内存空间，不同进程可以及时看到对方进程中对共享内存中数据得更新。这种方式需要依靠某种同步操作，如互斥锁和信号量等； 信号量：主要作为进程之间及同一种进程的不同线程之间得同步和互斥手段； 套接字：这是一种更为一般得进程间通信机制，它可用于网络中不同机器之间的进程间通信，应用非常广泛。 线程的实现方式(用户线程与内核线程的区别)根据操作系统内核是否对线程可感知，可以把线程分为内核线程和用户线程。 内核线程建立和销毁都是由操作系统负责、通过系统调用完成的，操作系统在调度时，参考各进程内的线程运行情况做出调度决定，如果一个进程中没有就绪态的线程，那么这个进程也不会被调度占用CPU。 和内核线程相对应的是用户线程，用户线程指不需要内核支持而在用户程序中实现的线程，其不依赖于操作系统核心，用户进程利用线程库提供创建、同步、调度和管理线程的函数来控制用户线程。用户线程多见于一些历史悠久的操作系统，例如Unix操作系统，不需要用户态/核心态切换，速度快，操作系统内核不知道多线程的存在，因此一个线程阻塞将使得整个进程（包括它的所有线程）阻塞。由于这里的处理器时间片分配是以进程为基本单位，所以每个线程执行的时间相对减少为了在操作系统中加入线程支持，采用了在用户空间增加运行库来实现线程，这些运行库被称为“线程包”，用户线程是不能被操作系统所感知的。 引入用户线程，具体而言，有以下四个方面的优势：（1）可以在不支持线程的操作系统中实现。 （2）创建和销毁线程、线程切换代价等线程管理的代价比内核线程少得多。 （3）允许每个进程定制自己的调度算法，线程管理比较灵活。 （4）线程能够利用的表空间和堆栈空间比内核级线程多。 用户线程的缺点主要有以下两点：（1）同一进程中只能同时有一个线程在运行，如果有一个线程使用了系统调用而阻塞，那么整个进程都会被挂起。 （2）页面失效也会产生类似的问题。 内核线程的优缺点刚好跟用户线程相反。实际上，操作系统可以使用混合的方式来实现线程。 进程有哪几种状态？就绪状态：当进程已经分配到除CPU以外的所有必要的资源，只要获得处理机便可立即执行； 运行状态：当进程已获得处理机，其程序正在处理机上执行； 阻塞状态： 正在执行的进程，由于某个事件发生而无法执行时，便放弃处理机而处于阻塞状态；引起进程阻塞状态的事件可以有多种，例如，等待I/O完成、申请缓冲区不能满足、等待信件（信号）。 注意区别就绪状态和等待状态：就绪状态是指进程仅缺少处理机，只要获得处理机资源就立即执行；而等待状态是指进程需要其他资源（除了处理机）或等待某一事件。 就绪状态 -&gt; 运行状态：处于就绪状态的进程被调度后，获得处理机资源（分派处理机时间片），于是进程由就绪状态转换为运行状态。 运行状态 -&gt; 就绪状态：处于运行状态的进程在时间片用完后，不得不让出处理机，从而进程由运行状态转换为就绪状态。此外，在可剥夺的操作系统中，当有更高优先级的进程就 、 绪时，调度程度将正执行的进程转换为就绪状态，让更高优先级的进程执行。 运行状态 -&gt; 阻塞状态：当进程请求某一资源（如外设）的使用和分配或等待某一事件的发生（如I/O操作的完成）时，它就从运行状态转换为阻塞状态。进程以系统调用的形式请求操作系统提供服务，这是一种特殊的、由运行用户态程序调用操作系统内核过程的形式。 阻塞状态 -&gt; 就绪状态：当进程等待的事件到来时，如I/O操作结束或中断结束时，中断处理程序必须把相应进程的状态由阻塞状态转换为就绪状态。 用户态和核心态的区别。当一个任务（进程）执行系统调用而陷入内核代码中执行时，我们就称进程处于内核运行态（或简称为内核态）。此时处理器处于特权级最高的（0级）内核代码中执行。当进程处于内核态时，执行的内核代码会使用当前进程的内核栈。每个进程都有自己的内核栈。当进程在执行用户自己的代码时，则称其处于用户运行态（用户态）。即此时处理器在特权级最低的（3级）用户代码中运行。当正在执行用户程序而突然被中断程序中断时，此时用户程序也可以象征性地称为处于进程的内核态。因为中断处理程序将使用当前进程的内核栈。这与处于内核态的进程的状态有些类似。 用户态切换到内核态的3种方式：系统调用、异常、外围设备中断。 什么是缓冲区溢出？有什么危害？其原因是什么？缓冲区溢出是指当计算机向缓冲区内填充数据时超过了缓冲区本身的容量，溢出的数据覆盖在合法数据上。 危害：在当前网络与分布式系统安全中，被广泛利用的50%以上都是缓冲区溢出，其中最著名的例子是1988年利用fingerd漏洞的蠕虫。而缓冲区溢出中，最为危险的是堆栈溢出，因为入侵者可以利用堆栈溢出，在函数返回时改变返回程序的地址，让其跳转到任意地址，带来的危害一种是程序崩溃导致拒绝服务，另外一种就是跳转并且执行一段恶意代码，比如得到shell，然后为所欲为。通过往程序的缓冲区写超出其长度的内容，造成缓冲区的溢出，从而破坏程序的堆栈，使程序转而执行其它指令，以达到攻击的目的。 造成缓冲区溢出的主原因是程序中没有仔细检查用户输入的参数。 死锁死锁的概念 所谓死锁是指两个或两个以上的进程在执行过程中，因争夺资源而造成的一种互相等待的现象，若无外力作用，它们都将无法推进下去，此时称系统处于死锁状态或系统产生了死锁。通俗的讲，就是两个或多个进程无限期的阻塞、相互等待的一种状态。 死锁产生的四个必要条件 互斥条件：一个资源每次只能被一个进程使用；若其他进程申请使用该资源，必须等到该资源被释放为止； 请求与保持条件：一个进程因请求资源而阻塞时，对已获得的资源保持不放； 不可剥夺条件：进程已获得的资源，在未使用完之前，不能强行剥夺； 循环等待条件：若干进程之间形成一种头尾相接的环形等待资源关系； 死锁的解除与预防1 死锁预防死锁预防的基本思想是 只要确保死锁发生的四个必要条件中至少有一个不成立，就能预防死锁的发生，具体方法包括： 注意：互斥条件无法破坏 打破请求与保持条件：可以实行资源预先分配策略(进程在运行前一次性向系统申请它所需要的全部资源，若所需全部资源得不到满足，则不分配任何资源，此进程暂不运行；只有当系统能满足当前进程所需的全部资源时，才一次性将所申请资源全部分配给该线程)或者只允许进程在没有占用资源时才可以申请资源（一个进程可申请一些资源并使用它们，但是在当前进程申请更多资源之前，它必须全部释放当前所占有的资源）。但是这种策略也存在一些缺点：在很多情况下，无法预知一个进程执行前所需的全部资源，因为进程是动态执行的，不可预知的；同时，会降低资源利用率，导致降低了进程的并发性。 打破不可剥夺条件：允许进程强剥夺使用其他进程占有的资源，从而破坏不可剥夺条件。也就是说，一个进程占有了一部分资源，在其申请新的资源且得不到满足时，它必须释放所有占有的资源以便让其它线程使用。这种预防死锁的方式实现起来困难，会降低系统性能。 打破循环等待条件：实行资源有序分配策略，破坏环路条件。对所有资源排序编号，所有进程对资源的请求必须严格按资源序号递增的顺序提出，即只有占用了小号资源才能申请大号资源，这样就不回产生环路，预防死锁的发生。 2死锁避免的基本思想死锁避免的基本思想是动态地检测资源分配状态，以确保循环等待条件不成立，从而确保系统处于安全状态。所谓安全状态是指：如果系统能按某个顺序为每个进程分配资源（不超过其最大值），那么系统状态是安全的，换句话说就是，如果存在一个安全序列，那么系统处于安全状态。资源分配图算法和银行家算法是两种经典的死锁避免的算法，其可以确保系统始终处于安全状态。其中，资源分配图算法应用场景为每种资源类型只有一个实例(申请边，分配边，需求边，不形成环才允许分配)，而银行家算法应用于每种资源类型可以有多个实例的场景。 银行家算法：该算法需要检查申请者对资源的最大需求量，如果系统现存的各类资源可以满足申请者的请求，就满足申请者的请求。这样申请者就可以很快完成其计算，然后释放它占用的资源，从而保证了系统中所有进程都能完成，所以可避免死锁的发生。 内存管理有哪几种方式(块式、页式、段式、段页式).内存管理有块式管理，页式管理，段式和段页式管理。现在常用段页式管理。 块式管理：把主存分为一大块、一大块的，当所需的程序片断不在主存时就分配一块主存空间，把程序片断load入主存，就算所需的程序片度只有几个字节也只能把这一块分配给它。这样会造成很大的浪费，平均浪费了50％的内存空间，但是易于管理。 页式管理：把主存分为一页一页的，每一页的空间要比一块一块的空间小很多，显然这种方法的空间利用率要比块式管理高很多。 段式管理：把主存分为一段一段的，每一段的空间又要比一页一页的空间小很多，这种方法在空间利用率上又比页式管理高很多，但是也有另外一个缺点。一个程序片断可能会被分为几十段，这样很多时间就会被浪费在计算每一段的物理地址上。 段页式管理：结合了段式管理和页式管理的优点。将程序分成若干段，每个段分成若干页。段页式管理每取一数据，要访问3次内存。分页和分段有什么区别（内存管理）？​ 段式存储管理是一种符合用户视角的内存分配管理方案。在段式存储管理中，将程序的地址空间划分为若干段（segment），如代码段，数据段，堆栈段；这样每个进程有一个二维地址空间，相互独立，互不干扰。段式管理的优点是：没有内碎片（因为段大小可变，改变段大小来消除内碎片）。但段换入换出时，会产生外碎片（比如4k的段换5k的段，会产生1k的外碎片） 页式存储管理方案是一种用户视角内存与物理内存相分离的内存分配管理方案。在页式存储管理中，将程序的逻辑地址划分为固定大小的页（page），而物理内存划分为同样大小的帧，程序加载时，可以将任意一页放入内存中任意一个帧，这些帧不必连续，从而实现了离散分配。页式存储管理的优点是：没有外碎片（因为页的大小固定），但会产生内碎片（一个页可能填充不满）。 两者的不同点： 目的不同：分页是由于系统管理的需要而不是用户的需要，它是信息的物理单位；分段的目的是为了能更好地满足用户的需要，它是信息的逻辑单位，它含有一组其意义相对完整的信息； 大小不同：页的大小固定且由系统决定，而段的长度却不固定，由其所完成的功能决定； 地址空间不同： 段向用户提供二维地址空间；页向用户提供的是一维地址空间； 信息共享：段是信息的逻辑单位，便于存储保护和信息的共享，页的保护和共享受到限制； 内存碎片：页式存储管理的优点是没有外碎片（因为页的大小固定），但会产生内碎片（一个页可能填充不满）；而段式管理的优点是没有内碎片（因为段大小可变，改变段大小来消除内碎片）。但段换入换出时，会产生外碎片（比如4k的段换5k的段，会产生1k的外碎片）。 页面置换算法最佳置换算法OPT：只具有理论意义的算法，用来评价其他页面置换算法。置换策略是将当前页面中在未来最长时间内不会被访问的页置换出去。 先进先出置换算法FIFO：简单粗暴的一种置换算法，没有考虑页面访问频率信息。每次淘汰最早调入的页面。 最近最久未使用算法LRU：算法赋予每个页面一个访问字段，用来记录上次页面被访问到现在所经历的时间t，每次置换的时候把t值最大的页面置换出去(实现方面可以采用寄存器或者栈的方式实现)。 时钟算法clock(也被称为是最近未使用算法NRU)：页面设置一个访问位，并将页面链接为一个环形队列，页面被访问的时候访问位设置为1。页面置换的时候，如果当前指针所指页面访问为为0，那么置换，否则将其置为0，循环直到遇到一个访问为位0的页面。 改进型Clock算法：在Clock算法的基础上添加一个修改位，替换时根究访问位和修改位综合判断。优先替换访问位和修改位都是0的页面，其次是访问位为0修改位为1的页面。 LFU最少使用算法LFU：设置寄存器记录页面被访问次数，每次置换的时候置换当前访问次数最少的。 操作系统中进程调度策略 先来先服务调度算法FCFS：队列实现，非抢占，先请求CPU的进程先分配到CPU，可以作为作业调度算法也可以作为进程调度算法；按作业或者进程到达的先后顺序依次调度，对于长作业比较有利； 最短作业优先调度算法SJF：作业调度算法，算法从就绪队列中选择估计时间最短的作业进行处理，直到得出结果或者无法继续执行，平均等待时间最短，但难以知道下一个CPU区间长度；缺点：不利于长作业；未考虑作业的重要性；运行时间是预估的，并不靠谱 ； 优先级调度算法(可以是抢占的，也可以是非抢占的)：优先级越高越先分配到CPU，相同优先级先到先服务，存在的主要问题是：低优先级进程无穷等待CPU，会导致无穷阻塞或饥饿； 时间片轮转调度算法(可抢占的)：按到达的先后对进程放入队列中，然后给队首进程分配CPU时间片，时间片用完之后计时器发出中断，暂停当前进程并将其放到队列尾部，循环 ;队列中没有进程被分配超过一个时间片的CPU时间，除非它是唯一可运行的进程。如果进程的CPU区间超过了一个时间片，那么该进程就被抢占并放回就绪队列。 高相应比算法HRN：响应比=(等待时间+要求服务时间)/要求服务时间； 多级队列调度算法：将就绪队列分成多个独立的队列，每个队列都有自己的调度算法，队列之间采用固定优先级抢占调度。其中，一个进程根据自身属性被永久地分配到一个队列中。 多级反馈队列调度算法：目前公认较好的调度算法；设置多个就绪队列并为每个队列设置不同的优先级，第一个队列优先级最高，其余依次递减。优先级越高的队列分配的时间片越短，进程到达之后按FCFS放入第一个队列，如果调度执行后没有完成，那么放到第二个队列尾部等待调度，如果第二次调度仍然没有完成，放入第三队列尾部…。只有当前一个队列为空的时候才会去调度下一个队列的进程。与多级队列调度算法相比，其允许进程在队列之间移动：若进程使用过多CPU时间，那么它会被转移到更低的优先级队列；在较低优先级队列等待时间过长的进程会被转移到更高优先级队列，以防止饥饿发生。 进程同步有哪几种机制 原子操作、信号量机制、自旋锁管程、会合、分布式系统 虚拟内存内存的发展历程 没有内存抽象(单进程，除去操作系统所用的内存之外，全部给用户程序使用) —&gt; 有内存抽象（多进程，进程独立的地址空间，交换技术(内存大小不可能容纳下所有并发执行的进程)）—&gt; 连续内存分配(固定大小分区(多道程序的程度受限)，可变分区(首次适应，最佳适应，最差适应)，碎片) —&gt; 不连续内存分配（分段，分页，段页式，虚拟内存） 虚拟内存 虚拟内存允许执行进程不必完全在内存中。虚拟内存的基本思想是：每个进程拥有独立的地址空间，这个空间被分为大小相等的多个块，称为页(Page)，每个页都是一段连续的地址。这些页被映射到物理内存，但并不是所有的页都必须在内存中才能运行程序。当程序引用到一部分在物理内存中的地址空间时，由硬件立刻进行必要的映射；当程序引用到一部分不在物理内存中的地址空间时，由操作系统负责将缺失的部分装入物理内存并重新执行失败的命令。这样，对于进程而言，逻辑上似乎有很大的内存空间，实际上其中一部分对应物理内存上的一块(称为帧，通常页和帧大小相等)，还有一些没加载在内存中的对应在硬盘上，如图所示。注意，请求分页系统、请求分段系统和请求段页式系统都是针对虚拟内存的，通过请求实现内存与外存的信息置换。 由图可以看出，虚拟内存实际上可以比物理内存大。当访问虚拟内存时，会访问MMU（内存管理单元）去匹配对应的物理地址（比如图5的0，1，2）。如果虚拟内存的页并不存在于物理内存中（如图5的3,4），会产生缺页中断，从磁盘中取得缺的页放入内存，如果内存已满，还会根据某种算法将磁盘中的页换出。 虚拟内存的应用与优点虚拟内存很适合在多道程序设计系统中使用，许多程序的片段同时保存在内存中。当一个程序等待它的一部分读入内存时，可以把CPU交给另一个进程使用。虚拟内存的使用可以带来以下好处： 在内存中可以保留多个进程，系统并发度提高 解除了用户与内存之间的紧密约束，进程可以比内存的全部空间还大 颠簸颠簸本质上是指频繁的页调度行为，具体来讲，进程发生缺页中断，这时，必须置换某一页。然而，其他所有的页都在使用，它置换一个页，但又立刻再次需要这个页。因此，会不断产生缺页中断，导致整个系统的效率急剧下降，这种现象称为颠簸（抖动）。 内存颠簸的解决策略包括： 如果是因为页面替换策略失误，可以修改替换算法来解决这个问题； 如果是因为运行的程序太多，造成程序无法同时将所有频繁访问的页面调入内存，则要降低多道程序的数量； 否则，还剩下两个办法：终止该进程或增加物理内存容量。 局部性原理时间上的局部性：最近被访问的页在不久的将来还会被访问； 空间上的局部性：内存中被访问的页周围的页也很可能被访问。","categories":[],"tags":[{"name":"Operating Systems","slug":"Operating-Systems","permalink":"https://kayleh.top/tags/Operating-Systems/"}]},{"title":"编码算法","slug":"编码算法","date":"2020-06-19T00:53:22.000Z","updated":"2020-06-19T01:08:34.559Z","comments":true,"path":"2020/06/19/编码算法/","link":"","permalink":"https://kayleh.top/2020/06/19/%E7%BC%96%E7%A0%81%E7%AE%97%E6%B3%95/","excerpt":"编码算法","text":"编码算法 要学习编码算法，先来看一看什么是编码。 ASCII码就是一种编码，字母A的编码是十六进制的0x41，字母B是0x42，以此类推： 字母 ASCII编码 A 0x41 B 0x42 C 0x43 D 0x44 … … 因为ASCII编码最多只能有127个字符，要想对更多的文字进行编码，就需要用Unicode。而中文的中使用Unicode编码就是0x4e2d，使用UTF-8则需要3个字节编码： 汉字 Unicode编码 UTF-8编码 中 0x4e2d 0xe4b8ad 文 0x6587 0xe69687 编 0x7f16 0xe7bc96 码 0x7801 0xe7a081 … … … 因此，最简单的编码是直接给每个字符指定一个若干字节表示的整数，复杂一点的编码就需要根据一个已有的编码推算出来。 比如UTF-8编码，它是一种不定长编码，但可以从给定字符的Unicode编码推算出来。 URL编码URL编码是浏览器发送数据给服务器时使用的编码，它通常附加在URL的参数部分，例如： https://www.baidu.com/s?wd=%E4%B8%AD%E6%96%87 之所以需要URL编码，是因为出于兼容性考虑，很多服务器只识别ASCII字符。但如果URL中包含中文、日文这些非ASCII字符怎么办？不要紧，URL编码有一套规则： 如果字符是AZ，az，0~9以及-、_、.、*，则保持不变； 如果是其他字符，先转换为UTF-8编码，然后对每个字节以%XX表示。 例如：字符中的UTF-8编码是0xe4b8ad，因此，它的URL编码是%E4%B8%AD。URL编码总是大写。 Java标准库提供了一个URLEncoder类来对任意字符串进行URL编码： 123456public class Main &#123; public static void main(String[] args) &#123; String encoded = URLEncoder.encode(\"中文!\", StandardCharsets.UTF_8); System.out.println(encoded); &#125;&#125; 上述代码的运行结果是%E4%B8%AD%E6%96%87%21，中的URL编码是%E4%B8%AD，文的URL编码是%E6%96%87，!虽然是ASCII字符，也要对其编码为%21。 和标准的URL编码稍有不同，URLEncoder把空格字符编码成+，而现在的URL编码标准要求空格被编码为%20，不过，服务器都可以处理这两种情况。 如果服务器收到URL编码的字符串，就可以对其进行解码，还原成原始字符串。Java标准库的URLDecoder就可以解码： 123456public class Main &#123; public static void main(String[] args) &#123; String decoded = URLDecoder.decode(\"%E4%B8%AD%E6%96%87%21\", StandardCharsets.UTF_8); System.out.println(decoded); &#125;&#125; 要特别注意：URL编码是编码算法，不是加密算法。URL编码的目的是把任意文本数据编码为%前缀表示的文本，编码后的文本仅包含AZ，az，0~9，-，_，.，*和%，便于浏览器和服务器处理。 Base64编码URL编码是对字符进行编码，表示成%xx的形式，而Base64编码是对二进制数据进行编码，表示成文本格式。 Base64编码可以把任意长度的二进制数据变为纯文本，且只包含AZ、az、0~9、+、/、=这些字符。它的原理是把3字节的二进制数据按6bit一组，用4个int整数表示，然后查表，把int整数用索引对应到字符，得到编码后的字符串。 举个例子：3个byte数据分别是e4、b8、ad，按6bit分组得到39、0b、22和2d： 123456789┌───────────────┬───────────────┬───────────────┐│ e4 │ b8 │ ad │└───────────────┴───────────────┴───────────────┘┌─┬─┬─┬─┬─┬─┬─┬─┬─┬─┬─┬─┬─┬─┬─┬─┬─┬─┬─┬─┬─┬─┬─┬─┐│1│1│1│0│0│1│0│0│1│0│1│1│1│0│0│0│1│0│1│0│1│1│0│1│└─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┘┌───────────┬───────────┬───────────┬───────────┐│ 39 │ 0b │ 22 │ 2d │└───────────┴───────────┴───────────┴───────────┘ 因为6位整数的范围总是063，所以，能用64个字符表示：字符AZ对应索引025，字符az对应索引2651，字符09对应索引52~61，最后两个索引62、63分别用字符+和/表示。 在Java中，二进制数据就是byte[]数组。Java标准库提供了Base64来对byte[]数组进行编解码： 1234567public class Main &#123; public static void main(String[] args) &#123; byte[] input = new byte[] &#123; (byte) 0xe4, (byte) 0xb8, (byte) 0xad &#125;; String b64encoded = Base64.getEncoder().encodeToString(input); System.out.println(b64encoded); &#125;&#125; 编码后得到5Lit4个字符。要对Base64解码，仍然用Base64这个类： 123456public class Main &#123; public static void main(String[] args) &#123; byte[] output = Base64.getDecoder().decode(\"5Lit\"); System.out.println(Arrays.toString(output)); // [-28, -72, -83] &#125;&#125; 有的童鞋会问：如果输入的byte[]数组长度不是3的整数倍肿么办？这种情况下，需要对输入的末尾补一个或两个0x00，编码后，在结尾加一个=表示补充了1个0x00，加两个=表示补充了2个0x00，解码的时候，去掉末尾补充的一个或两个0x00即可。 实际上，因为编码后的长度加上=总是4的倍数，所以即使不加=也可以计算出原始输入的byte[]。Base64编码的时候可以用withoutPadding()去掉=，解码出来的结果是一样的： 1234567891011public class Main &#123; public static void main(String[] args) &#123; byte[] input = new byte[] &#123; (byte) 0xe4, (byte) 0xb8, (byte) 0xad, 0x21 &#125;; String b64encoded = Base64.getEncoder().encodeToString(input); String b64encoded2 = Base64.getEncoder().withoutPadding().encodeToString(input); System.out.println(b64encoded); System.out.println(b64encoded2); byte[] output = Base64.getDecoder().decode(b64encoded2); System.out.println(Arrays.toString(output)); &#125;&#125; 因为标准的Base64编码会出现+、/和=，所以不适合把Base64编码后的字符串放到URL中。一种针对URL的Base64编码可以在URL中使用的Base64编码，它仅仅是把+变成-，/变成_： 123456789public class Main &#123; public static void main(String[] args) &#123; byte[] input = new byte[] &#123; 0x01, 0x02, 0x7f, 0x00 &#125;; String b64encoded = Base64.getUrlEncoder().encodeToString(input); System.out.println(b64encoded); byte[] output = Base64.getUrlDecoder().decode(b64encoded); System.out.println(Arrays.toString(output)); &#125;&#125; Base64编码的目的是把二进制数据变成文本格式，这样在很多文本中就可以处理二进制数据。例如，电子邮件协议就是文本协议，如果要在电子邮件中添加一个二进制文件，就可以用Base64编码，然后以文本的形式传送。 Base64编码的缺点是传输效率会降低，因为它把原始数据的长度增加了1/3。 和URL编码一样，Base64编码是一种编码算法，不是加密算法。 如果把Base64的64个字符编码表换成32个、48个或者58个，就可以使用Base32编码，Base48编码和Base58编码。字符越少，编码的效率就会越低。 小结URL编码和Base64编码都是编码算法，它们不是加密算法； URL编码的目的是把任意文本数据编码为%前缀表示的文本，便于浏览器和服务器处理； Base64编码的目的是把任意二进制数据编码为文本，但编码后数据量会增加1/3。","categories":[],"tags":[{"name":"dataAlgorithm","slug":"dataAlgorithm","permalink":"https://kayleh.top/tags/dataAlgorithm/"}]},{"title":"哈希算法","slug":"哈希算法","date":"2020-06-17T10:03:58.000Z","updated":"2020-06-17T11:03:45.393Z","comments":true,"path":"2020/06/17/哈希算法/","link":"","permalink":"https://kayleh.top/2020/06/17/%E5%93%88%E5%B8%8C%E7%AE%97%E6%B3%95/","excerpt":"哈希算法 哈希算法（Hash）又称摘要算法（Digest），它的作用是：对任意一组输入数据进行计算，得到一个固定长度的输出摘要。","text":"哈希算法 哈希算法（Hash）又称摘要算法（Digest），它的作用是：对任意一组输入数据进行计算，得到一个固定长度的输出摘要。 哈希算法最重要的特点就是： 相同的输入一定得到相同的输出； 不同的输入大概率得到不同的输出。 哈希算法的目的就是为了验证原始数据是否被篡改。 Java字符串的hashCode()就是一个哈希算法，它的输入是任意字符串，输出是固定的4字节int整数： 123&quot;hello&quot;.hashCode(); &#x2F;&#x2F; 0x5e918d2&quot;hello, java&quot;.hashCode(); &#x2F;&#x2F; 0x7a9d88e8&quot;hello, bob&quot;.hashCode(); &#x2F;&#x2F; 0xa0dbae2f 两个相同的字符串永远会计算出相同的hashCode，否则基于hashCode定位的HashMap就无法正常工作。这也是为什么当我们自定义一个class时，覆写equals()方法时我们必须正确覆写hashCode()方法。 哈希碰撞哈希碰撞是指，两个不同的输入得到了相同的输出： 12&quot;AaAaAa&quot;.hashCode(); &#x2F;&#x2F; 0x7460e8c0&quot;BBAaBB&quot;.hashCode(); &#x2F;&#x2F; 0x7460e8c0 有童鞋会问：碰撞能不能避免？答案是不能。碰撞是一定会出现的，因为输出的字节长度是固定的，String的hashCode()输出是4字节整数，最多只有4294967296种输出，但输入的数据长度是不固定的，有无数种输入。所以，哈希算法是把一个无限的输入集合映射到一个有限的输出集合，必然会产生碰撞。 碰撞不可怕，我们担心的不是碰撞，而是碰撞的概率，因为碰撞概率的高低关系到哈希算法的安全性。一个安全的哈希算法必须满足： 碰撞概率低； 不能猜测输出。 不能猜测输出是指，输入的任意一个bit的变化会造成输出完全不同，这样就很难从输出反推输入（只能依靠暴力穷举）。假设一种哈希算法有如下规律： 123hashA(&quot;java001&quot;) &#x3D; &quot;123456&quot;hashA(&quot;java002&quot;) &#x3D; &quot;123457&quot;hashA(&quot;java003&quot;) &#x3D; &quot;123458&quot; 那么很容易从输出123459反推输入，这种哈希算法就不安全。安全的哈希算法从输出是看不出任何规律的： 123hashB(&quot;java001&quot;) &#x3D; &quot;123456&quot;hashB(&quot;java002&quot;) &#x3D; &quot;580271&quot;hashB(&quot;java003&quot;) &#x3D; ??? 常用的哈希算法有： 算法 输出长度（位） 输出长度（字节） MD5 128 bits 16 bytes SHA-1 160 bits 20 bytes RipeMD-160 160 bits 20 bytes SHA-256 256 bits 32 bytes SHA-512 512 bits 64 bytes 根据碰撞概率，哈希算法的输出长度越长，就越难产生碰撞，也就越安全。 Java标准库提供了常用的哈希算法，并且有一套统一的接口。我们以MD5算法为例，看看如何对输入计算哈希： 1234567891011public class Main &#123; public static void main(String[] args) throws Exception &#123; // 创建一个MessageDigest实例: MessageDigest md = MessageDigest.getInstance(\"MD5\"); // 反复调用update输入数据: md.update(\"Hello\".getBytes(\"UTF-8\")); md.update(\"World\".getBytes(\"UTF-8\")); byte[] result = md.digest(); // 16 bytes: 68e109f0f40ca72a15e05cc22786f8e6 System.out.println(new BigInteger(1, result).toString(16)); &#125;&#125; 使用MessageDigest时，我们首先根据哈希算法获取一个MessageDigest实例，然后，反复调用update(byte[])输入数据。当输入结束后，调用digest()方法获得byte[]数组表示的摘要，最后，把它转换为十六进制的字符串。 运行上述代码，可以得到输入HelloWorld的MD5是68e109f0f40ca72a15e05cc22786f8e6。 哈希算法的用途因为相同的输入永远会得到相同的输出，因此，如果输入被修改了，得到的输出就会不同。 我们在网站上下载软件的时候，经常看到下载页显示的哈希： 如何判断下载到本地的软件是原始的、未经篡改的文件？我们只需要自己计算一下本地文件的哈希值，再与官网公开的哈希值对比，如果相同，说明文件下载正确，否则，说明文件已被篡改。 哈希算法的另一个重要用途是存储用户口令。如果直接将用户的原始口令存放到数据库中，会产生极大的安全风险： 数据库管理员能够看到用户明文口令； 数据库数据一旦泄漏，黑客即可获取用户明文口令。 不存储用户的原始口令，那么如何对用户进行认证？ 方法是存储用户口令的哈希，例如，MD5。 在用户输入原始口令后，系统计算用户输入的原始口令的MD5并与数据库存储的MD5对比，如果一致，说明口令正确，否则，口令错误。 因此，数据库存储用户名和口令的表内容应该像下面这样： username password bob f30aa7a662c728b7407c54ae6bfd27d1 alice 25d55ad283aa400af464c76d713c07ad tim bed128365216c019988915ed3add75fb 这样一来，数据库管理员看不到用户的原始口令。即使数据库泄漏，黑客也无法拿到用户的原始口令。想要拿到用户的原始口令，必须用暴力穷举的方法，一个口令一个口令地试，直到某个口令计算的MD5恰好等于指定值。 使用哈希口令时，还要注意防止彩虹表攻击。 什么是彩虹表呢？上面讲到了，如果只拿到MD5，从MD5反推明文口令，只能使用暴力穷举的方法。 然而黑客并不笨，暴力穷举会消耗大量的算力和时间。但是，如果有一个预先计算好的常用口令和它们的MD5的对照表： 常用口令 MD5 hello123 f30aa7a662c728b7407c54ae6bfd27d1 12345678 25d55ad283aa400af464c76d713c07ad passw0rd bed128365216c019988915ed3add75fb 19700101 570da6d5277a646f6552b8832012f5dc … … 20201231 6879c0ae9117b50074ce0a0d4c843060 这个表就是彩虹表。如果用户使用了常用口令，黑客从MD5一下就能反查到原始口令： bob的MD5：f30aa7a662c728b7407c54ae6bfd27d1，原始口令：hello123； alice的MD5：25d55ad283aa400af464c76d713c07ad，原始口令：12345678； tim的MD5：bed128365216c019988915ed3add75fb，原始口令：passw0rd。 这就是为什么不要使用常用密码，以及不要使用生日作为密码的原因。 即使用户使用了常用口令，我们也可以采取措施来抵御彩虹表攻击，方法是对每个口令额外添加随机数，这个方法称之为加盐（salt）： 1digest &#x3D; md5(salt+inputPassword) 经过加盐处理的数据库表，内容如下： username salt password bob H1r0a a5022319ff4c56955e22a74abcc2c210 alice 7$p2w e5de688c99e961ed6e560b972dab8b6a tim z5Sk9 1eee304b92dc0d105904e7ab58fd2f64 加盐的目的在于使黑客的彩虹表失效，即使用户使用常用口令，也无法从MD5反推原始口令。 SHA-1SHA-1也是一种哈希算法，它的输出是160 bits，即20字节。SHA-1是由美国国家安全局开发的，SHA算法实际上是一个系列，包括SHA-0（已废弃）、SHA-1、SHA-256、SHA-512等。 在Java中使用SHA-1，和MD5完全一样，只需要把算法名称改为&quot;SHA-1&quot;： 1234567891011public class Main &#123; public static void main(String[] args) throws Exception &#123; // 创建一个MessageDigest实例: MessageDigest md = MessageDigest.getInstance(\"SHA-1\"); // 反复调用update输入数据: md.update(\"Hello\".getBytes(\"UTF-8\")); md.update(\"World\".getBytes(\"UTF-8\")); byte[] result = md.digest(); // 20 bytes: db8ac1c259eb89d4a131b253bacfca5f319d54f2 System.out.println(new BigInteger(1, result).toString(16)); &#125;&#125; 类似的，计算SHA-256，我们需要传入名称&quot;SHA-256&quot;，计算SHA-512，我们需要传入名称&quot;SHA-512&quot;。Java标准库支持的所有哈希算法可以在这里查到。","categories":[],"tags":[{"name":"dataAlgorithm","slug":"dataAlgorithm","permalink":"https://kayleh.top/tags/dataAlgorithm/"}]},{"title":"插值查找算法","slug":"插值查找算法","date":"2020-06-17T01:18:21.000Z","updated":"2020-06-17T01:18:58.253Z","comments":true,"path":"2020/06/17/插值查找算法/","link":"","permalink":"https://kayleh.top/2020/06/17/%E6%8F%92%E5%80%BC%E6%9F%A5%E6%89%BE%E7%AE%97%E6%B3%95/","excerpt":"插值查找算法","text":"插值查找算法 12345678910111213141516171819202122232425262728293031323334/** * @Author: Wizard * @Date: 2020/6/17 9:06 */public class insertSearch &#123; /** * @param arr 数组 * @param left 左边的索引 * @param right 右边的索引 * @param findVal 要查找的值 * @return */ public static int insertValue(int[] arr, int left, int right, int findVal) &#123; System.out.println(\"插值查找次数...\"); //注意：findVal&lt;arr[0]和findVal&gt;arr[arr.length-1]必须需要 //否则得到的mid可能越界 if (left &gt; right || findVal &lt; arr[0] || findVal &gt; arr[arr.length - 1]) &#123; return -1; &#125; //求出mid,自适应 int mid = left + (right - left) * (findVal - arr[left] / arr[right] - arr[left]); int midVal = arr[mid]; if (findVal &gt; midVal) &#123; //应该向右递归 return insertValue(arr, mid + 1, right, findVal); &#125; else if (findVal &lt; midVal) &#123; return insertValue(arr, left, mid - 1, findVal); &#125; else &#123; return mid; &#125; &#125;&#125;","categories":[],"tags":[{"name":"dataAlgorithm","slug":"dataAlgorithm","permalink":"https://kayleh.top/tags/dataAlgorithm/"}]},{"title":"二分查找算法","slug":"二分查找算法","date":"2020-06-17T01:04:50.000Z","updated":"2020-06-17T01:17:21.808Z","comments":true,"path":"2020/06/17/二分查找算法/","link":"","permalink":"https://kayleh.top/2020/06/17/%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE%E7%AE%97%E6%B3%95/","excerpt":"二分查找算法","text":"二分查找算法 12345678910111213141516171819202122232425/** * 二分查找算法 * * @param arr 待查找的数组,arr是升序排序 * @param target 需要查找的数 * @return 返回对应的下标，-1表示没有 */ public static int binarySearch(int[] arr, int target) &#123; int left = 0; int right = arr.length - 1; while (left &lt;= right) &#123; //说明可以继续查找 int mid = (left + right) / 2; if (arr[mid] == target) &#123; return mid; &#125; else if (arr[mid] &gt; target) &#123; right = mid - 1;//需要向左边查找 &#125; else &#123; left = mid + 1;//需要向右边查找 &#125; &#125; return -1; &#125;","categories":[],"tags":[{"name":"dataAlgorithm","slug":"dataAlgorithm","permalink":"https://kayleh.top/tags/dataAlgorithm/"}]},{"title":"线性查找算法","slug":"线性查找算法","date":"2020-06-17T00:54:06.000Z","updated":"2020-06-17T01:00:56.756Z","comments":true,"path":"2020/06/17/线性查找算法/","link":"","permalink":"https://kayleh.top/2020/06/17/%E7%BA%BF%E6%80%A7%E6%9F%A5%E6%89%BE%E7%AE%97%E6%B3%95/","excerpt":"线性查找算法","text":"线性查找算法 有一个数列： {1,8, 10, 89, 1000, 1234} ，判断数列中是否包含此名称 【顺序查找】 要求: 如果找到了，就提示找到，并给出下标值。 12345678910111213141516171819/** * @Author: Wizard * @Date: 2020/6/17 8:57 */public class OrderSearch &#123; public static void main(String[] args) &#123; int[] arr = &#123;1, 8, 10, 89, 1000, 1234&#125;; System.out.println(OrderFind(arr, 10)); &#125; public static int OrderFind(int[] arr, int value) &#123; for (int i = 0; i &lt; arr.length - 1; i++) &#123; if (arr[i] == value) &#123; return i; &#125; &#125; return -1; &#125;&#125;","categories":[],"tags":[{"name":"dataAlgorithm","slug":"dataAlgorithm","permalink":"https://kayleh.top/tags/dataAlgorithm/"}]},{"title":"多线程","slug":"多线程","date":"2020-06-15T01:13:04.000Z","updated":"2020-06-16T13:47:08.940Z","comments":true,"path":"2020/06/15/多线程/","link":"","permalink":"https://kayleh.top/2020/06/15/%E5%A4%9A%E7%BA%BF%E7%A8%8B/","excerpt":"多线程","text":"多线程 一个线程的生命周期线程是一个动态执行的过程，它也有一个从产生到死亡的过程。 下图显示了一个线程完整的生命周期。 新建状态: 使用 new 关键字和 Thread 类或其子类建立一个线程对象后，该线程对象就处于新建状态。它保持这个状态直到程序 start() 这个线程。 就绪状态: 当线程对象调用了start()方法之后，该线程就进入就绪状态。就绪状态的线程处于就绪队列中，要等待JVM里线程调度器的调度。 运行状态: 如果就绪状态的线程获取 CPU 资源，就可以执行 run()，此时线程便处于运行状态。处于运行状态的线程最为复杂，它可以变为阻塞状态、就绪状态和死亡状态。 阻塞状态: 如果一个线程执行了sleep（睡眠）、suspend（挂起）等方法，失去所占用资源之后，该线程就从运行状态进入阻塞状态。在睡眠时间已到或获得设备资源后可以重新进入就绪状态。可以分为三种： 等待阻塞：运行状态中的线程执行 wait() 方法，使线程进入到等待阻塞状态。 同步阻塞：线程在获取 synchronized 同步锁失败(因为同步锁被其他线程占用)。 其他阻塞：通过调用线程的 sleep() 或 join() 发出了 I/O 请求时，线程就会进入到阻塞状态。当sleep() 状态超时，join() 等待线程终止或超时，或者 I/O 处理完毕，线程重新转入就绪状态。 死亡状态: 一个运行状态的线程完成任务或者其他终止条件发生时，该线程就切换到终止状态。 线程的优先级每一个 Java 线程都有一个优先级，这样有助于操作系统确定线程的调度顺序。 Java 线程的优先级是一个整数，其取值范围是 1 （Thread.MIN_PRIORITY ） - 10 （Thread.MAX_PRIORITY ）。 默认情况下，每一个线程都会分配一个优先级 NORM_PRIORITY（5）。 具有较高优先级的线程对程序更重要，并且应该在低优先级的线程之前分配处理器资源。但是，线程优先级不能保证线程执行的顺序，而且非常依赖于平台。 创建一个线程Java 提供了三种创建线程的方法： 通过实现 Runnable 接口； 通过继承 Thread 类本身； 通过 Callable 和 Future 创建线程。 通过实现 Runnable 接口来创建线程创建一个线程，最简单的方法是创建一个实现 Runnable 接口的类。 为了实现 Runnable，一个类只需要执行一个方法调用 run()，声明如下： 1public void run() 你可以重写该方法，重要的是理解的 run() 可以调用其他方法，使用其他类，并声明变量，就像主线程一样。 在创建一个实现 Runnable 接口的类之后，你可以在类中实例化一个线程对象。 Thread 定义了几个构造方法，下面的这个是我们经常使用的： 1Thread(Runnable threadOb,String threadName); 这里，threadOb 是一个实现 Runnable 接口的类的实例，并且 threadName 指定新线程的名字。 新线程创建之后，你调用它的 start() 方法它才会运行。 1void start(); 下面是一个创建线程并开始让它执行的实例： 编译以上程序运行结果如下： 12345678910111213141516Creating Thread-1Starting Thread-1Creating Thread-2Starting Thread-2Running Thread-1Thread: Thread-1, 4Running Thread-2Thread: Thread-2, 4Thread: Thread-1, 3Thread: Thread-2, 3Thread: Thread-1, 2Thread: Thread-2, 2Thread: Thread-1, 1Thread: Thread-2, 1Thread Thread-1 exiting.Thread Thread-2 exiting. 通过继承Thread来创建线程创建一个线程的第二种方法是创建一个新的类，该类继承 Thread 类，然后创建一个该类的实例。 继承类必须重写 run() 方法，该方法是新线程的入口点。它也必须调用 start() 方法才能执行。 该方法尽管被列为一种多线程实现方式，但是本质上也是实现了 Runnable 接口的一个实例。 编译以上程序运行结果如下： 12345678910111213141516Creating Thread-1Starting Thread-1Creating Thread-2Starting Thread-2Running Thread-1Thread: Thread-1, 4Running Thread-2Thread: Thread-2, 4Thread: Thread-1, 3Thread: Thread-2, 3Thread: Thread-1, 2Thread: Thread-2, 2Thread: Thread-1, 1Thread: Thread-2, 1Thread Thread-1 exiting.Thread Thread-2 exiting. Thread 方法下表列出了Thread类的一些重要方法： 序号 方法描述 1 public void start() 使该线程开始执行；Java 虚拟机调用该线程的 run 方法。 2 public void run() 如果该线程是使用独立的 Runnable 运行对象构造的，则调用该 Runnable 对象的 run 方法；否则，该方法不执行任何操作并返回。 3 public final void setName(String name) 改变线程名称，使之与参数 name 相同。 4 public final void setPriority(int priority) 更改线程的优先级。 5 public final void setDaemon(boolean on) 将该线程标记为守护线程或用户线程。 6 public final void join(long millisec) 等待该线程终止的时间最长为 millis 毫秒。 7 public void interrupt() 中断线程。 8 public final boolean isAlive() 测试线程是否处于活动状态。 测试线程是否处于活动状态。 上述方法是被Thread对象调用的。下面的方法是Thread类的静态方法。 序号 方法描述 1 public static void yield() 暂停当前正在执行的线程对象，并执行其他线程。 2 public static void sleep(long millisec) 在指定的毫秒数内让当前正在执行的线程休眠（暂停执行），此操作受到系统计时器和调度程序精度和准确性的影响。 3 public static boolean holdsLock(Object x) 当且仅当当前线程在指定的对象上保持监视器锁时，才返回 true。 4 public static Thread currentThread() 返回对当前正在执行的线程对象的引用。 5 public static void dumpStack() 将当前线程的堆栈跟踪打印至标准错误流。 实例如下的ThreadClassDemo 程序演示了Thread类的一些方法： 运行结果如下，每一次运行的结果都不一样。 1234567891011121314Starting hello thread...Starting goodbye thread...HelloHelloHelloHelloHelloHelloGoodbyeGoodbyeGoodbyeGoodbyeGoodbye....... 通过 Callable 和 Future 创建线程 创建 Callable 接口的实现类，并实现 call() 方法，该 call() 方法将作为线程执行体，并且有返回值。 创建 Callable 实现类的实例，使用 FutureTask 类来包装 Callable 对象，该 FutureTask 对象封装了该 Callable 对象的 call() 方法的返回值。 使用 FutureTask 对象作为 Thread 对象的 target 创建并启动新线程。 调用 FutureTask 对象的 get() 方法来获得子线程执行结束后的返回值。 创建线程的三种方式的对比 采用实现 Runnable、Callable 接口的方式创建多线程时，线程类只是实现了 Runnable 接口或 Callable 接口，还可以继承其他类。 使用继承 Thread 类的方式创建多线程时，编写简单，如果需要访问当前线程，则无需使用 Thread.currentThread() 方法，直接使用 this 即可获得当前线程。 多线程的使用有效利用多线程的关键是理解程序是并发执行而不是串行执行的。例如：程序中有两个子系统需要并发执行，这时候就需要利用多线程编程。 通过对多线程的使用，可以编写出非常高效的程序。不过请注意，如果你创建太多的线程，程序执行的效率实际上是降低了，而不是提升了。 请记住，上下文的切换开销也很重要，如果你创建了太多的线程，CPU 花费在上下文的切换的时间将多于执行程序的时间！","categories":[],"tags":[{"name":"Concurrency","slug":"Concurrency","permalink":"https://kayleh.top/tags/Concurrency/"}]},{"title":"模板方法","slug":"模板方法","date":"2020-06-13T09:22:53.000Z","updated":"2020-08-20T06:26:54.378Z","comments":true,"path":"2020/06/13/模板方法/","link":"","permalink":"https://kayleh.top/2020/06/13/%E6%A8%A1%E6%9D%BF%E6%96%B9%E6%B3%95/","excerpt":"模板方法 定义一个操作中的算法的骨架，而将一些步骤延迟到子类中，使得子类可以不改变一个算法的结构即可重定义该算法的某些特定步骤。","text":"模板方法 定义一个操作中的算法的骨架，而将一些步骤延迟到子类中，使得子类可以不改变一个算法的结构即可重定义该算法的某些特定步骤。 在模板模式（Template Pattern）中，一个抽象类公开定义了执行它的方法的方式/模板。它的子类可以按需要重写方法实现，但调用将以抽象类中定义的方式进行。这种类型的设计模式属于行为型模式。 介绍意图：定义一个操作中的算法的骨架，而将一些步骤延迟到子类中。模板方法使得子类可以不改变一个算法的结构即可重定义该算法的某些特定步骤。 主要解决：一些方法通用，却在每一个子类都重新写了这一方法。 何时使用：有一些通用的方法。 如何解决：将这些通用算法抽象出来。 关键代码：在抽象类实现，其他步骤在子类实现。 应用实例： 1、在造房子的时候，地基、走线、水管都一样，只有在建筑的后期才有加壁橱加栅栏等差异。 2、西游记里面菩萨定好的 81 难，这就是一个顶层的逻辑骨架。 3、spring 中对 Hibernate 的支持，将一些已经定好的方法封装起来，比如开启事务、获取 Session、关闭 Session 等，程序员不重复写那些已经规范好的代码，直接丢一个实体就可以保存。 优点： 1、封装不变部分，扩展可变部分。 2、提取公共代码，便于维护。 3、行为由父类控制，子类实现。 缺点：每一个不同的实现都需要一个子类来实现，导致类的个数增加，使得系统更加庞大。 使用场景： 1、有多个子类共有的方法，且逻辑相同。 2、重要的、复杂的方法，可以考虑作为模板方法。 注意事项：为防止恶意操作，一般模板方法都加上 final 关键词。 实现我们将创建一个定义操作的 Game 抽象类，其中，模板方法设置为 final，这样它就不会被重写。Cricket 和 Football 是扩展了 Game 的实体类，它们重写了抽象类的方法。 TemplatePatternDemo*，我们的演示类使用 *Game 来演示模板模式的用法。 步骤1创建一个抽象类，它的模板方法被设置为 final。 Game.java 123456789101112131415161718public abstract class Game &#123; abstract void initialize(); abstract void startPlay(); abstract void endPlay(); //模板 public final void play()&#123; //初始化游戏 initialize(); //开始游戏 startPlay(); //结束游戏 endPlay(); &#125;&#125; 步骤 2创建扩展了上述类的实体类。 Cricket.java 1234567891011121314151617public class Cricket extends Game &#123; @Override void endPlay() &#123; System.out.println(\"Cricket Game Finished!\"); &#125; @Override void initialize() &#123; System.out.println(\"Cricket Game Initialized! Start playing.\"); &#125; @Override void startPlay() &#123; System.out.println(\"Cricket Game Started. Enjoy the game!\"); &#125;&#125; Football.java 1234567891011121314151617public class Football extends Game &#123; @Override void endPlay() &#123; System.out.println(\"Football Game Finished!\"); &#125; @Override void initialize() &#123; System.out.println(\"Football Game Initialized! Start playing.\"); &#125; @Override void startPlay() &#123; System.out.println(\"Football Game Started. Enjoy the game!\"); &#125;&#125; 步骤 3使用 Game 的模板方法 play() 来演示游戏的定义方式。 TemplatePatternDemo.java 12345678910public class TemplatePatternDemo &#123; public static void main(String[] args) &#123; Game game = new Cricket(); game.play(); System.out.println(); game = new Football(); game.play(); &#125;&#125; 步骤 4执行程序，输出结果： 1234567Cricket Game Initialized! Start playing.Cricket Game Started. Enjoy the game!Cricket Game Finished!Football Game Initialized! Start playing.Football Game Started. Enjoy the game!Football Game Finished!","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://kayleh.top/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"DesignPatterns","slug":"DesignPatterns","permalink":"https://kayleh.top/tags/DesignPatterns/"}]},{"title":"访问者模式","slug":"访问者模式","date":"2020-06-13T09:22:33.000Z","updated":"2020-06-13T10:47:39.484Z","comments":true,"path":"2020/06/13/访问者模式/","link":"","permalink":"https://kayleh.top/2020/06/13/%E8%AE%BF%E9%97%AE%E8%80%85%E6%A8%A1%E5%BC%8F/","excerpt":"访问者 表示一个作用于某对象结构中的各元素的操作。它使你可以在不改变各元素的类的前提下定义作用于这些元素的新操作。","text":"访问者 表示一个作用于某对象结构中的各元素的操作。它使你可以在不改变各元素的类的前提下定义作用于这些元素的新操作。 访问者模式在访问者模式（Visitor Pattern）中，我们使用了一个访问者类，它改变了元素类的执行算法。通过这种方式，元素的执行算法可以随着访问者改变而改变。这种类型的设计模式属于行为型模式。根据模式，元素对象已接受访问者对象，这样访问者对象就可以处理元素对象上的操作。 介绍意图：主要将数据结构与数据操作分离。 主要解决：稳定的数据结构和易变的操作耦合问题。 何时使用：需要对一个对象结构中的对象进行很多不同的并且不相关的操作，而需要避免让这些操作”污染”这些对象的类，使用访问者模式将这些封装到类中。 如何解决：在被访问的类里面加一个对外提供接待访问者的接口。 关键代码：在数据基础类里面有一个方法接受访问者，将自身引用传入访问者。 应用实例：您在朋友家做客，您是访问者，朋友接受您的访问，您通过朋友的描述，然后对朋友的描述做出一个判断，这就是访问者模式。 优点： 1、符合单一职责原则。 2、优秀的扩展性。 3、灵活性。 缺点： 1、具体元素对访问者公布细节，违反了迪米特原则。 2、具体元素变更比较困难。 3、违反了依赖倒置原则，依赖了具体类，没有依赖抽象。 使用场景： 1、对象结构中对象对应的类很少改变，但经常需要在此对象结构上定义新的操作。 2、需要对一个对象结构中的对象进行很多不同的并且不相关的操作，而需要避免让这些操作”污染”这些对象的类，也不希望在增加新操作时修改这些类。 注意事项：访问者可以对功能进行统一，可以做报表、UI、拦截器与过滤器。 实现我们将创建一个定义接受操作的 ComputerPart 接口。Keyboard、Mouse、Monitor 和 Computer 是实现了 ComputerPart 接口的实体类。我们将定义另一个接口 ComputerPartVisitor，它定义了访问者类的操作。Computer 使用实体访问者来执行相应的动作。 VisitorPatternDemo，我们的演示类使用 *Computer、*ComputerPartVisitor 类来演示访问者模式的用法。 步骤 1定义一个表示元素的接口。 ComputerPart.java 123public interface ComputerPart &#123; public void accept(ComputerPartVisitor computerPartVisitor);&#125; 步骤 2创建扩展了上述类的实体类。 Keyboard.java 1234567public class Keyboard implements ComputerPart &#123; @Override public void accept(ComputerPartVisitor computerPartVisitor) &#123; computerPartVisitor.visit(this); &#125;&#125; Monitor.java 1234567public class Monitor implements ComputerPart &#123; @Override public void accept(ComputerPartVisitor computerPartVisitor) &#123; computerPartVisitor.visit(this); &#125;&#125; Mouse.java 1234567public class Mouse implements ComputerPart &#123; @Override public void accept(ComputerPartVisitor computerPartVisitor) &#123; computerPartVisitor.visit(this); &#125;&#125; Computer.java 1234567891011121314151617public class Computer implements ComputerPart &#123; ComputerPart[] parts; public Computer()&#123; parts = new ComputerPart[] &#123;new Mouse(), new Keyboard(), new Monitor()&#125;; &#125; @Override public void accept(ComputerPartVisitor computerPartVisitor) &#123; for (int i = 0; i &lt; parts.length; i++) &#123; parts[i].accept(computerPartVisitor); &#125; computerPartVisitor.visit(this); &#125;&#125; 步骤 3定义一个表示访问者的接口。 ComputerPartVisitor.java 123456public interface ComputerPartVisitor &#123; public void visit(Computer computer); public void visit(Mouse mouse); public void visit(Keyboard keyboard); public void visit(Monitor monitor);&#125; 步骤 4创建实现了上述类的实体访问者。 ComputerPartDisplayVisitor.java 12345678910111213141516171819202122public class ComputerPartDisplayVisitor implements ComputerPartVisitor &#123; @Override public void visit(Computer computer) &#123; System.out.println(\"Displaying Computer.\"); &#125; @Override public void visit(Mouse mouse) &#123; System.out.println(\"Displaying Mouse.\"); &#125; @Override public void visit(Keyboard keyboard) &#123; System.out.println(\"Displaying Keyboard.\"); &#125; @Override public void visit(Monitor monitor) &#123; System.out.println(\"Displaying Monitor.\"); &#125;&#125; 步骤 5使用 ComputerPartDisplayVisitor 来显示 Computer 的组成部分。 VisitorPatternDemo.java 1234567public class VisitorPatternDemo &#123; public static void main(String[] args) &#123; ComputerPart computer = new Computer(); computer.accept(new ComputerPartDisplayVisitor()); &#125;&#125; 步骤 6执行程序，输出结果： 1234Displaying Mouse.Displaying Keyboard.Displaying Monitor.Displaying Computer.","categories":[],"tags":[{"name":"DesignPatterns","slug":"DesignPatterns","permalink":"https://kayleh.top/tags/DesignPatterns/"}]},{"title":"策略模式","slug":"策略模式","date":"2020-06-13T09:17:47.000Z","updated":"2020-06-13T09:21:11.548Z","comments":true,"path":"2020/06/13/策略模式/","link":"","permalink":"https://kayleh.top/2020/06/13/%E7%AD%96%E7%95%A5%E6%A8%A1%E5%BC%8F/","excerpt":"策略 定义一系列的算法，把它们一个个封装起来，并且使它们可相互替换。本模式使得算法可独立于使用它的客户而变化。","text":"策略 定义一系列的算法，把它们一个个封装起来，并且使它们可相互替换。本模式使得算法可独立于使用它的客户而变化。 策略模式：Strategy，是指，定义一组算法，并把其封装到一个对象中。然后在运行时，可以灵活的使用其中的一个算法。 策略模式在Java标准库中应用非常广泛，我们以排序为例，看看如何通过Arrays.sort()实现忽略大小写排序： 12345678import java.util.Arrays; `public class Main &#123; public static void main(String[] args) throws InterruptedException &#123; String[] array = &#123; \"apple\", \"Pear\", \"Banana\", \"orange\" &#125;; Arrays.sort(array, String::compareToIgnoreCase); System.out.println(Arrays.toString(array)); &#125;&#125; 如果我们想忽略大小写排序，就传入String::compareToIgnoreCase，如果我们想倒序排序，就传入(s1, s2) -&gt; -s1.compareTo(s2)，这个比较两个元素大小的算法就是策略。 我们观察Arrays.sort(T[] a, Comparator c)这个排序方法，它在内部实现了TimSort排序，但是，排序算法在比较两个元素大小的时候，需要借助我们传入的Comparator对象，才能完成比较。因此，这里的策略是指比较两个元素大小的策略，可以是忽略大小写比较，可以是倒序比较，也可以根据字符串长度比较。 因此，上述排序使用到了策略模式，它实际上指，在一个方法中，流程是确定的，但是，某些关键步骤的算法依赖调用方传入的策略，这样，传入不同的策略，即可获得不同的结果，大大增强了系统的灵活性。 如果我们自己实现策略模式的排序，用冒泡法编写如下： 12345678910111213141516171819public class Main &#123; public static void main(String[] args) throws InterruptedException &#123; String[] array = &#123; \"apple\", \"Pear\", \"Banana\", \"orange\" &#125;; sort(array, String::compareToIgnoreCase); System.out.println(Arrays.toString(array)); &#125; static &lt;T&gt; void sort(T[] a, Comparator&lt;? super T&gt; c) &#123; for (int i = 0; i &lt; a.length - 1; i++) &#123; for (int j = 0; j &lt; a.length - 1 - i; j++) &#123; if (c.compare(a[j], a[j + 1]) &gt; 0) &#123; // 注意这里比较两个元素的大小依赖传入的策略 T temp = a[j]; a[j] = a[j + 1]; a[j + 1] = temp; &#125; &#125; &#125; &#125;&#125; 一个完整的策略模式要定义策略以及使用策略的上下文。我们以购物车结算为例，假设网站针对普通会员、Prime会员有不同的折扣，同时活动期间还有一个满100减20的活动，这些就可以作为策略实现。先定义打折策略接口： 1234public interface DiscountStrategy &#123; // 计算折扣额度: BigDecimal getDiscount(BigDecimal total);&#125; 接下来，就是实现各种策略。普通用户策略如下： 123456public class UserDiscountStrategy implements DiscountStrategy &#123; public BigDecimal getDiscount(BigDecimal total) &#123; // 普通会员打九折: return total.multiply(new BigDecimal(\"0.1\")).setScale(2, RoundingMode.DOWN); &#125;&#125; 满减策略如下： 123456public class OverDiscountStrategy implements DiscountStrategy &#123; public BigDecimal getDiscount(BigDecimal total) &#123; // 满100减20优惠: return total.compareTo(BigDecimal.valueOf(100)) &gt;= 0 ? BigDecimal.valueOf(20) : BigDecimal.ZERO; &#125;&#125; 最后，要应用策略，我们需要一个DiscountContext： 12345678910111213public class DiscountContext &#123; // 持有某个策略: private DiscountStrategy strategy = new UserDiscountStrategy(); // 允许客户端设置新策略: public void setStrategy(DiscountStrategy strategy) &#123; this.strategy = strategy; &#125; public BigDecimal calculatePrice(BigDecimal total) &#123; return total.subtract(this.strategy.getDiscount(total)).setScale(2); &#125;&#125; 调用方必须首先创建一个DiscountContext，并指定一个策略（或者使用默认策略），即可获得折扣后的价格： 123456789101112131415DiscountContext ctx = new DiscountContext();// 默认使用普通会员折扣:BigDecimal pay1 = ctx.calculatePrice(BigDecimal.valueOf(105));System.out.println(pay1);// 使用满减折扣:ctx.setStrategy(new OverDiscountStrategy());BigDecimal pay2 = ctx.calculatePrice(BigDecimal.valueOf(105));System.out.println(pay2);// 使用Prime会员折扣:ctx.setStrategy(new PrimeDiscountStrategy());BigDecimal pay3 = ctx.calculatePrice(BigDecimal.valueOf(105));System.out.println(pay3); 上述完整的策略模式如下图所示： 12345678910111213┌───────────────┐ ┌─────────────────┐│DiscountContext│─ ─ ─&gt;│DiscountStrategy │└───────────────┘ └─────────────────┘ ▲ │ ┌─────────────────────┐ ├─│UserDiscountStrategy │ │ └─────────────────────┘ │ ┌─────────────────────┐ ├─│PrimeDiscountStrategy│ │ └─────────────────────┘ │ ┌─────────────────────┐ └─│OverDiscountStrategy │ └─────────────────────┘ 策略模式的核心思想是在一个计算方法中把容易变化的算法抽出来作为“策略”参数传进去，从而使得新增策略不必修改原有逻辑。","categories":[],"tags":[{"name":"DesignPatterns","slug":"DesignPatterns","permalink":"https://kayleh.top/tags/DesignPatterns/"}]},{"title":"状态模式","slug":"状态模式","date":"2020-06-13T08:14:10.000Z","updated":"2020-08-20T06:29:23.611Z","comments":true,"path":"2020/06/13/状态模式/","link":"","permalink":"https://kayleh.top/2020/06/13/%E7%8A%B6%E6%80%81%E6%A8%A1%E5%BC%8F/","excerpt":"状态 允许一个对象在其内部状态改变时改变它的行为。对象看起来似乎修改了它的类。","text":"状态 允许一个对象在其内部状态改变时改变它的行为。对象看起来似乎修改了它的类。 状态模式（State）经常用在带有状态的对象中。 什么是状态？我们以QQ聊天为例，一个用户的QQ有几种状态： 离线状态（尚未登录）； 正在登录状态； 在线状态； 忙状态（暂时离开）。 如何表示状态？我们定义一个enum就可以表示不同的状态。但不同的状态需要对应不同的行为，比如收到消息时： 12345if (state == ONLINE) &#123; // 闪烁图标&#125; else if (state == BUSY) &#123; reply(\"现在忙，稍后回复\");&#125; else if ... 状态模式的目的是为了把上述一大串if...else...的逻辑给分拆到不同的状态类中，使得将来增加状态比较容易。 例如，我们设计一个聊天机器人，它有两个状态： 未连线； 已连线。 对于未连线状态，我们收到消息也不回复： 123456789public class DisconnectedState implements State &#123; public String init() &#123; return \"Bye!\"; &#125; public String reply(String input) &#123; return \"\"; &#125;&#125; 对于已连线状态，我们回应收到的消息： 123456789101112131415public class ConnectedState implements State &#123; public String init() &#123; return \"Hello, I'm Bob.\"; &#125; public String reply(String input) &#123; if (input.endsWith(\"?\")) &#123; return \"Yes. \" + input.substring(0, input.length() - 1) + \"!\"; &#125; if (input.endsWith(\".\")) &#123; return input.substring(0, input.length() - 1) + \"!\"; &#125; return input.substring(0, input.length() - 1) + \"?\"; &#125;&#125; 状态模式的关键设计思想在于状态切换，我们引入一个BotContext完成状态切换： 12345678910111213141516public class BotContext &#123; private State state = new DisconnectedState(); public String chat(String input) &#123; if (\"hello\".equalsIgnoreCase(input)) &#123; // 收到hello切换到在线状态: state = new ConnectedState(); return state.init(); &#125; else if (\"bye\".equalsIgnoreCase(input)) &#123; / 收到bye切换到离线状态: state = new DisconnectedState(); return state.init(); &#125; return state.reply(input); &#125;&#125; 这样，一个价值千万的AI聊天机器人就诞生了： 12345678Scanner scanner = new Scanner(System.in);BotContext bot = new BotContext();for (;;) &#123; System.out.print(\"&gt; \"); String input = scanner.nextLine(); String output = bot.chat(input); System.out.println(output.isEmpty() ? \"(no reply)\" : \"&lt; \" + output);&#125; 试试效果： 12345678&gt; hello&lt; Hello, I'm Bob.&gt; Nice to meet you.&lt; Nice to meet you!&gt; Today is cold?&lt; Yes. Today is cold!&gt; bye&lt; Bye!","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://kayleh.top/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"DesignPatterns","slug":"DesignPatterns","permalink":"https://kayleh.top/tags/DesignPatterns/"}]},{"title":"观察者模式","slug":"观察者模式","date":"2020-06-13T08:07:09.000Z","updated":"2020-06-13T08:11:49.749Z","comments":true,"path":"2020/06/13/观察者模式/","link":"","permalink":"https://kayleh.top/2020/06/13/%E8%A7%82%E5%AF%9F%E8%80%85%E6%A8%A1%E5%BC%8F/","excerpt":"观察者 定义对象间的一种一对多的依赖关系，当一个对象的状态发生改变时，所有依赖于它的对象都得到通知并被自动更新。","text":"观察者 定义对象间的一种一对多的依赖关系，当一个对象的状态发生改变时，所有依赖于它的对象都得到通知并被自动更新。 观察者模式（Observer）又称发布-订阅模式（Publish-Subscribe：Pub/Sub）。它是一种通知机制，让发送通知的一方（被观察方）和接收通知的一方（观察者）能彼此分离，互不影响。 要理解观察者模式，我们还是看例子。 假设一个电商网站，有多种Product（商品），同时，Customer（消费者）和Admin（管理员）对商品上架、价格改变都感兴趣，希望能第一时间获得通知。于是，Store（商场）可以这么写： 123456789101112131415161718192021222324public class Store &#123; Customer customer; Admin admin; private Map&lt;String, Product&gt; products = new HashMap&lt;&gt;(); public void addNewProduct(String name, double price) &#123; Product p = new Product(name, price); products.put(p.getName(), p); // 通知用户: customer.onPublished(p); // 通知管理员: admin.onPublished(p); &#125; public void setProductPrice(String name, double price) &#123; Product p = products.get(name); p.setPrice(price); // 通知用户: customer.onPriceChanged(p); // 通知管理员: admin.onPriceChanged(p); &#125;&#125; 我们观察上述Store类的问题：它直接引用了Customer和Admin。先不考虑多个Customer或多个Admin的问题，上述Store类最大的问题是，如果要加一个新的观察者类型，例如工商局管理员，Store类就必须继续改动。 因此，上述问题的本质是Store希望发送通知给那些关心Product的对象，但Store并不想知道这些人是谁。观察者模式就是要分离被观察者和观察者之间的耦合关系。 要实现这一目标也很简单，Store不能直接引用Customer和Admin，相反，它引用一个ProductObserver接口，任何人想要观察Store，只要实现该接口，并且把自己注册到Store即可： 12345678910111213141516171819202122232425262728public class Store &#123; private List&lt;ProductObserver&gt; observers = new ArrayList&lt;&gt;(); private Map&lt;String, Product&gt; products = new HashMap&lt;&gt;(); // 注册观察者: public void addObserver(ProductObserver observer) &#123; this.observers.add(observer); &#125; // 取消注册: public void removeObserver(ProductObserver observer) &#123; this.observers.remove(observer); &#125; public void addNewProduct(String name, double price) &#123; Product p = new Product(name, price); products.put(p.getName(), p); // 通知观察者: observers.forEach(o -&gt; o.onPublished(p)); &#125; public void setProductPrice(String name, double price) &#123; Product p = products.get(name); p.setPrice(price); // 通知观察者: observers.forEach(o -&gt; o.onPriceChanged(p)); &#125;&#125; 就是这么一个小小的改动，使得观察者类型就可以无限扩充，而且，观察者的定义可以放到客户端： 12345678// observer:Admin a = new Admin();Customer c = new Customer();// store:Store store = new Store();// 注册观察者:store.addObserver(a);store.addObserver(c); 甚至可以注册匿名观察者： 123456789store.addObserver(new ProductObserver() &#123; public void onPublished(Product product) &#123; System.out.println(\"[Log] on product published: \" + product); &#125; public void onPriceChanged(Product product) &#123; System.out.println(\"[Log] on product price changed: \" + product); &#125;&#125;); 用一张图画出观察者模式： 12345678910┌─────────┐ ┌───────────────┐│ Store │─ ─ ─&gt;│ProductObserver│└─────────┘ └───────────────┘ │ ▲ │ │ ┌─────┴─────┐ ▼ │ │┌─────────┐ ┌─────────┐ ┌─────────┐│ Product │ │ Admin │ │Customer │ ...└─────────┘ └─────────┘ └─────────┘ 观察者模式也有很多变体形式。有的观察者模式把被观察者也抽象出接口： 1234public interface ProductObservable &#123; // 注意此处拼写是Observable不是Observer! void addObserver(ProductObserver observer); void removeObserver(ProductObserver observer);&#125; 对应的实体被观察者就要实现该接口： 123public class Store implements ProductObservable &#123; ...&#125; 有些观察者模式把通知变成一个Event对象，从而不再有多种方法通知，而是统一成一种： 123public interface ProductObserver &#123; void onEvent(ProductEvent event);&#125; 让观察者自己从Event对象中读取通知类型和通知数据。 广义的观察者模式包括所有消息系统。所谓消息系统，就是把观察者和被观察者完全分离，通过消息系统本身来通知： 12345678910111213 ┌ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ┐ Messaging System │ │ ┌──────────────────┐ ┌──┼&gt;│Topic:newProduct │──┼─┐ ┌─────────┐ │ └──────────────────┘ ├───&gt;│ConsumerA│┌─────────┐ │ │ ┌──────────────────┐ │ │ └─────────┘│Producer │───┼───&gt;│Topic:priceChanged│────┘└─────────┘ │ │ └──────────────────┘ │ │ ┌──────────────────┐ ┌─────────┐ └──┼&gt;│Topic:soldOut │──┼─────&gt;│ConsumerB│ └──────────────────┘ └─────────┘ └ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ┘ 消息发送方称为Producer，消息接收方称为Consumer，Producer发送消息的时候，必须选择发送到哪个Topic。Consumer可以订阅自己感兴趣的Topic，从而只获得特定类型的消息。 使用消息系统实现观察者模式时，Producer和Consumer甚至经常不在同一台机器上，并且双方对对方完全一无所知，因为注册观察者这个动作本身都在消息系统中完成，而不是在Producer内部完成。 此外，注意到我们在编写观察者模式的时候，通知Observer是依靠语句： 1observers.forEach(o -&gt; o.onPublished(p)); 这说明各个观察者是依次获得的同步通知，如果上一个观察者处理太慢，会导致下一个观察者不能及时获得通知。此外，如果观察者在处理通知的时候，发生了异常，还需要被观察者处理异常，才能保证继续通知下一个观察者。 思考：如何改成异步通知，使得所有观察者可以并发同时处理？ 有的童鞋可能发现Java标准库有个java.util.Observable类和一个Observer接口，用来帮助我们实现观察者模式。但是，这个类非常不！好！用！实现观察者模式的时候，也不推荐借助这两个东东。","categories":[],"tags":[{"name":"DesignPatterns","slug":"DesignPatterns","permalink":"https://kayleh.top/tags/DesignPatterns/"}]},{"title":"备忘录模式","slug":"备忘录模式","date":"2020-06-13T07:20:47.000Z","updated":"2020-06-13T07:23:32.686Z","comments":true,"path":"2020/06/13/备忘录模式/","link":"","permalink":"https://kayleh.top/2020/06/13/%E5%A4%87%E5%BF%98%E5%BD%95%E6%A8%A1%E5%BC%8F/","excerpt":"备忘录模式 在不破坏封装性的前提下，捕获一个对象的内部状态，并在该对象之外保存这个状态。","text":"备忘录模式 在不破坏封装性的前提下，捕获一个对象的内部状态，并在该对象之外保存这个状态。 备忘录模式（Memento），主要用于捕获一个对象的内部状态，以便在将来的某个时候恢复此状态。 其实我们使用的几乎所有软件都用到了备忘录模式。最简单的备忘录模式就是保存到文件，打开文件。对于文本编辑器来说，保存就是把TextEditor类的字符串存储到文件，打开就是恢复TextEditor类的状态。对于图像编辑器来说，原理是一样的，只是保存和恢复的数据格式比较复杂而已。Java的序列化也可以看作是备忘录模式。 在使用文本编辑器的时候，我们还经常使用Undo、Redo这些功能。这些其实也可以用备忘录模式实现，即不定期地把TextEditor类的字符串复制一份存起来，这样就可以Undo或Redo。 标准的备忘录模式有这么几种角色： Memonto：存储的内部状态； Originator：创建一个备忘录并设置其状态； Caretaker：负责保存备忘录。 实际上我们在使用备忘录模式的时候，不必设计得这么复杂，只需要对类似TextEditor的类，增加getState()和setState()就可以了。 我们以一个文本编辑器TextEditor为例，它内部使用StringBuilder允许用户增删字符： 1234567891011121314151617public class TextEditor &#123; private StringBuilder buffer = new StringBuilder(); public void add(char ch) &#123; buffer.append(ch); &#125; public void add(String s) &#123; buffer.append(s); &#125; public void delete() &#123; if (buffer.length() &gt; 0) &#123; buffer.deleteCharAt(buffer.length() - 1); &#125; &#125;&#125; 为了支持这个TextEditor能保存和恢复状态，我们增加getState()和setState()两个方法： 1234567891011121314public class TextEditor &#123; ... // 获取状态: public String getState() &#123; return buffer.toString(); &#125; // 恢复状态: public void setState(String state) &#123; this.buffer.delete(0, this.buffer.length()); this.buffer.append(state); &#125;&#125; 对这个简单的文本编辑器，用一个String就可以表示其状态，对于复杂的对象模型，通常我们会使用JSON、XML等复杂格式。","categories":[],"tags":[{"name":"DesignPatterns","slug":"DesignPatterns","permalink":"https://kayleh.top/tags/DesignPatterns/"}]},{"title":"中介者模式","slug":"中介者模式","date":"2020-06-13T06:46:55.000Z","updated":"2020-08-20T06:29:15.001Z","comments":true,"path":"2020/06/13/中介者模式/","link":"","permalink":"https://kayleh.top/2020/06/13/%E4%B8%AD%E4%BB%8B%E8%80%85%E6%A8%A1%E5%BC%8F/","excerpt":"中介者模式 中介者模式（Mediator Pattern）是用来降低多个对象和类之间的通信复杂性。这种模式提供了一个中介类，该类通常处理不同类之间的通信，并支持松耦合，使代码易于维护。中介者模式属于行为型模式。","text":"中介者模式 中介者模式（Mediator Pattern）是用来降低多个对象和类之间的通信复杂性。这种模式提供了一个中介类，该类通常处理不同类之间的通信，并支持松耦合，使代码易于维护。中介者模式属于行为型模式。 介绍意图：用一个中介对象来封装一系列的对象交互，中介者使各对象不需要显式地相互引用，从而使其耦合松散，而且可以独立地改变它们之间的交互。 主要解决：对象与对象之间存在大量的关联关系，这样势必会导致系统的结构变得很复杂，同时若一个对象发生改变，我们也需要跟踪与之相关联的对象，同时做出相应的处理。 何时使用：多个类相互耦合，形成了网状结构。 如何解决：将上述网状结构分离为星型结构。 关键代码：对象 Colleague 之间的通信封装到一个类中单独处理。 应用实例： 1、中国加入 WTO 之前是各个国家相互贸易，结构复杂，现在是各个国家通过 WTO 来互相贸易。 2、机场调度系统。 3、MVC 框架，其中C（控制器）就是 M（模型）和 V（视图）的中介者。 优点： 1、降低了类的复杂度，将一对多转化成了一对一。 2、各个类之间的解耦。 3、符合迪米特原则。 缺点：中介者会庞大，变得复杂难以维护。 使用场景： 1、系统中对象之间存在比较复杂的引用关系，导致它们之间的依赖关系结构混乱而且难以复用该对象。 2、想通过一个中间类来封装多个类中的行为，而又不想生成太多的子类。 注意事项：不应当在职责混乱的时候使用。 实现我们通过聊天室实例来演示中介者模式。实例中，多个用户可以向聊天室发送消息，聊天室向所有的用户显示消息。我们将创建两个类 ChatRoom 和 User。User 对象使用 ChatRoom 方法来分享他们的消息。 MediatorPatternDemo*，我们的演示类使用 *User 对象来显示他们之间的通信。 步骤 1创建中介类。 ChatRoom.java 步骤 2创建 user 类。 User.java 步骤 3使用 User 对象来显示他们之间的通信。 MediatorPatternDemo.java 步骤 4执行程序，输出结果： 12Thu Jan 31 16:05:46 IST 2013 [Robert] : Hi! John!Thu Jan 31 16:05:46 IST 2013 [John] : Hello! Robert!","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://kayleh.top/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"DesignPatterns","slug":"DesignPatterns","permalink":"https://kayleh.top/tags/DesignPatterns/"}]},{"title":"迭代器模式","slug":"迭代器模式","date":"2020-06-13T05:26:48.000Z","updated":"2020-06-13T05:29:25.593Z","comments":true,"path":"2020/06/13/迭代器模式/","link":"","permalink":"https://kayleh.top/2020/06/13/%E8%BF%AD%E4%BB%A3%E5%99%A8%E6%A8%A1%E5%BC%8F/","excerpt":"迭代器 提供一种方法顺序访问一个聚合对象中的各个元素，而又不需要暴露该对象的内部表示。","text":"迭代器 提供一种方法顺序访问一个聚合对象中的各个元素，而又不需要暴露该对象的内部表示。 迭代器模式（Iterator）实际上在Java的集合类中已经广泛使用了。我们以List为例，要遍历ArrayList，即使我们知道它的内部存储了一个Object[]数组，也不应该直接使用数组索引去遍历，因为这样需要了解集合内部的存储结构。如果使用Iterator遍历，那么，ArrayList和LinkedList都可以以一种统一的接口来遍历： 1234List&lt;String&gt; list = ...for (Iterator&lt;String&gt; it = list.iterator(); it.hasNext(); ) &#123; String s = it.next();&#125; 实际上，因为Iterator模式十分有用，因此，Java允许我们直接把任何支持Iterator的集合对象用foreach循环写出来： 1234List&lt;String&gt; list = ...for (String s : list) &#123;&#125; 然后由Java编译器完成Iterator模式的所有循环代码。 虽然我们对如何使用Iterator有了一定了解，但如何实现一个Iterator模式呢？我们以一个自定义的集合为例，通过Iterator模式实现倒序遍历： 123456789101112public class ReverseArrayCollection&lt;T&gt; implements Iterable&lt;T&gt; &#123; // 以数组形式持有集合: private T[] array; public ReverseArrayCollection(T... objs) &#123; this.array = Arrays.copyOfRange(objs, 0, objs.length); &#125; public Iterator&lt;T&gt; iterator() &#123; return ???; &#125;&#125; 实现Iterator模式的关键是返回一个Iterator对象，该对象知道集合的内部结构，因为它可以实现倒序遍历。我们使用Java的内部类实现这个Iterator： 1234567891011121314151617181920212223242526272829303132public class ReverseArrayCollection&lt;T&gt; implements Iterable&lt;T&gt; &#123; private T[] array; public ReverseArrayCollection(T... objs) &#123; this.array = Arrays.copyOfRange(objs, 0, objs.length); &#125; public Iterator&lt;T&gt; iterator() &#123; return new ReverseIterator(); &#125; class ReverseIterator implements Iterator&lt;T&gt; &#123; // 索引位置: int index; public ReverseIterator() &#123; // 创建Iterator时,索引在数组末尾: this.index = ReverseArrayCollection.this.array.length; &#125; public boolean hasNext() &#123; // 如果索引大于0,那么可以移动到下一个元素(倒序往前移动): return index &gt; 0; &#125; public T next() &#123; // 将索引移动到下一个元素并返回(倒序往前移动): index--; return array[index]; &#125; &#125;&#125; 使用内部类的好处是内部类隐含地持有一个它所在对象的this引用，可以通过ReverseArrayCollection.this引用到它所在的集合。上述代码实现的逻辑非常简单，但是实际应用时，如果考虑到多线程访问，当一个线程正在迭代某个集合，而另一个线程修改了集合的内容时，是否能继续安全地迭代，还是抛出ConcurrentModificationException，就需要更仔细地设计。","categories":[],"tags":[{"name":"DesignPatterns","slug":"DesignPatterns","permalink":"https://kayleh.top/tags/DesignPatterns/"}]},{"title":"解释器模式","slug":"解释器模式","date":"2020-06-12T13:31:18.000Z","updated":"2020-06-13T05:26:03.274Z","comments":true,"path":"2020/06/12/解释器模式/","link":"","permalink":"https://kayleh.top/2020/06/12/%E8%A7%A3%E9%87%8A%E5%99%A8%E6%A8%A1%E5%BC%8F/","excerpt":"解释器模式 解释器模式（Interpreter Pattern）提供了评估语言的语法或表达式的方式，它属于行为型模式。这种模式实现了一个表达式接口，该接口解释一个特定的上下文。这种模式被用在 SQL 解析、符号处理引擎等。","text":"解释器模式 解释器模式（Interpreter Pattern）提供了评估语言的语法或表达式的方式，它属于行为型模式。这种模式实现了一个表达式接口，该接口解释一个特定的上下文。这种模式被用在 SQL 解析、符号处理引擎等。 介绍意图：给定一个语言，定义它的文法表示，并定义一个解释器，这个解释器使用该标识来解释语言中的句子。 主要解决：对于一些固定文法构建一个解释句子的解释器。 何时使用：如果一种特定类型的问题发生的频率足够高，那么可能就值得将该问题的各个实例表述为一个简单语言中的句子。这样就可以构建一个解释器，该解释器通过解释这些句子来解决该问题。 如何解决：构建语法树，定义终结符与非终结符。 关键代码：构建环境类，包含解释器之外的一些全局信息，一般是 HashMap。 应用实例：编译器、运算表达式计算。 优点： 1、可扩展性比较好，灵活。 2、增加了新的解释表达式的方式。 3、易于实现简单文法。 缺点： 1、可利用场景比较少。 2、对于复杂的文法比较难维护。 3、解释器模式会引起类膨胀。 4、解释器模式采用递归调用方法。 使用场景： 1、可以将一个需要解释执行的语言中的句子表示为一个抽象语法树。 2、一些重复出现的问题可以用一种简单的语言来进行表达。 3、一个简单语法需要解释的场景。 注意事项：可利用场景比较少，JAVA 中如果碰到可以用 expression4J 代替。 实现我们将创建一个接口 Expression 和实现了 Expression 接口的实体类。定义作为上下文中主要解释器的 TerminalExpression 类。其他的类 OrExpression、AndExpression 用于创建组合式表达式。 InterpreterPatternDemo*，我们的演示类使用 *Expression 类创建规则和演示表达式的解析。 步骤 1创建一个表达式接口。 步骤 2创建实现了上述接口的实体类。 步骤 3InterpreterPatternDemo 使用 Expression 类来创建规则，并解析它们。 步骤 4执行程序，输出结果： 12John is male? trueJulie is a married women? true","categories":[],"tags":[{"name":"DesignPatterns","slug":"DesignPatterns","permalink":"https://kayleh.top/tags/DesignPatterns/"}]},{"title":"命令模式","slug":"命令模式","date":"2020-06-12T10:12:06.000Z","updated":"2020-08-20T06:26:45.649Z","comments":true,"path":"2020/06/12/命令模式/","link":"","permalink":"https://kayleh.top/2020/06/12/%E5%91%BD%E4%BB%A4%E6%A8%A1%E5%BC%8F/","excerpt":"命令模式 命令模式（Command Pattern）是一种数据驱动的设计模式，它属于行为型模式。请求以命令的形式包裹在对象中，并传给调用对象。调用对象寻找可以处理该命令的合适的对象，并把该命令传给相应的对象，该对象执行命令。","text":"命令模式 命令模式（Command Pattern）是一种数据驱动的设计模式，它属于行为型模式。请求以命令的形式包裹在对象中，并传给调用对象。调用对象寻找可以处理该命令的合适的对象，并把该命令传给相应的对象，该对象执行命令。 介绍意图：将一个请求封装成一个对象，从而使您可以用不同的请求对客户进行参数化。 主要解决：在软件系统中，行为请求者与行为实现者通常是一种紧耦合的关系，但某些场合，比如需要对行为进行记录、撤销或重做、事务等处理时，这种无法抵御变化的紧耦合的设计就不太合适。 何时使用：在某些场合，比如要对行为进行”记录、撤销/重做、事务”等处理，这种无法抵御变化的紧耦合是不合适的。在这种情况下，如何将”行为请求者”与”行为实现者”解耦？将一组行为抽象为对象，可以实现二者之间的松耦合。 如何解决：通过调用者调用接受者执行命令，顺序：调用者→接受者→命令。 关键代码：定义三个角色：1、received 真正的命令执行对象 2、Command 3、invoker 使用命令对象的入口 应用实例：struts 1 中的 action 核心控制器 ActionServlet 只有一个，相当于 Invoker，而模型层的类会随着不同的应用有不同的模型类，相当于具体的 Command。 优点： 1、降低了系统耦合度。 ​ 2、新的命令可以很容易添加到系统中去。 缺点： 使用命令模式可能会导致某些系统有过多的具体命令类。 使用场景：认为是命令的地方都可以使用命令模式， 比如： ​ 1、GUI 中每一个按钮都是一条命令。 ​ 2、模拟 CMD。 注意事项：系统需要支持命令的撤销(Undo)操作和恢复(Redo)操作，也可以考虑使用命令模式，见命令模式的扩展。 实现我们首先创建作为命令的接口 Order*，然后创建作为请求的 *Stock 类。实体命令类 BuyStock 和 SellStock*，实现了 *Order 接口，将执行实际的命令处理。创建作为调用对象的类 Broker，它接受订单并能下订单。 Broker 对象使用命令模式，基于命令的类型确定哪个对象执行哪个命令。CommandPatternDemo*，我们的演示类使用 *Broker 类来演示命令模式。 步骤1创建一个命令接口。 Order.java123public interface Order &#123; void execute();&#125; 步骤 2创建一个请求类。 Stock.java1234567891011121314public class Stock &#123; private String name = \"ABC\"; private int quantity = 10; public void buy()&#123; System.out.println(\"Stock [ Name: \"+name+\", Quantity: \" + quantity +\" ] bought\"); &#125; public void sell()&#123; System.out.println(\"Stock [ Name: \"+name+\", Quantity: \" + quantity +\" ] sold\"); &#125;&#125; 步骤 3创建实现了 Order 接口的实体类。 BuyStock.java1234567891011public class BuyStock implements Order &#123; private Stock abcStock; public BuyStock(Stock abcStock)&#123; this.abcStock = abcStock; &#125; public void execute() &#123; abcStock.buy(); &#125;&#125; SellStock.java1234567891011public class SellStock implements Order &#123; private Stock abcStock; public SellStock(Stock abcStock)&#123; this.abcStock = abcStock; &#125; public void execute() &#123; abcStock.sell(); &#125;&#125; 步骤 4创建命令调用类。 Broker.java1234567891011121314151617import java.util.ArrayList;import java.util.List; public class Broker &#123; private List&lt;Order&gt; orderList = new ArrayList&lt;Order&gt;(); public void takeOrder(Order order)&#123; orderList.add(order); &#125; public void placeOrders()&#123; for (Order order : orderList) &#123; order.execute(); &#125; orderList.clear(); &#125;&#125; 使用 Broker 类来接受并执行命令。 CommandPatternDemo.java1234567891011121314public class CommandPatternDemo &#123; public static void main(String[] args) &#123; Stock abcStock = new Stock(); BuyStock buyStockOrder = new BuyStock(abcStock); SellStock sellStockOrder = new SellStock(abcStock); Broker broker = new Broker(); broker.takeOrder(buyStockOrder); broker.takeOrder(sellStockOrder); broker.placeOrders(); &#125;&#125; 步骤 6执行程序，输出结果： 12Stock [ Name: ABC, Quantity: 10 ] boughtStock [ Name: ABC, Quantity: 10 ] sold","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://kayleh.top/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"DesignPatterns","slug":"DesignPatterns","permalink":"https://kayleh.top/tags/DesignPatterns/"}]},{"title":"责任链模式","slug":"责任链模式","date":"2020-06-11T11:48:35.000Z","updated":"2020-08-20T06:29:11.110Z","comments":true,"path":"2020/06/11/责任链模式/","link":"","permalink":"https://kayleh.top/2020/06/11/%E8%B4%A3%E4%BB%BB%E9%93%BE%E6%A8%A1%E5%BC%8F/","excerpt":"责任链模式 责任链模式（Chain of Responsibility Pattern）为请求创建了一个接收者对象的链。这种模式给予请求的类型，对请求的发送者和接收者进行解耦。这种类型的设计模式属于行为型模式。","text":"责任链模式 责任链模式（Chain of Responsibility Pattern）为请求创建了一个接收者对象的链。这种模式给予请求的类型，对请求的发送者和接收者进行解耦。这种类型的设计模式属于行为型模式。 介绍意图：避免请求发送者与接收者耦合在一起，让多个对象都有可能接收请求，将这些对象连接成一条链，并且沿着这条链传递请求，直到有对象处理它为止。 主要解决：职责链上的处理者负责处理请求，客户只需要将请求发送到职责链上即可，无须关心请求的处理细节和请求的传递，所以职责链将请求的发送者和请求的处理者解耦了。 何时使用：在处理消息的时候以过滤很多道。 如何解决：拦截的类都实现统一接口。 关键代码：Handler 里面聚合它自己，在 HandlerRequest 里判断是否合适，如果没达到条件则向下传递，向谁传递之前 set 进去。 应用实例： 1、红楼梦中的”击鼓传花”。 2、JS 中的事件冒泡。 3、JAVA WEB 中 Apache Tomcat 对 Encoding 的处理，Struts2 的拦截器，jsp servlet 的 Filter。 优点： 1、降低耦合度。它将请求的发送者和接收者解耦。 2、简化了对象。使得对象不需要知道链的结构。 3、增强给对象指派职责的灵活性。通过改变链内的成员或者调动它们的次序，允许动态地新增或者删除责任。 4、增加新的请求处理类很方便。 缺点： 1、不能保证请求一定被接收。 2、系统性能将受到一定影响，而且在进行代码调试时不太方便，可能会造成循环调用。 3、可能不容易观察运行时的特征，有碍于除错。 使用场景： 1、有多个对象可以处理同一个请求，具体哪个对象处理该请求由运行时刻自动确定。 2、在不明确指定接收者的情况下，向多个对象中的一个提交一个请求。 3、可动态指定一组对象处理请求。 注意事项：在 JAVA WEB 中遇到很多应用。 实现我们创建抽象类 AbstractLogger，带有详细的日志记录级别。然后我们创建三种类型的记录器，都扩展了 AbstractLogger。每个记录器消息的级别是否属于自己的级别，如果是则相应地打印出来，否则将不打印并把消息传给下一个记录器。 步骤1创建抽象的记录器类。 AbstractLogger.java1234567891011121314151617181920212223242526public abstract class AbstractLogger &#123; public static int INFO = 1; public static int DEBUG = 2; public static int ERROR = 3; protected int level; //责任链中的下一个元素 protected AbstractLogger nextLogger; public void setNextLogger(AbstractLogger nextLogger)&#123; this.nextLogger = nextLogger; &#125; public void logMessage(int level, String message)&#123; if(this.level &lt;= level)&#123; write(message); &#125; if(nextLogger !=null)&#123; nextLogger.logMessage(level, message); &#125; &#125; abstract protected void write(String message); &#125; 步骤 2创建扩展了该记录器类的实体类。 ConsoleLogger.java1234567891011public class ConsoleLogger extends AbstractLogger &#123; public ConsoleLogger(int level)&#123; this.level = level; &#125; @Override protected void write(String message) &#123; System.out.println(\"Standard Console::Logger: \" + message); &#125;&#125; ErrorLogger.java1234567891011public class ErrorLogger extends AbstractLogger &#123; public ErrorLogger(int level)&#123; this.level = level; &#125; @Override protected void write(String message) &#123; System.out.println(\"Error Console::Logger: \" + message); &#125;&#125; FileLogger.java1234567891011public class FileLogger extends AbstractLogger &#123; public FileLogger(int level)&#123; this.level = level; &#125; @Override protected void write(String message) &#123; System.out.println(\"File::Logger: \" + message); &#125;&#125; 步骤 3创建不同类型的记录器。赋予它们不同的错误级别，并在每个记录器中设置下一个记录器。每个记录器中的下一个记录器代表的是链的一部分。 ChainPatternDemo.java1234567891011121314151617181920212223242526public class ChainPatternDemo &#123; private static AbstractLogger getChainOfLoggers()&#123; AbstractLogger errorLogger = new ErrorLogger(AbstractLogger.ERROR); AbstractLogger fileLogger = new FileLogger(AbstractLogger.DEBUG); AbstractLogger consoleLogger = new ConsoleLogger(AbstractLogger.INFO); errorLogger.setNextLogger(fileLogger); fileLogger.setNextLogger(consoleLogger); return errorLogger; &#125; public static void main(String[] args) &#123; AbstractLogger loggerChain = getChainOfLoggers(); loggerChain.logMessage(AbstractLogger.INFO, \"This is an information.\"); loggerChain.logMessage(AbstractLogger.DEBUG, \"This is a debug level information.\"); loggerChain.logMessage(AbstractLogger.ERROR, \"This is an error information.\"); &#125;&#125; 步骤 4执行程序，输出结果： 123456Standard Console::Logger: This is an information.File::Logger: This is a debug level information.Standard Console::Logger: This is a debug level information.Error Console::Logger: This is an error information.File::Logger: This is an error information.Standard Console::Logger: This is an error information.","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://kayleh.top/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"DesignPatterns","slug":"DesignPatterns","permalink":"https://kayleh.top/tags/DesignPatterns/"}]},{"title":"RESUME","slug":"RESUME","date":"2020-06-11T01:48:15.000Z","updated":"2020-08-20T06:48:31.848Z","comments":true,"path":"2020/06/11/RESUME/","link":"","permalink":"https://kayleh.top/2020/06/11/RESUME/","excerpt":"RESUME","text":"RESUME","categories":[],"tags":[{"name":"resume","slug":"resume","permalink":"https://kayleh.top/tags/resume/"}]},{"title":"代理模式","slug":"代理模式","date":"2020-06-09T12:46:15.000Z","updated":"2020-06-11T05:32:42.211Z","comments":true,"path":"2020/06/09/代理模式/","link":"","permalink":"https://kayleh.top/2020/06/09/%E4%BB%A3%E7%90%86%E6%A8%A1%E5%BC%8F/","excerpt":"代理模式 为其他对象提供一种代理以控制对这个对象的访问。","text":"代理模式 为其他对象提供一种代理以控制对这个对象的访问。 在代理模式（Proxy Pattern）中，一个类代表另一个类的功能。这种类型的设计模式属于结构型模式。 在代理模式中，我们创建具有现有对象的对象，以便向外界提供功能接口。 介绍意图：为其他对象提供一种代理以控制对这个对象的访问。 主要解决：在直接访问对象时带来的问题，比如说：要访问的对象在远程的机器上。在面向对象系统中，有些对象由于某些原因（比如对象创建开销很大，或者某些操作需要安全控制，或者需要进程外的访问），直接访问会给使用者或者系统结构带来很多麻烦，我们可以在访问此对象时加上一个对此对象的访问层。 何时使用：想在访问一个类时做一些控制。 如何解决：增加中间层。 关键代码：实现与被代理类组合。 应用实例： 1、Windows 里面的快捷方式。 2、猪八戒去找高翠兰结果是孙悟空变的，可以这样理解：把高翠兰的外貌抽象出来，高翠兰本人和孙悟空都实现了这个接口，猪八戒访问高翠兰的时候看不出来这个是孙悟空，所以说孙悟空是高翠兰代理类。 3、买火车票不一定在火车站买，也可以去代售点。 4、一张支票或银行存单是账户中资金的代理。支票在市场交易中用来代替现金，并提供对签发人账号上资金的控制。 5、spring aop。 优点： 1、职责清晰。 2、高扩展性。 3、智能化。 缺点： 1、由于在客户端和真实主题之间增加了代理对象，因此有些类型的代理模式可能会造成请求的处理速度变慢。 2、实现代理模式需要额外的工作，有些代理模式的实现非常复杂。 使用场景：按职责来划分，通常有以下使用场景： 1、远程代理。 2、虚拟代理。 3、Copy-on-Write 代理。 4、保护（Protect or Access）代理。 5、Cache代理。 6、防火墙（Firewall）代理。 7、同步化（Synchronization）代理。 8、智能引用（Smart Reference）代理。 注意事项： 1、和适配器模式的区别：适配器模式主要改变所考虑对象的接口，而代理模式不能改变所代理类的接口。 2、和装饰器模式的区别：装饰器模式为了增强功能，而代理模式是为了加以控制。 实现我们将创建一个 Image 接口和实现了 Image 接口的实体类。ProxyImage 是一个代理类，减少 RealImage 对象加载的内存占用。 ProxyPatternDemo*，我们的演示类使用 *ProxyImage 来获取要加载的 Image 对象，并按照需求进行显示。 代理模式，即Proxy，它和Adapter模式很类似。我们先回顾Adapter模式，它用于把A接口转换为B接口： 123456789public BAdapter implements B &#123; private A a; public BAdapter(A a) &#123; this.a = a; &#125; public void b() &#123; a.a(); &#125;&#125; 而Proxy模式不是把A接口转换成B接口，它还是转换成A接口： 123456789public AProxy implements A &#123; private A a; public AProxy(A a) &#123; this.a = a; &#125; public void a() &#123; this.a.a(); &#125;&#125; 合着Proxy就是为了给A接口再包一层，这不是脱了裤子放屁吗？ 当然不是。我们观察Proxy的实现A接口的方法： 123public void a() &#123; this.a.a();&#125; 这样写当然没啥卵用。但是，如果我们在调用a.a()的前后，加一些额外的代码： 1234567public void a() &#123; if (getCurrentUser().isRoot()) &#123; this.a.a(); &#125; else &#123; throw new SecurityException(\"Forbidden\"); &#125;&#125; 这样一来，我们就实现了权限检查，只有符合要求的用户，才会真正调用目标方法，否则，会直接抛出异常。 有的童鞋会问，为啥不把权限检查的功能直接写到目标实例A的内部？ 因为我们编写代码的原则有： 职责清晰：一个类只负责一件事； 易于测试：一次只测一个功能。 用Proxy实现这个权限检查，我们可以获得更清晰、更简洁的代码： A接口：只定义接口； ABusiness类：只实现A接口的业务逻辑； APermissionProxy类：只实现A接口的权限检查代理。 如果我们希望编写其他类型的代理，可以继续增加类似ALogProxy，而不必对现有的A接口、ABusiness类进行修改。 实际上权限检查只是代理模式的一种应用。Proxy还广泛应用在： 远程代理远程代理即Remote Proxy，本地的调用者持有的接口实际上是一个代理，这个代理负责把对接口的方法访问转换成远程调用，然后返回结果。Java内置的RMI机制就是一个完整的远程代理模式。 虚代理虚代理即Virtual Proxy，它让调用者先持有一个代理对象，但真正的对象尚未创建。如果没有必要，这个真正的对象是不会被创建的，直到客户端需要真的必须调用时，才创建真正的对象。JDBC的连接池返回的JDBC连接（Connection对象）就可以是一个虚代理，即获取连接时根本没有任何实际的数据库连接，直到第一次执行JDBC查询或更新操作时，才真正创建实际的JDBC连接。 保护代理保护代理即Protection Proxy，它用代理对象控制对原始对象的访问，常用于鉴权。 智能引用智能引用即Smart Reference，它也是一种代理对象，如果有很多客户端对它进行访问，通过内部的计数器可以在外部调用者都不使用后自动释放它。 我们来看一下如何应用代理模式编写一个JDBC连接池（DataSource）。我们首先来编写一个虚代理，即如果调用者获取到Connection后，并没有执行任何SQL操作，那么这个Connection Proxy实际上并不会真正打开JDBC连接。调用者代码如下： 123456789101112131415DataSource lazyDataSource = new LazyDataSource(jdbcUrl, jdbcUsername, jdbcPassword);System.out.println(\"get lazy connection...\");try (Connection conn1 = lazyDataSource.getConnection()) &#123; // 并没有实际打开真正的Connection&#125;System.out.println(\"get lazy connection...\");try (Connection conn2 = lazyDataSource.getConnection()) &#123; try (PreparedStatement ps = conn2.prepareStatement(\"SELECT * FROM students\")) &#123; // 打开了真正的Connection try (ResultSet rs = ps.executeQuery()) &#123; while (rs.next()) &#123; System.out.println(rs.getString(\"name\")); &#125; &#125; &#125;&#125; 现在我们来思考如何实现这个LazyConnectionProxy。为了简化代码，我们首先针对Connection接口做一个抽象的代理类： 12345678910111213141516public abstract class AbstractConnectionProxy implements Connection &#123; // 抽象方法获取实际的Connection: protected abstract Connection getRealConnection(); // 实现Connection接口的每一个方法: public Statement createStatement() throws SQLException &#123; return getRealConnection().createStatement(); &#125; public PreparedStatement prepareStatement(String sql) throws SQLException &#123; return getRealConnection().prepareStatement(sql); &#125; ...其他代理方法...&#125; 这个AbstractConnectionProxy代理类的作用是把Connection接口定义的方法全部实现一遍，因为Connection接口定义的方法太多了，后面我们要编写的LazyConnectionProxy只需要继承AbstractConnectionProxy，就不必再把Connection接口方法挨个实现一遍。 LazyConnectionProxy实现如下： 123456789101112131415161718192021222324public class LazyConnectionProxy extends AbstractConnectionProxy &#123; private Supplier&lt;Connection&gt; supplier; private Connection target = null; public LazyConnectionProxy(Supplier&lt;Connection&gt; supplier) &#123; this.supplier = supplier; &#125; // 覆写close方法：只有target不为null时才需要关闭: public void close() throws SQLException &#123; if (target != null) &#123; System.out.println(\"Close connection: \" + target); super.close(); &#125; &#125; @Override protected Connection getRealConnection() &#123; if (target == null) &#123; target = supplier.get(); &#125; return target; &#125;&#125; 如果调用者没有执行任何SQL语句，那么target字段始终为null。只有第一次执行SQL语句时（即调用任何类似prepareStatement()方法时，触发getRealConnection()调用），才会真正打开实际的JDBC Connection。 最后，我们还需要编写一个LazyDataSource来支持这个LazyConnecitonProxy： 123456789101112131415161718192021222324public class LazyDataSource implements DataSource &#123; private String url; private String username; private String password; public LazyDataSource(String url, String username, String password) &#123; this.url = url; this.username = username; this.password = password; &#125; public Connection getConnection(String username, String password) throws SQLException &#123; return new LazyConnectionProxy(() -&gt; &#123; try &#123; Connection conn = DriverManager.getConnection(url, username, password); System.out.println(\"Open connection: \" + conn); return conn; &#125; catch (SQLException e) &#123; throw new RuntimeException(e); &#125; &#125;); &#125; ...&#125; 我们执行代码，输出如下： 123456789get lazy connection...get lazy connection...Open connection: com.mysql.jdbc.JDBC4Connection@7a36aefa小明小红小军小白...Close connection: com.mysql.jdbc.JDBC4Connection@7a36aefa 可见第一个getConnection()调用获取到的LazyConnectionProxy并没有实际打开真正的JDBC Connection。 使用连接池的时候，我们更希望能重复使用连接。如果调用方编写这样的代码： 123456789DataSource pooledDataSource = new PooledDataSource(jdbcUrl, jdbcUsername, jdbcPassword);try (Connection conn = pooledDataSource.getConnection()) &#123;&#125;try (Connection conn = pooledDataSource.getConnection()) &#123; // 获取到的是同一个Connection&#125;try (Connection conn = pooledDataSource.getConnection()) &#123; // 获取到的是同一个Connection&#125; 调用方并不关心是否复用了Connection，但从PooledDataSource获取的Connection确实自带这个优化功能。如何实现可复用Connection的连接池？答案仍然是使用代理模式。 12345678910111213141516171819202122public class PooledConnectionProxy extends AbstractConnectionProxy &#123; // 实际的Connection: Connection target; // 空闲队列: Queue&lt;PooledConnectionProxy&gt; idleQueue; public PooledConnectionProxy(Queue&lt;PooledConnectionProxy&gt; idleQueue, Connection target) &#123; this.idleQueue = idleQueue; this.target = target; &#125; public void close() throws SQLException &#123; System.out.println(\"Fake close and released to idle queue for future reuse: \" + target); // 并没有调用实际Connection的close()方法, // 而是把自己放入空闲队列: idleQueue.offer(this); &#125; protected Connection getRealConnection() &#123; return target; &#125;&#125; 复用连接的关键在于覆写close()方法，它并没有真正关闭底层JDBC连接，而是把自己放回一个空闲队列，以便下次使用。 空闲队列由PooledDataSource负责维护： 123456789101112131415161718192021222324252627282930313233public class PooledDataSource implements DataSource &#123; private String url; private String username; private String password; // 维护一个空闲队列: private Queue&lt;PooledConnectionProxy&gt; idleQueue = new ArrayBlockingQueue&lt;&gt;(100); public PooledDataSource(String url, String username, String password) &#123; this.url = url; this.username = username; this.password = password; &#125; public Connection getConnection(String username, String password) throws SQLException &#123; // 首先试图获取一个空闲连接: PooledConnectionProxy conn = idleQueue.poll(); if (conn == null) &#123; // 没有空闲连接时，打开一个新连接: conn = openNewConnection(); &#125; else &#123; System.out.println(\"Return pooled connection: \" + conn.target); &#125; return conn; &#125; private PooledConnectionProxy openNewConnection() throws SQLException &#123; Connection conn = DriverManager.getConnection(url, username, password); System.out.println(\"Open new connection: \" + conn); return new PooledConnectionProxy(idleQueue, conn); &#125; ...&#125; 我们执行调用方代码，输出如下： 123456Open new connection: com.mysql.jdbc.JDBC4Connection@61ca2dfaFake close and released to idle queue for future reuse: com.mysql.jdbc.JDBC4Connection@61ca2dfaReturn pooled connection: com.mysql.jdbc.JDBC4Connection@61ca2dfaFake close and released to idle queue for future reuse: com.mysql.jdbc.JDBC4Connection@61ca2dfaReturn pooled connection: com.mysql.jdbc.JDBC4Connection@61ca2dfaFake close and released to idle queue for future reuse: com.mysql.jdbc.JDBC4Connection@61ca2dfa 除了第一次打开了一个真正的JDBC Connection，后续获取的Connection实际上是同一个JDBC Connection。但是，对于调用方来说，完全不需要知道底层做了哪些优化。 我们实际使用的DataSource，例如HikariCP，都是基于代理模式实现的，原理同上，但增加了更多的如动态伸缩的功能（一个连接空闲一段时间后自动关闭）。 有的童鞋会发现Proxy模式和Decorator模式有些类似。确实，这两者看起来很像，但区别在于：Decorator模式让调用者自己创建核心类，然后组合各种功能，而Proxy模式决不能让调用者自己创建再组合，否则就失去了代理的功能。Proxy模式让调用者认为获取到的是核心类接口，但实际上是代理类。","categories":[],"tags":[{"name":"DesignPatterns","slug":"DesignPatterns","permalink":"https://kayleh.top/tags/DesignPatterns/"}]},{"title":"享元模式","slug":"享元模式","date":"2020-06-09T10:05:02.000Z","updated":"2020-08-20T06:28:57.040Z","comments":true,"path":"2020/06/09/享元模式/","link":"","permalink":"https://kayleh.top/2020/06/09/%E4%BA%AB%E5%85%83%E6%A8%A1%E5%BC%8F/","excerpt":"享元 运用共享技术有效地支持大量细粒度的对象。","text":"享元 运用共享技术有效地支持大量细粒度的对象。 享元（Flyweight）的核心思想很简单：如果一个对象实例一经创建就不可变，那么反复创建相同的实例就没有必要，直接向调用方返回一个共享的实例就行，这样即节省内存，又可以减少创建对象的过程，提高运行速度。 享元模式在Java标准库中有很多应用。我们知道，包装类型如Byte、Integer都是不变类，因此，反复创建同一个值相同的包装类型是没有必要的。以Integer为例，如果我们通过Integer.valueOf()这个静态工厂方法创建Integer实例，当传入的int范围在-128~+127之间时，会直接返回缓存的Integer实例： 1234567public class Main &#123; public static void main(String[] args) throws InterruptedException &#123; Integer n1 = Integer.valueOf(100); Integer n2 = Integer.valueOf(100); System.out.println(n1 == n2); // true &#125;&#125; 对于Byte来说，因为它一共只有256个状态，所以，通过Byte.valueOf()创建的Byte实例，全部都是缓存对象。 因此，享元模式就是通过工厂方法创建对象，在工厂方法内部，很可能返回缓存的实例，而不是新创建实例，从而实现不可变实例的复用。 总是使用工厂方法而不是new操作符创建实例，可获得享元模式的好处。 在实际应用中，享元模式主要应用于缓存，即客户端如果重复请求某些对象，不必每次查询数据库或者读取文件，而是直接返回内存中缓存的数据。 我们以Student为例，设计一个静态工厂方法，它在内部可以返回缓存的对象： 123456789101112131415161718192021222324252627282930public class Student &#123; // 持有缓存: private static final Map&lt;String, Student&gt; cache = new HashMap&lt;&gt;(); // 静态工厂方法: public static Student create(int id, String name) &#123; String key = id + \"\\n\" + name; // 先查找缓存: Student std = cache.get(key); if (std == null) &#123; // 未找到,创建新对象: System.out.println(String.format(\"create new Student(%s, %s)\", id, name)); std = new Student(id, name); // 放入缓存: cache.put(key, std); &#125; else &#123; // 缓存中存在: System.out.println(String.format(\"return cached Student(%s, %s)\", std.id, std.name)); &#125; return std; &#125; private final int id; private final String name; public Student(int id, String name) &#123; this.id = id; this.name = name; &#125;&#125; 在实际应用中，我们经常使用成熟的缓存库，例如Guava的Cache，因为它提供了最大缓存数量限制、定时过期等实用功能。","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://kayleh.top/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"DesignPatterns","slug":"DesignPatterns","permalink":"https://kayleh.top/tags/DesignPatterns/"}]},{"title":"外观模式","slug":"外观模式","date":"2020-06-09T07:37:54.000Z","updated":"2020-08-20T06:27:14.522Z","comments":true,"path":"2020/06/09/外观模式/","link":"","permalink":"https://kayleh.top/2020/06/09/%E5%A4%96%E8%A7%82%E6%A8%A1%E5%BC%8F/","excerpt":"外观模式 为子系统中的一组接口提供一个一致的界面。Facade模式定义了一个高层接口，这个接口使得这一子系统更加容易使用。","text":"外观模式 为子系统中的一组接口提供一个一致的界面。Facade模式定义了一个高层接口，这个接口使得这一子系统更加容易使用。 外观模式，即Facade，是一个比较简单的模式。它的基本思想如下： 如果客户端要跟许多子系统打交道，那么客户端需要了解各个子系统的接口，比较麻烦。如果有一个统一的“中介”，让客户端只跟中介打交道，中介再去跟各个子系统打交道，对客户端来说就比较简单。所以Facade就相当于搞了一个中介。 我们以注册公司为例，假设注册公司需要三步： 向工商局申请公司营业执照； 在银行开设账户； 在税务局开设纳税号。 以下是三个系统的接口： 1234567891011121314151617181920// 工商注册:public class AdminOfIndustry &#123; public Company register(String name) &#123; ... &#125;&#125;// 银行开户:public class Bank &#123; public String openAccount(String companyId) &#123; ... &#125;&#125;// 纳税登记:public class Taxation &#123; public String applyTaxCode(String companyId) &#123; ... &#125;&#125; 如果子系统比较复杂，并且客户对流程也不熟悉，那就把这些流程全部委托给中介： 12345678910public class Facade &#123; public Company openCompany(String name) &#123; Company c = this.admin.register(name); String bankAccount = this.bank.openAccount(c.getId()); c.setBankAccount(bankAccount); String taxCode = this.taxation.applyTaxCode(c.getId()); c.setTaxCode(taxCode); return c; &#125;&#125; 这样，客户端只跟Facade打交道，一次完成公司注册的所有繁琐流程： 1Company c = facade.openCompany(\"Facade Software Ltd.\"); 很多Web程序，内部有多个子系统提供服务，经常使用一个统一的Facade入口，例如一个RestApiController，使得外部用户调用的时候，只关心Facade提供的接口，不用管内部到底是哪个子系统处理的。 更复杂的Web程序，会有多个Web服务，这个时候，经常会使用一个统一的网关入口来自动转发到不同的Web服务，这种提供统一入口的网关就是Gateway，它本质上也是一个Facade，但可以附加一些用户认证、限流限速的额外服务。","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://kayleh.top/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"DesignPatterns","slug":"DesignPatterns","permalink":"https://kayleh.top/tags/DesignPatterns/"}]},{"title":"装饰器模式","slug":"装饰器模式","date":"2020-06-09T07:10:41.000Z","updated":"2020-08-20T06:29:18.458Z","comments":true,"path":"2020/06/09/装饰器模式/","link":"","permalink":"https://kayleh.top/2020/06/09/%E8%A3%85%E9%A5%B0%E5%99%A8%E6%A8%A1%E5%BC%8F/","excerpt":"装饰器模式 动态地给一个对象添加一些额外的职责。就增加功能来说，相比生成子类更为灵活。","text":"装饰器模式 动态地给一个对象添加一些额外的职责。就增加功能来说，相比生成子类更为灵活。 装饰器（Decorator）模式，是一种在运行期动态给某个对象的实例增加功能的方法。 我们在IO的Filter模式一节中其实已经讲过装饰器模式了。在Java标准库中，InputStream是抽象类，FileInputStream、ServletInputStream、Socket.getInputStream()这些InputStream都是最终数据源。 现在，如果要给不同的最终数据源增加缓冲功能、计算签名功能、加密解密功能，那么，3个最终数据源、3种功能一共需要9个子类。如果继续增加最终数据源，或者增加新功能，子类会爆炸式增长，这种设计方式显然是不可取的。 Decorator模式的目的就是把一个一个的附加功能，用Decorator的方式给一层一层地累加到原始数据源上，最终，通过组合获得我们想要的功能。 例如：给FileInputStream增加缓冲和解压缩功能，用Decorator模式写出来如下： 123456// 创建原始的数据源:InputStream fis = new FileInputStream(\"test.gz\");// 增加缓冲功能:InputStream bis = new BufferedInputStream(fis);// 增加解压缩功能:InputStream gis = new GZIPInputStream(bis); 或者一次性写成这样： 1234InputStream input = new GZIPInputStream( // 第二层装饰 new BufferedInputStream( // 第一层装饰 new FileInputStream(\"test.gz\") // 核心功能 )); 观察BufferedInputStream和GZIPInputStream，它们实际上都是从FilterInputStream继承的，这个FilterInputStream就是一个抽象的Decorator。我们用图把Decorator模式画出来如下： 123456789101112131415 ┌───────────┐ │ Component │ └───────────┘ ▲ ┌────────────┼─────────────────┐ │ │ │┌───────────┐┌───────────┐ ┌───────────┐│ComponentA ││ComponentB │... │ Decorator │└───────────┘└───────────┘ └───────────┘ ▲ ┌──────┴──────┐ │ │ ┌───────────┐ ┌───────────┐ │DecoratorA │ │DecoratorB │... └───────────┘ └───────────┘ 最顶层的Component是接口，对应到IO的就是InputStream这个抽象类。ComponentA、ComponentB是实际的子类，对应到IO的就是FileInputStream、ServletInputStream这些数据源。Decorator是用于实现各个附加功能的抽象装饰器，对应到IO的就是FilterInputStream。而从Decorator派生的就是一个一个的装饰器，它们每个都有独立的功能，对应到IO的就是BufferedInputStream、GZIPInputStream等。 Decorator模式有什么好处？它实际上把核心功能和附加功能给分开了。核心功能指FileInputStream这些真正读数据的源头，附加功能指加缓冲、压缩、解密这些功能。如果我们要新增核心功能，就增加Component的子类，例如ByteInputStream。如果我们要增加附加功能，就增加Decorator的子类，例如CipherInputStream。两部分都可以独立地扩展，而具体如何附加功能，由调用方自由组合，从而极大地增强了灵活性。 如果我们要自己设计完整的Decorator模式，应该如何设计？ 我们还是举个栗子：假设我们需要渲染一个HTML的文本，但是文本还可以附加一些效果，比如加粗、变斜体、加下划线等。为了实现动态附加效果，可以采用Decorator模式。 首先，仍然需要定义顶层接口TextNode： 123456public interface TextNode &#123; // 设置text: void setText(String text); // 获取text: String getText();&#125; 对于核心节点，例如``，它需要从TextNode直接继承： 1234567891011public class SpanNode implements TextNode &#123; private String text; public void setText(String text) &#123; this.text = text; &#125; public String getText() &#123; return \"&lt;span&gt;\" + text + \"&lt;/span&gt;\"; &#125;&#125; 紧接着，为了实现Decorator模式，需要有一个抽象的Decorator类： 1234567891011public abstract class NodeDecorator implements TextNode &#123; protected final TextNode target; protected NodeDecorator(TextNode target) &#123; this.target = target; &#125; public void setText(String text) &#123; this.target.setText(text); &#125;&#125; 这个NodeDecorator类的核心是持有一个TextNode，即将要把功能附加到的TextNode实例。接下来就可以写一个加粗功能： 123456789public class BoldDecorator extends NodeDecorator &#123; public BoldDecorator(TextNode target) &#123; super(target); &#125; public String getText() &#123; return \"&lt;b&gt;\" + target.getText() + \"&lt;/b&gt;\"; &#125;&#125; 类似的，可以继续加ItalicDecorator、UnderlineDecorator等。客户端可以自由组合这些Decorator： 1234567891011121314TextNode n1 = new SpanNode();TextNode n2 = new BoldDecorator(new UnderlineDecorator(new SpanNode()));TextNode n3 = new ItalicDecorator(new BoldDecorator(new SpanNode()));n1.setText(\"Hello\");n2.setText(\"Decorated\");n3.setText(\"World\");System.out.println(n1.getText());// 输出&lt;span&gt;Hello&lt;/span&gt;System.out.println(n2.getText());// 输出&lt;b&gt;&lt;u&gt;&lt;span&gt;Decorated&lt;/span&gt;&lt;/u&gt;&lt;/b&gt;System.out.println(n3.getText());// 输出&lt;i&gt;&lt;b&gt;&lt;span&gt;World&lt;/span&gt;&lt;/b&gt;&lt;/i&gt;","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://kayleh.top/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"DesignPatterns","slug":"DesignPatterns","permalink":"https://kayleh.top/tags/DesignPatterns/"}]},{"title":"组合模式","slug":"组合模式","date":"2020-06-09T06:39:48.000Z","updated":"2020-08-20T06:29:36.233Z","comments":true,"path":"2020/06/09/组合模式/","link":"","permalink":"https://kayleh.top/2020/06/09/%E7%BB%84%E5%90%88%E6%A8%A1%E5%BC%8F/","excerpt":"组合模式 将对象组合成树形结构以表示“部分-整体”的层次结构，使得用户对单个对象和组合对象的使用具有一致性。","text":"组合模式 将对象组合成树形结构以表示“部分-整体”的层次结构，使得用户对单个对象和组合对象的使用具有一致性。 组合模式（Composite）经常用于树形结构，为了简化代码，使用Composite可以把一个叶子节点与一个父节点统一起来处理。 我们来看一个具体的例子。在XML或HTML中，从根节点开始，每个节点都可能包含任意个其他节点，这些层层嵌套的节点就构成了一颗树。 要以树的结构表示XML，我们可以先抽象出节点类型Node： 12345678public interface Node &#123; // 添加一个节点为子节点: Node add(Node node); // 获取子节点: List&lt;Node&gt; children(); // 输出为XML: String toXml();&#125; 对于一个这样的节点，我们称之为 ElementNode，它可以作为容器包含多个子节点： 123456789101112131415161718192021222324252627public class ElementNode implements Node &#123; private String name; private List&lt;Node&gt; list = new ArrayList&lt;&gt;(); public ElementNode(String name) &#123; this.name = name; &#125; public Node add(Node node) &#123; list.add(node); return this; &#125; public List&lt;Node&gt; children() &#123; return list; &#125; public String toXml() &#123; String start = \"&lt;\" + name + \"&gt;\\n\"; String end = \"&lt;/\" + name + \"&gt;\\n\"; StringJoiner sj = new StringJoiner(\"\", start, end); list.forEach(node -&gt; &#123; sj.add(node.toXml() + \"\\n\"); &#125;); return sj.toString(); &#125;&#125; 对于普通文本，我们把它看作TextNode，它没有子节点： 12345678910111213141516171819public class TextNode implements Node &#123; private String text; public TextNode(String text) &#123; this.text = text; &#125; public Node add(Node node) &#123; throw new UnsupportedOperationException(); &#125; public List&lt;Node&gt; children() &#123; return List.of(); &#125; public String toXml() &#123; return text; &#125;&#125; 此外，还可以有注释节点： 12345678910111213141516171819public class CommentNode implements Node &#123; private String text; public CommentNode(String text) &#123; this.text = text; &#125; public Node add(Node node) &#123; throw new UnsupportedOperationException(); &#125; public List&lt;Node&gt; children() &#123; return List.of(); &#125; public String toXml() &#123; return \"&lt;!-- \" + text + \" --&gt;\"; &#125;&#125; 通过ElementNode、TextNode和CommentNode，我们就可以构造出一颗树： 123456789Node root = new ElementNode(\"school\");root.add(new ElementNode(\"classA\") .add(new TextNode(\"Tom\")) .add(new TextNode(\"Alice\")));root.add(new ElementNode(\"classB\") .add(new TextNode(\"Bob\")) .add(new TextNode(\"Grace\")) .add(new CommentNode(\"comment...\")));System.out.println(root.toXml()); 最后通过root节点输出的XML如下： 1234567891011&lt;school&gt;&lt;classA&gt;TomAlice&lt;/classA&gt;&lt;classB&gt;BobGrace&lt;!-- comment... --&gt;&lt;/classB&gt;&lt;/school&gt; 可见，使用Composite模式时，需要先统一单个节点以及“容器”节点的接口： 123456789 ┌───────────┐ │ Node │ └───────────┘ ▲ ┌────────────┼────────────┐ │ │ │┌───────────┐┌───────────┐┌───────────┐│ElementNode││ TextNode ││CommentNode│└───────────┘└───────────┘└───────────┘ 作为容器节点的ElementNode又可以添加任意个Node，这样就可以构成层级结构。 类似的，像文件夹和文件、GUI窗口的各种组件，都符合Composite模式的定义，因为它们的结构天生就是层级结构。","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://kayleh.top/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"DesignPatterns","slug":"DesignPatterns","permalink":"https://kayleh.top/tags/DesignPatterns/"}]},{"title":"桥接模式","slug":"桥接模式","date":"2020-06-09T06:04:02.000Z","updated":"2020-08-20T06:26:57.897Z","comments":true,"path":"2020/06/09/桥接模式/","link":"","permalink":"https://kayleh.top/2020/06/09/%E6%A1%A5%E6%8E%A5%E6%A8%A1%E5%BC%8F/","excerpt":"桥接模式 将抽象部分与它的实现部分分离，使它们都可以独立地变化。","text":"桥接模式 将抽象部分与它的实现部分分离，使它们都可以独立地变化。 假设某个汽车厂商生产三种品牌的汽车：Big、Tiny和Boss，每种品牌又可以选择燃油、纯电和混合动力。如果用传统的继承来表示各个最终车型，一共有3个抽象类加9个最终子类： 1234567891011121314151617181920 ┌───────┐ │ Car │ └───────┘ ▲ ┌──────────────────┼───────────────────┐ │ │ │┌───────┐ ┌───────┐ ┌───────┐│BigCar │ │TinyCar│ │BossCar│└───────┘ └───────┘ └───────┘ ▲ ▲ ▲ │ │ │ │ ┌───────────────┐│ ┌───────────────┐│ ┌───────────────┐ ├─│ BigFuelCar │├─│ TinyFuelCar │├─│ BossFuelCar │ │ └───────────────┘│ └───────────────┘│ └───────────────┘ │ ┌───────────────┐│ ┌───────────────┐│ ┌───────────────┐ ├─│BigElectricCar │├─│TinyElectricCar│├─│BossElectricCar│ │ └───────────────┘│ └───────────────┘│ └───────────────┘ │ ┌───────────────┐│ ┌───────────────┐│ ┌───────────────┐ └─│ BigHybridCar │└─│ TinyHybridCar │└─│ BossHybridCar │ └───────────────┘ └───────────────┘ └───────────────┘ 如果要新增一个品牌，或者加一个新的引擎（比如核动力），那么子类的数量增长更快。 所以，桥接模式就是为了避免直接继承带来的子类爆炸。 我们来看看桥接模式如何解决上述问题。 在桥接模式中，首先把Car按品牌进行子类化，但是，每个品牌选择什么发动机，不再使用子类扩充，而是通过一个抽象的“修正”类，以组合的形式引入。我们来看看具体的实现。 首先定义抽象类Car，它引用一个Engine： 12345678910public abstract class Car &#123; // 引用Engine: protected Engine engine; public Car(Engine engine) &#123; this.engine = engine; &#125; public abstract void drive();&#125; Engine的定义如下： 123public interface Engine &#123; void start();&#125; 紧接着，在一个“修正”的抽象类RefinedCar中定义一些额外操作： 123456789101112public abstract class RefinedCar extends Car &#123; public RefinedCar(Engine engine) &#123; super(engine); &#125; public void drive() &#123; this.engine.start(); System.out.println(\"Drive \" + getBrand() + \" car...\"); &#125; public abstract String getBrand();&#125; 这样一来，最终的不同品牌继承自RefinedCar，例如BossCar： 123456789public class BossCar extends RefinedCar &#123; public BossCar(Engine engine) &#123; super(engine); &#125; public String getBrand() &#123; return \"Boss\"; &#125;&#125; 而针对每一种引擎，继承自Engine，例如HybridEngine： 12345public class HybridEngine implements Engine &#123; public void start() &#123; System.out.println(\"Start Hybrid Engine...\"); &#125;&#125; 客户端通过自己选择一个品牌，再配合一种引擎，得到最终的Car： 12RefinedCar car = new BossCar(new HybridEngine());car.drive(); 使用桥接模式的好处在于，如果要增加一种引擎，只需要针对Engine派生一个新的子类，如果要增加一个品牌，只需要针对RefinedCar派生一个子类，任何RefinedCar的子类都可以和任何一种Engine自由组合，即一辆汽车的两个维度：品牌和引擎都可以独立地变化。 123456789101112131415161718 ┌───────────┐ │ Car │ └───────────┘ ▲ │ ┌───────────┐ ┌─────────┐ │RefinedCar │ ─ ─ ─&gt;│ Engine │ └───────────┘ └─────────┘ ▲ ▲ ┌────────┼────────┐ │ ┌──────────────┐ │ │ │ ├─│ FuelEngine │┌───────┐┌───────┐┌───────┐ │ └──────────────┘│BigCar ││TinyCar││BossCar│ │ ┌──────────────┐└───────┘└───────┘└───────┘ ├─│ElectricEngine│ │ └──────────────┘ │ ┌──────────────┐ └─│ HybridEngine │ └──────────────┘ 桥接模式实现比较复杂，实际应用也非常少，但它提供的设计思想值得借鉴，即不要过度使用继承，而是优先拆分某些部件，使用组合的方式来扩展功能。","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://kayleh.top/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"DesignPatterns","slug":"DesignPatterns","permalink":"https://kayleh.top/tags/DesignPatterns/"}]},{"title":"适配器模式","slug":"适配器模式","date":"2020-06-08T06:28:13.000Z","updated":"2020-08-20T06:27:10.080Z","comments":true,"path":"2020/06/08/适配器模式/","link":"","permalink":"https://kayleh.top/2020/06/08/%E9%80%82%E9%85%8D%E5%99%A8%E6%A8%A1%E5%BC%8F/","excerpt":"适配器模式 将一个类的接口转换成客户希望的另外一个接口，使得原本由于接口不兼容而不能一起工作的那些类可以一起工作。","text":"适配器模式 将一个类的接口转换成客户希望的另外一个接口，使得原本由于接口不兼容而不能一起工作的那些类可以一起工作。 适配器模式是Adapter，也称Wrapper，是指如果一个接口需要B接口，但是待传入的对象却是A接口，怎么办？ 我们举个例子。如果去美国，我们随身带的电器是无法直接使用的，因为美国的插座标准和中国不同，所以，我们需要一个适配器： 123456789101112131415public class Task implements Callable&lt;Long&gt; &#123; private long num; public Task(long num) &#123; this.num = num; &#125; public Long call() throws Exception &#123; long r = 0; for (long n = 1; n &lt;= this.num; n++) &#123; r = r + n; &#125; System.out.println(\"Result: \" + r); return r; &#125;&#125; 现在，我们想通过一个线程去执行它： 123Callable&lt;Long&gt; callable = new Task(123450000L);Thread thread = new Thread(callable); // compile error!thread.start(); 发现编译不过！因为Thread接收Runnable接口，但不接收Callable接口，肿么办？ 一个办法是改写Task类，把实现的Callable改为Runnable，但这样做不好，因为Task很可能在其他地方作为Callable被引用，改写Task的接口，会导致其他正常工作的代码无法编译。 另一个办法不用改写Task类，而是用一个Adapter，把这个Callable接口“变成”Runnable接口，这样，就可以正常编译： 123Callable&lt;Long&gt; callable = new Task(123450000L);Thread thread = new Thread(new RunnableAdapter(callable));thread.start(); 这个RunnableAdapter类就是Adapter，它接收一个Callable，输出一个Runnable。怎么实现这个RunnableAdapter呢？我们先看完整的代码： 123456789101112131415161718public class RunnableAdapter implements Runnable &#123; // 引用待转换接口: private Callable&lt;?&gt; callable; public RunnableAdapter(Callable&lt;?&gt; callable) &#123; this.callable = callable; &#125; // 实现指定接口: public void run() &#123; // 将指定接口调用委托给转换接口调用: try &#123; callable.call(); &#125; catch (Exception e) &#123; throw new RuntimeException(e); &#125; &#125;&#125; 编写一个Adapter的步骤如下： 实现目标接口，这里是Runnable； 内部持有一个待转换接口的引用，这里是通过字段持有Callable接口； 在目标接口的实现方法内部，调用待转换接口的方法。 这样一来，Thread就可以接收这个RunnableAdapter，因为它实现了Runnable接口。Thread作为调用方，它会调用RunnableAdapter的run()方法，在这个run()方法内部，又调用了Callable的call()方法，相当于Thread通过一层转换，间接调用了Callable的call()方法。 适配器模式在Java标准库中有广泛应用。比如我们持有数据类型是String[]，但是需要List接口时，可以用一个Adapter： 12String[] exist = new String[] &#123;\"Good\", \"morning\", \"Bob\", \"and\", \"Alice\"&#125;;Set&lt;String&gt; set = new HashSet&lt;&gt;(Arrays.asList(exist)); 注意到List Arrays.asList(T[])就相当于一个转换器，它可以把数组转换为List。 我们再看一个例子：假设我们持有一个InputStream，希望调用readText(Reader)方法，但它的参数类型是Reader而不是InputStream，怎么办？ 当然是使用适配器，把InputStream“变成”Reader： 123InputStream input = Files.newInputStream(Paths.get(\"/path/to/file\"));Reader reader = new InputStreamReader(input, \"UTF-8\");readText(reader); InputStreamReader就是Java标准库提供的Adapter，它负责把一个InputStream适配为Reader。类似的还有OutputStreamWriter。 如果我们把readText(Reader)方法参数从Reader改为FileReader，会有什么问题？这个时候，因为我们需要一个FileReader类型，就必须把InputStream适配为FileReader： 1FileReader reader = new InputStreamReader(input, \"UTF-8\"); // compile error! 直接使用InputStreamReader这个Adapter是不行的，因为它只能转换出Reader接口。事实上，要把InputStream转换为FileReader也不是不可能，但需要花费十倍以上的功夫。这时，面向抽象编程这一原则就体现出了威力：持有高层接口不但代码更灵活，而且把各种接口组合起来也更容易。一旦持有某个具体的子类类型，要想做一些改动就非常困难。","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://kayleh.top/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"DesignPatterns","slug":"DesignPatterns","permalink":"https://kayleh.top/tags/DesignPatterns/"}]},{"title":"原型","slug":"原型","date":"2020-06-08T01:43:14.000Z","updated":"2020-08-20T06:29:07.404Z","comments":true,"path":"2020/06/08/原型/","link":"","permalink":"https://kayleh.top/2020/06/08/%E5%8E%9F%E5%9E%8B/","excerpt":"原型 用原型实例指定创建对象的种类，并且通过拷贝这些原型创建新的对象。","text":"原型 用原型实例指定创建对象的种类，并且通过拷贝这些原型创建新的对象。 原型模式，即Prototype，是指创建新对象的时候，根据现有的一个原型来创建。 我们举个例子：如果我们已经有了一个String[]数组，想再创建一个一模一样的String[]数组，怎么写？ 实际上创建过程很简单，就是把现有数组的元素复制到新数组。如果我们把这个创建过程封装一下，就成了原型模式。用代码实现如下： 1234// 原型:String[] original = &#123; \"Apple\", \"Pear\", \"Banana\" &#125;;// 新对象:String[] copy = Arrays.copyOf(original, original.length); 对于普通类，我们如何实现原型拷贝？Java的Object提供了一个clone()方法，它的意图就是复制一个新的对象出来，我们需要实现一个Cloneable接口来标识一个对象是“可复制”的： 1234567891011121314public class Employee implements Cloneable &#123; private int id; private String name; private int score; // 复制新对象并返回: public Object clone() &#123; Employee employee = new Employee(); employee.id = this.id; employee.name = this.name; employee.score = this.score; return employee; &#125;&#125; 使用的时候，因为clone()的方法签名是定义在Object中，返回类型也是Object，所以要强制转型，比较麻烦： 123456789Employee employee = new Employee();employee.setId(123);employee.setName(\"Bob\");employee.setScore(88);// 复制新对象:Employee employee2 = (Employee) employee.clone();System.out.println(employee);System.out.println(employee2);System.out.println(employee == employee2); // false 实际上，使用原型模式更好的方式是定义一个copy()方法，返回明确的类型： 12345678910111213public class Employee &#123; private int id; private String name; private int score; public Employee copy() &#123; Student employee = new Employee(); employee.id = this.id; employee.name = this.name; employee.score = this.score; return employee; &#125;&#125; 原型模式应用不是很广泛，因为很多实例会持有类似文件、Socket这样的资源，而这些资源是无法复制给另一个对象共享的，只有存储简单类型的“值”对象可以复制。","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://kayleh.top/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"DesignPatterns","slug":"DesignPatterns","permalink":"https://kayleh.top/tags/DesignPatterns/"}]},{"title":"生成器","slug":"生成器","date":"2020-06-08T01:39:43.000Z","updated":"2020-08-20T06:27:05.691Z","comments":true,"path":"2020/06/08/生成器/","link":"","permalink":"https://kayleh.top/2020/06/08/%E7%94%9F%E6%88%90%E5%99%A8/","excerpt":"生成器 将一个复杂对象的构建与它的表示分离，使得同样的构建过程可以创建不同的表示。","text":"生成器 将一个复杂对象的构建与它的表示分离，使得同样的构建过程可以创建不同的表示。 生成器模式（Builder）是使用多个“小型”工厂来最终创建出一个完整对象。 当我们使用Builder的时候，一般来说，是因为创建这个对象的步骤比较多，每个步骤都需要一个零部件，最终组合成一个完整的对象。 使用Builder模式时，适用于创建的对象比较复杂，最好一步一步创建出“零件”，最后再装配起来。JavaMail的MimeMessage就可以看作是一个Builder模式，只不过Builder和最终产品合二为一，都是MimeMessage： 1234567891011121314151617181920Multipart multipart &#x3D; new MimeMultipart();&#x2F;&#x2F; 添加text:BodyPart textpart &#x3D; new MimeBodyPart();textpart.setContent(body, &quot;text&#x2F;html;charset&#x3D;utf-8&quot;);multipart.addBodyPart(textpart);&#x2F;&#x2F; 添加image:BodyPart imagepart &#x3D; new MimeBodyPart();imagepart.setFileName(fileName);imagepart.setDataHandler(new DataHandler(new ByteArrayDataSource(input, &quot;application&#x2F;octet-stream&quot;)));multipart.addBodyPart(imagepart);MimeMessage message &#x3D; new MimeMessage(session);&#x2F;&#x2F; 设置发送方地址:message.setFrom(new InternetAddress(&quot;me@example.com&quot;));&#x2F;&#x2F; 设置接收方地址:message.setRecipient(Message.RecipientType.TO, new InternetAddress(&quot;xiaoming@somewhere.com&quot;));&#x2F;&#x2F; 设置邮件主题:message.setSubject(&quot;Hello&quot;, &quot;UTF-8&quot;);&#x2F;&#x2F; 设置邮件内容为multipart:message.setContent(multipart); 很多时候，我们可以简化Builder模式，以链式调用的方式来创建对象。例如，我们经常编写这样的代码：123456StringBuilder builder &#x3D; new StringBuilder();builder.append(secure ? &quot;https:&#x2F;&#x2F;&quot; : &quot;http:&#x2F;&#x2F;&quot;) .append(&quot;www.liaoxuefeng.com&quot;) .append(&quot;&#x2F;&quot;) .append(&quot;?t&#x3D;0&quot;);String url &#x3D; builder.toString(); 由于我们经常需要构造URL字符串，可以使用Builder模式编写一个URLBuilder，调用方式如下：123456String url &#x3D; URLBuilder.builder() &#x2F;&#x2F; 创建Builder .setDomain(&quot;www.liaoxuefeng.com&quot;) &#x2F;&#x2F; 设置domain .setScheme(&quot;https&quot;) &#x2F;&#x2F; 设置scheme .setPath(&quot;&#x2F;&quot;) &#x2F;&#x2F; 设置路径 .setQuery(Map.of(&quot;a&quot;, &quot;123&quot;, &quot;q&quot;, &quot;K&amp;R&quot;)) &#x2F;&#x2F; 设置query .build(); &#x2F;&#x2F; 完成build","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://kayleh.top/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"DesignPatterns","slug":"DesignPatterns","permalink":"https://kayleh.top/tags/DesignPatterns/"}]},{"title":"工厂设计模式","slug":"工厂设计模式","date":"2020-06-06T12:42:10.000Z","updated":"2020-06-08T01:49:25.791Z","comments":true,"path":"2020/06/06/工厂设计模式/","link":"","permalink":"https://kayleh.top/2020/06/06/%E5%B7%A5%E5%8E%82%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/","excerpt":"工厂设计模式工厂方法工厂方法即Factory Method，是一种对象创建型模式。","text":"工厂设计模式工厂方法工厂方法即Factory Method，是一种对象创建型模式。 工厂方法的目的是使得创建对象和使用对象是分离的，并且客户端总是引用抽象工厂和抽象产品： 12345678┌─────────────┐ ┌─────────────┐│ Product │ │ Factory │└─────────────┘ └─────────────┘ ▲ ▲ │ │┌─────────────┐ ┌─────────────┐│ ProductImpl │&lt;─ ─ ─│ FactoryImpl │└─────────────┘ └─────────────┘ 例如实现一个解析字符串到Number的Factory，可以定义如下： 12345public class NumberFactoryImpl implements NumberFactory &#123; public Number parse(String s) &#123; return new BigDecimal(s); &#125;&#125; 而产品接口是Number，NumberFactoryImpl返回的实际产品是BigDecimal。 那么客户端如何创建NumberFactoryImpl呢？通常我们会在接口Factory中定义一个静态方法getFactory()来返回真正的子类： 123456789public interface NumberFactory &#123; // 创建方法: Number parse(String s); // 获取工厂实例: static NumberFactory getFactory() &#123; return impl; &#125; static NumberFactory impl = new NumberFactoryImpl();&#125; 在客户端中，我们只需要和工厂接口NumberFactory以及抽象产品Number打交道： 12NumberFactory factory = NumberFactory.getFactory();Number result = factory.parse(\"123.456\"); 调用方可以完全忽略真正的工厂NumberFactoryImpl和实际的产品BigDecimal，这样做的好处是允许创建产品的代码独立地变换，而不会影响到调用方。 实际上大多数情况下我们并不需要抽象工厂，而是通过静态方法直接返回产品，即： 12345public class NumberFactory &#123; public static Number parse(String s) &#123; return new BigDecimal(s); &#125;&#125; 这种简化的使用静态方法创建产品的方式称为静态工厂方法（Static Factory Method）。静态工厂方法广泛地应用在Java标准库中。例如： 1Integer n = Integer.valueOf(100); Integer既是产品又是静态工厂。它提供了静态方法valueOf()来创建Integer。那么这种方式和直接写new Integer(100)有何区别呢？我们观察valueOf()方法： 12345678public final class Integer &#123; public static Integer valueOf(int i) &#123; if (i &gt;= IntegerCache.low &amp;&amp; i &lt;= IntegerCache.high) return IntegerCache.cache[i + (-IntegerCache.low)]; return new Integer(i); &#125; ...&#125; 它的好处在于，valueOf()内部可能会使用new创建一个新的Integer实例，但也可能直接返回一个缓存的Integer实例。对于调用方来说，没必要知道Integer创建的细节。 工厂方法可以隐藏创建产品的细节，且不一定每次都会真正创建产品，完全可以返回缓存的产品，从而提升速度并减少内存消耗。 如果调用方直接使用Integer n = new Integer(100)，那么就失去了使用缓存优化的可能性。 我们经常使用的另一个静态工厂方法是List.of()： 1List&lt;String&gt; list = List.of(\"A\", \"B\", \"C\"); 这个静态工厂方法接收可变参数，然后返回List接口。需要注意的是，调用方获取的产品总是List接口，而且并不关心它的实际类型。即使调用方知道List产品的实际类型是java.util.ImmutableCollections$ListN，也不要去强制转型为子类，因为静态工厂方法List.of()保证返回List，但也完全可以修改为返回java.util.ArrayList。这就是里氏替换原则：返回实现接口的任意子类都可以满足该方法的要求，且不影响调用方。 总是引用接口而非实现类，能允许变换子类而不影响调用方，即尽可能面向抽象编程。 和List.of()类似，我们使用MessageDigest时，为了创建某个摘要算法，总是使用静态工厂方法getInstance(String)： 12MessageDigest md5 = MessageDigest.getInstance(\"MD5\");MessageDigest sha1 = MessageDigest.getInstance(\"SHA-1\"); 调用方通过产品名称获得产品实例，不但调用简单，而且获得的引用仍然是MessageDigest这个抽象类。 抽象工厂 提供一个创建一系列相关或相互依赖对象的接口，而无需指定它们具体的类。 抽象工厂模式（Abstract Factory）是一个比较复杂的创建型模式。 抽象工厂模式和工厂方法不太一样，它要解决的问题比较复杂，不但工厂是抽象的，产品是抽象的，而且有多个产品需要创建，因此，这个抽象工厂会对应到多个实际工厂，每个实际工厂负责创建多个实际产品： 1234567891011121314151617 ┌────────┐ ─ &gt;│ProductA│┌────────┐ ┌─────────┐ │ └────────┘│ Client │─ ─&gt;│ Factory │─ ─└────────┘ └─────────┘ │ ┌────────┐ ▲ ─ &gt;│ProductB│ ┌───────┴───────┐ └────────┘ │ │ ┌─────────┐ ┌─────────┐ │Factory1 │ │Factory2 │ └─────────┘ └─────────┘ │ ┌─────────┐ │ ┌─────────┐ ─ &gt;│ProductA1│ ─ &gt;│ProductA2│ │ └─────────┘ │ └─────────┘ ┌─────────┐ ┌─────────┐ └ ─&gt;│ProductB1│ └ ─&gt;│ProductB2│ └─────────┘ └─────────┘ 这种模式有点类似于多个供应商负责提供一系列类型的产品。我们举个例子： 假设我们希望为用户提供一个Markdown文本转换为HTML和Word的服务，它的接口定义如下： 123456public interface AbstractFactory &#123; // 创建Html文档: HtmlDocument createHtml(String md); // 创建Word文档: WordDocument createWord(String md);&#125; 注意到上面的抽象工厂仅仅是一个接口，没有任何代码。同样的，因为HtmlDocument和WordDocument都比较复杂，现在我们并不知道如何实现它们，所以只有接口： 12345678910// Html文档接口:public interface HtmlDocument &#123; String toHtml(); void save(Path path) throws IOException;&#125;// Word文档接口:public interface WordDocument &#123; void save(Path path) throws IOException;&#125; 这样，我们就定义好了抽象工厂（AbstractFactory）以及两个抽象产品（HtmlDocument和WordDocument）。因为实现它们比较困难，我们决定让供应商来完成。 现在市场上有两家供应商：FastDoc Soft的产品便宜，并且转换速度快，而GoodDoc Soft的产品贵，但转换效果好。我们决定同时使用这两家供应商的产品，以便给免费用户和付费用户提供不同的服务。 我们先看看FastDoc Soft的产品是如何实现的。首先，FastDoc Soft必须要有实际的产品，即FastHtmlDocument和FastWordDocument： 1234567891011121314public class FastHtmlDocument implements HtmlDocument &#123; public String toHtml() &#123; ... &#125; public void save(Path path) throws IOException &#123; ... &#125;&#125;public class FastWordDocument implements WordDocument &#123; public void save(Path path) throws IOException &#123; ... &#125;&#125; 然后，FastDoc Soft必须提供一个实际的工厂来生产这两种产品，即FastFactory： 12345678public class FastFactory implements AbstractFactory &#123; public HtmlDocument createHtml(String md) &#123; return new FastHtmlDocument(md); &#125; public WordDocument createWord(String md) &#123; return new FastWordDocument(md); &#125;&#125; 这样，我们就可以使用FastDoc Soft的服务了。客户端编写代码如下： 12345678// 创建AbstractFactory，实际类型是FastFactory:AbstractFactory factory = new FastFactory();// 生成Html文档:HtmlDocument html = factory.createHtml(\"#Hello\\nHello, world!\");html.save(Paths.get(\".\", \"fast.html\"));// 生成Word文档:WordDocument word = fastFactory.createWord(\"#Hello\\nHello, world!\");word.save(Paths.get(\".\", \"fast.doc\")); 如果我们要同时使用GoodDoc Soft的服务怎么办？因为用了抽象工厂模式，GoodDoc Soft只需要根据我们定义的抽象工厂和抽象产品接口，实现自己的实际工厂和实际产品即可： 123456789101112131415161718// 实际工厂:public class GoodFactory implements AbstractFactory &#123; public HtmlDocument createHtml(String md) &#123; return new GoodHtmlDocument(md); &#125; public WordDocument createWord(String md) &#123; return new GoodWordDocument(md); &#125;&#125;// 实际产品:public class GoodHtmlDocument implements HtmlDocument &#123; ...&#125;public class GoodWordDocument implements HtmlDocument &#123; ...&#125; 客户端要使用GoodDoc Soft的服务，只需要把原来的new FastFactory()切换为new GoodFactory()即可。 注意到客户端代码除了通过new创建了FastFactory或GoodFactory外，其余代码只引用了产品接口，并未引用任何实际产品（例如，FastHtmlDocument），如果把创建工厂的代码放到AbstractFactory中，就可以连实际工厂也屏蔽了： 1234567891011public interface AbstractFactory &#123; public static AbstractFactory createFactory(String name) &#123; if (name.equalsIgnoreCase(\"fast\")) &#123; return new FastFactory(); &#125; else if (name.equalsIgnoreCase(\"good\")) &#123; return new GoodFactory(); &#125; else &#123; throw new IllegalArgumentException(\"Invalid factory name\"); &#125; &#125;&#125;","categories":[],"tags":[{"name":"DesignPatterns","slug":"DesignPatterns","permalink":"https://kayleh.top/tags/DesignPatterns/"}]},{"title":"单例模式","slug":"单例模式","date":"2020-06-06T06:05:04.000Z","updated":"2020-08-20T06:51:50.864Z","comments":true,"path":"2020/06/06/单例模式/","link":"","permalink":"https://kayleh.top/2020/06/06/%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F/","excerpt":"单例设计模式","text":"单例设计模式 所谓类的单例设计模式，就是采用一定的方法保证在整个软件系统中，对某个类只能存在一个对象实例，并且该类只提供一个取得对象实例的方法(静态方法)。 比如Hibernate的SessionFactory，它充当数据存储源的代理，并负责创建Session 对象。SessionFactory并不是轻量级的，一般情况下，一个项目通常只需要一个 SessionFactory就够，这是就会使用到单例模式。 单例模式有八种方式： 饿汉式(静态常量) 饿汉式（静态代码块） 懒汉式(线程不安全) 懒汉式(线程安全，同步方法) 懒汉式(线程安全，同步代码块) 双重检查 静态内部类 枚举 饿汉式(静态变量) 123456789101112131415161718192021222324/** * @Author: Wizard * @Date: 2020/6/6 14:13 */public class Singleton1 &#123; public static void main(String[] args) &#123; //Test SingleTon instance1 = SingleTon.getInstance(); SingleTon instance2 = SingleTon.getInstance(); System.out.println(instance1==instance2);//true &#125;&#125;//饿汉式(静态变量)class SingleTon1 &#123; //1.构造器私有化, 外部不能new private SingleTon1() &#123; &#125; //2.在本类内部创建对象实例 private final static SingleTon1 instance = new SingleTon1(); //3.提供一个公有的静态方法，返回实例对象 public static SingleTon1 getInstance() &#123; return instance; &#125;&#125; 优缺点： 优点：这种写法比较简单，就是在类装载的时候就完成实例化。避免了线程同 步问题。 缺点：在类装载的时候就完成实例化，没有达到Lazy Loading的效果。如果从始 至终从未使用过这个实例，则会造成内存的浪费 这种方式基于classloder机制避免了多线程的同步问题，不过，instance在类装载 时就实例化，在单例模式中大多数都是调用getInstance方法， 但是导致类装载 的原因有很多种，因此不能确定有其他的方式（或者其他的静态方法）导致类 装载，这时候初始化instance就没有达到 lazy loading的效果 结论：这种单例模式可用，可能造成内存浪费 饿汉式(静态代码块) 1234567891011121314151617181920212223/** * @Author: Wizard * @Date: 2020/6/6 14:13 *///饿汉式(静态代码块)class SingleTon2 &#123; //1.构造器私有化, 外部不能new private SingleTon2() &#123; &#125; //2.在本类内部创建对象实例 private static SingleTon2 instance; static &#123; //在静态代码块中，创建单例对象,静态代码块只执行一次 instance = new SingleTon2(); &#125; //3.提供一个公有的静态方法，返回实例对象 public static SingleTon2 getInstance() &#123; return instance; &#125;&#125; 优缺点和静态变量相同 懒汉式(线程不安全) 1234567891011121314//懒汉式class SingleTon3 &#123; private static SingleTon3 instance; private SingleTon3() &#123; &#125; //提供一个静态的公有方法,当使用到该方法时，才去创建instance public static SingleTon3 getInstance()&#123; if (instance==null)&#123; instance = new SingleTon3(); &#125; return instance; &#125;&#125; 优缺点： 起到了Lazy Loading的效果，但是只能在单线程下使用。 如果在多线程下，一个线程进入了if (singleton == null)判断语句块，还未来得及 往下执行，另一个线程也通过了这个判断语句，这时便会产生多个实例。所以 在多线程环境下不可使用这种方式 结论：在实际开发中，不要使用这种方式. 懒汉式(线程安全，同步方法) 1234567891011121314//懒汉式(线程安全，同步方法)class SingleTon4 &#123; private static SingleTon4 instance; private SingleTon4() &#123; &#125; //提供一个静态的公有方法,加入同步处理的代码，解决线程安全问题 public static synchronized SingleTon4 getInstance()&#123; if (instance==null)&#123; instance = new SingleTon4(); &#125; return instance; &#125;&#125; 优缺点说明： 解决了线程不安全问题 效率太低了，每个线程在想获得类的实例时候，执行getInstance()方法都要进行 同步。而其实这个方法只执行一次实例化代码就够了，后面的想获得该类实例， 直接return就行了。方法进行同步效率太低 结论：在实际开发中，不推荐使用这种方式 懒汉式(线程安全，同步代码块) 123456789101112131415//懒汉式(线程安全，同步代码块)class SingleTon5 &#123; private static SingleTon5 instance; private SingleTon5() &#123; &#125; //提供一个静态的公有方法,加入同步处理的代码，解决线程安全问题 public static SingleTon5 getInstance() &#123; if (instance == null) &#123; synchronized (SingleTon5.class) &#123; instance = new SingleTon5(); &#125; &#125; return instance; &#125;&#125; 优缺点说明： 这种方式，本意是想对第四种实现方式的改进，因为前面同步方法效率太低， 改为同步产生实例化的的代码块 但是这种同步并不能起到线程同步的作用。跟第3种实现方式遇到的情形一 致，假如一个线程进入了if (singleton == null)判断语句块，还未来得及往下执行， 另一个线程也通过了这个判断语句，这时便会产生多个实例 结论：在实际开发中，不能使用这种方式 双重检查 1234567891011121314151617181920//懒汉式(线程安全,双重检查)class SingleTon6 &#123; //必须加volatile关键字的原因：new对象分为3步:1.分配空间 2.初始化对象 3.指向对象内存地址 // 2和3可能被编译器自动重排序,导致判断非空但是实际拿的对象还未完成初始化 private static volatile SingleTon6 instance; private SingleTon6() &#123; &#125; //提供一个静态的公有方法,加入双重检查代码，解决线程安全问题,同时解决懒加载的问题 public static SingleTon6 getInstance() &#123; if (instance == null) &#123; synchronized (SingleTon6.class) &#123; if (instance == null) &#123; instance = new SingleTon6(); &#125; &#125; &#125; return instance; &#125;&#125; 优缺点说明： Double-Check概念是多线程开发中常使用到的，如代码中所示，我们进行了两 次if (singleton == null)检查，这样就可以保证线程安全了。 这样，实例化代码只用执行一次，后面再次访问时，判断if (singleton == null)， 直接return实例化对象，也避免的反复进行方法同步 线程安全；延迟加载；效率较高 结论：在实际开发中，推荐使用这种单例设计模式 静态内部类 12345678910111213141516171819//静态内部类class SingleTon7 &#123; private static volatile SingleTon7 instance; private SingleTon7() &#123; &#125; //写一个静态内部类,该类中有一个静态属性SingleTon7 //静态内部类SingletonInstance在外部类SingleTon7在类装载的时候,并不会马上执行,不会导致静态内部类SingletonInstance马上装载 //在JVM中，类的转载是线程安全的，导致了INSTANCE的初始化是线程安全的 private static class SingletonInstance &#123; private static final SingleTon7 INSTANCE = new SingleTon7(); &#125; public static SingleTon7 getInstance() &#123; //当调用getInstance这个方法时,会去取静态内部类SingletonInstance里的INSTANCE属性,这时会导致SingletonInstance会被装载 return SingletonInstance.INSTANCE; &#125;&#125; 优缺点说明： 这种方式采用了类装载的机制来保证初始化实例时只有一个线程。 静态内部类方式在Singleton类被装载时并不会立即实例化，而是在需要实例化 时，调用getInstance方法，才会装载SingletonInstance类，从而完成Singleton的 实例化。 类的静态属性只会在第一次加载类的时候初始化，所以在这里，JVM帮助我们 保证了线程的安全性，在类进行初始化时，别的线程是无法进入的。 优点：避免了线程不安全，利用静态内部类特点实现延迟加载，效率高 结论：推荐使用. 枚举 123456789101112131415161718192021/** * @Author: Wizard * @Date: 2020/6/6 14:38 */public class Singleton8 &#123; public static void main(String[] args) &#123; Singleton instance = Singleton.INSTANCE; Singleton instance2 = Singleton.INSTANCE; System.out.println(instance == instance2);//true System.out.println(instance.hashCode()); System.out.println(instance2.hashCode()); &#125;&#125;//枚举enum Singleton &#123; INSTANCE; public void ok() &#123; System.out.println(\"ok\"); &#125;&#125; 优缺点说明： 这借助JDK1.5中添加的枚举来实现单例模式。不仅能避免多线程同步问题，而 且还能防止反序列化重新创建新的对象。 这种方式是Effective Java作者Josh Bloch 提倡的方式 结论：推荐使用 单例模式在JDK 应用的源码分析单例模式在JDK 应用的源码分析 JDK中，java.lang.Runtime就是经典的单例模式(饿汉式) 单例模式注意事项和细节说明 单例模式保证了 系统内存中该类只存在一个对象，节省了系统资源，对于一些需 要频繁创建销毁的对象，使用单例模式可以提高系统性能 当想实例化一个单例类的时候，必须要记住使用相应的获取对象的方法，而不是使用new 单例模式使用的场景：需要频繁的进行创建和销毁的对象、创建对象时耗时过多或 耗费资源过多(即：重量级对象)，但又经常用到的对象、工具类对象、频繁访问数 据库或文件的对象(比如数据源、session工厂等)","categories":[],"tags":[{"name":"DesignPatterns","slug":"DesignPatterns","permalink":"https://kayleh.top/tags/DesignPatterns/"}]},{"title":"合成复用原则","slug":"合成复用原则","date":"2020-06-05T07:42:54.000Z","updated":"2020-06-06T09:19:06.090Z","comments":true,"path":"2020/06/05/合成复用原则/","link":"","permalink":"https://kayleh.top/2020/06/05/%E5%90%88%E6%88%90%E5%A4%8D%E7%94%A8%E5%8E%9F%E5%88%99/","excerpt":"合成复用原则 Composite Resue Principle","text":"合成复用原则 Composite Resue Principle 基本介绍原则是尽量使用合成/聚合的方式，而不是使用继承。 123456不使用继承的方法：使用: 1.依赖(参数传递) 2.聚合(set) 3.组合(new) 设计原则核心思想 找出应用中可能需要变化之处，把他们独立出来，不要和那些不需要变化的代码混在一起。 针对接口编程，而不是针对实现编程 为了交互对象之间的松耦合设计而努力","categories":[],"tags":[{"name":"DesignPatterns","slug":"DesignPatterns","permalink":"https://kayleh.top/tags/DesignPatterns/"}]},{"title":"迪米特法则","slug":"迪米特法则","date":"2020-06-05T03:09:31.000Z","updated":"2020-06-06T09:08:03.719Z","comments":true,"path":"2020/06/05/迪米特法则/","link":"","permalink":"https://kayleh.top/2020/06/05/%E8%BF%AA%E7%B1%B3%E7%89%B9%E6%B3%95%E5%88%99/","excerpt":"基本介绍 Demeter Principle","text":"基本介绍 Demeter Principle 一个对象应该对其他对象保持最少的了解 类与类关系越密切，耦合度越大 迪米特法则又叫最少知道原则，即一个类对自己依赖的类知道的 越少越好。也就是说，对于被依赖的类不管多么复杂，都尽量将逻辑封装在类的内 部。对外除了提供的public 方法，不对外泄露任何信息 迪米特法则还有个更简单的定义：只与直接的朋友通信 直接的朋友：每个对象都会与其他对象有耦合关系，只要两个对象之间有耦合关系， 我们就说这两个对象之间是朋友关系。耦合的方式很多，依赖，关联，组合，聚合 等。其中，我们称出现成员变量，方法参数，方法返回值中的类为直接的朋友，而 出现在局部变量中的类不是直接的朋友。也就是说，陌生的类最好不要以局部变量 的形式出现在类的内部。 细节： 迪米特法则的核心是降低类之间的耦合 注意：由于每个类都减少了不必要的依赖，因此迪米特法则只是要求降低 类间(对象间)耦合关系， 并不是要求完全没有依赖关系","categories":[],"tags":[{"name":"DesignPatterns","slug":"DesignPatterns","permalink":"https://kayleh.top/tags/DesignPatterns/"}]},{"title":"开闭原则","slug":"开闭原则","date":"2020-06-05T01:07:12.000Z","updated":"2020-06-05T01:51:47.697Z","comments":true,"path":"2020/06/05/开闭原则/","link":"","permalink":"https://kayleh.top/2020/06/05/%E5%BC%80%E9%97%AD%E5%8E%9F%E5%88%99/","excerpt":"开闭原则 Open Closed Principle 基本介绍","text":"开闭原则 Open Closed Principle 基本介绍 开闭原则是编程中最基础、最重要的设计原则 一个软件实体如类，模块和函数应该对扩展开放，对修改关闭。用抽象构建框架，用实体扩展细节。 当软件需要变化时，尽量通过扩展软件实体的行为来实现变化，而不是通过修改已有的代码来实现变化。 编程中遵循其他原则，以及使用设计模式的目的就是遵循开闭原则。 12345678910111213141516171819202122232425262728293031323334public class Ocp&#123; public status void main(String[] args)&#123; GraphicEditor graphicEditor = new GraphicEditor(); graphicEditor.drawShape(new Rectangle()); &#125;&#125;class GraphicEditor&#123; public void drawShape(Shape shape)&#123; shape.draw(); &#125;&#125;//Shape类，基类abstract class Shape&#123; int m_type; public abstract void draw();//抽象方法&#125;class Rectangle extends Shape&#123; Rectangle()&#123; super.m_type = 1; &#125; @Override public void draw()&#123; System.out.println(\"绘制矩形\") &#125;&#125;class Circle extends Shape&#123; Circle()&#123; super.m_type = 2; &#125; @Override public void draw()&#123; System.out.println(\"绘制圆形\") &#125;&#125;","categories":[],"tags":[{"name":"DesignPatterns","slug":"DesignPatterns","permalink":"https://kayleh.top/tags/DesignPatterns/"}]},{"title":"里氏替换原则","slug":"里氏替换原则","date":"2020-06-04T10:13:11.000Z","updated":"2020-06-05T01:52:00.733Z","comments":true,"path":"2020/06/04/里氏替换原则/","link":"","permalink":"https://kayleh.top/2020/06/04/%E9%87%8C%E6%B0%8F%E6%9B%BF%E6%8D%A2%E5%8E%9F%E5%88%99/","excerpt":"里氏替换原则 Liskov Substitution Principle 里氏替换原则在1988年，由麻省理工学院的一位姓里的女士提出的。","text":"里氏替换原则 Liskov Substitution Principle 里氏替换原则在1988年，由麻省理工学院的一位姓里的女士提出的。 如果对每个类型为T1的对象o1，都有类型为T2的对象o2，使得以T1定义的所有程序P在所有的对象o1都代换成o2时，程序P的行为没有发生变化，那么类型T2是类型T1的子类型。所有引用基类的地方必须能透明地使用其子类的对象。换句话说，既然抽象出来当作共同的实现方法就不应再具体实现类中重写。 在使用继承时，遵守里氏替换原则，在子类中尽量不要重写父类的方法 里氏替换原则告诉我们，继承实际上让两个类耦合性增强了，在适当的情况下，可以通过聚合，组合，依赖来解决问题。 1234567891011121314151617//A类class A&#123; //返回两个数的差 public in func1(int num1,int num2)&#123; return num1 - num2; &#125;&#125;//B类继承了A类class B extends A&#123; // ↓重写了A的方法 public int func1(int a,int b)&#123; return a + b; &#125; public int func2(int a,int b)&#123; return func1(a,b)+9; &#125;&#125; 改进： 12345678910111213141516171819202122232425262728class Base&#123; //把更加基础的方法和成员写到Base类&#125;//A类class A extends Base&#123; //返回两个数的差 public in func1(int num1,int num2)&#123; return num1 - num2; &#125;&#125;//B类继承了A类class B extends Base&#123; //如果B需要使用A类的方法，使用组合关系 private A a = new A(); // ↓重写了A的方法 public int func1(int a,int b)&#123; return a + b; &#125; public int func2(int a,int b)&#123; return func1(a,b)+9; &#125; //使用A的方法 public int func3(int a,int b)&#123; return this.a.func1(a,b); &#125;&#125;","categories":[],"tags":[{"name":"DesignPatterns","slug":"DesignPatterns","permalink":"https://kayleh.top/tags/DesignPatterns/"}]},{"title":"依赖倒转原则","slug":"依赖倒转原则","date":"2020-06-03T12:29:20.000Z","updated":"2020-08-20T06:29:02.261Z","comments":true,"path":"2020/06/03/依赖倒转原则/","link":"","permalink":"https://kayleh.top/2020/06/03/%E4%BE%9D%E8%B5%96%E5%80%92%E8%BD%AC%E5%8E%9F%E5%88%99/","excerpt":"依赖倒转原则 Dependence Inversion Priciple","text":"依赖倒转原则 Dependence Inversion Priciple 基本介绍 高层模块不应该依赖低层模块，二者都应该依赖其抽象 抽象不应该依赖细节，细节应该依赖抽象 依赖倒转的中心思想是面向接口编程 依赖倒转原则是基于这样的设计理念：相对于细节的多变性，抽象的东西要稳定的多。以抽象为基础搭建的架构比细节为基础的架构要稳定的多。在java中，抽象指的是接口或抽象类，细节就是具体的实现类 使用接口或抽象类的目的是制定好规范，而不涉及任何具体的操作，把展现细节的任务交给他们的实现类去完成 细节 低层模块尽量都要有抽象类或接口，或者两者都有，程序稳定性更好 变量的声明类型尽量是抽象类或接口，这样我们的变量引用和实际对象间，就存在一个缓冲层。利于程序扩展和优化 继承时遵循里氏替换原则 1通过接口传递实现依赖123456789101112131415161718192021interface IOpenAndClose&#123; //抽象方法 public void open(ITV tv);&#125;interface ITV&#123; //ITV接口 public void play();&#125;class Htc implements ITV&#123; @Override public void play() &#123; System.out.println(\"htc电视机，打开\"); &#125;&#125;//实现接口class OpenAndClose implements IOpenAndClose&#123; public void open(ITV tv)&#123; tv.play(); &#125;&#125; 2.通过构造方法依赖传递1234567891011121314151617181920212223242526interface IOpenAndClose&#123; //抽象方法 public void open(ITV tv);&#125;interface ITV&#123; //ITV接口 public void play();&#125;class Htc implements ITV&#123; @Override public void play() &#123; System.out.println(\"htc电视机，打开\"); &#125;&#125;//实现接口class OpenAndClose implements IOpenAndClose&#123; public ITV tv; public OpenAndClose(ITV tv)&#123; //构造器 this.tv = tv; &#125; public void open()&#123; tv.play(); &#125;&#125; 3.通过setter方法传递123456789101112131415161718192021222324252627interface IOpenAndClose&#123; //抽象方法 public void open(ITV tv); public void name(ITV tv);&#125;interface ITV&#123; //ITV接口 public void play();&#125;class Htc implements ITV&#123; @Override public void play() &#123; System.out.println(\"htc电视机，打开\"); &#125;&#125;//实现接口class OpenAndClose implements IOpenAndClose&#123; public ITV tv; public setTv(ITV tv)&#123; //构造器 this.tv = tv; &#125; public void open()&#123; tv.play(); &#125;&#125;","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://kayleh.top/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"DesignPatterns","slug":"DesignPatterns","permalink":"https://kayleh.top/tags/DesignPatterns/"}]},{"title":"接口隔离原则","slug":"接口隔离原则","date":"2020-06-03T09:56:04.000Z","updated":"2020-06-04T01:39:09.487Z","comments":true,"path":"2020/06/03/接口隔离原则/","link":"","permalink":"https://kayleh.top/2020/06/03/%E6%8E%A5%E5%8F%A3%E9%9A%94%E7%A6%BB%E5%8E%9F%E5%88%99/","excerpt":"接口隔离原则 Interface Segregation Principle","text":"接口隔离原则 Interface Segregation Principle 基本介绍 客户端不应该依赖它不需要的接口，即一个类对另一个类的依赖应该建立在最小的接口上。 类A通过接口Interface依赖类D，类C通过接口Interface依赖类D，如果接口Interface对于类A和来说不是最小接口那么类B和类D必须去实现他们不需要的方法。 按隔离原则应当这样处理： 将接口Interface拆分为独立的几个接口，类A和类C分别与他们需要的接口建立依赖关系。也就是采用接口隔离原则。","categories":[],"tags":[{"name":"DesignPatterns","slug":"DesignPatterns","permalink":"https://kayleh.top/tags/DesignPatterns/"}]},{"title":"单一职责原则","slug":"单一职责原则","date":"2020-06-03T08:57:48.000Z","updated":"2020-06-05T03:16:28.003Z","comments":true,"path":"2020/06/03/单一职责原则/","link":"","permalink":"https://kayleh.top/2020/06/03/%E5%8D%95%E4%B8%80%E8%81%8C%E8%B4%A3%E5%8E%9F%E5%88%99/","excerpt":"单一职责原则","text":"单一职责原则 基本介绍 对类来说，即一个类应该只负责一个原则。如果A负责两个不同的原则：职责1，职责2。当职责1需求变更而改变A时，可能导致职责2执行错误。所以需要将类A的粒度分解为A1，A2 细节 降低类的复杂度，一个类只负责一项职责。 降低类的可读性，可维护性。 降低变更引起的风险。 通常情况下，我们应当遵守单一职责原则，只有逻辑足够简单，才可以在代码级违反单一职责原则；只有类中方法数量足够少，可以在方法级别保持单一原则。","categories":[],"tags":[{"name":"DesignPatterns","slug":"DesignPatterns","permalink":"https://kayleh.top/tags/DesignPatterns/"}]},{"title":"XSS跨站脚本攻击","slug":"XSS跨站脚本攻击","date":"2020-05-31T12:58:53.000Z","updated":"2020-08-20T06:46:15.247Z","comments":true,"path":"2020/05/31/XSS跨站脚本攻击/","link":"","permalink":"https://kayleh.top/2020/05/31/XSS%E8%B7%A8%E7%AB%99%E8%84%9A%E6%9C%AC%E6%94%BB%E5%87%BB/","excerpt":"XSS跨站脚本攻击","text":"XSS跨站脚本攻击 在做社区项目的时候，发现了一个XSS漏洞。 什么是XSS跨站脚本攻击？ XSS攻击全称跨站脚本攻击，是一种在web应用中的计算机安全漏洞，它允许恶意web用户将代码植入到提供给其它用户使用的页面中。 在点击回复二级评论时，JavaScript脚本会注入页面: 示例： 然后客户端就调用脚本alert导致无限弹窗。 还可以使用 1&lt;script&gt;alert(document.cookie)&lt;/script&gt; 获取页面cookie，比如登录的token。 解决办法： Jsoup使用标签白名单的机制用来进行防止XSS攻击 参考： [XSS跨站脚本攻击]","categories":[],"tags":[{"name":"safe","slug":"safe","permalink":"https://kayleh.top/tags/safe/"}]},{"title":"SQL注入式攻击","slug":"SQL注入式攻击","date":"2020-05-30T13:13:52.000Z","updated":"2020-08-20T06:46:26.951Z","comments":true,"path":"2020/05/30/SQL注入式攻击/","link":"","permalink":"https://kayleh.top/2020/05/30/SQL%E6%B3%A8%E5%85%A5%E5%BC%8F%E6%94%BB%E5%87%BB/","excerpt":"SQL注入式攻击","text":"SQL注入式攻击 攻击者把SQL命令插入到Web表单的输入域或页面请求的查询字符串，欺骗服务器执行恶意的SQL命令。在某些表单中，用户输入的内容直接用来构造（或者影响）动态SQL命令，或作为存储过程的输入参数，这类表单特别容易受到SQL注入式攻击。 常见的SQL注入式攻击主要是利用Statement的缺陷，服务端验证： 12345678910111213141516171819@Override public void login(Account account) throws SQLException &#123; String sql = \"insert into account values(null,\" + account.userName + \",\" + account.password + \")\"; try (Connection conn = DriverManager.getConnection(\"jdbc:mysql://127.0.0.1:3306/account?characterEncoding=UTF-8\", \"root\", \"password\")) &#123; try (Statement stmt = conn.createStatement()) &#123; try (ResultSet rs = stmt.executeQuery(\"SELECT id, grade, name, gender FROM students WHERE gender=1\")) &#123; while (rs.next()) &#123; int id = rs.getInt(1); String username = rs.getString(2); String password = rs.getString(3); &#125; &#125; &#125; &#125; &#125; 客户端 1234567891011121314151617181920212223242526&lt;link rel=\"stylesheet\" href=\"https://cdn.jsdelivr.net/npm/bootstrap@3.3.7/dist/css/bootstrap.min.css\" integrity=\"sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u\" crossorigin=\"anonymous\"&gt;&lt;link rel=\"stylesheet\" href=\"https://cdn.jsdelivr.net/npm/bootstrap@3.3.7/dist/css/bootstrap-theme.min.css\" integrity=\"sha384-rHyoN1iRsVXV4nD0JutlnGaslCJuC7uwjduW9SVrLvRYooPp2bWYgmgJQIXwl/Sp\" crossorigin=\"anonymous\"&gt;&lt;script src=\"https://cdn.jsdelivr.net/npm/bootstrap@3.3.7/dist/js/bootstrap.min.js\" integrity=\"sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa\" crossorigin=\"anonymous\"&gt;&lt;/script&gt;&lt;div class=\"col-xs-8 col-sm-8 col-md-8 jumbotron\"&gt; &lt;form&gt; &lt;div class=\"form-group\"&gt; &lt;label for=\"exampleInputEmail1\"&gt;Username&lt;/label&gt; &lt;input type=\"email\" class=\"form-control\" id=\"exampleInputEmail1\" placeholder=\"Email\"&gt; &lt;/div&gt; &lt;div class=\"form-group\"&gt; &lt;label for=\"exampleInputPassword1\"&gt;Password&lt;/label&gt; &lt;input type=\"password\" class=\"form-control\" id=\"exampleInputPassword1\" placeholder=\"Password\"&gt; &lt;/div&gt; &lt;div class=\"form-group\"&gt; &lt;label for=\"exampleInputFile\"&gt;File input&lt;/label&gt; &lt;input type=\"file\" id=\"exampleInputFile\"&gt; &lt;p class=\"help-block\"&gt;Example block-level help text here.&lt;/p&gt; &lt;/div&gt; &lt;div class=\"checkbox\"&gt; &lt;label&gt; &lt;input type=\"checkbox\"&gt; Check me out &lt;/label&gt; &lt;/div&gt; &lt;button type=\"submit\" class=\"btn btn-default\"&gt;Submit&lt;/button&gt; &lt;/form&gt;&lt;/div&gt; 如果是客户端精心构造的字符串，例如 12name = \"kayleh' OR pass=\", pass = \" OR pass='\"' or 1= ' 1 命令行永远为真，导致注入成功。 所以使用JDBC时，尽量使用速度比较快且安全的 PreparedStatement ，PreparedStatement 使用的是预编译机制。","categories":[],"tags":[{"name":"safe","slug":"safe","permalink":"https://kayleh.top/tags/safe/"}]},{"title":"维护2","slug":"维护2","date":"2020-05-21T11:12:06.000Z","updated":"2020-08-19T11:27:26.491Z","comments":true,"path":"2020/05/21/维护2/","link":"","permalink":"https://kayleh.top/2020/05/21/%E7%BB%B4%E6%8A%A42/","excerpt":"","text":"网站成功双线部署GitHub、Coding 境外： https://kayleh.github.io/ 境内访问： http://dqlcr5.coding-pages.com/ 完善标签tags功能 完善搜索功能 修复3处页面重定向","categories":[],"tags":[{"name":"maintain","slug":"maintain","permalink":"https://kayleh.top/tags/maintain/"}]},{"title":"二叉排序树","slug":"二叉排序树","date":"2020-05-20T12:42:23.000Z","updated":"2020-06-08T06:27:32.073Z","comments":true,"path":"2020/05/20/二叉排序树/","link":"","permalink":"https://kayleh.top/2020/05/20/%E4%BA%8C%E5%8F%89%E6%8E%92%E5%BA%8F%E6%A0%91/","excerpt":"二叉排序树二叉排序树：BST: (Binary Sort(Search) Tree), 对于二叉排序树的任何一个非叶子节点，要求左子节点的值比当前节点的值小，右子节点的值比当前节点的值大。 如果有相同的值，可以将该节点放在左子节点或右子节点","text":"二叉排序树二叉排序树：BST: (Binary Sort(Search) Tree), 对于二叉排序树的任何一个非叶子节点，要求左子节点的值比当前节点的值小，右子节点的值比当前节点的值大。 如果有相同的值，可以将该节点放在左子节点或右子节点 ​ 数据 (7, 3, 10, 12, 5, 1, 9) ，对应的二叉排序树为 ​ ​ ↓ ​ 二叉排序树的删除情况比较复杂，有下面三种情况需要考虑 1)删除叶子节点 (比如：2, 5, 9, 12) 2)删除只有一颗子树的节点 (比如：1) 3)删除有两颗子树的节点. (比如：7, 3，10 ) 1234567891011121314151617181920212223242526272829303132333435第一种情况:删除叶子节点 (比如：2, 5, 9, 12)思路(1) 需求先去找到要删除的结点 targetNode(2) 找到targetNode 的 父结点 parent (3) 确定 targetNode 是 parent的左子结点 还是右子结点(4) 根据前面的情况来对应删除左子结点 parent.left = null右子结点 parent.right = null;第二种情况: 删除只有一颗子树的节点 比如 1思路(1) 需求先去找到要删除的结点 targetNode(2) 找到targetNode 的 父结点 parent (3) 确定targetNode 的子结点是左子结点还是右子结点(4) targetNode 是 parent 的左子结点还是右子结点(5) 如果targetNode 有左子结点5. 1 如果 targetNode 是 parent 的左子结点parent.left = targetNode.left;5.2 如果 targetNode 是 parent 的右子结点parent.right = targetNode.left;(6) 如果targetNode 有右子结点6.1 如果 targetNode 是 parent 的左子结点parent.left = targetNode.right;6.2 如果 targetNode 是 parent 的右子结点parent.right = targetNode.right情况三 ： 删除有两颗子树的节点. (比如：7, 3，10 )思路(1) 需求先去找到要删除的结点 targetNode(2) 找到targetNode 的 父结点 parent (3) 从targetNode 的右子树找到最小的结点(4) 用一个临时变量，将 最小结点的值保存 temp = 11(5) 删除该最小结点(6) targetNode.value = temp 代码实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266package binarysorttree;/** * @Author: Wizard * @Date: 2020/5/20 11:42 */public class BinarySortTreeDemo &#123; public static void main(String[] args) &#123;// int[] arr = &#123;7, 3, 10, 12, 5, 1, 9&#125;; int[] arr = &#123;7,3&#125;; BinarySortTree binarySortTree = new BinarySortTree(); for (int i = 0; i &lt; arr.length; i++) &#123; binarySortTree.add(new Node(arr[i])); &#125; binarySortTree.infixOrder(); binarySortTree.delNode(7); System.out.println(\"删除后\"); binarySortTree.infixOrder(); &#125;&#125;//创建二叉排序树class BinarySortTree &#123; private Node root; //查找要删除的结点 public Node search(int value) &#123; if (root == null) &#123; return null; &#125; else &#123; return root.search(value); &#125; &#125; //查找父结点 public Node searchParent(int value) &#123; if (root == null) &#123; return null; &#125; else &#123; return root.searchParent(value); &#125; &#125; /** * 右边找最小的 * 左边找最大的 * * 返回的 以node为根结点的最小结点的值 * 删除以node为根结点的最小结点的值 * * @param node 传入的结点（当做二叉排序树的根结点） * @return 返回的 以node为根结点的最小结点的值 */ public int delRightTreeMin(Node node) &#123; Node target = node; //循环的查找左子节点，就会找到最小值 while (target.left != null) &#123; target = target.left; &#125; //这是target就指向了最小结点 //删除最小结点 delNode(target.value); return target.value; &#125; //删除结点 public void delNode(int value) &#123; if (root == null) &#123; return; &#125; else &#123; //需要先去找到要删除的结点 targetNode Node targetNode = search(value); //如果没有找到要删除的结点 if (targetNode == null) &#123; return; &#125; //如果发现targetNode没有父结点（就是根结点）(只有一个结点) if (root.left == null &amp;&amp; root.right == null) &#123; root = null; return; &#125; //去找到targetNode的父结点 Node parent = searchParent(value); //如果要删除的结点是叶子结点 if (targetNode.left == null &amp;&amp; targetNode.right == null) &#123; //判断targetNode是父结点的左子结点还是右子结点 if (parent.left != null &amp;&amp; parent.left.value == value) &#123; parent.left = null; &#125; else if (parent.right != null &amp;&amp; parent.right.value == value) &#123; parent.right = null; &#125; &#125; else if (targetNode.left != null &amp;&amp; targetNode.right != null) &#123; //删除有两颗子树的结点 int min = delRightTreeMin(targetNode.right);//target右边最小的值 targetNode.value = min; &#125; else &#123; //删除只有一颗子树的结点 //如果要删除的结点有左子结点// System.out.println(parent); if (parent!=null) &#123; if (targetNode.left != null) &#123; //如果targetNode是parent的左子结点 if (parent.left.value == value) &#123; parent.left = targetNode.left; &#125; else &#123; //如果targetNode是parent的右子结点 parent.right = targetNode.left; &#125; &#125; else &#123; //如果要删除的结点有右子结点 if (parent.left.value == value) &#123; //如果targetNode是parent的左子结点 parent.left = targetNode.right; &#125; else &#123; //如果targetNode是parent的右子结点 parent.right = targetNode.right; &#125; &#125; &#125;else &#123; if (root.left!=null)&#123; root = root.left; &#125;else &#123; root = root.right; &#125; &#125; &#125; &#125; &#125; //添加结点的方法 public void add(Node node) &#123; if (root == null) &#123; root = node; &#125; else &#123; root.add(node); &#125; &#125; //中序遍历方法 public void infixOrder() &#123; if (root != null) &#123; root.infixOrder(); &#125; else &#123; System.out.println(\"当前二叉排序树为空，不能遍历\"); &#125; &#125;&#125;//创建Node结点class Node &#123; int value; Node left; Node right; @Override public String toString() &#123; return \"Node&#123;\" + \"value=\" + value + '&#125;'; &#125; /** * 查找要删除的结点 * * @param value 希望删除的结点的值 * @return 如果找到返回该结点，否则返回null */ public Node search(int value) &#123; if (value == this.value) &#123; //找到就是该结点 return this; &#125; else if (value &lt; this.value) &#123; //如果查找的值小于当前结点，向左子树递归查找 //如果左子结点为空 if (this.left == null) &#123; return null; &#125; return this.left.search(value); &#125; else &#123; //如果查找的值不小于当前结点，向右子树递归查找 if (this.right == null) &#123; return null; &#125; return this.right.search(value); &#125; &#125; /** * 查找要删除结点的父结点 * * @param value 要找到结点的值 * @return 返回的是要删除的结点的父结点，如果没有就返回null */ public Node searchParent(int value) &#123; //如果当前结点就是要删除的结点的父结点，就返回 if ((this.left != null &amp;&amp; this.left.value == value) || (this.right != null &amp;&amp; this.right.value == value)) &#123; return this; &#125; else &#123; //如果查找的值小于当前结点的值，并且当前结点的左子结点不为空 if (value &lt; this.value &amp;&amp; this.left != null) &#123; return this.left.search(value);//向左子树递归查找 &#125; else if (value &gt;= this.value &amp;&amp; this.right != null) &#123; return this.right.search(value);//向右子树递归查找 &#125; else &#123; return null;//没有找到父结点 &#125; &#125; &#125; public Node(int value) &#123; this.value = value; &#125; //添加结点的方式 //递归的形式添加结点，需要满足二叉排序树的要求 public void add(Node node) &#123; if (node == null) &#123; return; &#125; //判断传入的结点的值，和当前子树的根结点的值的关系 if (node.value &lt; this.value) &#123; //如果当前结点的左子结点为null if (this.left == null) &#123; //把结点挂在左子结点 this.left = node; &#125; else &#123; //如果左子结点不为空，向左子树递归添加 this.left.add(node); &#125; &#125; else &#123; //如果 添加的结点的值 大于 根结点的值 if (this.right == null) &#123; this.right = node; &#125; else &#123; this.right.add(node); &#125; &#125; &#125; //中序遍历 public void infixOrder() &#123; if (this.left != null) &#123; this.left.infixOrder(); &#125; System.out.println(this); if (this.right != null) &#123; this.right.infixOrder(); &#125; &#125;&#125;","categories":[],"tags":[{"name":"dataAlgorithm","slug":"dataAlgorithm","permalink":"https://kayleh.top/tags/dataAlgorithm/"}]},{"title":"堆排序","slug":"堆排序","date":"2020-05-18T12:40:11.000Z","updated":"2020-08-20T06:51:31.072Z","comments":true,"path":"2020/05/18/堆排序/","link":"","permalink":"https://kayleh.top/2020/05/18/%E5%A0%86%E6%8E%92%E5%BA%8F/","excerpt":"堆排序","text":"堆排序 1.堆排序是利用堆这种数据结构而设计的一种算法，堆排序是一种选择排序，它的最坏，最好，平均复杂度均为O(nlogn)，它也是不稳定的排序。 2.堆是具有以下性质的完全二叉树：每个结点的值都大于或等于其左右孩子结点的值，称为大顶堆。没有要求结点的左孩子的值和右孩子的值大小关系。 3.每个结点的值都小于或等于其左右孩子结点的值，称为小顶堆 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687package sort;import java.util.Arrays;/** * @Author: Wizard * @Date: 2020/5/18 21:16 */public class heapSort &#123; public static void main(String[] args) &#123; //要求将数组进行升序排列 &#125; //编写一个堆排序的方法 public static void heapSort(int arr[]) &#123; int temp = 0; System.out.println(\"堆排序！\"); // i 第一个非叶子结点 // 这里的目的是把最大的数交换到堆顶，成为一个大顶堆结构 for (int i = arr.length / 2 - 1; i &gt;= 0; i--) &#123; adjustHeap(arr, i, arr.length); System.out.println(Arrays.toString(arr)); &#125; /* 将堆顶元素于末尾元素交换，将最大元素“沉”到数组末端 重新调整结构，使其满足堆定义，然后继续交换堆顶元素与当前末尾元素，反复执行调整+交换步骤，直到整个序列有序 */ //一共5个数，调整4个数就可以了 for (int j = arr.length - 1; j &gt; 0; j--) &#123; temp = arr[j]; arr[j] = arr[0];//arr[0] 是上面调整后的最大值 arr[0] = temp; adjustHeap(arr, 0, j); System.out.println(\"第\"+(arr.length-j)+\"次沉\"+Arrays.toString(arr)); &#125; System.out.println(Arrays.toString(arr)); //每次遍历把最大的数（在调整之后的父节点，第一位）沉到数组的末端 //然后 再调整 把最大的数交换到堆顶（adjustHeap），再沉到数组的末端的位置-1，随着j的递减，末尾的前几个数字逐渐确定（调整的范围减少） &#125; //将一个数组(二叉树),调整为一个大顶堆 /** * 功能：完成将以 i 对应的非叶子结点的树调整为大顶堆 * int arr[] = &#123;4,6,8,5,9&#125;; → i = 1 → adjustHeap → 得到&#123;4,9,8,5,6&#125; * 再次调用adjustHeap 传入的是 i= 0 → 得到&#123;9,6,8,5,4&#125; * * @param arr 待调整的数组 * @param i 表示非叶子结点在数组中的索引 * @param lenght 表示归多少个元素继续调整，length 是在逐渐的减少 */ public static void adjustHeap(int arr[], int i, int lenght) &#123; int temp = arr[i];//取出当前元素的值，保存在临时变量， 以 i 作为父节点（局部） //开始调整 //k = i对应的左子节点 for (int k = 2 * i + 1; k &lt; lenght; k = 2 * i + 1) &#123; if (k + 1 &lt; lenght &amp;&amp; arr[k] &lt; arr[k + 1]) &#123; //说明左子节点的值小于右子节点 k++;//让 k 指向右子节点 &#125; if (arr[k] &gt; temp) &#123; //如果子节点大于父节点 //就把较大的值赋值给当前节点 arr[i] = arr[k]; // ! i指向k 继续循环比较 i = k; //把i（父节点）指向 k（子节点）。作为父节点继续循环 &#125; else &#123; //如果子节点小于父节点 //堆排序是从左至右，从下至上 break; &#125; &#125; //当for循环结束后，已经将以i为父节点的树的最大值，放在了最顶（局部） arr[i] = temp;//将temp值放到调整后的位置 //adjustHeap()方法中依然要循环, 是因为最后在堆排序的时候是从下到上的, 排序中向上调用这个方法时 , i也会往上走, 这时再次调用adjustHeapt //这时再次调用adjustHeap方法时, i就不是最后一个非叶子节点了, 会破坏原先已经排序好的大顶堆, 所以需要循环往下将被破坏的大顶堆重新建立起来 &#125;&#125;","categories":[],"tags":[{"name":"dataAlgorithm","slug":"dataAlgorithm","permalink":"https://kayleh.top/tags/dataAlgorithm/"}]},{"title":"7种排序算法","slug":"7种排序算法","date":"2020-05-17T13:42:21.000Z","updated":"2020-08-20T06:52:02.099Z","comments":true,"path":"2020/05/17/7种排序算法/","link":"","permalink":"https://kayleh.top/2020/05/17/7%E7%A7%8D%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/","excerpt":"冒泡排序","text":"冒泡排序 冒泡排序（BubbleSorting)的基本思想是：通过对待排序序列从前向后（从下标较小的元素开始）,依次比较相邻元素的值，若发现逆序则交换，使值较大的元素逐渐从前移向后部。 代码实现 1234567891011121314151617181920212223242526// 将前面的冒泡排序算法，封装成一个方法 public static void bubbleSort(int[] arr) &#123; // 冒泡排序 的时间复杂度 O(n^2), 自己写出 int temp = 0; // 临时变量 boolean flag = false; // 标识变量，表示是否进行过交换 for (int i = 0; i &lt; arr.length - 1; i++) &#123; for (int j = 0; j &lt; arr.length - 1 - i; j++) &#123; // 如果前面的数比后面的数大，则交换 if (arr[j] &gt; arr[j + 1]) &#123; flag = true; temp = arr[j]; arr[j] = arr[j + 1]; arr[j + 1] = temp; &#125; &#125; //System.out.println(\"第\" + (i + 1) + \"趟排序后的数组\"); //System.out.println(Arrays.toString(arr)); if (!flag) &#123; // 在一趟排序中，一次交换都没有发生过 break; &#125; else &#123; flag = false; // 重置flag!!!, 进行下次判断 &#125; &#125; 插入排序 插入排序（insertSorting) 基本思想是：把n个待排序的元素看成为一个有序表和一个无序表，开始时有序表中只包含一个元素，无序表中包含有n-1个元素，排序过程中每次从无序表中取出第一个元素，把它的排序码依次与有序表元素的排序码进行比较，将它插入到有序表中的适当位置，使之成为新的有序表。 代码实现 1234567891011121314151617181920212223public static void insertSort(int attr[]) &#123; //从第2个数开始遍历 【1】 for (int i = 1; i &lt; attr.length - 1; i++) &#123; // 等待插入的数的前一个数下标 int insertIndex = i - 1; //等待插入的数的值 int insertValue = attr[i]; // insertIndex不能越界 // insertValue待插入到前面有序列表的数 // insertValue待插入的数 小于 前1个数 while (insertIndex &gt;= 0 &amp;&amp; attr[insertIndex] &gt; insertValue) &#123; // 交换 // attr[insertIndex]后移 attr[insertIndex + 1] = attr[insertIndex]; insertIndex--; &#125; //当退出while循环时，说明插入的位置找到, insertIndex + 1 if (insertIndex + 1 != i) &#123; attr[insertIndex + 1] = insertValue; &#125; &#125; &#125; 选择排序 选择排序（selectSorting)的基本思想是： 第一次从arr[0]arr[n-1]中选取最小值，与arr[0]交换，第二次从arr[1]arr[n-1]中选取最小值，与arr[1]交换，第三次从arr[2]arr[n-1]中选取最小值，与arr[2]交换，…，第i次从arr[i-1]arr[n-1]中选取最小值，与arr[i-1]交换，…,第n-1次从arr[n-2]~arr[n-1]中选取最小值，与arr[n-2]交换，总共通过n-1次，得到一个按排序码从小到大排列的有序序列。 代码实现 123456789101112131415161718192021222324public class selectSort &#123; public static void selectSort(int attr[]) &#123; for (int i = 0; i &lt; attr.length - 1; i++) &#123; //假设第一个数就是最小值 int minindex = 0; int min = attr[0]; //从1开始遍历 for (int j = 1; j &lt; attr.length - 1; j++) &#123; //如果第0个数（最小值）比第1个数 大 //说明假设的第0个并不是最小值 if (min &gt; attr[j]) &#123; min = attr[j];//重置最小值 minindex = j;//重置最小值索引 &#125; &#125; //如果最小值的索引不是0，就发生交换 if (minindex != i) &#123; //把第0个数（不是最小值）赋值到 第1个数（较小值）的位置 attr[minindex] = attr[i]; //把较小值赋值给第1个数 attr[i] = min; &#125; &#125; &#125; 希尔排序 冒泡排序（BubbleSorting)的基本思想是： 把记录按下标的一定增量分组，对每组使用直接插入排序算法排序；随着增量逐渐减少，每组包含的关键词越来越多，当增量减至1时，整个文件恰被分成一组，算法便终止 代码实现 12345678910111213141516171819202122//移动法 //增量gap，并逐步的缩小增量 for (int gap = attr.length/2;gap&gt;0;gap/=2)&#123; //从第gap个元素开始，逐个对其所在的组进行直接插入排序 for (int i =gap;i&lt;attr.length;i++)&#123; // 当前位置 int j = i; //当前位置的值赋值给temp int temp = attr[j]; // 如果 当前组的gap个步长前面的数大于当前位置的数 if(attr[j]&lt;attr[j-gap])&#123; while (j-gap &gt;= 0 &amp;&amp; temp &lt; attr[j-gap])&#123; //移动 attr[j] = attr[j-gap]; j -= gap; &#125; //当退出while循环后，就给temp找到插入的位置 attr[j] = temp; &#125; &#125; &#125; 快速排序 快速排序（QuickSorting) 是对冒泡排序的一种改进。基本思想是：通过一趟排序将要排序的数据分割成独立的两部分，其中一部分的所有数据都比另外一部分的所有数据都要小，然后再按此方法对这两部分数据分别进行快速排序，整个排序过程可以递归进行，以此达到整个数据变成有序序列 代码实现 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051public static void quickSort(int[] arr,int left, int right) &#123; int l = left; //左下标 int r = right; //右下标 //pivot 中轴值 int pivot = arr[(left + right) / 2]; int temp = 0; //临时变量，作为交换时使用 //while循环的目的是让比pivot 值小放到左边 //比pivot 值大放到右边 while( l &lt; r) &#123; //在pivot的左边一直找,找到大于等于pivot值,才退出 while( arr[l] &lt; pivot) &#123; l += 1; &#125; //在pivot的右边一直找,找到小于等于pivot值,才退出 while(arr[r] &gt; pivot) &#123; r -= 1; &#125; //如果l &gt;= r说明pivot 的左右两的值，已经按照左边全部是 //小于等于pivot值，右边全部是大于等于pivot值 if( l &gt;= r) &#123; break; &#125; //交换 temp = arr[l]; arr[l] = arr[r]; arr[r] = temp; //如果交换完后，发现这个arr[l] == pivot值 相等 r--， 前移 if(arr[l] == pivot) &#123; r -= 1; &#125; //如果交换完后，发现这个arr[r] == pivot值 相等 l++， 后移 if(arr[r] == pivot) &#123; l += 1; &#125; &#125; // 如果 l == r, 必须l++, r--, 否则为出现栈溢出 if (l == r) &#123; l += 1; r -= 1; &#125; //向左递归 if(left &lt; r) &#123; quickSort(arr, left, r); &#125; //向右递归 if(right &gt; l) &#123; quickSort(arr, l, right); &#125; &#125; 归并排序 归并排序（mergeSorting)的基本思想是： 是利用归并的思想实现的排序方法，该算法采用经典的分治（divide-and-conquer）策略（分治法将问题分(divide)成一些小的问题然后递归求解，而治(conquer)的阶段则将分的阶段得到的各答案”修补”在一起，即分而治之)。 代码实现 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869//分+合方法 public static void mergeSort(int[] arr, int left, int right, int[] temp) &#123; if(left &lt; right) &#123; int mid = (left + right) / 2; //中间索引 //向左递归进行分解 mergeSort(arr, left, mid, temp); //向右递归进行分解 mergeSort(arr, mid + 1, right, temp); //合并 merge(arr, left, mid, right, temp); &#125; &#125; //合并的方法 /** * * @param arr 排序的原始数组 * @param left 左边有序序列的初始索引 * @param mid 中间索引 * @param right 右边索引 * @param temp 做中转的数组 */ public static void merge(int[] arr, int left, int mid, int right, int[] temp) &#123; int i = left; // 初始化i, 左边有序序列的初始索引 int j = mid + 1; //初始化j, 右边有序序列的初始索引 int t = 0; // 指向temp数组的当前索引 //(一) //先把左右两边(有序)的数据按照规则填充到temp数组 //直到左右两边的有序序列，有一边处理完毕为止 while (i &lt;= mid &amp;&amp; j &lt;= right) &#123;//继续 //如果左边的有序序列的当前元素，小于等于右边有序序列的当前元素 //即将左边的当前元素，填充到 temp数组 //然后 t++, i++ if(arr[i] &lt;= arr[j]) &#123; temp[t] = arr[i]; t += 1; i += 1; &#125; else &#123; //反之,将右边有序序列的当前元素，填充到temp数组 temp[t] = arr[j]; t += 1; j += 1; &#125; &#125; //(二) //把有剩余数据的一边的数据依次全部填充到temp while( i &lt;= mid) &#123; //左边的有序序列还有剩余的元素，就全部填充到temp temp[t] = arr[i]; t += 1; i += 1; &#125; while( j &lt;= right) &#123; //右边的有序序列还有剩余的元素，就全部填充到temp temp[t] = arr[j]; t += 1; j += 1; &#125; //(三) //将temp数组的元素拷贝到arr //注意，并不是每次都拷贝所有 t = 0; int tempLeft = left; // //第一次合并 tempLeft = 0 , right = 1 // tempLeft = 2 right = 3 // tL=0 ri=3 //最后一次 tempLeft = 0 right = 7 while(tempLeft &lt;= right) &#123; arr[tempLeft] = temp[t]; t += 1; tempLeft += 1; &#125; &#125; 基数排序 基数排序（mergeSorting)的基本思想是： 将所有待比较数值统一为同样的数位长度，数位较短的数前面补零。然后，从最低位开始，依次进行一次排序。这样从最低位排序一直到最高位排序完成以后, 数列就变成一个有序序列。 代码实现 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758//基数排序方法public static void radixSort(int[] arr) &#123; //根据前面的推导过程，我们可以得到最终的基数排序代码 //1. 得到数组中最大的数的位数 int max = arr[0]; //假设第一数就是最大数 for(int i = 1; i &lt; arr.length; i++) &#123; if (arr[i] &gt; max) &#123; max = arr[i]; &#125; &#125; //得到最大数是几位数 int maxLength = (max + \"\").length(); //定义一个二维数组，表示10个桶, 每个桶就是一个一维数组 //说明 //1. 二维数组包含10个一维数组 //2. 为了防止在放入数的时候，数据溢出，则每个一维数组(桶)，大小定为arr.length //3. 名明确，基数排序是使用空间换时间的经典算法 int[][] bucket = new int[10][arr.length]; //为了记录每个桶中，实际存放了多少个数据,我们定义一个一维数组来记录各个桶的每次放入的数据个数 //可以这里理解 //比如：bucketElementCounts[0] , 记录的就是 bucket[0] 桶的放入数据个数 int[] bucketElementCounts = new int[10]; //这里使用循环将代码处理 for(int i = 0 , n = 1; i &lt; maxLength; i++, n *= 10) &#123; //(针对每个元素的对应位进行排序处理)， 第一次是个位，第二次是十位，第三次是百位.. for(int j = 0; j &lt; arr.length; j++) &#123; //取出每个元素的对应位的值 int digitOfElement = arr[j] / n % 10; //放入到对应的桶中 bucket[digitOfElement][bucketElementCounts[digitOfElement]] = arr[j]; bucketElementCounts[digitOfElement]++; &#125; //按照这个桶的顺序(一维数组的下标依次取出数据，放入原来数组) int index = 0; //遍历每一桶，并将桶中是数据，放入到原数组 for(int k = 0; k &lt; bucketElementCounts.length; k++) &#123; //如果桶中，有数据，我们才放入到原数组 if(bucketElementCounts[k] != 0) &#123; //循环该桶即第k个桶(即第k个一维数组), 放入 for(int l = 0; l &lt; bucketElementCounts[k]; l++) &#123; //取出元素放入到arr arr[index++] = bucket[k][l]; &#125; &#125; //第i+1轮处理后，需要将每个 bucketElementCounts[k] = 0 ！！！！ bucketElementCounts[k] = 0; &#125; &#125;&#125; 各个算法的复杂度","categories":[],"tags":[{"name":"dataAlgorithm","slug":"dataAlgorithm","permalink":"https://kayleh.top/tags/dataAlgorithm/"}]},{"title":"计算机组成原理","slug":"计算机组成原理","date":"2020-05-14T14:04:21.000Z","updated":"2020-05-16T11:15:07.455Z","comments":true,"path":"2020/05/14/计算机组成原理/","link":"","permalink":"https://kayleh.top/2020/05/14/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86/","excerpt":"计算机组成原理1.第一台电子计算机何时何地诞生？英文全称？1946年2月14日 美国宾夕法尼亚大学","text":"计算机组成原理1.第一台电子计算机何时何地诞生？英文全称？1946年2月14日 美国宾夕法尼亚大学 ENIAC：电子数字积分计算机 Electronic(电子的) Numerical(数字的) Integrator(综合者) And Calculator(计算机) 2.冯·诺依曼型计算机组成,思想?计算机组成: 运算器、控制器、存储器、输入设备、输出设备。 思想： 采用二进制的形式表示数据和指令，将数据和指令事先保存在存储器中，按照顺序执行程序来控制计算机工作运行。 3.现代计算机硬件系统与冯·诺依曼型计算机组成有什么不同？相同点： 现代计算机仍是冯·诺依曼体系结构。 不同点：组成形式改变很大 (1)逻辑元件组装成电路高度集成,把运算、控制器集成到一块CPU芯片上。 (2)存储器分为三级：高速缓冲存储器Cache，主存储器(内存),外部存储器; 其中Cache现在都集成在CPU里,主存由内存条实现,外部存储器主要有机械硬盘,固态硬盘等; (3)输出与输入设备主要有显示屏,鼠标,键盘. 显示器有专门显示接口(集成或独立显卡)连接CPU或主存,键盘和鼠标也通过集成接口CPU. 此外还配置集成网卡和声卡. (4)USB多种连接接口实现网络与多媒体连接.整个系统采用多级总线结构组成. 4.CPU的性能公式,性能指标,如何评价?","categories":[],"tags":[]},{"title":"队列","slug":"队列","date":"2020-05-14T08:52:39.000Z","updated":"2020-08-20T06:51:21.293Z","comments":true,"path":"2020/05/14/队列/","link":"","permalink":"https://kayleh.top/2020/05/14/%E9%98%9F%E5%88%97/","excerpt":"队列","text":"队列 定义：遵循先进先出，就是队列。可以想象为排队，先排队的人先办理业务。 队列是一个有序列表。 遵循先进先出的原则。即：先存入的数据先取出，后存入的数据后取出。 示意：数组模拟： 队列本身是有序列表，如使用数组的结构来存储队列的数据，因为队列的输出、输入是分别从前后端来处理，因此需要两个变量front及rear分别记录队列前后端的下标，front会随着数据输出而改变，而rear则是随着数据输入而改变，其中 maxSize是该队列的最大容量。如图所示。 用稀疏数组代替二维数组，第0行表示稀疏数组的总行，总列和所需内容的个数。 代码实现 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151package queue;import java.util.Scanner;public class CircleArrayQueueDemo &#123; public static void main(String[] args) &#123; //测试 System.out.println(\"测试数组模拟环形队列的案例~~~\"); // 创建一个环形队列 CircleArray queue = new CircleArray(4); //说明设置4, 其队列的有效数据最大是3 char key = ' '; // 接收用户输入 Scanner scanner = new Scanner(System.in);// boolean loop = true; // 输出一个菜单 while (loop) &#123; System.out.println(\"s(show): 显示队列\"); System.out.println(\"e(exit): 退出程序\"); System.out.println(\"a(add): 添加数据到队列\"); System.out.println(\"g(get): 从队列取出数据\"); System.out.println(\"h(head): 查看队列头的数据\"); key = scanner.next().charAt(0);// 接收一个字符 switch (key) &#123; case 's': queue.showQueue(); break; case 'a': System.out.println(\"输出一个数\"); int value = scanner.nextInt(); queue.addQueue(value); break; case 'g': // 取出数据 try &#123; int res = queue.getQueue(); System.out.printf(\"取出的数据是%d\\n\", res); &#125; catch (Exception e) &#123; // TODO: handle exception System.out.println(e.getMessage()); &#125; break; case 'h': // 查看队列头的数据 try &#123; int res = queue.headQueue(); System.out.printf(\"队列头的数据是%d\\n\", res); &#125; catch (Exception e) &#123; // TODO: handle exception System.out.println(e.getMessage()); &#125; break; case 'e': // 退出 scanner.close(); loop = false; break; default: break; &#125; &#125; System.out.println(\"程序退出~~\"); &#125;&#125;class CircleArray &#123; private int maxSize; // 表示数组的最大容量 //front 变量的含义做一个调整：front 就指向队列的第一个元素, 也就是说 arr[front] 就是队列的第一个元素 //front 的初始值 = 0 private int front; //rear 变量的含义做一个调整：rear 指向队列的最后一个元素的后一个位置. 因为希望空出一个空间做为约定. //rear 的初始值 = 0 private int rear; // 队列尾 private int[] arr; // 该数据用于存放数据, 模拟队列 public CircleArray(int arrMaxSize) &#123; maxSize = arrMaxSize; arr = new int[maxSize]; &#125; // 判断队列是否满 public boolean isFull() &#123; return (rear + 1) % maxSize == front; &#125; // 判断队列是否为空 public boolean isEmpty() &#123; return rear == front; &#125; // 添加数据到队列 public void addQueue(int n) &#123; // 判断队列是否满 if (isFull()) &#123; System.out.println(\"队列满，不能加入数据~\"); return; &#125; //直接将数据加入 arr[rear] = n; //将 rear 后移, 这里必须考虑取模 rear = (rear + 1) % maxSize; &#125; // 获取队列的数据, 出队列 public int getQueue() &#123; // 判断队列是否空 if (isEmpty()) &#123; // 通过抛出异常 throw new RuntimeException(\"队列空，不能取数据\"); &#125; // 这里需要分析出 front是指向队列的第一个元素 // 1. 先把 front 对应的值保留到一个临时变量 // 2. 将 front 后移, 考虑取模 // 3. 将临时保存的变量返回 int value = arr[front]; front = (front + 1) % maxSize; return value; &#125; // 显示队列的所有数据 public void showQueue() &#123; // 遍历 if (isEmpty()) &#123; System.out.println(\"队列空的，没有数据~~\"); return; &#125; // 思路：从front开始遍历，遍历多少个元素 // 动脑筋 for (int i = front; i &lt; front + size() ; i++) &#123; System.out.printf(\"arr[%d]=%d\\n\", i % maxSize, arr[i % maxSize]); &#125; &#125; // 求出当前队列有效数据的个数 public int size() &#123; // rear = 2 // front = 1 // maxSize = 3 return (rear + maxSize - front) % maxSize; &#125; // 显示队列的头数据， 注意不是取出数据 public int headQueue() &#123; // 判断 if (isEmpty()) &#123; throw new RuntimeException(\"队列空的，没有数据~~\"); &#125; return arr[front]; &#125;&#125;","categories":[],"tags":[{"name":"dataAlgorithm","slug":"dataAlgorithm","permalink":"https://kayleh.top/tags/dataAlgorithm/"}]},{"title":"Inversion of Control控制反转","slug":"Inversion-of-Control控制反转","date":"2020-05-13T08:42:55.000Z","updated":"2020-08-20T06:49:18.899Z","comments":true,"path":"2020/05/13/Inversion-of-Control控制反转/","link":"","permalink":"https://kayleh.top/2020/05/13/Inversion-of-Control%E6%8E%A7%E5%88%B6%E5%8F%8D%E8%BD%AC/","excerpt":"控制反转的定义","text":"控制反转的定义 Inversion of Control控制反转，贯穿Spring的始终，Spring的核心。由spring来负责控制对象的生命周期和对象间的关系。 IOC的思想是反转资源获取方向.传统的资源查找方式要求组件向容器发起请求查找资源.作为回应,容器适时的返回资源,而应用IOC之后,则是容器主动的将资源推送给它所管理的组件,组件所要做的仅仅是选择一种合适的方式来接受资源,这种行为也被称为查找的被动形式. ▼传统的方法获取： 1Pojo pojo = new Pojo( ); ▼Spring管理的bean获取： 12@AutowiredPojo pojo; ’ 对象的生命周期由Spring来管理，直接从Spring那里去获取一个对象。IOC是反转控制 (Inversion Of Control)的缩写，就像控制权从本来在自己手里，交给了Spring。‘","categories":[],"tags":[{"name":"frame","slug":"frame","permalink":"https://kayleh.top/tags/frame/"}]},{"title":"链表","slug":"链表","date":"2020-05-12T11:21:40.000Z","updated":"2020-06-06T09:12:33.874Z","comments":true,"path":"2020/05/12/链表/","link":"","permalink":"https://kayleh.top/2020/05/12/%E9%93%BE%E8%A1%A8/","excerpt":"链表是有序的列表，但它在内存里是无序的。","text":"链表是有序的列表，但它在内存里是无序的。 链表是以节点的方式来存储,是链式存储 每个节点包含data 域， next 域：指向下一个节点 各个节点不一定是连续存储. 链表分带头节点的链表和没有头节点的链表，根据实际的需求来确定 ▼单链表： 实现： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572573574575576577578579580581582583584585586587588589590591592593594595596597598599600601602603604605606607608609610611612613614615616617618619620621622623624625626627628629630631632633634635636637638639640641642643644645646647648649650651652653654655package linkedlist;/** * @Author * @Date: 2020/5/11 10:59 */import java.util.Stack;public class SingleLinkedListDemo &#123; public static void main(String[] args) &#123; //进行测试 //先创建节点 HeroNode hero1 = new HeroNode(1, \"宋江\", \"及时雨\"); HeroNode hero2 = new HeroNode(2, \"卢俊义\", \"玉麒麟\"); HeroNode hero3 = new HeroNode(3, \"吴用\", \"智多星\"); HeroNode hero4 = new HeroNode(4, \"林冲\", \"豹子头\"); //创建要给链表 SingleLinkedList singleLinkedList = new SingleLinkedList(); //加入 singleLinkedList.add(hero1); singleLinkedList.add(hero4); singleLinkedList.add(hero2); singleLinkedList.add(hero3); // 测试一下单链表的反转功能 System.out.println(\"原来链表的情况~~\"); singleLinkedList.list();// System.out.println(\"反转单链表~~\");// reversetList(singleLinkedList.getHead());// singleLinkedList.list(); System.out.println(\"测试逆序打印单链表, 没有改变链表的结构~~\"); reversetList(singleLinkedList.getHead()); //加入按照编号的顺序 singleLinkedList.addByOrder(hero1); singleLinkedList.addByOrder(hero4); singleLinkedList.addByOrder(hero2); singleLinkedList.addByOrder(hero3); //显示一把 singleLinkedList.list(); //测试修改节点的代码 HeroNode newHeroNode = new HeroNode(2, \"小卢\", \"玉麒麟~~\"); singleLinkedList.update(newHeroNode); System.out.println(\"修改后的链表情况~~\"); singleLinkedList.list(); //删除一个节点 singleLinkedList.del(1); singleLinkedList.del(4); System.out.println(\"删除后的链表情况~~\"); singleLinkedList.list(); //测试一下 求单链表中有效节点的个数 System.out.println(\"有效的节点个数=\" + getLength(singleLinkedList.getHead()));//2 //测试一下看看是否得到了倒数第K个节点 HeroNode res = findLastIndexNode(singleLinkedList.getHead(), 3); System.out.println(\"res=\" + res); &#125; //将单链表反转 public static void reversetList(HeroNode head) &#123; //如果当前链表为空，或者只有一个节点，无需反转，直接返回 if(head.next == null || head.next.next == null) &#123; return ; &#125; //定义一个辅助的指针(变量)，帮助我们遍历原来的链表 HeroNode cur = head.next; HeroNode next = null;// 指向当前节点[cur]的下一个节点 HeroNode reverseHead = new HeroNode(0, \"\", \"\"); //遍历原来的链表，每遍历一个节点，就将其取出，并放在新的链表reverseHead 的最前端 //动脑筋 while(cur != null) &#123; next = cur.next;//先暂时保存当前节点的下一个节点，因为后面需要使用 cur.next = reverseHead.next;//将cur的下一个节点指向新的链表的最前端 reverseHead.next = cur; //将cur 连接到新的链表上 cur = next;//让cur后移 &#125; //将head.next 指向 reverseHead.next , 实现单链表的反转 head.next = reverseHead.next; &#125; //查找单链表中的倒数第k个结点 【新浪面试题】 //思路 //1. 编写一个方法，接收head节点，同时接收一个index //2. index 表示是倒数第index个节点 //3. 先把链表从头到尾遍历，得到链表的总的长度 getLength //4. 得到size 后，我们从链表的第一个开始遍历 (size-index)个，就可以得到 //5. 如果找到了，则返回该节点，否则返回nulll public static HeroNode findLastIndexNode(HeroNode head, int index) &#123; //判断如果链表为空，返回null if(head.next == null) &#123; return null;//没有找到 &#125; //第一个遍历得到链表的长度(节点个数) int size = getLength(head); //第二次遍历 size-index 位置，就是我们倒数的第K个节点 //先做一个index的校验 if(index &lt;=0 || index &gt; size) &#123; return null; &#125; //定义给辅助变量， for 循环定位到倒数的index HeroNode cur = head.next; //3 // 3 - 1 = 2 for(int i =0; i&lt; size - index; i++) &#123; cur = cur.next; &#125; return cur; &#125; //方法：获取到单链表的节点的个数(如果是带头结点的链表，需求不统计头节点) /** * * @param head 链表的头节点 * @return 返回的就是有效节点的个数 */ public static int getLength(HeroNode head) &#123; if(head.next == null) &#123; //空链表 return 0; &#125; int length = 0; //定义一个辅助的变量, 这里我们没有统计头节点 HeroNode cur = head.next; while(cur != null) &#123; length++; cur = cur.next; //遍历 &#125; return length; &#125;&#125;//定义SingleLinkedList 管理我们的英雄class SingleLinkedList &#123; //先初始化一个头节点, 头节点不要动, 不存放具体的数据 private HeroNode head = new HeroNode(0, \"\", \"\"); //返回头节点 public HeroNode getHead() &#123; return head; &#125; //添加节点到单向链表 //思路，当不考虑编号顺序时 //1. 找到当前链表的最后节点 //2. 将最后这个节点的next 指向 新的节点 public void add(HeroNode heroNode) &#123; //因为head节点不能动，因此我们需要一个辅助遍历 temp HeroNode temp = head; //遍历链表，找到最后 while(true) &#123; //找到链表的最后 if(temp.next == null) &#123;// break; &#125; //如果没有找到最后, 将将temp后移 temp = temp.next; &#125; //当退出while循环时，temp就指向了链表的最后 //将最后这个节点的next 指向 新的节点 temp.next = heroNode; &#125; //第二种方式在添加英雄时，根据排名将英雄插入到指定位置 //(如果有这个排名，则添加失败，并给出提示) public void addByOrder(HeroNode heroNode) &#123; //因为头节点不能动，因此我们仍然通过一个辅助指针(变量)来帮助找到添加的位置 //因为单链表，因为我们找的temp 是位于 添加位置的前一个节点，否则插入不了 HeroNode temp = head; boolean flag = false; // flag标志添加的编号是否存在，默认为false while(true) &#123; if(temp.next == null) &#123;//说明temp已经在链表的最后 break; // &#125; if(temp.next.no &gt; heroNode.no) &#123; //位置找到，就在temp的后面插入 break; &#125; else if (temp.next.no == heroNode.no) &#123;//说明希望添加的heroNode的编号已然存在 flag = true; //说明编号存在 break; &#125; temp = temp.next; //后移，遍历当前链表 &#125; //判断flag 的值 if(flag) &#123; //不能添加，说明编号存在 System.out.printf(\"准备插入的英雄的编号 %d 已经存在了, 不能加入\\n\", heroNode.no); &#125; else &#123; //插入到链表中, temp的后面 heroNode.next = temp.next; temp.next = heroNode; &#125; &#125; //修改节点的信息, 根据no编号来修改，即no编号不能改. //说明 //1. 根据 newHeroNode 的 no 来修改即可 public void update(HeroNode newHeroNode) &#123; //判断是否空 if(head.next == null) &#123; System.out.println(\"链表为空~\"); return; &#125; //找到需要修改的节点, 根据no编号 //定义一个辅助变量 HeroNode temp = head.next; boolean flag = false; //表示是否找到该节点 while(true) &#123; if (temp == null) &#123; break; //已经遍历完链表 &#125; if(temp.no == newHeroNode.no) &#123; //找到 flag = true; break; &#125; temp = temp.next; &#125; //根据flag 判断是否找到要修改的节点 if(flag) &#123; temp.name = newHeroNode.name; temp.nickname = newHeroNode.nickname; &#125; else &#123; //没有找到 System.out.printf(\"没有找到 编号 %d 的节点，不能修改\\n\", newHeroNode.no); &#125; &#125; //删除节点 //思路 //1. head 不能动，因此我们需要一个temp辅助节点找到待删除节点的前一个节点 //2. 说明我们在比较时，是temp.next.no 和 需要删除的节点的no比较 public void del(int no) &#123; HeroNode temp = head; boolean flag = false; // 标志是否找到待删除节点的 while(true) &#123; if(temp.next == null) &#123; //已经到链表的最后 break; &#125; if(temp.next.no == no) &#123; //找到的待删除节点的前一个节点temp flag = true; break; &#125; temp = temp.next; //temp后移，遍历 &#125; //判断flag if(flag) &#123; //找到 //可以删除 temp.next = temp.next.next; &#125;else &#123; System.out.printf(\"要删除的 %d 节点不存在\\n\", no); &#125; &#125; //显示链表[遍历] public void list() &#123; //判断链表是否为空 if(head.next == null) &#123; System.out.println(\"链表为空\"); return; &#125; //因为头节点，不能动，因此我们需要一个辅助变量来遍历 HeroNode temp = head.next; while(true) &#123; //判断是否到链表最后 if(temp == null) &#123; break; &#125; //输出节点的信息 System.out.println(temp); //将temp后移， 一定小心 temp = temp.next; &#125; &#125;&#125;//定义HeroNode ， 每个HeroNode 对象就是一个节点class HeroNode &#123; public int no; public String name; public String nickname; public HeroNode next; //指向下一个节点 //构造器 public HeroNode(int no, String name, String nickname) &#123; this.no = no; this.name = name; this.nickname = nickname; &#125; //为了显示方法，我们重新toString @Override public String toString() &#123; return \"HeroNode [no=\" + no + \", name=\" + name + \", nickname=\" + nickname + \"]\"; &#125;&#125;▼双向链表：单向链表，查找的方向只能是一个方向，而双向链表可以向前或者向后查找。单向链表不能自我删除，需要靠辅助节点，而双向链表，则可以自我删除，所以前面我们单链表删除时节点，总是找到temp,temp是待删除节点的前一个节点package linkedlist;public class DoubleLinkedListDemo &#123; public static void main(String[] args) &#123; // 测试 System.out.println(\"双向链表的测试\"); // 先创建节点 HeroNode2 hero1 = new HeroNode2(1, \"宋江\", \"及时雨\"); HeroNode2 hero2 = new HeroNode2(2, \"卢俊义\", \"玉麒麟\"); HeroNode2 hero3 = new HeroNode2(3, \"吴用\", \"智多星\"); HeroNode2 hero4 = new HeroNode2(4, \"林冲\", \"豹子头\"); // 创建一个双向链表 DoubleLinkedList doubleLinkedList = new DoubleLinkedList(); doubleLinkedList.add(hero1); doubleLinkedList.add(hero2); doubleLinkedList.add(hero3); doubleLinkedList.add(hero4); doubleLinkedList.list(); // 修改 HeroNode2 newHeroNode = new HeroNode2(4, \"公孙胜\", \"入云龙\"); doubleLinkedList.update(newHeroNode); System.out.println(\"修改后的链表情况\"); doubleLinkedList.list(); // 删除 doubleLinkedList.del(3); System.out.println(\"删除后的链表情况~~\"); doubleLinkedList.list(); &#125;&#125;// 创建一个双向链表的类class DoubleLinkedList &#123; // 先初始化一个头节点, 头节点不要动, 不存放具体的数据 private HeroNode2 head = new HeroNode2(0, \"\", \"\"); // 返回头节点 public HeroNode2 getHead() &#123; return head; &#125; // 遍历双向链表的方法 // 显示链表[遍历] public void list() &#123; // 判断链表是否为空 if (head.next == null) &#123; System.out.println(\"链表为空\"); return; &#125; // 因为头节点，不能动，因此我们需要一个辅助变量来遍历 HeroNode2 temp = head.next; while (true) &#123; // 判断是否到链表最后 if (temp == null) &#123; break; &#125; // 输出节点的信息 System.out.println(temp); // 将temp后移， 一定小心 temp = temp.next; &#125; &#125; // 添加一个节点到双向链表的最后. public void add(HeroNode2 heroNode) &#123; // 因为head节点不能动，因此我们需要一个辅助遍历 temp HeroNode2 temp = head; // 遍历链表，找到最后 while (true) &#123; // 找到链表的最后 if (temp.next == null) &#123;// break; &#125; // 如果没有找到最后, 将将temp后移 temp = temp.next; &#125; // 当退出while循环时，temp就指向了链表的最后 // 形成一个双向链表 temp.next = heroNode; heroNode.pre = temp; &#125; // 修改一个节点的内容, 可以看到双向链表的节点内容修改和单向链表一样 // 只是 节点类型改成 HeroNode2 public void update(HeroNode2 newHeroNode) &#123; // 判断是否空 if (head.next == null) &#123; System.out.println(\"链表为空~\"); return; &#125; // 找到需要修改的节点, 根据no编号 // 定义一个辅助变量 HeroNode2 temp = head.next; boolean flag = false; // 表示是否找到该节点 while (true) &#123; if (temp == null) &#123; break; // 已经遍历完链表 &#125; if (temp.no == newHeroNode.no) &#123; // 找到 flag = true; break; &#125; temp = temp.next; &#125; // 根据flag 判断是否找到要修改的节点 if (flag) &#123; temp.name = newHeroNode.name; temp.nickname = newHeroNode.nickname; &#125; else &#123; // 没有找到 System.out.printf(\"没有找到 编号 %d 的节点，不能修改\\n\", newHeroNode.no); &#125; &#125; // 从双向链表中删除一个节点, // 说明 // 1 对于双向链表，我们可以直接找到要删除的这个节点 // 2 找到后，自我删除即可 public void del(int no) &#123; // 判断当前链表是否为空 if (head.next == null) &#123;// 空链表 System.out.println(\"链表为空，无法删除\"); return; &#125; HeroNode2 temp = head.next; // 辅助变量(指针) boolean flag = false; // 标志是否找到待删除节点的 while (true) &#123; if (temp == null) &#123; // 已经到链表的最后 break; &#125; if (temp.no == no) &#123; // 找到的待删除节点的前一个节点temp flag = true; break; &#125; temp = temp.next; // temp后移，遍历 &#125; // 判断flag if (flag) &#123; // 找到 // 可以删除 // temp.next = temp.next.next;[单向链表] temp.pre.next = temp.next; // 这里我们的代码有问题? // 如果是最后一个节点，就不需要执行下面这句话，否则出现空指针 if (temp.next != null) &#123; temp.next.pre = temp.pre; &#125; &#125; else &#123; System.out.printf(\"要删除的 %d 节点不存在\\n\", no); &#125; &#125;&#125;// 定义HeroNode2 ， 每个HeroNode 对象就是一个节点class HeroNode2 &#123; public int no; public String name; public String nickname; public HeroNode2 next; // 指向下一个节点, 默认为null public HeroNode2 pre; // 指向前一个节点, 默认为null // 构造器 public HeroNode2(int no, String name, String nickname) &#123; this.no = no; this.name = name; this.nickname = nickname; &#125; // 为了显示方法，我们重新toString @Override public String toString() &#123; return \"HeroNode [no=\" + no + \", name=\" + name + \", nickname=\" + nickname + \"]\"; &#125;&#125;▼循环链表：package linkedlist;public class Josepfu &#123; public static void main(String[] args) &#123; // 测试一把看看构建环形链表，和遍历是否ok CircleSingleLinkedList circleSingleLinkedList = new CircleSingleLinkedList(); circleSingleLinkedList.addBoy(125);// 加入5个小孩节点 circleSingleLinkedList.showBoy(); //测试一把小孩出圈是否正确 circleSingleLinkedList.countBoy(10, 20, 125); // 2-&gt;4-&gt;1-&gt;5-&gt;3 //String str = \"7*2*2-5+1-5+3-3\"; &#125;&#125;// 创建一个环形的单向链表class CircleSingleLinkedList &#123; // 创建一个first节点,当前没有编号 private Boy first = null; // 添加小孩节点，构建成一个环形的链表 public void addBoy(int nums) &#123; // nums 做一个数据校验 if (nums &lt; 1) &#123; System.out.println(\"nums的值不正确\"); return; &#125; Boy curBoy = null; // 辅助指针，帮助构建环形链表 // 使用for来创建我们的环形链表 for (int i = 1; i &lt;= nums; i++) &#123; // 根据编号，创建小孩节点 Boy boy = new Boy(i); // 如果是第一个小孩 if (i == 1) &#123; first = boy; first.setNext(first); // 构成环 curBoy = first; // 让curBoy指向第一个小孩 &#125; else &#123; curBoy.setNext(boy);// boy.setNext(first);// curBoy = boy; &#125; &#125; &#125; // 遍历当前的环形链表 public void showBoy() &#123; // 判断链表是否为空 if (first == null) &#123; System.out.println(\"没有任何小孩~~\"); return; &#125; // 因为first不能动，因此我们仍然使用一个辅助指针完成遍历 Boy curBoy = first; while (true) &#123; System.out.printf(\"小孩的编号 %d \\n\", curBoy.getNo()); if (curBoy.getNext() == first) &#123;// 说明已经遍历完毕 break; &#125; curBoy = curBoy.getNext(); // curBoy后移 &#125; &#125; // 根据用户的输入，计算出小孩出圈的顺序 /** * * @param startNo * 表示从第几个小孩开始数数 * @param countNum * 表示数几下 * @param nums * 表示最初有多少小孩在圈中 */ public void countBoy(int startNo, int countNum, int nums) &#123; // 先对数据进行校验 if (first == null || startNo &lt; 1 || startNo &gt; nums) &#123; System.out.println(\"参数输入有误， 请重新输入\"); return; &#125; // 创建要给辅助指针,帮助完成小孩出圈 Boy helper = first; // 需求创建一个辅助指针(变量) helper , 事先应该指向环形链表的最后这个节点 while (true) &#123; if (helper.getNext() == first) &#123; // 说明helper指向最后小孩节点 break; &#125; helper = helper.getNext(); &#125; //小孩报数前，先让 first 和 helper 移动 k - 1次 for(int j = 0; j &lt; startNo - 1; j++) &#123; first = first.getNext(); helper = helper.getNext(); &#125; //当小孩报数时，让first 和 helper 指针同时 的移动 m - 1 次, 然后出圈 //这里是一个循环操作，知道圈中只有一个节点 while(true) &#123; if(helper == first) &#123; //说明圈中只有一个节点 break; &#125; //让 first 和 helper 指针同时 的移动 countNum - 1 for(int j = 0; j &lt; countNum - 1; j++) &#123; first = first.getNext(); helper = helper.getNext(); &#125; //这时first指向的节点，就是要出圈的小孩节点 System.out.printf(\"小孩%d出圈\\n\", first.getNo()); //这时将first指向的小孩节点出圈 first = first.getNext(); helper.setNext(first); // &#125; System.out.printf(\"最后留在圈中的小孩编号%d \\n\", first.getNo()); &#125;&#125;// 创建一个Boy类，表示一个节点class Boy &#123; private int no;// 编号 private Boy next; // 指向下一个节点,默认null public Boy(int no) &#123; this.no = no; &#125; public int getNo() &#123; return no; &#125; public void setNo(int no) &#123; this.no = no; &#125; public Boy getNext() &#123; return next; &#125; public void setNext(Boy next) &#123; this.next = next; &#125;&#125;","categories":[],"tags":[{"name":"dataAlgorithm","slug":"dataAlgorithm","permalink":"https://kayleh.top/tags/dataAlgorithm/"}]},{"title":"栈Stack","slug":"栈Stack","date":"2020-05-11T07:30:11.000Z","updated":"2020-06-06T09:12:51.771Z","comments":true,"path":"2020/05/11/栈Stack/","link":"","permalink":"https://kayleh.top/2020/05/11/%E6%A0%88Stack/","excerpt":"栈(stack)1栈是一个先入后出(FILO-First In Last Out)的有序列表。","text":"栈(stack)1栈是一个先入后出(FILO-First In Last Out)的有序列表。 2栈(stack)是限制线性表中元素的插入和删除只能在线性表的同一端进行的一种特殊线性表。允许插入和删除的一端，为变化的一端，称为栈顶(Top)，另一端为固定的一端，称为栈底(Bottom)。 3.根据栈的定义可知，最先放入栈中元素在栈底，最后放入的元素在栈顶，而删除元素刚好相反，最后放入的元素最先删除，最先放入的元素最后删除 123456 ───────────────────────────────┐ (\\(\\ (\\(\\ (\\(\\ (\\(\\ (\\(\\ │ (&#x3D;&#39;.&#39;) &lt;─&gt; (&#x3D;&#39;.&#39;) (&#x3D;&#39;.&#39;) (&#x3D;&#39;.&#39;) (&#x3D;&#39;.&#39;)│O(_&quot;)&quot;) O(_&quot;)&quot;) O(_&quot;)&quot;) O(_&quot;)&quot;) O(_&quot;)&quot;)│ ───────────────────────────────┘ stack 和队列区别开 123456 ──────────────────────── (\\(\\ (\\(\\ (\\(\\ (\\(\\ (\\(\\ (&#x3D;&#39;.&#39;) ─&gt; (&#x3D;&#39;.&#39;) (&#x3D;&#39;.&#39;) (&#x3D;&#39;.&#39;) ─&gt; (&#x3D;&#39;.&#39;)O(_&quot;)&quot;) O(_&quot;)&quot;) O(_&quot;)&quot;) O(_&quot;)&quot;) O(_&quot;)&quot;) ──────────────────────── Queue 栈的结构12345678 ───────────────────────────────┐ (\\(\\ (\\(\\ (\\(\\ (\\(\\ │ (&#x3D;&#39;.&#39;) (&#x3D;&#39;.&#39;) (&#x3D;&#39;.&#39;) (&#x3D;&#39;.&#39;)│ O(_&quot;)&quot;) O(_&quot;)&quot;) O(_&quot;)&quot;) O(_&quot;)&quot;)│ ───────────────────────────────┘ ↑ ↑ Top栈顶 Bottom栈底初始化为-1 入栈12345678 ───────────────────────────────┐ (\\(\\ (\\(\\ (\\(\\ (\\(\\ │ (&#x3D;&#39;.&#39;) ─&gt; (&#x3D;&#39;.&#39;) (&#x3D;&#39;.&#39;) (&#x3D;&#39;.&#39;)│O(_&quot;)&quot;) O(_&quot;)&quot;) O(_&quot;)&quot;) O(_&quot;)&quot;)│ data ───────────────────────────────┘ push入栈 top++; stack[top]&#x3D;data 出栈123456789 ───────────────────────────────┐ (\\(\\ (\\(\\ (\\(\\ (\\(\\ │&lt;─ (&#x3D;&#39;.&#39;) (&#x3D;&#39;.&#39;) (&#x3D;&#39;.&#39;) (&#x3D;&#39;.&#39;)│ O(_&quot;)&quot;) O(_&quot;)&quot;) O(_&quot;)&quot;) O(_&quot;)&quot;)│ ───────────────────────────────┘ pop出栈 int value &#x3D; stack[top]; top--; return value;","categories":[],"tags":[{"name":"dataAlgorithm","slug":"dataAlgorithm","permalink":"https://kayleh.top/tags/dataAlgorithm/"}]},{"title":"SparseArray稀疏数组","slug":"SparseArray稀疏数组","date":"2020-05-07T13:28:41.000Z","updated":"2020-08-20T06:48:26.012Z","comments":true,"path":"2020/05/07/SparseArray稀疏数组/","link":"","permalink":"https://kayleh.top/2020/05/07/SparseArray%E7%A8%80%E7%96%8F%E6%95%B0%E7%BB%84/","excerpt":"SparseArray","text":"SparseArray 稀疏数组​ （稀疏数组） 定义当一个数组中大部分的值未被使用，只有少部分的值的空间使用，造成了内存的浪费，这个时候就可以用到稀疏数组，保存需要的数据，节约内存空间。当记录一个棋盘时： 记录棋盘的位置，只有两个内容，其他未被使用没有意义的值浪费了内存空间 使用稀疏数组代替二维数组，第0行表示稀疏数组的总行，总列和所需内容的个数。 实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105package com.kayleh.tmall.controller;/** * @Author: Wizard * @Date: 2020/5/7 9:16 */public class SparseArray &#123; public static void main(String[] args) &#123; //创建一个二维数组 //0:表示没有棋子 1表示黑子 2表示蓝子 int chessArr[][] = new int[11][10]; chessArr[1][2] = 1; chessArr[2][3] = 2; for(int[] row:chessArr)&#123; for(int data:row)&#123; System.out.printf(\"%d\\t\",data); &#125; System.out.println(); &#125; int[][] array = getSparseArray(chessArr); System.out.println(\"-------\"); for(int i = 0 ; i&lt; array.length;i++)&#123; System.out.printf(\"%d\\t%d\\t%d\\t\\n\",array[i][0],array[i][1],array[i][2]); &#125; System.out.println(\"--------\"); int[][] startArr = recovery(array); for(int[] row:startArr)&#123; for(int data:row)&#123; System.out.printf(\"%d\\t\",data); &#125; System.out.println(); &#125; &#125; /** * 将普通数组转换为稀疏数组 * @param chessArr * @return */ public static int[][] getSparseArray(int[][] chessArr)&#123; if(!checkIsRight(chessArr))&#123; return null; &#125; //1.拿到数组后 首先获取元素的个数,然后才能建立稀疏数组 int sum = 0; for(int[] arr:chessArr)&#123; for(int i:arr)&#123; if(i != 0)&#123; sum++; &#125; &#125; &#125; //2.建立稀疏数组 int[][] sparseArr = new int[sum+1][3]; sparseArr[0][0] = chessArr.length; //行 sparseArr[0][1] = chessArr[0].length;//列 sparseArr[0][2] = sum; //元素个数 //3.数组存放 int count = 0; for(int i = 0; i &lt;chessArr.length; i++ )&#123; for(int j = 0; j &lt;chessArr[i].length;j++ )&#123; if(chessArr[i][j] != 0)&#123; sparseArr[++count][0] = i;//行 sparseArr[count][1] = j;//列 sparseArr[count][2] = chessArr[i][j]; &#125; &#125; &#125; return sparseArr; &#125; /** * 将稀疏数组转回普通数组 * @param sparseArr * @return */ public static int[][] recovery(int[][] sparseArr)&#123; if(!checkIsRight(sparseArr))&#123; return null; &#125; //获取原数组的 行数和列数 并创建原数组 int arr[][] = new int[sparseArr[0][0]][sparseArr[0][1]]; for(int i = 1; i &lt; sparseArr.length;i++)&#123; arr[sparseArr[i][0]][sparseArr[i][1]] = sparseArr[i][2]; &#125; return arr; &#125; public static boolean checkIsRight(int[][] arr)&#123; if(arr == null || arr.length &lt;= 1 )&#123; return false; &#125; return true; &#125;&#125;","categories":[],"tags":[{"name":"dataAlgorithm","slug":"dataAlgorithm","permalink":"https://kayleh.top/tags/dataAlgorithm/"}]},{"title":"维护1","slug":"维护1","date":"2020-05-01T10:21:32.000Z","updated":"2020-08-19T11:27:33.110Z","comments":true,"path":"2020/05/01/维护1/","link":"","permalink":"https://kayleh.top/2020/05/01/%E7%BB%B4%E6%8A%A41/","excerpt":"","text":"1.添加评论功能 2.添加鼠标点击出现爱心事件","categories":[],"tags":[{"name":"maintain","slug":"maintain","permalink":"https://kayleh.top/tags/maintain/"}]},{"title":"JMM内存模型","slug":"Java-memory-model内存模型","date":"2020-04-30T01:40:45.000Z","updated":"2020-08-20T06:49:00.900Z","comments":true,"path":"2020/04/30/Java-memory-model内存模型/","link":"","permalink":"https://kayleh.top/2020/04/30/Java-memory-model%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B/","excerpt":"Java内存模型","text":"Java内存模型 ​ jmm规范，他规范了java虚拟机与计算机内存如何协调工作，他规定了一个线程如何及何时看到其他线程修改过的变量的值，以及在必须时，如何同步的访问共享变量。 jmm内存分配概念堆heap:优点:运行时数据区,动态分配内存大小,有gc; 缺点:因为要在运行时动态分配,所以存取速度慢,对象存储在堆上,静态类型的变量跟着类的定义一起存储在堆上. 栈stack:存取速度快,仅次于寄存器, 缺点: 数据大小与生存期必须是确定的,缺乏灵活性,栈中主要存放基本类型变量(比如,int,short,byte,char,double,float,boolean和对象句柄),jmm要求,调用栈和本地变量存放在线程栈上 当一个线程可以访问一个对象时,也可以访问对象的成员变量,如果有两个线程访问对象的成员变量,则每个线程都有对象的成员变量,则每个线程都有对象的成员变量的私有拷贝.","categories":[],"tags":[{"name":"jvm","slug":"jvm","permalink":"https://kayleh.top/tags/jvm/"}]},{"title":"面向对象","slug":"面向对象的特征","date":"2020-04-29T13:33:19.000Z","updated":"2020-07-25T05:43:39.315Z","comments":true,"path":"2020/04/29/面向对象的特征/","link":"","permalink":"https://kayleh.top/2020/04/29/%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E7%9A%84%E7%89%B9%E5%BE%81/","excerpt":"面向对象的特征有哪些方面封装最常见的是把属性私有化封装在一个类里面，只能通过方法去访问","text":"面向对象的特征有哪些方面封装最常见的是把属性私有化封装在一个类里面，只能通过方法去访问 继承extends可以复用代码， 继承是面向对象编程的一种强大的代码复用方式； 子类继承父类，从而继承了父类的方法和属性； Java只允许单继承，所有类最终的根类是Object； protected允许子类访问父类的字段和方法； protected关键字可以把字段和方法的访问权限控制在继承树内部，一个protected字段和方法可以被其子类，以及子类的子类所访问。 父类没有无参构造器时，子类任何class调用父类构造器时，必须调用super父类有的构造器。 如果父类没有默认的构造方法，子类就必须显式调用super()并给出参数以便让编译器定位到父类的一个合适的构造方法。即子类不会继承任何父类的构造方法。子类默认的构造方法是编译器自动生成的，不是继承的。 向上转型类型提升。 把一个子类类型安全地变为父类类型的赋值，被称为向上转型（upcasting）。 向上转型实际上是把一个子类型安全地变为更加抽象的父类型。 向下转型 和向上转型相反，如果把一个父类类型强制转型为子类类型，就是向下转型（downcasting）。 向下转型很可能会失败。 抽象 由于多态的存在，每个子类都可以覆写父类的方法 如果一个class定义了方法，但没有具体执行代码，这个方法就是抽象方法，抽象方法用abstract修饰。 因为无法执行抽象方法，因此这个类也必须申明为抽象类（abstract class）。 使用abstract修饰的类就是抽象类。我们无法实例化一个抽象类。 通过abstract定义的方法是抽象方法，它只有定义，没有实现。抽象方法定义了子类必须实现的接口规范； 定义了抽象方法的class必须被定义为抽象类，从抽象类继承的子类必须实现抽象方法； 如果不实现抽象方法，则该子类仍是一个抽象类； 面向抽象编程使得调用者只关心抽象方法的定义，不关心子类的具体实现。 多态 在继承关系中，子类如果定义了一个与父类方法签名完全相同的方法，被称为覆写（Override）。 多态具有一个非常强大的功能，就是允许添加更多类型的子类实现功能扩展，却不需要修改基于父类的代码。 子类可以覆写父类的方法（Override），覆写在子类中改变了父类方法的行为； Java的方法调用总是作用于运行期对象的实际类型，这种行为称为多态； final修饰符有多种作用： final修饰的方法可以阻止被覆写； final修饰的class可以阻止被继承； final修饰的field必须在创建对象时初始化，随后不可修改。","categories":[],"tags":[]},{"title":"动态数组","slug":"动态数组","date":"2020-04-26T01:02:37.000Z","updated":"2020-08-20T06:51:41.177Z","comments":true,"path":"2020/04/26/动态数组/","link":"","permalink":"https://kayleh.top/2020/04/26/%E5%8A%A8%E6%80%81%E6%95%B0%E7%BB%84/","excerpt":"数组(Array)","text":"数组(Array) 数组是一种顺序储存的线性表,所有元素的内存地址是连续.12int[] array = new int[]&#123;20, 30, 40&#125;//向内存申请了12个字节地址 在很多编程语言中，数组有个致命的缺点， 无法动态修改容量。 实际开发中我们希望数组的容量是动态变化的。 动态数组创建ArrayList类,创建size属性来管理数组中元素的个数,创建element属性来管理存取的数据. 可以对动态数组进行增删改查操作. 12345678910111213141516171819202122232425public class ArrayList&lt;E&gt; &#123; private int size; private E[] elements; // 元素的数量 int size(); // 是否为空 boolean isEmpty(); // 是否包含某个元素 boolean contains(E element); // 添加元素到最后面 void add(E element); // 返回index位置对应的元素 E get(int index); // 设置index位置的元素 E set(int index, E element); // 往index位置添加元素 void add(int index, E element); // 删除index位置对应的元素 E remove(int index); // 查看元素的位置 int indexOf(E element); // 清除所有元素 void clear(); &#125; 动态数组的实现构造方法如果构建的数组空间小于默认空间,则会以默认空间创建数组. 1234567891011121314151617181920212223242526272829303132333435public class ArrayList&lt;E&gt; &#123; /** * 元素的数量 */ private int size; /** * 所有元素 */ private E[] elements; /** * 数组的默认容量 */ private static final int DEFAULT_CAPACITY = 10; /** * 找不到元素返回-1 */ private static final int ELEMENT_NOT_FOUNT = -1; public ArrayList() &#123; // 默认容量 //elements = new int[DEFAULT_CAPACITY]; this(DEFAULT_CAPACITY); // 调用下面的构造器 &#125; public ArrayList(int capacity) &#123; // 设置默认容量为 10 capacity = (capacity &lt; DEFAULT_CAPACITY) ? DEFAULT_CAPACITY : capacity; // 因为泛型(所以传一个Object数组,然后通过强转) elements = (E[]) new Object[capacity]; &#125;&#125; 添加元素 数组添加元素分为在最后一个元素的后面添加新元素和将元素插入到某个位置（非最后面）两种情况。 第一种情况，这个新元素需要添加到的索引等于当前数组元素的个数，在ArrayList中size属性就是当前数组元素的个数，所以就是将新元素添加到数组的size位置上，然后size加1。 1234public void add(int index, E element) &#123; elements[index] = element; size++;&#125; 如果是第二种情况，只需要将插入位置后面的元素向后移动即可。 注意：需要从后向前移动元素，如果从前向后移动元素，那么会进行元素覆盖, 最后出错。 数组越界添加元素,还要注意传入的索引不能越界,即不能小于0,也不能大于size. 12345678910/** * 根据index插入元素时,判断index是否有效 * * @param index */private void rangeCheckForAdd(int index) &#123; if (index &lt; 0 || index &gt; size) &#123; indexOutOfBounds(index); &#125;&#125; 12345678/** * 封装数组越界异常 * * @param index */private void indexOutOfBounds(int index) &#123; throw new IndexOutOfBoundsException(\"Index:\" + index + \", Size:\" + size);&#125; 数组扩容动态扩容思路: 通过默认容量创建的数组,是在堆空间中随机生成的地址;如此一来再申请空间拼接到该数组后,这种方式不可能实现; 我们只能再创建一个大容量的数组,然后将之前数组中的元素移动到这个数组中;然后将引用指向新数组即可! 由于数组elements最大的容量只有10，所以当数组存满元素时，就需要对数组进行扩容。 因为数组是无法动态扩容的，所以需要创建一个新的数组，这个数组的容量要比之前数组的容量大。 然后在将原数组中的元素存放到新数组中，这样就实现了数组的扩容。 该方法确保默认容量为多少,为了验证是否超过给定的默认容量,然后进行判断是否要扩容;这里size+1为数组当前数量+1, 因为每次add都会增加一个容量。 123456789101112131415161718192021222324/** * 确保至少要有capacity个容量 * * @param capacity */private void ensureCapacity(int capacity) &#123; // 获取数组当前容量 int oldCapacity = elements.length; // 判断是否要扩容 if (oldCapacity &gt;= capacity) return; // 此时不扩容 // 这种方式是扩容1.5倍 int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1); E[] newElements = (E[]) new Object[newCapacity]; // 将原来数组中的元素移动到新数组中 for (int i = 0; i &lt; size; i++) &#123; newElements[i] = elements[i]; &#125; // 将数组引用指向新数组 elements = newElements;&#125; 实现add函数，需要在添加新元素之前，判断数组越界和扩容。 12345678910111213141516171819/** * 在index位置插入一个元素 * * @param index * @param element */public void add(int index, E element) &#123; // 在添加元素的时候,判断index是否有效 rangeCheckForAdd(index); ensureCapacity(size + 1); // 注意: 插入元素后,元素是从后开始往后挪 for (int i = size - 1; i &gt;= index; i--) &#123; elements[i + 1] = elements[i]; &#125; elements[index] = element; size++;&#125; 最终在最后一个元素的后面添加新元素，即添加元素到尾部的实现方式如下 12345678910/** * 添加元素到尾部 * * @param element */public void add(E element) &#123; // elements[size++] = element; // 传入数组数量(相当于在最后插入元素) add(size, element);&#125; 删除元素 删除元素，实际上就是移除指定位置的元素，并将后面的元素向前移动。 如下图，当删除索引为3的元素时，只需要将后面的元素向前移动，然后在去掉最后一个元素，size减1即可。 数组越界 删除元素时传入的索引不能越界, 即不能小于0, 也不能大于等于size所以我们在删除元素之前需要先进行索引检查。 123456789private void indexOutOfBounds(int index) &#123; throw new IndexOutOfBoundsException(\"Index:\" + index + \", Size:\" + size);&#125; private void rangeCheck(int index) &#123; if (index &lt; 0 || index &gt;= size) &#123; outOfBounds(index); &#125;&#125; 数组缩容 当数组中的元素删除后，数组剩余的空间可能会很大，这样就会造成内存的浪费。 所以当数组中元素删除后，我们需要对数组进行缩容。 实现方法类似于扩容，当数组中容量小于某个值时，创建新的数组，然后将原有数组中的元素存入新数组即可。 12345678910111213141516171819/** * 数组缩容 */public void trim() &#123; // 获取当前数组的容量 int capacity = elements.length; // 当size大于等于容量的一半, 或则容量已经小于默认容量(10)时, 直接返回 if (size &gt;= capacity &gt;&gt; 1 || capacity &lt; CAPACITY_DEFAULT) return; // 计算新的容量 = 原有容量的一半 int newCapacity = capacity &gt;&gt; 1; // 创建新数组 E[] newElements = (E[]) new Object[newCapacity]; // 将原数组元素存入新数组 for (int i = 0; i &lt; size; i++) &#123; newElements[i] = elements[i]; &#125; // 引用新数组 elements = newElements;&#125; 最终, remove方法实现如下 1234567891011121314151617181920212223242526272829/** * 删除index位置的元素 * * @param index * @return 被删除的元素 */public E remove(int index) &#123; rangeCheck(index); E delEle = elements[index]; // 当删除一个元素时,需要挪动后面元素的范围 for (int i = index + 1; i &lt;= size - 1; i++) &#123; elements[i - 1] = elements[i]; &#125; size--; // 同clear的细节,当从后往前以后时,最后一个的地址需要释放 elements[size] = null; // 判断数组是否需要缩容 trim(); return delEle;&#125;/** * 删除传入的元素 * @param element */public void remove(E element)&#123; remove(indexOf(element));&#125; 清空数组 清空数组时，需要将所有的元素置为null，只有这样才能真正的释放对象，然后size置为0。 123456789/** * 清除所有元素 */public void clear() &#123; for (int i = 0; i &lt; size; i++) &#123; elements[i] = null; &#125; size = 0;&#125; 修改元素 修改元素时，只需要将原有位置的元素替换掉即可，同样需要注意一下索引是否越界。 1234567891011121314/** * 设置index位置的元素 * * @param index * @param element * @return 原来的元素 */public E set(int index, E element) &#123; rangeCheck(index); E oldEle = elements[index]; elements[index] = element; return oldEle;&#125; 查询元素 查询元素，只需要将指定索引的元素返回，注意索引是否越界即可。 1234567891011/** * 获取index位置的元素 * * @param index * @return */public E get(int index) &#123; // 约束Index rangeCheck(index); return elements[index];&#125; 查看元素位置 可以通过循环, 查找元素在数组中的位置。 注意：假如数组中可以存储null，而null是不能调用equals方法的，所以需要对传入的元素进行判断，如果查找的元素是null，需要单独处理。 当元素存在时返回索引，否则返回变量ELEMENT_ON_FOUND的值。 12345678910111213141516171819202122/** * 查看元素的索引 * * @param element * @return */public int indexOf(E element) &#123; if (element == null) &#123; // 循环判断如果element为null,直接返回null的索引 for (int i = 0; i &lt; size; i++) &#123; if (elements[i] == null) return i; &#125; &#125; else &#123; for (int i = 0; i &lt; size; i++) &#123; // 因为element肯定不为null了,所以放在前面;避免空指针异常 if (element.equals(elements[i])) return i; &#125; &#125; return ELEMENT_NOT_FOUNT;&#125; 是否包含某元素 只需通过判断索引是否等于ELEMENT_ON_FOUND即可。 12345678910/** * 是否包含某个元素 * * @param element * @return */public boolean contains(E element) &#123; // 如果element元素可以找到 return indexOf(element) != ELEMENT_NOT_FOUNT;&#125; 元素的数量 size的值，即为元素的数量 12345678/** * 元素的数量 * * @return */public int size() &#123; return size;&#125; 数组是否为空 通过判断size的值是否为0即可 12345678/** * 是否为空 * * @return */public boolean inEmpty() &#123; return size == 0;&#125; 动态数组打印 可以重写toString方法, 来打印ArrayList中的元素。 123456789101112131415@Overridepublic String toString() &#123; // 打印格式: size=3, [10, 20, 30] // 使用StringBuilder 效率高一些 StringBuilder string = new StringBuilder(); string.append(\"size=\").append(size).append(\", [\"); for (int i = 0; i &lt; size; i++) &#123; string.append(elements[i]); if (i != size - 1) &#123; string.append(\", \"); &#125; &#125; string.append(\"]\"); return string.toString();&#125; 这样就实现了动态数组的基本操作。 ArrayList能否进一步优化？ 在ArrayList中，如果要删除索引0位置的元素，则需要将索引0之后的元素全部往前移一位。 如果要在索引0位置添加元素，也需要将索引0及之后的元素全部往后移一位。 在ArrayList中增加一个记录首元素位置的属性。 删除索引0位置的元素，我们只需要将first属性改为1。 -在索引0位置添加元素，则只需要将first属性改为0。 如果继续往前插入元素，则将插入的元素存放在索引8这个位置，并将first改为8。 当要获取索引8下一个元素时，对索引取模，则拿到索引0位置的元素。 如果插入元素，则可选择挪动前半段数据或后半段数据。 在索引2处插入元素99，可以选择将元素22，33左移，然后插入99即可。 扩容和缩容同样可以优化。 重点总结动态扩容思路通过默认容量创建的数组,是在堆空间中随机生成的地址;如此一来再申请空间拼接到该数组后,这种方式不可能实现;我们只能再创建一个大容量的数组,然后将之前数组中的元素移动到这个数组中;然后将引用指向新数组即可! 如何确保容量是否越界该方法确保默认容量为多少, 为了验证是否超过给定的默认容量,然后进行判断是否要扩容; 这里size+1为数组当前数量+1, 因为每次add都会增加一个容量。 1ensureCapacity(size + 1); 增加泛型使用泛型, 使动态数组可以添加任何类型的数据。 1elements = (E[]) new Object[capacity]; clear方法的过渡细节因为之前存储的都是int数据, 直接设置size=0时, 开辟的存储int类型的空间就不能被访问, 当add后, 就可以访问后面的空间, 所以此时的空间可以重复利用; 当使用泛型后, 动态数组中存储的都是对象类型, 实际存储的都是对象的地址, 每一个对象的地址又有一块空间引用着; 此时如果仍设置 size=0, 当clear后,开辟的存储空间中的地址没有被销毁, 地址仍被对象空间引用着; 这样以来存储对象的空间就不会被释放; 但是存储地址的数组可以重复利用; 所以要将地址数组都置为null, 然后size=0, 这样以来,引用该地址的对象空间也就释放了! remove、indexOf的细节remove最后一个地址也要情况, 同clear细节在indexOf方法中,不用==比较, 因为比较的是地址值,一般重写equals方法自己定义比较内容即可;null值处理: 当往数组传null的时候,indexOf的比较处理: 如果那null.equals来比较会出现空指针异常;","categories":[],"tags":[{"name":"dataAlgorithm","slug":"dataAlgorithm","permalink":"https://kayleh.top/tags/dataAlgorithm/"}]},{"title":"Spring、SpringMVC、Mybatis整合","slug":"Spring、SpringMVC、Mybatis整合","date":"2020-04-20T13:05:31.000Z","updated":"2020-08-20T06:47:16.106Z","comments":true,"path":"2020/04/20/Spring、SpringMVC、Mybatis整合/","link":"","permalink":"https://kayleh.top/2020/04/20/Spring%E3%80%81SpringMVC%E3%80%81Mybatis%E6%95%B4%E5%90%88/","excerpt":"SSM整合","text":"SSM整合 整合说明服务器开发分为三层,表现层、业务层、持久层表现层使用SpringMVC实现,业务程使用Spring实现,持久层使用Mybatis实现使用Spring框架来整合 SpringMVC和Mybatis框架这里使用xml配置文件+注解的方式进行搭建 最终目标最终实现通过前端页面对数据库进行查询和插入,实现用户的登录注册功能准备创建Maven工程 选择webapp 数据库准备1234567create database ssm;use ssm;create table account(id int primary key auto_increment,name varchar(20),money double); ####创建目录####导入依赖 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.kayleh&lt;/groupId&gt; &lt;artifactId&gt;SSM&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;war&lt;/packaging&gt; &lt;name&gt;SSM Maven Webapp&lt;/name&gt; &lt;!-- FIXME change it to the project's website --&gt; &lt;url&gt;http://www.example.com&lt;/url&gt; &lt;!--版本锁定--&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;maven.compiler.source&gt;1.7&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.7&lt;/maven.compiler.target&gt; &lt;spring.version&gt;5.0.2.RELEASE&lt;/spring.version&gt; &lt;slf4j.version&gt;1.6.6&lt;/slf4j.version&gt; &lt;log4j.version&gt;1.2.12&lt;/log4j.version&gt; &lt;mysql.version&gt;5.1.6&lt;/mysql.version&gt; &lt;mybatis.version&gt;3.4.5&lt;/mybatis.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.11&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- spring --&gt; &lt;dependency&gt; &lt;groupId&gt;org.aspectj&lt;/groupId&gt; &lt;artifactId&gt;aspectjweaver&lt;/artifactId&gt; &lt;version&gt;1.6.8&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-aop&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-web&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-test&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-tx&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-jdbc&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.12&lt;/version&gt; &lt;scope&gt;compile&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;$&#123;mysql.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;servlet-api&lt;/artifactId&gt; &lt;version&gt;2.5&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet.jsp&lt;/groupId&gt; &lt;artifactId&gt;jsp-api&lt;/artifactId&gt; &lt;version&gt;2.0&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;jstl&lt;/groupId&gt; &lt;artifactId&gt;jstl&lt;/artifactId&gt; &lt;version&gt;1.2&lt;/version&gt; &lt;/dependency&gt; &lt;!-- log start --&gt; &lt;dependency&gt; &lt;groupId&gt;log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j&lt;/artifactId&gt; &lt;version&gt;$&#123;log4j.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt; &lt;version&gt;$&#123;slf4j.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt; &lt;version&gt;$&#123;slf4j.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!-- log end --&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis&lt;/artifactId&gt; &lt;version&gt;$&#123;mybatis.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring&lt;/artifactId&gt; &lt;version&gt;1.3.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;c3p0&lt;/groupId&gt; &lt;artifactId&gt;c3p0&lt;/artifactId&gt; &lt;version&gt;0.9.1.2&lt;/version&gt; &lt;type&gt;jar&lt;/type&gt; &lt;scope&gt;compile&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;finalName&gt;SSM&lt;/finalName&gt; &lt;pluginManagement&gt;&lt;!-- lock down plugins versions to avoid using Maven defaults (may be moved to parent pom) --&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-clean-plugin&lt;/artifactId&gt; &lt;version&gt;3.1.0&lt;/version&gt; &lt;/plugin&gt; &lt;!-- see http://maven.apache.org/ref/current/maven-core/default-bindings.html#Plugin_bindings_for_war_packaging --&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-resources-plugin&lt;/artifactId&gt; &lt;version&gt;3.0.2&lt;/version&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;version&gt;3.8.0&lt;/version&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-surefire-plugin&lt;/artifactId&gt; &lt;version&gt;2.22.1&lt;/version&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-war-plugin&lt;/artifactId&gt; &lt;version&gt;3.2.2&lt;/version&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-install-plugin&lt;/artifactId&gt; &lt;version&gt;2.5.2&lt;/version&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-deploy-plugin&lt;/artifactId&gt; &lt;version&gt;2.8.2&lt;/version&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/pluginManagement&gt; &lt;/build&gt;&lt;/project&gt; 编写实体类1234567891011121314151617181920package com.kayleh.domain;import java.io.Serializable;/** * @Author: Wizard * @Date: 2020/4/21 9:06 * * 账户 */public class Account implements Serializable &#123; private Integer id; private String name; private Double money; public Integer getId() &#123; return id; &#125; ......... public void setMoney(Double money) &#123; this.money = money; &#125;&#125; dao接口123456789101112131415package com.kayleh.dao;import com.kayleh.domain.Account;import java.util.List;/** * @Author: Wizard * @Date: 2020/4/21 9:11 * &lt;p&gt; * 账户dao接口 */public interface AccountDao &#123; //查询所有账户 public List&lt;Account&gt; findAll(); //保存账户信息 public void saveAccount(Account account);&#125; 业务service层和实现123456789101112131415161718192021222324252627282930313233package com.kayleh.service;import com.kayleh.domain.Account;import java.util.List;/** * @Author: Wizard * @Date: 2020/4/21 9:16 */public interface AccountService &#123; //查询所有账户 public List&lt;Account&gt; findAll(); //保存账户信息 public void saveAccount(Account account);&#125;-----------------------------------------------------package com.kayleh.service.impl;import com.kayleh.domain.Account;import com.kayleh.service.AccountService;import org.springframework.stereotype.Service;import java.util.List;/** * @Author: Wizard * @Date: 2020/4/21 9:18 */@Service(\"accountService\")public class AccountServiceImpl implements AccountService &#123; public List&lt;Account&gt; findAll() &#123; System.out.println(\"业务层:查询所有账户...\"); return null; &#125; public void saveAccount(Account account) &#123; System.out.println(\"业务层:保存账户...\"); &#125;&#125; Spring整合在resource下创建Spring配置文件####命名空间 12345678910111213 xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:context=\"http://www.springframework.org/schema/context\" xmlns:aop=\"http://www.springframework.org/schema/aop\" xmlns:tx=\"http://www.springframework.org/schema/tx\" xsi:schemaLocation=\"http://www.springframework.org/schema/beanshttp://www.springframework.org/schema/beans/spring-beans.xsdhttp://www.springframework.org/schema/contexthttp://www.springframework.org/schema/context/spring-context.xsdhttp://www.springframework.org/schema/aophttp://www.springframework.org/schema/aop/spring-aop.xsdhttp://www.springframework.org/schema/txhttp://www.springframework.org/schema/tx/spring-tx.xsd\"&gt; ####注解扫描 12345&lt;!-- 开启注解的扫描,希望处理service和dao,controller不需要Spring框架去处理,controller注解由SpringMVC处理 --&gt; &lt;context:component-scan base-package=\"com.kayleh\"&gt; &lt;!-- 配置哪些注解不扫描 --&gt; &lt;context:exclude-filter type=\"annotation\" expression=\"org.springframework.stereotype.Controller\"/&gt; &lt;/context:component-scan&gt; ####测试 1234567891011121314151617181920package com.kayleh.test;import com.kayleh.service.AccountService;import org.junit.Test;import org.springframework.context.ApplicationContext;import org.springframework.context.support.ClassPathXmlApplicationContext;/** * @Author: Wizard * @Date: 2020/4/21 9:38 */public class TestSpring &#123; @Test public void run1()&#123; //加载配置文件 ApplicationContext ac = new ClassPathXmlApplicationContext(\"classpath:applicationContext.xml\"); //获取对象 AccountService as = (AccountService) ac.getBean(\"accountService\"); //调用方法 as.findAll(); &#125;&#125; 运行测试,成功调用accountService 搭建和测试SpringMVC的开发环境1.在web.xml中配置DispatcherServlet前端控制器 12345678910111213141516&lt;!-- 配置前端控制器：服务器启动必须加载,需要加载springmvc.xml配置文件 --&gt;&lt;servlet&gt;&lt;servlet-name&gt;dispatcherServlet&lt;/servlet-name&gt;&lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt;&lt;!-- 配置初始化参数,创建完DispatcherServlet对象,加载springmvc.xml配置文件 --&gt;&lt;init-param&gt;&lt;param-name&gt;contextConfigLocation&lt;/param-name&gt;&lt;param-value&gt;classpath:springmvc.xml&lt;/param-value&gt;&lt;/init-param&gt;&lt;!-- 服务器启动的时候,让DispatcherServlet对象创建 --&gt;&lt;load-on-startup&gt;1&lt;/load-on-startup&gt;&lt;/servlet&gt;&lt;servlet-mapping&gt;&lt;servlet-name&gt;dispatcherServlet&lt;/servlet-name&gt;&lt;url-pattern&gt;/&lt;/url-pattern&gt;&lt;/servlet-mapping&gt; 2.在web.xml中配置DispatcherServlet过滤器解决中文乱码 12345678910111213&lt;!-- 配置解决中文乱码的过滤器 --&gt;&lt;filter&gt;&lt;filter-name&gt;characterEncodingFilter&lt;/filter-name&gt;&lt;filter-class&gt;org.springframework.web.filter.CharacterEncodingFilter&lt;/filter-class&gt;&lt;init-param&gt;&lt;param-name&gt;encoding&lt;/param-name&gt;&lt;param-value&gt;UTF-8&lt;/param-value&gt;&lt;/init-param&gt;&lt;/filter&gt;&lt;filter-mapping&gt;&lt;filter-name&gt;characterEncodingFilter&lt;/filter-name&gt;&lt;url-pattern&gt;/*&lt;/url-pattern&gt;&lt;/filter-mapping&gt; 3.创建springmvc.xml的配置文件,编写配置文件 12345678910111213141516171819202122232425262728293031&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:mvc=\"http://www.springframework.org/schema/mvc\" xmlns:context=\"http://www.springframework.org/schema/context\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.springframework.org/schema/beanshttp://www.springframework.org/schema/beans/spring-beans.xsdhttp://www.springframework.org/schema/mvchttp://www.springframework.org/schema/mvc/spring-mvc.xsdhttp://www.springframework.org/schema/contexthttp://www.springframework.org/schema/context/spring-context.xsd\"&gt; &lt;!-- 开启注解扫描 --&gt; &lt;context:component-scan base-package=\"com.kayleh\"&gt; &lt;context:include-filter type=\"annotation\" expression=\"org.springframework.stereotype.Controller\"/&gt; &lt;/context:component-scan&gt; &lt;!--配置的视图解析器对象--&gt; &lt;bean id=\"internalResourceViewResolver\" class=\"org.springframework.web.servlet.view.InternalResourceViewResolver\"&gt; &lt;property name=\"prefix\" value=\"/WEB-INF/pages/\"/&gt; &lt;property name=\"suffix\" value=\".jsp\"/&gt; &lt;/bean&gt; &lt;!--过滤静态资源--&gt; &lt;mvc:resources mapping=\"/CSS/**\" location=\"/CSS/\"/&gt; &lt;mvc:resources mapping=\"/images/**\" location=\"/images/\"/&gt; &lt;mvc:resources mapping=\"/js/**\" location=\"/js/\"/&gt; &lt;!--开启SpringMVC的注解支持--&gt; &lt;mvc:annotation-driven/&gt;&lt;/beans&gt; 测试SpringMVC的框架搭建是否成功1.编写index.jsp和list.jsp编写,超链接 自带的index.jsp没有头部信息，需要重新创建1&lt;a href=\"account/findAll\"&gt;查询所有&lt;/a&gt; 2.创建AccountController类,编写方法,进行测试 12345678910111213141516package cn.kayleh.controller;import org.springframework.stereotype.Controller;import org.springframework.web.bind.annotation.RequestMapping;@Controller@RequestMapping(\"/account\")public class AccountController &#123;/*** 查询所有的数据* @return*/@RequestMapping(\"/findAll\")public String findAll() &#123;System.out.println(\"表现层：查询所有账户...\");return \"list\";&#125;&#125; ##Spring整合SpringMVC的框架 目的：在controller中能成功的调用service对象中的方法. 在项目启动的时候,就去加载applicationContext.xml的配置文件,在web.xml中配置ContextLoaderListener监听器（该监听器只能加载WEB-INF目录下的applicationContext.xml的配置文件）。123456789&lt;!-- 配置Spring的监听器 --&gt;&lt;listener&gt;&lt;listener-class&gt;org.springframework.web.context.ContextLoaderListener&lt;/listenerclass&gt;&lt;/listener&gt;&lt;!-- 配置加载类路径的配置文件 --&gt;&lt;context-param&gt;&lt;param-name&gt;contextConfigLocation&lt;/param-name&gt;&lt;param-value&gt;classpath:applicationContext.xml&lt;/param-value&gt;&lt;/context-param&gt; 在controller中注入service对象,调用service对象的方法进行测试123456789101112131415161718192021package cn.itcast.controller;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Controller;import org.springframework.web.bind.annotation.RequestMapping;import cn.kayleh.service.AccountService;@Controller@RequestMapping(\"/account\")public class AccountController &#123; @Autowired private AccountService accoutService;/*** 查询所有的数据* @return*/@RequestMapping(\"/findAll\")public String findAll() &#123;System.out.println(\"表现层：查询所有账户...\");accoutService.findAll();return \"list\"; &#125;&#125; Spring整合MyBatis框架搭建和测试MyBatis的环境在web项目中编写SqlMapConfig.xml的配置文件，编写核心配置文件,在后面整合进applicationContext.xml后可以删除1234567891011121314151617181920212223&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;!DOCTYPE configurationPUBLIC \"-//mybatis.org//DTD Config 3.0//EN\"\"http://mybatis.org/dtd/mybatis-3-config.dtd\"&gt;&lt;configuration&gt;&lt;environments default=\"mysql\"&gt;&lt;environment id=\"mysql\"&gt;&lt;transactionManager type=\"JDBC\"/&gt;&lt;dataSource type=\"POOLED\"&gt;&lt;property name=\"driver\" value=\"com.mysql.jdbc.Driver\"/&gt;&lt;property name=\"url\" value=\"jdbc:mysql:///ssm\"/&gt;&lt;property name=\"username\" value=\"root\"/&gt;&lt;property name=\"password\" value=\"admin\"/&gt;&lt;/dataSource&gt;&lt;/environment&gt;&lt;/environments&gt;&lt;!-- 使用的是注解 --&gt;&lt;mappers&gt;&lt;!-- &lt;mapper class=\"cn.kayleh.dao.AccountDao\"/&gt; --&gt;&lt;!-- 该包下所有的dao接口都可以使用 --&gt;&lt;package name=\"cn.kayleh.dao\"/&gt;&lt;/mappers&gt;&lt;/configuration&gt; #####在AccountDao接口的方法上添加注解，编写SQL语句 123456789101112131415161718192021222324252627package com.kayleh.dao;import com.kayleh.domain.Account;import org.apache.ibatis.annotations.Insert;import org.apache.ibatis.annotations.Select;import org.springframework.stereotype.Repository;import java.util.List;/** * @Author: Wizard * @Date: 2020/4/21 9:11 * &lt;p&gt; * 账户dao接口 */@Repositorypublic interface AccountDao &#123; //查询所有账户 @Select(\"select * from account\") public List&lt;Account&gt; findAll(); //保存账户信息 @Insert(\"insert into account(name,money) values (#&#123;name&#125;,#&#123;money&#125;)\") public void saveAccount(Account account);&#125; 编写测试的方法1234567891011121314151617181920package com.kayleh.test;import com.kayleh.service.AccountService;import org.junit.Test;import org.springframework.context.ApplicationContext;import org.springframework.context.support.ClassPathXmlApplicationContext;/** * @Author: Wizard * @Date: 2020/4/21 9:38 */public class TestSpring &#123; @Test public void run1()&#123; //加载配置文件 ApplicationContext ac = new ClassPathXmlApplicationContext(\"classpath:applicationContext.xml\"); //获取对象 AccountService as = (AccountService) ac.getBean(\"accountService\"); //调用方法 as.findAll(); &#125;&#125; Spring整合MyBatis框架#####目的：把SqlMapConfig.xml配置文件中的内容配置到applicationContext.xml配置文件中 1234567891011121314151617181920 &lt;!--Srping整合MyBatis框架--&gt; &lt;!--配置连接池--&gt; &lt;!--引入外部配置文件--&gt;&lt;!-- &lt;context:property-placeholder location=\"classpath:jdbc.properties\"/&gt;--&gt; &lt;bean id=\"ds\" class=\"com.mchange.v2.c3p0.ComboPooledDataSource\"&gt; &lt;property name=\"driverClass\" value=\"com.mysql.jdbc.Driver\"/&gt; &lt;property name=\"jdbcUrl\" value=\"jdbc:mysql:///ssm\"/&gt;&lt;!--省略了localhost:3306--&gt; &lt;property name=\"user\" value=\"root\"/&gt; &lt;property name=\"password\" value=\"admin\"/&gt; &lt;/bean&gt; &lt;!--配置SqlSessionFactory工厂--&gt; &lt;bean id=\"sqlSessionFactory\" class=\"org.mybatis.spring.SqlSessionFactoryBean\"&gt; &lt;property name=\"dataSource\" ref=\"ds\"/&gt; &lt;/bean&gt; &lt;!--配置AccountDao接口所在包--&gt; &lt;bean id=\"mapperScannerConfigurer\" class=\"org.mybatis.spring.mapper.MapperScannerConfigurer\"&gt; &lt;property name=\"basePackage\" value=\"com.kayleh.dao\" /&gt; &lt;/bean&gt; 在AccountDao接口中添加@Repository注解在service中注入dao对象，进行测试123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101package com.kayleh.dao;import com.kayleh.domain.Account;import org.apache.ibatis.annotations.Insert;import org.apache.ibatis.annotations.Select;import org.springframework.stereotype.Repository;import java.util.List;/** * @Author: Wizard * @Date: 2020/4/21 9:11 * &lt;p&gt; * 账户dao接口 */@Repositorypublic interface AccountDao &#123; //查询所有账户 @Select(\"select * from account\") public List&lt;Account&gt; findAll(); //保存账户信息 @Insert(\"insert into account(name,money) values (#&#123;name&#125;,#&#123;money&#125;)\") public void saveAccount(Account account);&#125;-------------------------------------------------------------package com.kayleh.service.impl;import com.kayleh.dao.AccountDao;import com.kayleh.domain.Account;import com.kayleh.service.AccountService;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Service;import java.util.List;/** * @Author: Wizard * @Date: 2020/4/21 9:18 */@Service(\"accountService\")public class AccountServiceImpl implements AccountService &#123; @Autowired private AccountDao accountDao; public List&lt;Account&gt; findAll() &#123; System.out.println(\"业务层:查询所有账户...\"); return accountDao.findAll(); &#125; public void saveAccount(Account account) &#123; System.out.println(\"业务层:保存账户...\"); accountDao.saveAccount(account); &#125;&#125;-------------------------------------------------------------package com.kayleh.controller;import com.kayleh.domain.Account;import com.kayleh.service.AccountService;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Controller;import org.springframework.ui.Model;import org.springframework.web.bind.annotation.RequestMapping;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;import javax.xml.ws.RequestWrapper;import java.io.IOException;import java.util.List;/** * @Author: Wizard * @Date: 2020/4/21 9:21 * &lt;p&gt; * 用户web层 */@Controller@RequestMapping(\"/account\")public class AccountController &#123; @Autowired private AccountService accountService; @RequestMapping(\"/findAll\") public String findAll(Model model) &#123; System.out.println(\"表现层:查询所有的账户...\"); List&lt;Account&gt; list = accountService.findAll(); model.addAttribute(\"list\", list); return \"list\"; &#125; 配置Spring的声明式事务管理1234567891011121314151617181920applicationContext.xml &lt;!-- 配置Spring框架声明式事务管理 --&gt; &lt;!-- 配置事务管理器 --&gt; &lt;bean id=\"transactionManager\" class=\"org.springframework.jdbc.datasource.DataSourceTransactionManager\"&gt; &lt;property name=\"dataSource\" ref=\"ds\"/&gt; &lt;/bean&gt; &lt;!-- 配置事务通知 --&gt; &lt;tx:advice id=\"txAdvice\" transaction-manager=\"transactionManager\"&gt; &lt;tx:attributes&gt; &lt;tx:method name=\"find*\" read-only=\"true\"/&gt; &lt;tx:method name=\"*\" isolation=\"DEFAULT\"/&gt; &lt;/tx:attributes&gt; &lt;/tx:advice&gt; &lt;!-- 配置AOP增强 --&gt; &lt;aop:config&gt; &lt;aop:advisor advice-ref=\"txAdvice\" pointcut=\"execution(* com.kayleh.service.impl.*ServiceImpl.*(..))\"/&gt; &lt;/aop:config&gt; 123456789101112131415/** * 保存 * * @param account * @return */ @RequestMapping(\"/save\") public void save(Account account, HttpServletRequest request, HttpServletResponse response) throws Exception &#123; System.out.println(\"表现层:查询所有的账户...\"); accountService.saveAccount(account); response.sendRedirect(request.getContextPath() + \"/account/findAll\"); return; &#125;","categories":[],"tags":[{"name":"frame","slug":"frame","permalink":"https://kayleh.top/tags/frame/"}]},{"title":"回文数","slug":"回文数","date":"2020-04-19T13:17:57.000Z","updated":"2020-06-06T10:15:54.188Z","comments":true,"path":"2020/04/19/回文数/","link":"","permalink":"https://kayleh.top/2020/04/19/%E5%9B%9E%E6%96%87%E6%95%B0/","excerpt":"什么是回文数？回文数指的是正序和倒序读都是一样的数，例如121从左到右，从右到左读都是121。任何一个自然数与它的倒序数相加，所得的和再与和的倒序数相加，……如此反复进行下去，经过有限次步骤后，最后必定能得到一个回文数。","text":"什么是回文数？回文数指的是正序和倒序读都是一样的数，例如121从左到右，从右到左读都是121。任何一个自然数与它的倒序数相加，所得的和再与和的倒序数相加，……如此反复进行下去，经过有限次步骤后，最后必定能得到一个回文数。 问题：判断一个数是否为回文数，是返回true，否侧抛出false。1234567891011121314151617181920212223242526272829303132@题目来源lettcode利用Java的StringBuilder通过把整数转换为字符串来实现↓import java.util.Scanner;/** * @Author: Wizard * @Date: 2020/4/12 13:14 */public class palindrome &#123; public static boolean ispalindrome(int i) &#123; String str = (new StringBuilder(i + \"\")).reverse().toString(); return (i + \"\").equals(str); &#125; public static void main(String[] args) &#123; while (true) &#123; System.out.println(\"输入需要判断的整数\"); Scanner scanner = new Scanner(System.in); int str1 = scanner.nextInt(); System.out.println(ispalindrome(str1)); &#125; &#125;&#125;/** * 输入需要判断的整数：1 * false * 输入需要判断的整数：12121 * true */ 123456789101112131415161718192021222324252627进阶：不改变整数为字符串通过取整和取余获取整数中的数字进行比较/** * @Author: Wizard * @Date: 2020/4/12 13:14 */public class palindrome &#123; public static boolean ispalindrome(int i) &#123; if(i&lt;0||(i%10==0&amp;&amp;i!=0)) return false; int number = 0; while(i&gt;number)&#123; number = number * 10 + i % 10; i /=10; &#125; return i == number || i==number/10; &#125; public static void main(String[] args) &#123; while (true) &#123; System.out.println(\"输入需要判断的整数\"); Scanner scanner = new Scanner(System.in); int str1 = scanner.nextInt(); System.out.println(ispalindrome(str1)); &#125; &#125;&#125; 微信公众号:每日学习干货↓&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;","categories":[],"tags":[{"name":"dataAlgorithm","slug":"dataAlgorithm","permalink":"https://kayleh.top/tags/dataAlgorithm/"}]},{"title":"【SpringMVC】-@ModelAttribute","slug":"【SpringMVC】-@ModelAttribute","date":"2020-04-19T13:04:07.000Z","updated":"2020-05-21T10:07:53.130Z","comments":true,"path":"2020/04/19/【SpringMVC】-@ModelAttribute/","link":"","permalink":"https://kayleh.top/2020/04/19/%E3%80%90SpringMVC%E3%80%91-@ModelAttribute/","excerpt":"@ModelAttribute？@ModelAttribute的原理比较复杂，需要对源码有一定的理解。它可以使被","text":"@ModelAttribute？@ModelAttribute的原理比较复杂，需要对源码有一定的理解。它可以使被 @ModelAttribute修饰的方法在控制器的处理方法之前调用。但如果@ModelAttribute标注在方法的入参前，它可以从隐含对象中获取隐含的模型数据中获取对象，再将请求参数绑定到对象中，再传入入参。 实际场景：Spring在进行数据库update全字段更新操作提交表单的时候，从页面获取的数据会封装成一个new的pojo对象，没有带的值为null；所以我们只能更新我们提交的数据。ModelAttribute暂时保存表单pojo对象，覆盖数据库保存的pojo对象的数据即可。 1234567891011121314151617181920ModelAttribute提前与目标方法运行/** * @author Kayleh */@Controllerpublic class ModelAttributeTest &#123; @RequestMapping(\"/update\") public String update()&#123; System.out.println(\"页面update的bean对象：\"+bean); &#125; @ModelAttribute public void modelAttribute()&#123; System.out.println(\"ModelAttribute调用了...\"); &#125;===========输出=========ModelAttribute调用了...页面update的bean对象：bean&#123;......&#125; 可以得出：ModelAttribute标注的方法总会在目标方法(update)前执行。ModelAttribute可以取出隐含对象的值1234567891011121314151617@ModelAttribute public void TestModelAttribute(Map&lt;String, Object&gt; map)&#123; POJO pojo = new POJO(\"kayleh\", 1104); map.put(\"value\",pojo); System.out.println(\"modelAttribute方法...); &#125;@RequestMapping(\"/updateBook\") public String updateBook(@RequestParam(value=\"author\")String author, Map&lt;String, Object&gt; model, HttpServletRequest request, @ModelAttribute(\"value\")POJO pojo )&#123; System.out.println(pojo); return \"ok\"; &#125; @ModelAttribute(“value”)这里如果指定的”value”,value就是从map取出参数的key.如果是@ModelAttribute,没有指定key,SpringMVC会默认使用返回值类型的首字母小写作为key.如pOJO. 微信公众号:每日学习干货↓&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;","categories":[],"tags":[{"name":"frame","slug":"frame","permalink":"https://kayleh.top/tags/frame/"}]},{"title":"Spring架构","slug":"Spring架构","date":"2020-04-19T12:40:54.000Z","updated":"2020-08-20T06:46:54.832Z","comments":true,"path":"2020/04/19/Spring架构/","link":"","permalink":"https://kayleh.top/2020/04/19/Spring%E6%9E%B6%E6%9E%84/","excerpt":"架构图","text":"架构图","categories":[],"tags":[{"name":"frame","slug":"frame","permalink":"https://kayleh.top/tags/frame/"}]},{"title":"并发:原理","slug":"并发：原理","date":"2020-04-19T03:32:02.990Z","updated":"2020-04-22T06:51:27.589Z","comments":true,"path":"2020/04/19/并发：原理/","link":"","permalink":"https://kayleh.top/2020/04/19/%E5%B9%B6%E5%8F%91%EF%BC%9A%E5%8E%9F%E7%90%86/","excerpt":"多线程为什么要创建线程池1如果系统要运行多个线程,大量反复的启动创建和回收线程会非常占用系统资源,导致性能下降.","text":"多线程为什么要创建线程池1如果系统要运行多个线程,大量反复的启动创建和回收线程会非常占用系统资源,导致性能下降. 创建线程池,可以:1.降低资源消耗2.提升响应速度3.提高 线程池原理1234提交一个任务到线程池中,线程池的处理流程如下:1.判断线程池里的核心线程是否都在执行任务,如果不是(核心线程空闲或者核心线程没有被创建)则创建一个新的工作线程来执行任务.如果核心线程都在执行任务,则进入下个流程.2.线程池判断工作队列是否已满,如果工作路径没有满,则新提交的任务储存在这个工作队列里.如果工作队列满了,则进入下个流程.3.判断线程池里的线程是否都处于工作状态,如果没有,则创建一个新的工作线程来执行任务.如果已经满了,则交给饱和策略来处理这个任务. 线程池的分类1234567public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler); ThreadPoolExecutor是线程池的真正实现,他通过构造方法的一系列参数，来构成不同配置的线程池。corePoolSize： 核心池的大小。 当有任务来之后，就会创建一个线程去执行任务，当线程池中的线程数目达到corePoolSize后，就会把到达的任务放到缓存队列当中maximumPoolSize： 线程池最大线程数，它表示在线程池中最多能创建多少个线程；keepAliveTime： 表示线程没有任务执行时最多保持多久时间会终止。unit： 参数keepAliveTime的时间单位，有7种取值，在TimeUnit类中有7种静态属性。workQueue：一个阻塞队列，提交的任务将会被放到这个队列里。threadFactory：线程工厂，用来创建线程，主要是为了给线程起名字，默认工厂的线程名字：pool-1-thread-3。handler：拒绝策略，当线程池里线程被耗尽，且队列也满了的时候会调用。 线程池的创建方法Java通过Executors（jdk1.5并发包）提供四种线程池，分别为： newCachedThreadPool创建一个可缓存线程池，如果线程池长度超过处理需要，可灵活回收空闲线程，若无可回收，则新建线程。案例演示: newFixedThreadPool 创建一个定长线程池，可控制线程最大并发数，超出的线程会在队列中等待。 newScheduledThreadPool 创建一个定长线程池，支持定时及周期性任务执行。 newSingleThreadExecutor 创建一个单线程化的线程池，它只会用唯一的工作线程来执行任务，保证所有任务按照指定顺序(FIFO, LIFO, 优先级)执行。 12345678910111213141516171819202122232425262728293031323334newCachedThreadPool创建一个可缓存线程池，如果线程池长度超过处理需要，可灵活回收空闲线程，若无可回收，则新建线程。package cn.qbz.thread;import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors;public class Test111907 &#123; public static void main(String[] args) &#123; ExecutorService executorService = Executors.newCachedThreadPool(); for (int i = 0; i &lt; 10; i++) &#123; final int temp = i; executorService.execute(new Runnable() &#123; @Override public void run() &#123; try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(Thread.currentThread().getName() + \" i=\" + temp); &#125; &#125;); &#125; &#125;&#125; public static ExecutorService newCachedThreadPool() &#123; return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;()); &#125; 12345678910111213141516171819202122232425262728293031323334newFixedThreadPool创建一个定长线程池，可控制线程最大并发数，超出的线程会在队列中等待。package cn.qbz.thread;import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors;public class Test111907 &#123; public static void main(String[] args) &#123; ExecutorService executorService = Executors.newFixedThreadPool(3); for (int i = 0; i &lt; 10; i++) &#123; final int temp = i; executorService.execute(new Runnable() &#123; @Override public void run() &#123; try &#123; Thread.sleep(100); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(Thread.currentThread().getName() + \" i=\" + temp); &#125; &#125;); &#125; &#125;&#125; public static ExecutorService newFixedThreadPool(int nThreads) &#123; return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;()); &#125; 1234567891011121314151617181920212223242526272829303132333435363738newScheduledThreadPool创建一个定长线程池，支持定时及周期性任务执行。package cn.qbz.thread;import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors;import java.util.concurrent.ScheduledExecutorService;import java.util.concurrent.TimeUnit;public class Test111907 &#123; public static void main(String[] args) &#123; final long begin = System.currentTimeMillis(); ExecutorService executorService = Executors.newScheduledThreadPool(3); for (int i = 0; i &lt; 10; i++) &#123; final int temp = i; final long time = begin; executorService.schedule(new Runnable() &#123; @Override public void run() &#123; try &#123; Thread.sleep(100); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(Thread.currentThread().getName() + \" i=\" + temp + \" time=\" + (System.currentTimeMillis() - time)); &#125; &#125;, 5, TimeUnit.SECONDS); &#125; &#125;&#125; public static ScheduledExecutorService newScheduledThreadPool(int corePoolSize) &#123; return new ScheduledThreadPoolExecutor(corePoolSize); &#125; public ScheduledThreadPoolExecutor(int corePoolSize) &#123; super(corePoolSize, Integer.MAX_VALUE, 0, TimeUnit.NANOSECONDS, new DelayedWorkQueue()); &#125; 12345678910111213141516171819202122newSingleThreadExecutor创建一个单线程化的线程池，它只会用唯一的工作线程来执行任务，保证所有任务按照指定顺序(FIFO, LIFO, 优先级)执行。public class Test111907 &#123; public static void main(String[] args) &#123; ExecutorService executorService = Executors.newSingleThreadExecutor(); for (int i = 0; i &lt; 10; i++) &#123; final int temp = i; executorService.execute(new Runnable() &#123; @Override public void run() &#123; try &#123; Thread.sleep(100); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(Thread.currentThread().getName() + \" i=\" + temp); &#125; &#125;); &#125; &#125;&#125; 微信公众号:每日学习干货","categories":[],"tags":[]},{"title":"unix的常用指令","slug":"unix","date":"2020-04-19T03:24:46.854Z","updated":"2020-04-19T04:28:07.834Z","comments":true,"path":"2020/04/19/unix/","link":"","permalink":"https://kayleh.top/2020/04/19/unix/","excerpt":"unix的常用指令","text":"unix的常用指令 1234567891011121314ls 显示指定目录下的文件目录清单相当于dos下的dir命令。pwd 显示当前目录。mkdir 在当前目录下创建目录。rm 删除文件或目录。cp 复制文件。mv 移动文件。cd 切换工作目录。ps 查看进程。ftp 传送文件。telnet 远程登录命令。ping 用来测试本机与目标主机是否联通。env 查看当前系统中的环境变量。more 分屏显示指定文件的内容。echo在终端上显示你要显示的内容，向C语言中的printf函数。 微信公众号:每日学习干货","categories":[],"tags":[]},{"title":"Rest架构风格","slug":"Rest架构/Rest架构","date":"2020-04-18T08:26:55.693Z","updated":"2020-04-18T08:35:41.496Z","comments":true,"path":"2020/04/18/Rest架构/Rest架构/","link":"","permalink":"https://kayleh.top/2020/04/18/Rest%E6%9E%B6%E6%9E%84/Rest%E6%9E%B6%E6%9E%84/","excerpt":"Rest是什么?12REST(Representational State Transfe),是一种软件架构风格，它结构清晰、符合标准、易于理解、扩展方便，并且规范了URI的风格；规范了HTTP请求动作的使用，具有对应的语义。Spring支持并推荐使用这种风格的URL地址。他可以处理除POST或GET的其他请求.rest可以把普通的请求转化(如:GET.POST)为规定形式的请求(DELETE等等),使URL请求地址状态化.","text":"Rest是什么?12REST(Representational State Transfe),是一种软件架构风格，它结构清晰、符合标准、易于理解、扩展方便，并且规范了URI的风格；规范了HTTP请求动作的使用，具有对应的语义。Spring支持并推荐使用这种风格的URL地址。他可以处理除POST或GET的其他请求.rest可以把普通的请求转化(如:GET.POST)为规定形式的请求(DELETE等等),使URL请求地址状态化. Rest实现配置web.xml文件,添加一个Filter过滤器1234567891011121314151617&lt;filter&gt; &lt;!--HiddenHttpMethodFilter继承HttpServletRequest类--&gt; &lt;filter-name&gt;HiddenHttpMethodFilter&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.web.filter.HiddenHttpMethodFilter&lt;/filter-class&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;HiddenHttpMethodFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;/filter-mapping&gt; &lt;!--要想获取其他类型的请求,要先创建一个form表单--&gt;&lt;form action=\"pojo/1\" method=\"post\"&gt; &lt;!--添加一个_method参数,它的值就是请求的类型--&gt; &lt;input name=\"_method\" value=\"delete\"&gt; &lt;input type=\"submit\" value=\"删除请求\"&gt; &lt;/form&gt; 注意≥8.0版本的Tomcat服务器Filter会拦截JSP页面,这种情况需要在index.jsp页面加上这个约定.isErrorPage=”true”12&lt;%@ page language=\"java\" contentType=\"text/html; charset=UTF-8\" pageEncoding=\"UTF-8\"% isErrorPage=\"true\"&gt; 没有HiddenHttpMethodFilter的提示话,需要绑定源码jar包.微信公众号:每日学习干货","categories":[],"tags":[]},{"title":"SpringMVC环境搭建","slug":"SpringMVC环境搭建","date":"2020-04-17T11:59:30.293Z","updated":"2020-08-20T06:32:26.221Z","comments":true,"path":"2020/04/17/SpringMVC环境搭建/","link":"","permalink":"https://kayleh.top/2020/04/17/SpringMVC%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/","excerpt":"SpringMVC","text":"SpringMVC 12345Spring MVC是Spring Framework的一部分，是基于Java实现MVC的轻量级Web框架，实现MVC模块，简化了Web开发。MVC提倡每一层只写自己的东西，不写其他任何代码。为了解耦，为了维护方便和分工合作。SpringMVC为展现层提供的基于MVC设计理念的优秀Web框架，是目前最主流的框架之一。 环境搭建1.导包(Maven工程忽略) 需要导入log包，spring核心包，SpringMVC包 1234567891.junit-x.x.x.jar 2.spring-webmvc-x.x.x.RELEASE.jar3.spring-aop-x.x.x.RELEASE.jar4.spring-beans-x.x.x.RELEASE.jar5.spring-context-x.x.x.RELEASE.jar6.spring-core-x.x.x.RELEASE.jar7.spring-expression-x.x.x.RELEASE.jar8.spring-web-x.x.x.RELEASE.jar9.commons-log-.x.x.x.RELEASE.jar 写配置1234567891011121314151617181920212223242526272829303132333435363738394041/** * web.xml */&lt;servlet&gt; &lt;servlet-name&gt;springDispatcherServlet&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;init-param&gt; &lt;!-- contextConfigLocation：指定SpringMVC配置文件位置 --&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:springmvc.xml&lt;/param-value&gt; &lt;/init-param&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;springDispatcherServlet&lt;/servlet-name&gt; &lt;url-pattern&gt;/&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; =========================================================== /** * springmvc.xml */ &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:context=\"http://www.springframework.org/schema/context\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-4.0.xsd\"&gt; &lt;!-- 这里是扫描所有组件 --&gt; &lt;context:component-scan base-package=\"com.wizard\"&gt;&lt;/context:component-scan&gt; &lt;!-- 配置一个视图解析器 作用是拼接页面的地址，方便调用--&gt; &lt;bean class=\"org.springframework.web.servlet.view.InternalResourceViewResolver\"&gt; &lt;!--前缀--&gt; &lt;property name=\"prefix\" value=\"/WEB-INF/page/\"&gt;&lt;/property&gt; &lt;!--后缀--&gt; &lt;property name=\"suffix\" value=\".jsp\"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;/beans&gt; 12345678910111213141516/**view层*/&lt;%@ page language=\"java\" contentType=\"text/html; charset=UTF-8\" pageEncoding=\"UTF-8\"%&gt;&lt;!DOCTYPE html PUBLIC \"-//W3C//DTD HTML 4.01 Transitional//EN\" \"http://www.w3.org/TR/html4/loose.dtd\"&gt;&lt;html&gt;&lt;head&gt;&lt;meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\"&gt;&lt;title&gt;Insert title here&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;h1&gt;来了!&lt;/h1&gt;&lt;/body&gt;&lt;/html&gt; 123456789101112131415161718控制器层/** * @author Kayleh * @Controller:标识哪个组件是控制器 *@RequestMapping * 告诉SpringMVC，这个方法用来处理什么请求; */@Controllerpublic class firstController &#123;//这是一次转发操作 @RequestMapping(\"/hello\") public String firstRequest()&#123; System.out.println(\"收到请求\"); return \"success\"; &#125;&#125; 12345678910111213index.jsp&lt;%@ page language=\"java\" contentType=\"text/html; charset=UTF-8\" pageEncoding=\"UTF-8\"%&gt;&lt;!DOCTYPE html PUBLIC \"-//W3C//DTD HTML 4.01 Transitional//EN\" \"http://www.w3.org/TR/html4/loose.dtd\"&gt;&lt;html&gt;&lt;head&gt;&lt;meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\"&gt;&lt;title&gt;Insert title here&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;a href=\"hello\"&gt;Hello bug&lt;/a&gt;&lt;/body&gt;&lt;/html&gt; 运行结果1Hello bug 其他细节细节：@RequestMapping注解不仅可以写在方法前,还可以写在类前,如果写在类前,意思为当前类所有的方法的请求地址指定一个基准路径,访问firstRequest方法的路径为/类前的注解/方法的注解(/hello). @RequestMapping注解的参数(“/hello”)的/可以不写,但习惯为了方便维护应该写上. 控制器处理的请求 firstController 是请求转发操作,Tomcat访问地址栏不变 如果前端控制器没有指定配置文件位置,Spring也会在/WEB-INF/xxx-servlet.xml路径下查找文件.xxx为web.xml配置的前端控制器 详细流程 1.客户端点击链接会发送http://localhost:8080/springmvc/hello请求 2.来到Tomcat服务器 3.springMVC的前端控制器收到所有请求 4.看请求地址和@RequestMapping标注的哪个匹配,来找到使用什么类的什么方法 5.前端控制器找到了目标处理器类和目标方法,直接利用反射执行目标方法 6.方法执行完成之后会有一个返回值;SpringMVC认为这个返回值就是要去的页面 7.拿到方法返回值后,用视图解析器进行拼串得到完整的页面地址 8.拿到页面地址,前端控制器转发到页面 其他问题?1为什么web.xml中配置的拦截为 1234&lt;servlet-mapping&gt; &lt;servlet-name&gt;springDispatcherServlet&lt;/servlet-name&gt; &lt;url-pattern&gt;/&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; 为什么没有拦截index.jsp?? 因为Tomcat的底层本来就能拦截jsp页面,配置的”/“的子类web.xml相当于覆盖了Webapp的父类web.xml中的DefaultServlet,DefaultServlet的作用是处理静态资源,覆盖了DefaultServlet,也就拦截了除jsp和servlet外的静态资源,而JspServlet的配置并没有覆盖. 而”/*”的作用是拦截所有请求,包括jsp页面.","categories":[{"name":"SpringMVC","slug":"SpringMVC","permalink":"https://kayleh.top/categories/SpringMVC/"}],"tags":[{"name":"frame","slug":"frame","permalink":"https://kayleh.top/tags/frame/"}]}],"categories":[{"name":"分布式","slug":"分布式","permalink":"https://kayleh.top/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"},{"name":"设计模式","slug":"设计模式","permalink":"https://kayleh.top/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"SpringMVC","slug":"SpringMVC","permalink":"https://kayleh.top/categories/SpringMVC/"}],"tags":[{"name":"maintain","slug":"maintain","permalink":"https://kayleh.top/tags/maintain/"},{"name":"DistributedMicroservices","slug":"DistributedMicroservices","permalink":"https://kayleh.top/tags/DistributedMicroservices/"},{"name":"sql","slug":"sql","permalink":"https://kayleh.top/tags/sql/"},{"name":"network","slug":"network","permalink":"https://kayleh.top/tags/network/"},{"name":"Interview","slug":"Interview","permalink":"https://kayleh.top/tags/Interview/"},{"name":"about","slug":"about","permalink":"https://kayleh.top/tags/about/"},{"name":"Linux","slug":"Linux","permalink":"https://kayleh.top/tags/Linux/"},{"name":"C","slug":"C","permalink":"https://kayleh.top/tags/C/"},{"name":"Operating Systems","slug":"Operating-Systems","permalink":"https://kayleh.top/tags/Operating-Systems/"},{"name":"dataAlgorithm","slug":"dataAlgorithm","permalink":"https://kayleh.top/tags/dataAlgorithm/"},{"name":"Concurrency","slug":"Concurrency","permalink":"https://kayleh.top/tags/Concurrency/"},{"name":"DesignPatterns","slug":"DesignPatterns","permalink":"https://kayleh.top/tags/DesignPatterns/"},{"name":"resume","slug":"resume","permalink":"https://kayleh.top/tags/resume/"},{"name":"safe","slug":"safe","permalink":"https://kayleh.top/tags/safe/"},{"name":"frame","slug":"frame","permalink":"https://kayleh.top/tags/frame/"},{"name":"jvm","slug":"jvm","permalink":"https://kayleh.top/tags/jvm/"}]}